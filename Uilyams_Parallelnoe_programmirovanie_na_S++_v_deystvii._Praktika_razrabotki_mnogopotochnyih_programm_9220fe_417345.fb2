<?xml version="1.0" encoding="UTF-8"?>
<FictionBook xmlns="http://www.gribuser.ru/xml/fictionbook/2.0" xmlns:l="http://www.w3.org/1999/xlink">
  <stylesheet type="text/css">
                                                 section section title { page-break-before: auto }
  cite p { font-style: normal }
  subtitle { font-style: normal }
  p &gt; code { font-size: 100% }
  cite &gt; p &gt; code { font-size: 100% }
  image + p { page-break-before: avoid; margin-bottom: 1em; }
 </stylesheet>
<description>
  <title-info>
    <genre>comp_db</genre>
    <author>
      <first-name>Энтони</first-name>
      <last-name>Уильямс</last-name>
    <home-page>https://coollib.net/a/173065</home-page>
</author>
<book-title>Параллельное программирование на С++ в действии. Практика разработки многопоточных программ</book-title>
    <annotation>
      <p>В наши дни компьютеры с несколькими многоядерными процессорами стали нормой. Стандарт С++11 языка С++ предоставляет развитую поддержку многопоточности в приложениях. Поэтому, чтобы сохранять конкурентоспособность, вы должны овладеть принципами и приемами их разработки, а также новыми средствами языка, относящимися к параллелизму.</p>
      <p>Книга «Параллельное программирование на С++ в действии» не предполагает предварительных знаний в этой области. Вдумчиво читая ее, вы научитесь писать надежные и элегантные многопоточные программы на С++11. Вы узнаете о том, что такое потоковая модель памяти, и о том, какие средства поддержки многопоточности, в том числе запуска и синхронизации потоков, имеются в стандартной библиотеке. Попутно вы познакомитесь с различными нетривиальными проблемами программирования в условиях параллелизма.</p>
    </annotation>
    <date>2012</date>
    <coverpage>
      <image l:href="#cover.jpg"/>
    </coverpage>
    <lang>ru</lang>
    <src-lang>en</src-lang>
    <translator>
      <first-name>А.</first-name>
      <middle-name>А.</middle-name>
      <last-name>Слинкин</last-name>
    </translator>
  </title-info>
  <src-title-info>
    <genre>comp_programming</genre>
    <author>
      <first-name>Anthony</first-name>
      <last-name>Williams</last-name>
    </author>
    <book-title>C++ Concurrency in Action. Practical Multithreading</book-title>
    <date>2012</date>
    <lang>en</lang>
  </src-title-info>
  <document-info>
    <author>
      <nickname>rusec</nickname>
      <email>lib_at_rus.ec</email>
    </author>
    <program-used>OOoFBTools-2.9 (ExportToFB21), FictionBook Editor Release 2.6.6</program-used>
    <date value="2018-05-22">22/05/2018</date>
    <id>OOoFBTools-2017-9-29-13-56-56-1227</id>
    <version>1.0</version>
    <history>
      <p>1.0 Создание</p>
    </history>
  </document-info>
  <publish-info>
    <book-name>Параллельное программирование на С++ в действии. Практика разработки многопоточных программ</book-name>
    <publisher>ДМК Пресс</publisher>
    <city>Москва</city>
    <year>2012</year>
    <isbn>978-5-94074-448-1</isbn>
  </publish-info>
</description>
<body>
    <title>
      <p>Энтони Уильямс</p>
      <p>Параллельное программирование на С++ в действии</p>
      <p>Практика разработки многопоточных программ</p>
    </title>
    <epigraph>
      <p>Ким, Хью и Ирен.</p>
    </epigraph>
    <section>
      <title>
        <p>Предисловие</p>
      </title>
      <p>С идеей многопоточного программирования я столкнулся на своей первой работе после окончания колледжа. Мы занимались приложением, которое должно было помещать входные записи в базу данных. Данных было много, но все они были независимы и требовали значительной предварительной обработки. Чтобы задействовать всю мощь нашего десятипроцессорного компьютера UltraSPARC, мы организовали несколько потоков, каждый из которых обрабатывал свою порцию входных данных. Код был написан на языке С++, с использованием потоков POSIX. Ошибок мы наделали кучу — многопоточность для всех была внове — но до конца все-таки добрались. Именно во время работы над этим проектом я впервые услыхал о комитете по стандартизации С++ и о недавно опубликованном стандарте языка С++.</p>
      <p>С тех мой интерес к многопоточному программированию и параллелизму не затухает. Там, где другим видятся трудности и источник разнообразных проблем, я нахожу мощный инструмент, который позволяет программе использовать всё наличное оборудование и в результате работать быстрее. Позднее я научился применять эти идеи и при наличии всего одного процессора или ядра, чтобы улучшить быстроту реакции и повысить производительность, — благодаря тому, что одновременная работа нескольких потоков дает программе возможность не простаивать во время таких длительных операций, как ввод/вывод. Я также узнал, как это устроено на уровне ОС и как в процессорах Intel реализовано контекстное переключение задач.</p>
      <p>Тем временем интерес к С++ свел меня с членами Ассоциации пользователей С и С++ (ACCU), а затем с членами комиссии по стандартизации С++ при Институте стандартов Великобритании (BSI) и разработчиками библиотек Boost. Я с интересом наблюдал за началом разработки библиотеки многопоточности Boost, а когда автор забросил проект, я воспользовался шансом перехватить инициативу. С тех пор разработка и сопровождение библиотеки Boost Thread Library лежит в основном на мне.</p>
      <p>По мере того как в работе комитета по стандартизации С++ наметился сдвиг от исправления дефектов в существующем стандарте в сторону выработки предложений для нового стандарта (получившего условное название С++0х в надежде, что его удастся завершить до 2009 года, и официально названного С++11, так как он наконец был опубликован в 2011 году), я стал принимать более активное участие в деятельности BSI и даже вносить собственные предложения. Когда стало ясно, что многопоточность стоит на повестке дня, я по-настоящему встрепенулся — многие вошедшие в стандарт предложения по многопоточности и параллелизму написаны как мной самим, так и в соавторстве с коллегами. Я считаю большой удачей, что таким образом удалось совместить две основных сферы моих интересов в области программирования — язык С++ и многопоточность.</p>
      <p>В этой книге, опирающейся на весь мой опыт работы с С++ и многопоточностью, я ставил целью научить других программистов, как безопасно и эффективно пользоваться библиотекой С++11 Thread Library. Надеюсь, что мне удастся заразить читателей своим энтузиазмом.</p>
    </section>
    <section>
      <title>
        <p>Благодарности</p>
      </title>
      <p>Прежде всего, хочу сказать огромное спасибо своей супруге, Ким, за любовь и поддержку, которую она выказывала на протяжении работы над книгой, отнимавшей изрядную долю моего свободного времени за последние четыре года. Без ее терпения, ободрения и понимания я бы не справился.</p>
      <p>Далее я хочу поблагодарить коллектив издательства Manning, благодаря которому эта книга появилась на свет: Марджана Баджи (Marjan Васе), главного редактора; Майкла Стивенса (Michael Stephens), его заместителя; Синтию Кейн (Cynthia Kane), моего редактора-консультанта; Карен Тегтмейер (Karen Tegtmeyer), выпускающего редактора; Линду Ректенвальд (Linda Recktenwald), редактора; Кати Теннант (корректора) и Мэри Пирджис, начальника производства. Без их стараний вы не читали бы сейчас эту книгу. Я хочу также поблагодарить других членов комитета по стандартизации С++, которые подавали на рассмотрение материалы, относящиеся к многопоточности: Андрея Александреску (Andrei Alexandrescu), Пита Беккера (Pete Becker), Боба Блэйнера (Bob Blainer), Ханса Бема (Hans Boehm), Бимана Доуса (Beman Dawes), Лоуренса Кроула (Lawrence Crowl), Петера Димова (Peter Dimov), Джеффа Гарланда (Jeff Garland), Кевлина Хэнни (Kevlin Henney), Ховарда Хиннанта (Howard Hinnant), Бена Хатчингса (Ben Hutchings), Йана Кристоферсона (Jan Kristofferson), Дуга Ли (Doug Lea), Пола Маккинни (Paul МсKenney), Ника Макларена (Nick McLaren), Кларка Нельсона (Clark Nelson), Билла Пью (Bill Pugh), Рауля Силвера (Raul Silvera), Герба Саттера (Herb Sutter), Детлефа Вольмана (Detlef Vollmann) и Майкла Вонга (Michael Wong), а также всех тех, кто рецензировал материалы, принимал участие в их обсуждении на заседаниях комитета и иными способами содействовал оформлению поддержки многопоточности и параллелизма в С++11.</p>
      <p>Наконец, хочу выразить благодарность людям, чьи предложения позволили заметно улучшить книгу: д-ру Джейми Оллсопу (Jamie Allsop), Петеру Димову, Ховарду Хиннанту, Рику Моллою (Rick Molloy), Джонатану Уэйкли (Jonathan Wakely) и д-ру Расселу Уиндеру (Russel Winder). Отдельное спасибо Расселу за подробные рецензии и Джонатану, который в качестве технического редактора, тщательно проверил окончательный текст на предмет наличия вопиющих ошибок. (Все оставшиеся ошибки — целиком моя вина.) И напоследок выражаю признательность группе рецензентов: Райану Стивенсу (Ryan Stephens), Нилу Хорлоку (Neil Horlock), Джону Тейлору младшему (John Taylor Jr.), Эзре Дживану (Ezra Jivan), Джошуа Хейеру (Joshua Heyer), Киту С. Киму (Keith S. Kim), Мишель Галли (Michele Galli) Майку Тянь-Чжань Чжану (Mike Tian-Jian Jiang), Дэвиду Стронгу (David Strong), Роджеру Орру (Roger Orr), Вагнеру Рику (Wagner Rick), Майку Буксасу (Mike Buksas) и Бас Воде (Bas Vodde). Также спасибо всем читателям предварительного издания, которые нашли время указать на ошибки и отметить места, нуждающиеся в уточнении.</p>
    </section>
    <section>
      <title>
        <p>Об этой книге</p>
      </title>
      <p>Эта книга представляет собой углубленное руководство по средствам поддержки многопоточности и параллелизма в новом стандарте С++, от базового использования классов и функций из пространств имел <code>std::thread</code>, <code>std::mutex</code> и <code>std::async</code> до сложных вопросов, связанных с атомарными операциями и моделью памяти.</p>
      <subtitle>Структура книги</subtitle>
      <p>В первых четырех главах описываются различные библиотечные средства и порядок работы с ними.</p>
      <p>Глава 5 посвящена низкоуровневым техническим деталям модели памяти и атомарных операций. В частности, рассматривается вопрос об использовании атомарных операций для задания ограничений на порядок выполнения других частей программы. Вводные главы на этом заканчиваются.</p>
      <p>В главах 6 и 7 начинается изучение программирования на более высоком уровне, с примерами использования базовых средств для построения сложных структур данных — с блокировками (глава 6) и без блокировок (глава 7).</p>
      <p>В главе 8 эта линия продолжается: даются рекомендации по проектированию многопоточных программ, рассматриваются аспекты, влияющие на производительность, и приводятся примеры реализации различных параллельных алгоритмов.</p>
      <p>Глава 9 посвящена средствам управления потоками, рассматриваются пулы потоков, очереди работ и прерывание операций.</p>
      <p>Тема главы 10 — тестирование и отладка: типы ошибок, методы их отыскания, способы тестирования и так далее.</p>
      <p>В приложениях вы найдете краткое описание некоторых языковых средств, добавленных в новый стандарт и имеющих отношение к многопоточности; детали реализации библиотеки передачи сообщениями, упомянутой в главе 4, и полный справочник по библиотеке С++11 Thread Library.</p>
      <subtitle>На кого рассчитана эта книга</subtitle>
      <p>Если вы пишете многопоточный код на С++, то эта книга для вас. Если вы пользуетесь средствами многопоточности из стандартной библиотеки С++, то здесь вы найдете руководство по основным вопросам. Если вы работаете с другими библиотеками многопоточности, то описанные рекомендации и приемы все равно могут оказаться полезным подспорьем.</p>
      <p>Предполагается владение языком С++ на рабочем уровне, по предварительное знакомство с новыми языковыми средствами необязательно — они описаны в приложении А. Также не требуются знания или опыт работы в области многопоточного программирования, хотя их наличие было бы плюсом.</p>
      <subtitle>Как пользоваться этой книгой</subtitle>
      <p>Если раньше вы не писали многопоточных программ, то я рекомендую читать книгу последовательно от начала до конца, опустив, быть может, кое-какие детали из главы 5. Глава 7 опирается на материал главы 5, поэтому если вы пропустите главу 5, то отложите также чтение седьмой главы.</p>
      <p>Если вам не доводилось использовать новые языковые средства, вошедшие в стандарт С++11, то имеет смысл с самого начала бегло просмотреть приложение А, чтобы понимать приведенные в тексте примеры. Впрочем, в основном тексте упоминания о новых средствах графически выделены, так что, встретив что-то незнакомое, вы всегда можете обратиться к приложению.</p>
      <p>Если вы располагаете обширным опытом написания многопоточного кода в других средах, то все-таки стоит просмотреть печальные главы, чтобы попять, как знакомые вам понятия соответствуют средствам из нового стандарта С++. Если вы планируете работать с атомарными переменными на низком уровне, то главу 5 следует изучить обязательно. Полезно также ознакомиться с главой 8, где рассказывается о безопасности исключений в многопоточных программах на С++. Если перед вами стоит конкретная задача, то указатель и оглавление помогут быстро найти соответствующий раздел.</p>
      <p>Даже после того как вы освоите библиотеку С++ Thread Library, приложение D все равно останется полезным, потому что в нем легко найти детали использования каждого класса и функции. Время от времени вы, наверное, будет заглядывать и в основные главы, чтобы освежить в памяти порядок работы с той или иной конструкцией или взглянуть на пример кода.</p>
      <subtitle>Графические выделения и загрузка исходного кода</subtitle>
      <p>Исходный код в листингах и основном тексте набран <code>моноширинным шрифтом</code>. Многие листинги сопровождаются аннотациями, в которых излагаются важные концепции. В некоторых случаях в листингах присутствуют нумерованные маркеры, с которыми соотносятся последующие пояснения.</p>
      <p>Исходный код всех примеров можно скачать с сайта издательства по адресу www.manning.com/CPlusPlusConcurrencyinAction.</p>
      <subtitle>Требования к программному обеспечению</subtitle>
      <p>Чтобы приведенный в этой книге код работал без модификаций, понадобится версия компилятора С++ с поддержкой тех вошедших в стандарт С++11 средств, которые перечислены в приложении А. Кроме того, нужна стандартная библиотека многопоточности С++ (Standard Thread Library).</p>
      <p>На момент написания этой книги единственный известный мне компилятор, поставляемый с библиотекой Standard Thread Library, — это g++, хотя в предварительную версию Microsoft Visual Studio 2011 она также входит. Что касается g++, то первая реализация основных возможностей библиотеки многопоточности была включена в версию g++ 4.3, а впоследствии добавлялись улучшения и расширения. Кроме того, в g++ 4.3 впервые появилась поддержка некоторых новых языковых средств С++11, и в каждой новой версии она расширяется. Дополнительные сведения см. на странице текущего состояния реализации С++11 в g++<a l:href="#n1" type="note">[1]</a>.</p>
      <p>В составе Microsoft Visual Studio 2010 также имеются некоторые новые средства из стандарта С++11, например лямбда-функции и ссылки на r-значения, по реализация библиотеки Thread Library отсутствует.</p>
      <p>Моя компания, Just Software Solutions Ltd, продает полную реализацию стандартной библиотеки С++11 Standard Thread Library для Microsoft Visual Studio 2005, Microsoft Visual Studio 2008, Microsoft Visual Studio 2010 различных версий g++<a l:href="#n2" type="note">[2]</a>. Именно эта реализация применялась для тестирования примеров из этой книги.</p>
      <p>В библиотеке Boost Thread Library<a l:href="#n3" type="note">[3]</a>, протестированной на многих платформах, реализовал API, основанный на предложениях, поданных в комитет по стандартизации С++. Большинство приведенных в книге примеров будут работать с Boost Thread Library, если заменить <code>std::</code> на <code>boost::</code> и включить подходящие директивы <code>#include</code>. Но некоторые возможности в библиотеке Boost Thread Library либо не поддерживаются вовсе (например, <code>std::async</code>), либо называются по-другому (например, <code>boost::unique_future</code>).</p>
      <subtitle>Автор в Сети</subtitle>
      <p>Приобретение книги «Параллелизм на С++ в действии» открывает бесплатный доступ к закрытому форуму, организованному издательством Manning Publications, где вы можете оставить свои комментарии к книге, задать технические вопросы и получить помощь от автора и других пользователей. Получить доступ к форуму и подписаться на список рассылки можно на странице www.manning.com/CPlusPlusConcurrencyinAction. Там же написано, как зайти на форум после регистрации, на какую помощь можно рассчитывать, и изложены правила поведения в форуме.</p>
      <p>Издательство Manning обязуется предоставлять читателям площадку для общения с другими читателями и автором. Однако это не означает, что автор обязан как-то участвовать в обсуждениях; его присутствие на форуме остается чисто добровольным (и не оплачивается). Мы советуем задавать автору хитроумные вопросы, чтобы его интерес к форуму не угасал!</p>
      <p>Форум автора в сети и архивы будут доступны на сайте издательства до тех пор, пока книга не перестает печататься.</p>
    </section>
    <section>
      <title>
        <p>Об иллюстрации на обложке</p>
      </title>
      <p>Рисунок на обложке книги «Параллельное программирование на С++ в действии» называется «Традиционный костюм японской девушки». Репродукция взята из четырехтомного «Собрания костюмов разных пародов», напечатанного в Лондоне между 1757 и 1772 годом. Это издание, включающее изумительные раскрашенные вручную гравюры на меди с изображениями одежды пародов мира, оказало большое влияние на дизайн театральных костюмов. Разнообразие рисунков позволяет составить наглядное представление о великолепии костюма на Лондонской сцене свыше 200 лет назад. Костюмы, исторические и того времени, позволяли познакомиться с традиционной одеждой людей, живших в разное время в разных странах, и тем самым сделать их ближе и понятнее лондонской театральной публике.</p>
      <p>Манера одеваться за последние 100 лет сильно изменилась, и различия между областями, когда-то столь разительные, сгладились. Теперь трудно отличить друг от друга даже выходцев с разных континентов. Но можно взглянуть на это и с оптимизмом — мы обменяли культурное и визуальное разнообразие на иное устройство личной жизни — основанное на многостороннем и стремительном технологическом и интеллектуальном развитии.</p>
      <p>Издательство Manning откликается на новации, инициативы и курьезы в компьютерной отрасли обложками своих книг, на которых представлено широкое разнообразие местных укладов и театральной жизни в позапрошлом веке. Мы возвращаем его в виде иллюстраций из этой коллекции.</p>
    </section>
    <section>
      <title>
        <p>Глава 1.</p>
        <p>Здравствуй, параллельный мир!</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Что понимается под параллелизмом и многопоточностью.</p>
        <p>&#9632; Зачем использовать параллелизм и многопоточность в своих приложениях.</p>
        <p>&#9632; Замечания об истории поддержки параллелизма в С++.</p>
        <p>&#9632; Структура простой многопоточной программы на С++.</p>
      </annotation>
      <section>
        <p>Для программистов на языке С++ настали радостные дни. Спустя тринадцать лет после публикации первой версии стандарта С++ в 1998 году комитет по стандартизации С++ решил основательно пересмотреть как сам язык, так и поставляемую вместе с ним библиотеку. Новый стандарт С++ (обозначаемый С++11 или С++0х), опубликованный в 2010 году, несёт многочисленные изменения, призванные упростить программирование на С++ и сделать его более продуктивным.</p>
        <p>К числу наиболее существенных новшеств в стандарте С++11 следует отнести поддержку многопоточных программ. Впервые комитет официально признал существование многопоточных приложений, написанных на С++, и включил в библиотеку компоненты для их разработки. Это позволит писать на С++ многопоточные программы с гарантированным поведением, не полагаясь на зависящие от платформы расширения. И как раз вовремя, потому что разработчики, стремясь повысить производительность приложений, все чаще посматривают в сторону параллелизма вообще и многопоточного программирования в особенности.</p>
        <p>Эта книга о том, как писать на С++ параллельные программы с несколькими потоками и о тех средствах самого языка и библиотеки времени выполнения, благодаря которым это стало возможно. Я начну с объяснения того, что понимаю под параллелизмом и многопоточностью и для чего это может пригодиться в приложениях. После краткого отвлечения на тему о том, когда программу <emphasis>не</emphasis> следует делать многопоточной, я в общих чертах расскажу о поддержке параллелизма в С++ и закончу главу примером простой параллельной программы. Читатели, имеющие опыт разработки многопоточных приложений, могут пропустить начальные разделы. В последующих главах мы рассмотрим более сложные примеры и детально изучим библиотечные средства. В конце книги приведено подробное справочное руководство по всем включенным в стандартную библиотеку С++ средствам поддержки многопоточности и параллелизма.</p>
        <p>Итак, что же я понимаю под <emphasis>параллелизмом</emphasis> и <emphasis>многопоточностью</emphasis>?</p>
      </section>
      <section>
        <title>
          <p>1.1. Что такое параллелизм?</p>
        </title>
        <section>
          <p>Если упростить до предела, то параллелизм — это одновременное выполнение двух или более операций. В жизни он встречается на каждом шагу: мы можем одновременно идти и разговаривать или одной рукой делать одно, а второй — другое. Ну и, разумеется, каждый из нас живет своей жизнью независимо от других — вы смотрите футбол, я в это время плаваю и т.д.</p>
        </section>
        <section>
          <title>
            <p>1.1.1. Параллелизм в вычислительных системах</p>
          </title>
          <p>Говоря о параллелизме в контексте компьютеров, мы имеем в виду, что одна и та же система выполняет несколько независимых операций параллельно, а не последовательно. Идея не нова: многозадачные операционные системы, позволяющие одновременно запускать на одном компьютере несколько приложений с помощью переключения между задачами уже много лет как стали привычными, а дорогие серверы с несколькими процессорами, обеспечивающие истинный параллелизм, появились еще раньше. <emphasis>Новым</emphasis> же является широкое распространение компьютеров, которые не просто создают иллюзию одновременного выполнения задач, а действительно исполняют их параллельно.</p>
          <p>Исторически компьютеры, как правило, оснащались одним процессором с одним блоком обработки, или ядром, и это остается справедливым для многих настольных машин и по сей день. Такая машина в действительности способна исполнять только одну задачу в каждый момент времени, по может переключаться между задачами много раз в секунду. Таким образом, сначала одна задача немножко поработает, потом другая, а в итоге складывается впечатление, будто все происходит одновременно. Это называется <emphasis>переключением задач</emphasis>. Тем не менее, и для таких систем мы можем говорить о <emphasis>параллелизме:</emphasis> задачи сменяются очень часто и заранее нельзя сказать, в какой момент процессор приостановит одну и переключится на другую. Переключение задач создает иллюзию параллелизма не только у пользователя, но и у самого приложения. Но так как это всего лишь <emphasis>иллюзия</emphasis>, то между поведением приложения в однопроцессорной и истинно параллельной среде могут существовать топкие различия. В частности, неверные допущения о модели памяти (см. главу 5) в однопроцессорной среде могут не проявляться. Подробнее эта тема рассматривается в главе 10.</p>
          <p>Компьютеры с несколькими процессорами применяются для организации серверов и выполнения высокопроизводительных вычислений уже много лет, а теперь машины с несколькими ядрами на одном кристалле (многоядерные процессоры) все чаще используются в качестве настольных компьютеров. И неважно, оснащена машина несколькими процессорами или одним процессором с несколькими ядрами (или комбинацией того и другого), она все равно может исполнять более одной задачи в каждый момент времени. Это называется <emphasis>аппаратным параллелизмом</emphasis>.</p>
          <p>На рис. 1.1 показан идеализированный случай: компьютер, исполняющий ровно две задачи, каждая из которых разбита на десять одинаковых этапов. На двухъядерной машине каждая задача может исполняться в своем ядре. На одноядерной машине с переключением задач этапы той и другой задачи чередуются. Однако между ними существует крохотный промежуток времени (на рисунке эти промежутки изображены в виде серых полосок, разделяющих более широкие этапы выполнения) — чтобы обеспечить чередование, система должна произвести <emphasis>контекстное переключение</emphasis> при каждом переходе от одной задачи к другой, а на это требуется время. Чтобы переключить контекст, ОС должна сохранить состояние процессора и счетчик команд для текущей задачи, определить, какая задача будет выполняться следующей, и загрузить в процессор состояние новой задачи. Не исключено, что затем процессору потребуется загрузить команды и данные новой задачи в кэш-память; в течение этой операции никакие команды не выполняются, что вносит дополнительные задержки.</p>
          <image l:href="#img_1_novyjjrazmer.png"/>
          <p><strong>Рис. 1.1</strong>. Два подхода к параллелизму: параллельное выполнение на двухъядерном компьютере и переключение задач на одноядерном</p>
          <p>Хотя аппаратная реализация параллелизма наиболее наглядно проявляется в многопроцессорных и многоядерных компьютерах, существуют процессоры, способные выполнять несколько потоков на одном ядре. В действительности существенным фактором является количество <emphasis>аппаратных потоков</emphasis> характеристика числа независимых задач, исполняемых оборудованием по-настоящему одновременно. И наоборот, в системе с истинным параллелизмом количество задач может превышать число ядер, тогда будет применяться механизм переключения задач. Например, в типичном настольном компьютере может быть запущено несколько сотен задач, исполняемых в фоновом режиме даже тогда, когда компьютер по видимости ничего не делает. Именно за счет переключения эти задачи могут работать параллельно, что и позволяет одновременно открывать текстовый процессор, компилятор, редактор и веб-браузер (да и вообще любую комбинацию приложений). На рис. 1.2 показано переключение четырех задач на двухъядерной машине, опять-таки в идеализированном случае, когда задачи разбиты на этапы одинаковой продолжительности. На практике существует много причин, из-за которых разбиение неравномерно и планировщик выделяет процессор каждой задаче не столь регулярно. Некоторые из них будут рассмотрены в главе 8 при обсуждении факторов, влияющих на производительность параллельных программ.</p>
          <image l:href="#img_2_novyjjrazmer.png"/>
          <p><strong>Рис. 1.2</strong>. Переключение задач на двухъядерном компьютере</p>
          <p>Все рассматриваемые в этой книге приемы, функции и классы применимы вне зависимости оттого, исполняется приложение на машине с одноядерным процессором или с несколькими многоядерными процессорами. Не имеет значения, как реализован параллелизм: с помощью переключения задач или аппаратно. Однако же понятно, что способ использования параллелизма в приложении вполне может зависеть от располагаемого оборудования. Эта тема обсуждается в главе 8 при рассмотрении вопросов проектирования параллельного кода на С++.</p>
        </section>
        <section>
          <title>
            <p>1.1.2. Подходы к организации параллелизма</p>
          </title>
          <p>Представьте себе пару программистов, работающих над одним проектом. Если они сидят в разных кабинетах, то могут мирно трудиться, не мешая друг другу, причем у каждого имеется свой комплект документации. Но общение при этом затруднено вместо того чтобы просто обернуться и обменяться парой слов, приходится звонить по телефону, писать письма или даже встать и дойти до коллеги. К тому же, содержание двух кабинетов сопряжено с издержками, да и на несколько комплектов документации надо будет потратиться.</p>
          <p>А теперь представьте, что всех разработчиков собрали в одной комнате. У них появилась возможность обсуждать между собой проект приложения, рисовать на бумаге или на доске диаграммы, обмениваться мыслями. Содержать придется только один офис и одного комплекта документации вполне хватит. Но есть и минусы теперь им труднее сконцентрироваться и могут возникать проблемы с общим доступом к ресурсам («Ну куда опять запропастилось это справочное руководство?»).</p>
          <p>Эти два способа организации труда разработчиков иллюстрируют два основных подхода к параллелизму. Разработчик это модель потока, а кабинет модель процесса В первом случае имеется несколько однопоточных процессов (у каждого разработчика свой кабинет), во втором несколько потоков в одном процессе (два разработчика в одном кабинете). Разумеется, возможны произвольные комбинации: может быть несколько процессов, многопоточных и однопоточных, но принцип остается неизменным. А теперь поговорим немного о том, как эти два подхода к параллелизму применяются в приложениях.</p>
          <subtitle>Параллелизм за счет нескольких процессов</subtitle>
          <p>Первый способ распараллелить приложение — разбить его на несколько однопоточных одновременно исполняемых процессов. Именно так вы и поступаете, запуская вместе браузер и текстовый процессор. Затем эти отдельные процессы могут обмениваться сообщениями, применяя стандартные каналы межпроцессной коммуникации (сигналы, сокеты, файлы, конвейеры и т.д.), как показано на рис. 1.3. Недостаток такой организации связи между процессами в его сложности, медленности, а иногда том и другом вместе. Дело в том, что операционная система должна обеспечить защиту процессов, так чтобы ни один не мог случайно изменить данные, принадлежащие другому. Есть и еще один недостаток — неустранимые накладные расходы на запуск нескольких процессов: для запуска процесса требуется время, ОС должна выделить внутренние ресурсы для управления процессом и т.д.</p>
          <image l:href="#img_3_novyjjrazmer.png"/>
          <p><strong>Рис. 1.3</strong>. Коммуникация между двумя параллельно работающими процессами</p>
          <p>Конечно, есть и плюсы. Благодаря надежной защите процессов, обеспечиваемой операционной системой, и высокоуровневым механизмам коммуникации написать <emphasis>безопасный</emphasis> параллельный код проще, когда имеешь дело с процессами, а не с потоками. Например, в среде исполнения, создаваемой языком программирования Erlang, в качестве фундаментального механизма параллелизма используются процессы, и это дает отличный эффект.</p>
          <p>У применения процессов для реализации параллелизма есть и еще одно достоинство — процессы можно запускать на разных машинах, объединенных сетью. Хотя затраты на коммуникацию при этом возрастают, по в хорошо спроектированной системе такой способ повышения степени параллелизма может оказаться очень эффективным, и общая производительность увеличится.</p>
          <subtitle>Параллелизм за счет нескольких потоков</subtitle>
          <p>Альтернативный подход к организации параллелизма — запуск нескольких потоков в одном процессе. Потоки можно считать облегченными процессами — каждый поток работает независимо от всех остальных, и все потоки могут выполнять разные последовательности команд. Однако все принадлежащие процессу потоки разделяют общее адресное пространство и имеют прямой доступ к большей части данных — глобальные переменные остаются глобальными, указатели и ссылки на объекты можно передавать из одного потока в другой. Для процессов тоже можно организовать доступ к разделяемой памяти, но это и сделать сложнее, и управлять не так просто, потому что адреса одного и того же элемента данных в разных процессах могут оказаться разными. На рис. 1.4 показано, как два потока в одном процессе обмениваются данными через разделяемую память.</p>
          <image l:href="#img_4.png"/>
          <p><strong>Рис. 1.4</strong>. Коммуникация между двумя параллельно исполняемыми потоками в одном процессе</p>
          <p>Благодаря общему адресному пространству и отсутствию защиты данных от доступа со стороны разных потоков накладные расходы, связанные с наличием нескольких потоков, существенно меньше, так как на долю операционной системы выпадает гораздо меньше учетной работы, чем в случае нескольких процессов. Однако же за гибкость разделяемой памяти приходится расплачиваться — если к некоторому элементу данных обращаются несколько потоков, то программист должен обеспечить согласованность представления этого элемента во всех потоках. Возникающие при этом проблемы, а также средства и рекомендации по их разрешению рассматриваются на протяжении всей книги, а особенно в главах 3, 4, 5 и 8. Эти проблемы не являются непреодолимыми, надо лишь соблюдать осторожность при написании кода. Но само их наличие означает, что коммуникацию между потоками необходимо тщательно продумывать.</p>
          <p>Низкие накладные расходы на запуск потоков внутри процесса и коммуникацию между ними стали причиной популярности этого подхода во всех распространенных языках программирования, включая С++, даже несмотря на потенциальные проблемы, связанные с разделением памяти. Кроме того, в стандарте С++ не оговаривается встроенная поддержка межпроцессной коммуникации, а, значит, приложения, основанные на применении нескольких процессов, вынуждены полагаться на платформенно-зависимые API. Поэтому в этой книге мы будем заниматься исключительно параллелизмом на основе многопоточности, и в дальнейшем всякое упоминание о параллелизме предполагает использование нескольких потоков.</p>
          <p>Определившись с тем, что понимать под параллелизмом, посмотрим, зачем он может понадобиться в приложениях.</p>
        </section>
      </section>
      <section>
        <title>
          <p>1.2. Зачем нужен параллелизм?</p>
        </title>
        <section>
          <p>Существует две основных причины для использования параллелизма в приложении: разделение обязанностей и производительность. Я бы даже рискнул сказать, что это <emphasis>единственные</emphasis> причины — если внимательно приглядеться, то окажется, что все остальное сводится к одной или к другой (или к обеим сразу). Ну, конечно, если не рассматривать в качестве аргумента «потому что я так хочу».</p>
        </section>
        <section>
          <title>
            <p>1.2.1. Применение параллелизма для разделения обязанностей</p>
          </title>
          <p>Разделение обязанностей почти всегда приветствуется при разработке программ: если сгруппировать взаимосвязанные и разделить несвязанные части кода, то программа станет проще для понимания и тестирования и, стало быть, будет содержать меньше ошибок. Использовать распараллеливание для разделения функционально не связанных между собой частей программы имеет смысл даже, если относящиеся к разным частям операции должны выполняться одновременно: без явного распараллеливания нам пришлось бы либо реализовать какую-то инфраструктуру переключения задач, либо то и дело обращаться к коду из посторонней части программы во время выполнения операции.</p>
          <p>Рассмотрим приложение, имеющее графический интерфейс и выполняющее сложные вычисления, например DVD-проигрыватель на настольном компьютере. У такого приложения два принципиально разных набора обязанностей: во-первых, читать данные с диска, декодировать изображение и звук и своевременно посылать их графическому и звуковому оборудованию, чтобы при просмотре фильма не было заминок, а, во-вторых, реагировать на действия пользователя, например, на нажатие кнопок «Пауза», «Возврат в меню» и даже «Выход». Если бы приложение было однопоточным, то должно было бы периодически проверять, не было ли каких-то действий пользователя, поэтому код воспроизведения DVD перемежался бы кодом, относящимся к пользовательскому интерфейсу Если же для разделения этих обязанностей использовать несколько потоков, то код интерфейса и воспроизведения уже не будут так тесно переплетены: один поток может заниматься отслеживанием действий пользователя, а другой - воспроизведением. Конечно, как-то взаимодействовать они все равно должны, например, если пользователь нажимает кнопку «Пауза», но такого рода взаимодействия непосредственно связаны с решаемой задачей.</p>
          <p>В результате мы получаем «отзывчивый» интерфейс, так как поток пользовательского интерфейса обычно способен немедленно отреагировать на запрос пользователя, даже если реакция заключается всего лишь в смене формы курсора на «занято» или выводе сообщения «Подождите, пожалуйста» на время, требуемое для передачи запроса другому потоку для обработки. Аналогично, несколько потоков часто создаются для выполнения постоянно работающих фоновых задач, например, мониторинга изменений файловой системы в приложении локального поиска. Такое использование потоков позволяет существенно упростить логику каждого потока, так как взаимодействие между ними ограничено немногими четко определенными точками, а не размазано по всей программе.</p>
          <p>В данном случае количество потоков не зависит от количества имеющихся процессорных ядер, потому что программа разбивается на потоки ради чистоты дизайна, а не в попытке увеличить производительность.</p>
        </section>
        <section>
          <title>
            <p>1.2.2. Применение параллелизма для повышения производительности</p>
          </title>
          <p>Многопроцессорные системы существуют уже десятки лет, но до недавнего времени они использовались исключительно в суперкомпьютерах, больших ЭВМ и крупных серверах. Однако ныне производители микропроцессоров предпочитают делать процессоры с 2, 4, 16 и более ядрами на одном кристалле, а не наращивать производительность одного ядра. Поэтому все большее распространение получают настольные компьютеры и даже встраиваемые устройства с многоядерными процессорами. Увеличение вычислительной мощи в этом случае связано не с тем, что каждая отдельная задача работает быстрее, а с тем, что несколько задач исполняются параллельно.</p>
          <p>В прошлом программист мог откинуться на спинку стула и наблюдать, как его программа работает все быстрее с каждым новым поколением процессоров, без каких-либо усилий с его стороны. Но теперь, как говорит Герб Саттер, «время бесплатных завтраков закончилось» [Sutter 2005]. <emphasis>Если требуется, чтобы программа выигрывала от увеличения вычислительной мощности, то ее необходимо проектировать как набор параллельных задач</emphasis>. Поэтому программистам придется подтянуться, и те, кто до сих пор не обращал внимания на параллелизм, должны будут добавить его в свой арсенал.</p>
          <p>Существует два способа применить распараллеливание для повышения производительности. Первый, самый очевидный, разбить задачу на части и запустить их параллельно, уменьшив тем самым общее время выполнения. Это <emphasis>распараллеливание по задачам</emphasis>. Хотя эта процедура и представляется простой, на деле все может сильно усложниться из-за наличия многочисленных зависимостей между разными частями. Разбиение можно формулировать как в терминах обработки: один поток выполняет одну часть обработки, другой — другую, так и в терминах данных: каждый поток выполняет одну и ту же операцию, но с разными данными. Последний вариант называется <emphasis>распараллеливание по данным</emphasis>.</p>
          <p>Алгоритмы, легко поддающиеся такому распараллеливанию, часто называют <emphasis>естественно параллельными</emphasis> (embarrassingly parallel, naturally parallel, conveniently concurrent.). Они очень хорошо масштабируются — если число располагаемых аппаратных потоков увеличивается, то и степень параллелизма алгоритма возрастает. Такой алгоритм — идеальная иллюстрации пословицы «берись дружно, не будет грузно». Те части алгоритма, которые не являются естественно параллельными, можно разбить на фиксированное (и потому не масштабируемое) число параллельных задач. Техника распределения задач по потокам рассматривается в главе 8.</p>
          <p>Второй способ применения распараллеливания для повышения производительности — воспользоваться имеющимся параллелизмом для решения более крупных задач, например, обрабатывать не один файл за раз, а сразу два, десять или двадцать. Это по сути дела пример распараллеливания но данным, так как одна и та же операция производится над несколькими наборами данных одновременно, но акцент немного иной. Для обработки одной порции данных требуется столько же времени, сколько и раньше, но за фиксированное время можно обработать больше данных. Очевидно, что и у этого подхода есть ограничения, и не во всех случаях он дает выигрыш, но достигаемое повышение производительности иногда открывает новые возможности. Например, если разные области изображения можно обрабатывать параллельно, то можно будет обработать видео более высокого разрешения.</p>
        </section>
        <section>
          <title>
            <p>1.2.3. Когда параллелизм вреден?</p>
          </title>
          <p>Понимать, когда параллелизмом пользоваться <emphasis>не</emphasis> следует, не менее важно. Принцип простой: единственная причина не использовать параллелизм — ситуация, когда затраты перевешивают выигрыш. Часто параллельная программа сложнее для понимания, поэтому для написания и сопровождения многопоточного кода требуются дополнительные интеллектуальные усилия, а, стало быть, возрастает и количество ошибок. Если потенциальный прирост производительности недостаточно велик или достигаемое разделение обязанностей не настолько очевидно, чтобы оправдать дополнительные затраты времени на разработку, отладку и сопровождение многопоточной программы, то не используйте параллелизм.</p>
          <p>Кроме того, прирост производительности может оказаться меньше ожидаемого: с запуском потоков связаны неустранимые накладные расходы, потому что ОС должна выделить ресурсы ядра и память для стека и сообщить о новом потоке планировщику, а на все это требуется время. Если задача, исполняемая в отдельном потоке, завершается быстро, то может оказаться, что в общем времени ее работы доминируют именно накладные расходы на запуск потока, поэтому производительность приложения в целом может оказаться хуже, чем если бы задача исполнялась в уже имеющемся потоке.</p>
          <p>Далее, потоки — это ограниченный ресурс. Если одновременно работает слишком много потоков, то ресурсы ОС истощаются, что может привести к замедлению работы всей системы. Более того, при чрезмерно большом количестве потоков может исчерпаться память или адресное пространство, выделенное процессу, так как каждому потоку необходим собственный стек. Особенно часто эта проблема возникает в 32-разрядных процессах с «плоской» структурой памяти, где на размер адресного пространства налагается ограничение 4 ГБ: если у каждого потока есть стек размером 1 МБ (типичное соглашение во многих системах), то 4096 потоков займут все адресное пространство, не оставив места для кода, статических данных и кучи. В 64-разрядных системах (и системах с большей разрядностью слова) такого ограничения на размер адресного пространства нет, но ресурсы все равно конечны: если запустить слишком много потоков, то рано или поздно возникнут проблемы. Для ограничения количества потоков можно воспользоваться пулами потоков (см. главу 9), но и это не панацея — у пулов есть и свои проблемы.</p>
          <p>Если на серверной стороне клиент-серверного приложения создается по одному потоку для каждого соединения, то при небольшом количестве соединений все будет работать прекрасно, но когда нагрузка на сервер возрастает и ему приходится обрабатывать очень много соединений, такая техника быстро приведет к истощению системных ресурсов. В такой ситуации оптимальную производительность может дать обдуманное применение пулов потоков (см. главу 9).</p>
          <p>Наконец, чем больше работает потоков, тем чаще операционная система должна выполнять контекстное переключение. На каждое такое переключение уходит время, которое можно было бы потратить на полезную работу, поэтому в какой-то момент добавление нового потока не увеличивает, а <emphasis>снижает</emphasis> общую производительность приложения. Поэтому, пытаясь достичь максимально возможной производительности системы, вы должны выбирать число потоков с учетом располагаемого аппаратного параллелизма (или его отсутствия).</p>
          <p>Применение распараллеливания для повышения производительности ничем не отличается от любой другой стратегии оптимизации — оно может существенно увеличить скорость работы приложения, но при этом сделать код более сложным для понимания, что чревато ошибками. Поэтому распараллеливать имеет смысл только критически важные с точки зрения производительности участки программы, когда это может принести поддающийся измерению выигрыш. Но, конечно, если вопрос об увеличении производительности вторичен, а на первую роль выходит ясность дизайна или разделение обязанностей, то рассмотреть возможность многопоточной структуры все равно стоит.</p>
          <p>Но предположим, что вы уже решили, что хотите распараллелить приложение, будь то для повышения производительности, ради разделения обязанностей или просто потому, что сегодня «День многопоточности». Что это означает для программиста на С++?</p>
        </section>
      </section>
      <section>
        <title>
          <p>1.3. Параллелизм и многопоточность в С++</p>
        </title>
        <section>
          <p>Стандартизованная поддержка параллелизма за счет многопоточности — вещь новая для С++. Только новый стандарт С++11 позволит писать многопоточный код, не прибегая к платформенно-зависимым расширениям. Чтобы разобраться в подоплёке многочисленных решений, принятых в новой стандартной библиотеке С++ Thread Library, необходимо вспомнить историю.</p>
        </section>
        <section>
          <title>
            <p>1.3.1. История многопоточности в С++</p>
          </title>
          <p>Стандарт С++ 1998 года не признавал существования потоков, поэтому результаты работы различных языковых конструкций описывались в терминах последовательной абстрактной машины. Более того, модель памяти не была формально определена, поэтому без поддержки со стороны расширений стандарта С++ 1998 года писать многопоточные приложения вообще было невозможно.</p>
          <p>Разумеется, производители компиляторов вправе добавлять в язык любые расширения, а наличие различных API для поддержки многопоточности в языке С, например, в стандарте POSIX С Standard и в Microsoft Windows API, заставило многих производителей компиляторов С++ поддержать многопоточность с помощью платформенных расширений. Как правило, эта поддержка ограничивается разрешением использовать соответствующий платформе С API с гарантией, что библиотека времени исполнения С++ (в частности, механизм обработки исключений) будет корректно работать при наличии нескольких потоков. Хотя лишь очень немногие производители компиляторов предложили формальную модель памяти с поддержкой многопоточности, практическое поведение компиляторов и процессоров оказалось достаточно приемлемым для создания большого числа многопоточных программ на С++.</p>
          <p>Не удовлетворившись использованием платформенно-зависимых С API для работы с многопоточностью, программисты на С++ пожелали, чтобы в используемых ими библиотеках классов были реализованы объектно-ориентированные средства для написания многопоточных программ. В различные программные каркасы типа MFC и в универсальные библиотеки на С++ типа Boost и АСЕ были включены наборы классов С++, которые обертывали платформенно-зависимые API и предоставляли высокоуровневые средства для работы с многопоточностью, призванные упростить программирование. Детали реализации в этих библиотеках существенно различаются, особенно в части запуска новых потоков, но общая структура классов очень похожа. В частности, во многих библиотеках классов С++ применяется крайне полезная идиома <emphasis>захват ресурса есть инициализация (RAII)</emphasis>, которая материализуется в виде блокировок, гарантирующих освобождение мьютекса при выходе из соответствующей области видимости.</p>
          <p>Во многих случаях поддержка многопоточности в имеющихся компиляторах С++ вкупе с доступностью платформенно-зависимых API и платформенно-независимых библиотек классов типа Boost и АСЕ оказывается достаточно прочным основанием, на котором можно писать многопоточные программы. В результате уже написаны многопоточные приложения на С++, содержащие миллионы строк кода. Но коль скоро прямой поддержки в стандарте нет, бывают случаи, когда отсутствие модели памяти, учитывающей многопоточность, приводит к проблемам. Особенно часто с этим сталкиваются разработчики, пытающиеся увеличить производительность за счет использования особенностей конкретного процессора, а также те, кто пишет кросс-платформенный код, который должен работать независимо от различий между компиляторами на разных платформах.</p>
        </section>
        <section>
          <title>
            <p>1.3.2. Поддержка параллелизма в новом стандарте</p>
          </title>
          <p>Все изменилось с выходом стандарта С++11. Мало того что в нем определена совершенно новая модель памяти с поддержкой многопоточности, так еще и в стандартную библиотеку С++ включены классы для управления потоками (глава 2), защиты разделяемых данных (глава 3), синхронизации операций между потоками (глава 4) и низкоуровневых атомарных операций (глава 5).</p>
          <p>В основу новой библиотеки многопоточности для С++ положен опыт, накопленный за время использования вышеупомянутых библиотек классов. В частности, моделью новой библиотеки стала библиотека Boost Thread Library, из которой заимствованы имена и структура многих классов. Эволюция нового стандарта была двунаправленным процессом, и сама библиотека Boost Thread Library во многих отношениях изменилась, чтобы лучше соответствовать стандарту. Поэтому пользователи Boost, переходящие на новый стандарт, будут чувствовать себя очень комфортно.</p>
          <p>Поддержка параллелизма — лишь одна из новаций в стандарте С++. Как уже отмечалось в начале главы, в сам язык тоже внесено много изменений, призванных упростить жизнь программистам. Хотя, вообще говоря, сами по себе они не являются предметом настоящей книги, некоторые оказывают прямое влияние на библиотеку многопоточности и способы ее использования. В приложении А содержится краткое введение в эти языковые средства.</p>
          <p>Прямая языковая поддержка атомарных операций позволяет писать эффективный код с четко определенной семантикой, не прибегая к языку ассемблера для конкретной платформы. Это манна небесная для тех, кто пытается создавать эффективный и переносимый код, — мало того что компилятор берет на себя заботу об особенностях платформы, так еще и оптимизатор можно написать так, что он будет учитывать семантику операций и, стало быть, лучше оптимизировать программу в целом.</p>
        </section>
        <section>
          <title>
            <p>1.3.3. Эффективность библиотеки многопоточности для С++</p>
          </title>
          <p>Одна из проблем, с которыми сталкиваются разработчики высокопроизводительных приложений при использовании языка С++ вообще и классов, обертывающих низкоуровневые средства, типа тех, что включены в стандартную библиотеку С++ Thread Library, в частности, — это эффективность. Если вас интересует достижение максимальной производительности, то необходимо понимать, что использование любых высокоуровневых механизмов вместо обертываемых ими низкоуровневых средств влечет за собой некоторые издержки. Эти издержки называются <emphasis>платой за абстрагирование</emphasis>.</p>
          <p>Комитет по стандартизации С++ прекрасно донимал это, когда проектировал стандартную библиотеку С++ вообще и стандартную библиотеку многопоточности для С++ в частности. Среди целей проектирования была и такая: выигрыш от использования низкоуровневых средств по сравнению с высокоуровневой оберткой (если такая предоставляется) должен быть ничтожен или отсутствовать вовсе. Поэтому библиотека спроектирована так, чтобы ее можно было эффективно реализовать (с очень небольшой платой за абстрагирование) на большинстве популярных платформ.</p>
          <p>Комитет по стандартизации С++ поставил и другую цель — обеспечить достаточное количество низкоуровневых средств для желающих работать на уровне «железа», чтобы выдавить из него все, что возможно. Поэтому наряду с новой моделью памяти включена полная библиотека атомарных операций для прямого управления на уровне битов и байтов, а также средства межпоточной синхронизации и обеспечения видимости любых изменений. Атомарные типы и соответствующие операции теперь можно использовать во многих местах, где раньше разработчики были вынуждены опускаться на уровень языка ассемблера для конкретной платформы. Таким образом, код с применением новых стандартных типов и операций получается более переносимым и удобным для сопровождения.</p>
          <p>Стандартная библиотека С++ также предлагает высокоуровневые абстракции и средства, позволяющие писать многопоточный код проще и с меньшим количеством ошибок. Некоторые из них несколько снижают производительность из-за необходимости выполнять дополнительный код. Однако эти накладные расходы не обязательно означают высокую плату за абстрагирование: в общем случае цена не выше, чем пришлось бы заплатить при написании эквивалентной функциональности вручную, и к тому же компилятор волне может встроить значительную часть дополнительного кода.</p>
          <p>В некоторых случаях высокоуровневые средства обеспечивают большую функциональность, чем необходимо для конкретной задачи. Как правило, это не страшно: вы не платите за то, чем не пользуетесь. Редко, но бывает, что избыточная функциональность негативно сказывается на производительности других частей программы. Если ее стоимость слишком высока, а производительность имеет первостепенное значение, то, быть может, имеет смысл вручную запрограммировать необходимую функциональность, пользуясь низкоуровневыми средствами. Но в подавляющем большинстве случаев дополнительная сложность и возможность внести ошибки намного перевешивают небольшой выигрыш в производительности. Даже если профилирование показывает, что средства стандартной библиотеки С++ <emphasis>действительно</emphasis> являются узким местом, не исключено, что проблема в неудачном дизайне приложения, а не в плохой реализации библиотеки. Например, когда слишком много потоков конкурируют за один мьютекс, производительность упадет — и сильно. Но лучше не пытаться чуть-чуть ускорить операции с мьютексами, а изменить структуру приложения, так чтобы снизить конкуренцию. Вопрос о том, как проектировать приложения, чтобы уменьшить конкуренцию, обсуждается в главе 8.</p>
          <p>В тех крайне редких случаях, когда стандартная библиотека не обеспечивает необходимой производительности или поведения, может возникнуть необходимость в использовании платформенно-зависимых средств.</p>
        </section>
        <section>
          <title>
            <p>1.3.4. Платформенно-зависимые средства</p>
          </title>
          <p>Хотя библиотека многопоточности для С++ содержит достаточно полный набор средств для создания многопоточных программ, на любой платформе имеются специальные средства, помимо включенных в библиотеку. Чтобы можно было получить доступ к этим средствам, не отказываясь от использования стандартной библиотеки, типы, имеющиеся в библиотеки многопоточности, иногда содержат функцию-член <code>native_handle()</code>, которая позволяет работать на уровне платформенного API. По природе своей любые операции, выполняемые с помощью функции <code>native_handle()</code>, зависят от платформы и потому в данной книге (как и в самой стандартной библиотеке С++) не рассматриваются.</p>
          <p>Разумеется, перед тем задумываться о применении платформенно-зависимых средств, стоит как следует разобраться в том, что предлагает стандартная библиотека, поэтому начнем с примера.</p>
        </section>
      </section>
      <section>
        <title>
          <p>1.4. В начале пути</p>
        </title>
        <section>
          <p>Итак, вы получили новенький, с пылу с жару компилятор, совместимый со стандартом С++11. Что дальше? Как выглядит многопоточная программа на С++? Да примерно так же, как любая другая программа, — с переменными, классами и функциями. Единственное существенное отличие состоит в том, что некоторые функции могут работать параллельно, поэтому нужно следить за тем, чтобы доступ к разделяемым данным был безопасен (см. главу 3). Понятно, что для параллельного исполнения необходимо использовать специальные функции и объекты, предназначенные для управления потоками.</p>
        </section>
        <section>
          <title>
            <p>1.4.1. Здравствуй, параллельный мир</p>
          </title>
          <p>Начнем с классического примера — программы, которая печатает фразу «Здравствуй, мир». Ниже приведена тривиальная однопоточная программа такого сорта, от нее мы будем отталкиваться при переходе к нескольким потокам.</p>
          <p>
            <code>#include &lt;iostream&gt;</code>
          </p>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> std::cout &lt;&lt; "Здравствуй, мир\n";</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Эта программа всего лишь выводит строку <emphasis>Здравствуй мир</emphasis> в стандартный поток вывода. Сравним ее с простой программой «Здравствуй, параллельный мир», показанной в листинге 1.1, — в ней для вывода сообщения запускается отдельный поток.</p>
          <p>
            <code>#include &lt;iostream&gt;</code>
          </p>
          <p>
            <code>#include &lt;thread&gt; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code>void hello()      &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>{</code>
          </p>
          <p>
            <code> std::cout &lt;&lt; "Здравствуй, параллельный мир\n";</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int</code>
          </p>
          <p>
            <code>main() {</code>
          </p>
          <p>
            <code> std::thread t(hello); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> t.join();             &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Прежде всего, отметим наличие дополнительной директивы <code>#include &lt;thread&gt;</code> <strong>(1)</strong>. Все объявления, необходимые для поддержки многопоточности, помещены в новые заголовочные файлы; функции и классы для управления потоками объявлены в файле <code>&lt;thread&gt;</code>, а те, что нужны для защиты разделяемых данных, — в других заголовках.</p>
          <p>Далее, код вывода сообщения перемещен в отдельную функцию <strong>(2)</strong>. Это объясняется тем, что в каждом потоке должна быть <emphasis>начальная функция</emphasis>, в которой начинается исполнение потока. Для первого потока в приложении таковой является <code>main()</code>, а для всех остальных задается в конструкторе объекта <code>std::thread</code>. В данном случае в качестве начальной функции объекта типа <code>std::thread</code>, названного <code>t</code> <strong>(3)</strong>, выступает функция <code>hello()</code>.</p>
          <p>Есть и еще одно отличие вместо того, чтобы сразу писать на стандартный вывод или вызывать <code>hello()</code> из <code>main()</code>, эта программа запускает новый поток, так что теперь общее число потоков равно двум: главный, с начальной функцией <code>main()</code>, и дополнительный, начинающий работу в функции <code>hello()</code>.</p>
          <p>После запуска нового потока <strong>(3)</strong> начальный поток продолжает работать. Если бы он не ждал завершения нового потока, то просто дошел бы до конца <code>main()</code>, после чего исполнение программы закончилась бы быть может, еще до того, как у нового потока появился шанс начать работу. Чтобы предотвратить такое развитие событие, мы добавили обращение к функции <code>join()</code> <strong>(4)</strong>; в главе 2 объясняется, что это заставляет вызывающий поток (<code>main()</code>) ждать завершения потока, ассоциированного с объектом <code>std::thread</code>, — в данном случае <code>t</code>.</p>
          <p>Если вам показалось, что для элементарного вывода сообщения на стандартный вывод работы слишком много, то так оно и есть, — в разделе 1.2.3 выше мы говорили, что обычно для решения такой простой задачи не имеет смысла создавать несколько потоков, особенно если главному потоку в это время нечего делать. Но далее мы встретимся с примерами, когда запуск нескольких потоков дает очевидный выигрыш.</p>
        </section>
      </section>
      <section>
        <title>
          <p>1.5. Резюме</p>
        </title>
        <p>В этой главе мы говорили о том, что такое параллелизм и многопоточность и почему стоит (или не стоит) использовать их в программах. Мы также рассмотрели историю многопоточности в С++ — от полного отсутствия поддержки в стандарте 1998 года через различные платформенно-зависимые расширения к полноценной поддержке в новом стандарте С++11. Эта поддержка, появившаяся очень вовремя, дает программистам возможность воспользоваться преимуществами аппаратного параллелизма, которые стали доступны в современных процессорах, поскольку их производители пошли но пути наращивания мощности за счет реализации нескольких ядер, а не увеличения быстродействия одного ядра.</p>
        <p>Мы также видели (пример в разделе 1.4), как просто использовать классы и функции из стандартной библиотеки С++. В С++ использование нескольких потоков само по себе несложно — сложно спроектировать программу так, чтобы она вела себя, как задумано.</p>
        <p>Закусив примерами из раздела 1.4, пора приступить к чему-нибудь более питательному. В главе 1 мы рассмотрим классы и функции для управления потоками.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Глава 2.</p>
        <p>Управление потоками</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Запуск потоков и различные способы задания кода, исполняемого в новом потоке.</p>
        <p>&#9632; Ждать завершения потока или позволить ему работать независимо?</p>
        <p>&#9632; Уникальные идентификаторы потоков.</p>
      </annotation>
      <section>
        <p>Итак, вы решили написать параллельную программу, а конкретно — использовать несколько потоков. И что теперь? Как запустить потоки, как узнать, что поток завершился, и как отслеживать их выполнение? Средства, имеющиеся в стандартной библиотеке, позволяют относительно просто решить большинство задач управления потоками. Как мы увидим, почти все делается с помощью объекта <code>std::thread</code>, ассоциированного с потоком. Для более сложных задач библиотека позволяет построить то, что нужно, из простейших кирпичиком.</p>
        <p>Мы начнем эту главу с рассмотрения базовых операций: запуск потока, ожидание его завершения, исполнение в фоновом режиме. Затем мы поговорим о передаче дополнительных параметров функции потока в момент запуска и о том, как передать владение потока от одного объекта <code>std::thread</code> другому. Наконец, мы обсудим вопрос о том, сколько запускать потоков и как идентифицировать отдельный поток.</p>
      </section>
      <section>
        <title>
          <p>2.1. Базовые операции управления потоками</p>
        </title>
        <section>
          <p>В каждой программе на С++ имеется по меньшей мере один поток, запускаемый средой исполнения С++: тот, в котором исполняется функция <code>main()</code>. Затем программа может запускать дополнительные потоки с другими функциями в качестве точки входа. Эти потоки работают параллельно друг с другом и с начальным потоком. Мы знаем, что программа завершает работу, когда <code>main()</code> возвращает управление; точно так же, при возврате из точки входа в поток этот поток завершается. Ниже мы увидим, что, имея объект <code>std::thread</code> для некоторого потока, мы можем дождаться завершения этого потока, но сначала посмотрим, как потоки запускаются.</p>
        </section>
        <section>
          <title>
            <p>2.1.1. Запуск потока</p>
          </title>
          <p>В главе 1 мы видели, что для запуска потока следует сконструировать объект <code>std::thread</code>, который определяет, какая задача будет исполняться в потоке. В простейшем случае задача представляет собой обычную функцию без параметров, возвращающую <code>void</code>. Эта функция работает в своем потоке, пока не вернет управление, и в этом момент поток завершается. С другой стороны, в роли задачи может выступать объект-функция, который принимает дополнительные параметры и выполняет ряд независимых операций, информацию о которых получает во время работы от той или иной системы передачи сообщений. И останавливается такой поток, когда получит соответствующий сигнал, опять же с помощью системы передачи сообщений. Вне зависимости от того, что поток будет делать и откуда он запускается, сам запуск потока в стандартном С++ всегда сводится к конструированию объекта <code>std::thread</code>:</p>
          <p>
            <code>void do_some_work();</code>
          </p>
          <p>
            <code>std::thread my_thread(do_some_work);</code>
          </p>
          <p>Как видите, все просто. Разумеется, как и во многих других случаях в стандартной библиотеке С++, класс <code>std::thread</code> работает с любым типом, допускающим вызов (<emphasis>Callable</emphasis>), поэтому конструктору <code>std::thread</code> можно передать экземпляр класса, в котором определен оператор вызова:</p>
          <p>
            <code>class background_task {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void operator()() const {</code>
          </p>
          <p>
            <code>  do_something();</code>
          </p>
          <p>
            <code>  do_something_else();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>background_task f;</code>
          </p>
          <p>
            <code>std::thread my_thread(f);</code>
          </p>
          <p>В данном случае переданный объект-функция <emphasis>копируется</emphasis> в память, принадлежащую только что созданному потоку выполнения, и оттуда вызывается. Поэтому необходимо, чтобы с точки зрения поведения копия была эквивалентна оригиналу, иначе можно получить неожиданный результат.</p>
          <p>При передаче объекта-функции конструктору потока нужно избегать феномена «самого досадного разбора в С++» (C++'s most vexing parse). Синтаксически передача конструктору временного объекта вместо именованной переменной выглядит так же, как объявление функции, и именно так компилятор и интерпретирует эту конструкцию. Например, в предложении</p>
          <p>
            <code>std::thread my_thread(background_task());</code>
          </p>
          <p>объявлена функция <code>my_thread</code>, принимающая единственный параметр (типа указателя на функцию без параметров, которая возвращает объект <code>background_task</code>) и возвращающая объект <code>std::thread</code>. Никакой новый поток здесь не запускается. Решить эту проблему можно тремя способами: поименовать объект-функцию, как в примере выше; добавить лишнюю пару скобок или воспользоваться новым универсальным синтаксисом инициализации, например:</p>
          <p>
            <code>std::thread my_thread(<strong>(</strong>background_task()<strong>)</strong>); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>std::thread my_thread<strong>{</strong>background_task()<strong>}</strong>;   &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>В случае <strong>(1)</strong> наличие дополнительных скобок не дает компилятору интерпретировать конструкцию как объявление функции, так что действительно объявляется переменная <code>my_thread</code> типа <code>std::thread</code>. В случае <strong>(2)</strong> использован новый универсальный синтаксис инициализации с фигурными, а не круглыми скобками, он тоже приводит к объявлению переменной.</p>
          <p>В стандарте С++11 имеется новый тип допускающего вызов объекта, в котором описанная проблема не возникает, — <emphasis>лямбда-выражение</emphasis>. Этот механизм позволяет написать локальную функцию, которая может захватывать некоторые локальные переменные, из-за чего передавать дополнительные аргументы просто не нужно (см. раздел 2.2). Подробная информация о лямбда-выражениях приведена в разделе А.5 приложения А. С помощью лямбда-выражений предыдущий пример можно записать в таком виде:</p>
          <p>
            <code>std::thread my_thread([](</code>
          </p>
          <p>
            <code> do_something();</code>
          </p>
          <p>
            <code> do_something_else();</code>
          </p>
          <p>
            <code>});</code>
          </p>
          <p>После запуска потока необходимо явно решить, ждать его завершения (присоединившись к нему, см. раздел 2.1.2) или предоставить собственной судьбе (отсоединив его, см. раздел 2.1.3). Если это решение не будет принято к моменту уничтожения объекта <code>std::thread</code>, то программа завершится (деструктор <code>std::thread</code> вызовет функцию <code>std::terminate()</code>). Поэтому вы обязаны гарантировать, что поток корректно присоединен либо отсоединен, даже если возможны исключения. Соответствующая техника программирования описана в разделе 2.1.3. Отметим, что это решение следует принять именно до уничтожения объекта <code>std::thread</code>, к самому потоку оно не имеет отношения. Поток вполне может завершиться задолго до того, как программа присоединится к нему или отсоединит его. А отсоединенный поток может продолжать работу и после уничтожения объекта <code>std::thread</code>.</p>
          <p>Если вы не хотите дожидаться завершения потока, то должны гарантировать, что данные, к которым поток обращается, остаются действительными до тех пор, пока они могут ему понадобиться. Эта проблема не нова даже в однопоточной программа доступ к уже уничтоженному объекту считается неопределенным поведением, но при использовании потоков есть больше шансов столкнуться с проблемами, обусловленными временем жизни.</p>
          <p>Например, такая проблема возникает, если функция потока хранит указатели или ссылки на локальные переменные, и поток еще не завершился, когда произошел выход из области видимости, где эти переменные определены. Соответствующий пример приведен в листинге 2.1.</p>
          <empty-line/>
          <p><strong>Листинг 2.1.</strong> Функция возвращает управление, когда поток имеет доступ к определенным в ней локальным переменным</p>
          <p>
            <code>struct func {</code>
          </p>
          <p>
            <code> int&amp; i;</code>
          </p>
          <p>
            <code> func(int&amp; i_) : i(i_){}</code>
          </p>
          <p>
            <code> void operator() () {</code>
          </p>
          <p>
            <code>  for(unsigned j = 0; j &lt; 1000000; ++j) {</code>
          </p>
          <p>
            <code>   do_something(i); &#8592;&#9488;</code>
            <strong>Потенциальный доступ</strong>
          </p>
          <p><code>  }                 </code> <strong>(1) к висячей ссылке</strong></p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>void oops() {</code>
          </p>
          <p>
            <code> int some_local_state = 0;        </code>
            <strong>(2) He ждем завершения</strong>
          </p>
          <p>
            <code> func my_func(some_local_state); &#8592;&#9496;</code>
            <strong>потока</strong>
          </p>
          <p>
            <code> std::thread my_thread(my_func); &#8592;&#9488;</code>
            <strong>Новый поток, возможно,</strong>
          </p>
          <p>
            <code> my_thread.detach();             </code>
            <strong> (3) еще работает</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В данном случае вполне возможно, что новый поток, ассоциированный с объектом <code>my_thread</code>, будет еще работать, когда функция <code>oops</code> вернет управление <strong>(2)</strong>, поскольку мы явно решили не дожидаться его завершения, вызвав <code>detach()</code> <strong>(3)</strong>. А если поток <emphasis>действительно</emphasis> работает, то при следующем вызове <code>do_something(i)</code> <strong>(1)</strong> произойдет обращение к уже уничтоженной переменной. Точно так же происходит в обычном однопоточном коде — сохранять указатель или ссылку на локальную переменную после выхода из функции всегда плохо, — но в многопоточном коде такую ошибку сделать проще, потому что не сразу видно, что произошло.</p>
          <p>Один из распространенных способов разрешить такую ситуацию — сделать функцию потока замкнутой, то есть <emphasis>копировать</emphasis> в поток данные, а не разделять их. Если функция потока реализовала в виде вызываемого объекта, то сам этот объект копируется в поток, поэтому исходный объект можно сразу же уничтожить. Однако по-прежнему необходимо следить за тем, чтобы объект не содержал ссылок или указателей, как в листинге 2.1. В частности, не стоит создавать внутри функции поток, имеющий доступ к локальным переменным этой функции, если нет гарантии, что поток завершится до выхода из функции.</p>
          <p>Есть и другой способ — явно гарантировать, что поток завершит исполнение до выхода из функции, <emphasis>присоединившись</emphasis> к нему.</p>
        </section>
        <section>
          <title>
            <p>2.1.2. Ожидание завершения потока</p>
          </title>
          <p>Чтобы дождаться завершения потока, следует вызвать функцию <code>join()</code> ассоциированного объекта <code>std::thread</code>. В листинге 2.1 мы можем заменить вызов <code>my_thread.detach()</code> перед закрывающей скобкой тела функции вызовом <code>my_thread.join()</code>, и тем самым гарантировать, что поток завершится до выхода из функции, то есть раньше, чем будут уничтожены локальные переменные. В данном случае это означает, что запускать функцию в отдельном потоке не имело смысла, так как первый поток в это время ничего не делает, по в реальной программе исходный поток мог бы либо сам делать что-то полезное, либо запустить несколько потоков параллельно, а потом дождаться их всех.</p>
          <p>Функция <code>join()</code> дает очень простую и прямолинейную альтернативу — либо мы ждем завершения потока, либо нет. Если необходим более точный контроль над ожиданием потока, например если необходимо проверить, завершился ли поток, или ждать только ограниченное время, то следует прибегнуть к другим механизмам, таким, как условные переменные и будущие результаты, которые мы будем рассматривать в главе 4. Кроме тот, при вызове <code>join()</code> очищается вся ассоциированная с потоком память, так что объект <code>std::thread</code> более не связан с завершившимся потоком — он вообще не связан ни с каким потоком. Это значит, что для каждого потока вызвать функцию <code>join()</code> можно только один раз; после первого вызова объект <code>std::thread</code> уже не допускает присоединения, и функция <code>joinable()</code> возвращает <code>false</code>.</p>
        </section>
        <section>
          <title>
            <p>2.1.3. Ожидание в случае исключения</p>
          </title>
          <p>Выше уже отмечалось, что функцию <code>join()</code> или <code>detach()</code> необходимо вызвать до уничтожения объекта <code>std::thread</code>. Если вы хотите отсоединить поток, то обычно достаточно вызвать <code>detach()</code> сразу после его запуска, так что здесь проблемы не возникает. Но если вы собираетесь дождаться завершения потока, то надо тщательно выбирать место, куда поместить вызов <code>join()</code>. Важно, чтобы из-за исключения, произошедшего между запуском потока и вызовом <code>join()</code>, не оказалось, что обращение к <code>join()</code> вообще окажется пропущенным.</p>
          <p>Чтобы приложение не завершилось аварийно при возникновении исключения, необходимо решить, что делать в этом случае. Вообще говоря, если вы намеревались вызвать функцию <code>join()</code> при нормальном выполнении программы, то следует вызывать ее и в случае исключения, чтобы избежать проблем, связанных с временем жизни. В листинге 2.2 приведен простой способ решения этой задачи.</p>
          <empty-line/>
          <p><strong>Листинг 2.2.</strong> Ожидание завершения потока</p>
          <p>
            <code>struct func; &#8592;&#9488;</code>
            <strong>см. определение</strong>
          </p>
          <p>
            <code>              &#9474;</code>
            <strong>в листинге 2.1</strong>
          </p>
          <p>
            <code>void f() {</code>
          </p>
          <p>
            <code> int some_local_state = 0;</code>
          </p>
          <p>
            <code> func my_func(some_local_state)</code>
          </p>
          <p>
            <code> std::thread t(my_func);</code>
          </p>
          <p>
            <code> try {</code>
          </p>
          <p>
            <code>  do_something_in_current_thread()</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> catch(...) {</code>
          </p>
          <p>
            <code>  t.join(); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  throw;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> t.join();  &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В листинге 2.2 блок <code>try</code>/<code>catch</code> используется для того, чтобы поток, имеющий доступ к локальному состоянию, гарантированно завершился до выхода из функции вне зависимости оттого, происходит выход нормально <strong>(2)</strong> или вследствие исключения <strong>(1)</strong>. Записывать блоки <code>try</code>/<code>catch</code> очень долго и при этом легко допустить ошибку, поэтому такой способ не идеален. Если необходимо гарантировать, что поток завершается до выхода из функции потому ли, что он хранит ссылки на локальные переменные, или по какой-то иной причине то важно обеспечить это на всех возможных путях выхода, как нормальных, так и в результате исключения, и хотелось бы иметь для этого простой и лаконичный механизм.</p>
          <p>Один из способов решить эту задачу воспользоваться стандартной идиомой <emphasis>захват ресурса есть инициализация</emphasis> (RAII) и написать класс, который вызывает <code>join()</code> в деструкторе, например, такой, как в листинге 2.3. Обратите внимание, насколько проще стала функция <code>f()</code>.</p>
          <empty-line/>
          <p><strong>Листинг 2.3.</strong> Использование идиомы RAII для ожидания завершения потока</p>
          <p>
            <code>class thread_guard {</code>
          </p>
          <p>
            <code> std::threads t;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> explicit thread_guard(std::thread&amp; t_) : t(t_) {}</code>
          </p>
          <p>
            <code> ~thread_guard() {</code>
          </p>
          <p>
            <code>  if (t.joinable()) &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  {</code>
          </p>
          <p>
            <code>   t.join();        &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> thread_guard(thread_guard const&amp;)=delete; &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> thread_guard&amp; operator=(thread_guard const&amp;)=delete;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>struct func; &#8592;&#9488;</code>
            <strong>см.определение</strong>
          </p>
          <p>
            <code>              &#9474;</code>
            <strong>в листинге 2.1</strong>
          </p>
          <p>
            <code>void f() {</code>
          </p>
          <p>
            <code> int some_local_state;</code>
          </p>
          <p>
            <code> std::thread t(func(some_local_state));</code>
          </p>
          <p>
            <code> thread_guard g(t);</code>
          </p>
          <p>
            <code> do_something_in_current_thread();</code>
          </p>
          <p>
            <code>}             &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>Когда текущий поток доходит до конца <code>f</code> <strong>(4)</strong>, локальные объекты уничтожаются в порядке, обратном тому, в котором были сконструированы. Следовательно, сначала уничтожается объект <code>g</code> типа <code>thread_guard</code>, и в его деструкторе <strong>(2)</strong> происходит присоединение к потоку Это справедливо даже в том случае, когда выход из функции <code>f</code> произошел в результате исключения внутри функции <code>do_something_in_current_thread</code>.</p>
          <p>Деструктор класса <code>thread_guard</code> в листинге 2.3 сначала проверяет, что объект <code>std::thread</code> находится в состоянии <code>joinable()</code> <strong>(1)</strong> и, лишь если это так, вызывает <code>join()</code> <strong>(2)</strong>. Это существенно, потому что функцию <code>join()</code> можно вызывать только один раз для данного потока, так что если он уже присоединился, то делать это вторично было бы ошибкой.</p>
          <p>Копирующий конструктор и копирующий оператор присваивания помечены признаком <code>=delete</code> <strong>(3)</strong>, чтобы компилятор не генерировал их автоматически: копирование или присваивание такого объекта таит в себе опасность, поскольку время жизни копии может оказаться дольше, чем время жизни присоединяемого потока. Но раз эти функции объявлены как «удаленные», то любая попытка скопировать объект типа <code>thread_guard</code> приведет к ошибке компиляции. Дополнительные сведения об удаленных функциях см. в приложении А, раздел А.2.</p>
          <p>Если ждать завершения потока не требуется, то от проблемы безопасности относительно исключений можно вообще уйти, отсоединив поток. Тем самым связь потока с объектом <code>std::thread</code> разрывается, и при уничтожении объекта <code>std::thread</code> функция <code>std::terminate()</code> не будет вызвана. Но отсоединенный поток по-прежнему работает — в фоновом режиме.</p>
        </section>
        <section>
          <title>
            <p>2.1.4. Запуск потоков в фоновом режиме</p>
          </title>
          <p>Вызов функции-члeнa <code>detach()</code> объекта <code>std::thread</code> оставляет поток работать в фоновом режиме, без прямых способов коммуникации с ним. Теперь ждать завершения потока не получится — после того как поток отсоединен, уже невозможно получить ссылающийся на него объект <code>std::thread</code>, для которого можно было бы вызвать <code>join()</code>. Отсоединенные потоки действительно работают в фоне: отныне ими владеет и управляет библиотека времени выполнения С++, которая обеспечит корректное освобождение связанных с потоком ресурсов при его завершении.</p>
          <p>Отсоединенные потоки часто называют <emphasis>потоками-демонами</emphasis> по аналогии с <emphasis>процессами-демонами</emphasis> в UNIX, то есть с процессами, работающими в фоновом режиме и не имеющими явного интерфейса с пользователем. Обычно такие потоки работают в течение длительного времени, в том числе на протяжении всего времени жизни приложения. Они, например, могут следить за состоянием файловой системы, удалять неиспользуемые записи из кэша или оптимизировать структуры данных. С другой стороны, иногда отсоединенный поток применяется, когда существует какой-то другой способ узнать о его завершении или в случае, когда нужно запустить задачу и «забыть» о ней.</p>
          <p>В разделе 2.1.2 мы уже видели, что для отсоединения потока следует вызвать функцию-член <code>detach()</code> объекта <code>std::thread</code>. После возврата из этой функции объект <code>std::thread</code> уже не связан ни с каким потоком, и потому присоединиться к нему невозможно.</p>
          <p>
            <code>std::thread t(do_background_work);</code>
          </p>
          <p>
            <code>t.detach();</code>
          </p>
          <p>
            <code>assert(!t.joinable());</code>
          </p>
          <p>Разумеется, чтобы отсоединить поток от объекта <code>std::thread</code>, поток должен существовать: нельзя вызвать <code>detach()</code> для объекта <code>std::thread</code>, с которым не связан никакой поток. Это то же самое требование, которое предъявляется к функции <code>join()</code>, поэтому и проверяется оно точно так же — вызывать <code>t.detach()</code> для объекта <code>t</code> типа <code>std::thread</code> можно только тогда, когда <code>t.joinable()</code> возвращает <code>true</code>.</p>
          <p>Возьмем в качестве примера текстовый редактор, который умеет редактировать сразу несколько документов. Реализовать его можно разными способами — как на уровне пользовательского интерфейса, так и с точки зрения внутренней организации. В настоящее время все чаще для этой цели используют несколько окон верхнего уровня, по одному для каждого редактируемого документа. Хотя эти окна выглядят совершенно независимыми, в частности, у каждого есть свое меню и все прочее, на самом деле они существуют внутри единственного экземпляра приложения. Один из подходов к внутренней организации программы заключается в том, чтобы запускать каждое окно в отдельном потоке: каждый такой поток исполняет один и тот же код, но с разными данными, описывающими редактируемый документ и соответствующее ему окно. Таким образом, чтобы открыть еще один документ, необходимо создать новый поток. Потоку, обрабатывающему запрос, нет дела до того, когда созданный им поток завершится, потому что он работает над другим, независимым документом. Вот типичная ситуация, когда имеет смысл запускать отсоединенный поток.</p>
          <p>В листинге 2.4 приведен набросок кода, реализующего этот подход.</p>
          <empty-line/>
          <p><strong>Листинг 2.4.</strong> Отсоединение потока для обработки другого документа</p>
          <p>
            <code>void edit_document(std::string const&amp; filename) {</code>
          </p>
          <p>
            <code> open_document_and_display_gui(filename);</code>
          </p>
          <p>
            <code> while(!done_editing()) {</code>
          </p>
          <p>
            <code>  user_command cmd = get_user_input();</code>
          </p>
          <p>
            <code>  if (cmd.type == open_new_document) {</code>
          </p>
          <p>
            <code>   std::string const new_name = get_filename_from_user();</code>
          </p>
          <p>
            <code>   std::thread t(edit_document,new_name); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>   t.detach(); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  else {</code>
          </p>
          <p>
            <code>   process_user_input(cmd);</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Когда пользователь открывает новый документ, мы спрашиваем, какой документ открыть, затем запускаем поток, в котором этот документ открывается <strong>(1)</strong>, и отсоединяем его <strong>(2)</strong>. Поскольку новый поток делает то же самое, что текущий, только с другим файлом, то мы можем использовать ту же функцию (<code>edit_document</code>), передав ей в качестве аргумента имя только что выбранного файла.</p>
          <p>Этот пример демонстрирует также, почему бывает полезно передавать аргументы функции потока: мы передаем конструктору объекта <code>std::thread</code> не только имя функции <strong>(1)</strong>, но и её параметр — имя файла. Существуют другие способы добиться той же цели, например, использовать не обычную функцию с параметрами, а объект-функцию с данными-членами, но библиотека предлагает и такой простой механизм.</p>
        </section>
      </section>
      <section>
        <title>
          <p>2.2. Передача аргументов функции потока</p>
        </title>
        <p>Из листинга 2.4 видно, что по существу передача аргументов вызываемому объекту или функции сводится просто к передаче дополнительных аргументов конструктору <code>std::thread</code>. Однако важно иметь в виду, что по умолчанию эти аргументы <emphasis>копируются</emphasis> в память объекта, где они доступны вновь созданному потоку, причем так происходит даже в том случае, когда функция ожидает на месте соответствующего параметра ссылку. Вот простой пример:</p>
        <p>
          <code>void f(int i, std::string const&amp; s);</code>
        </p>
        <p>
          <code>std::thread t(f, 3, "hello");</code>
        </p>
        <p>Здесь создается новый ассоциированный с объектом <code>t</code> поток, в котором вызывается функция <code>f(3, "hello")</code>. Отметим, что функция <code>f</code> принимает в качестве второго параметра объект типа <code>std::string</code>, но мы передаем строковый литерал <code>char const*</code>, который преобразуется к типу <code>std::string</code> уже в контексте нового потока. Это особенно важно, когда переданный аргумент является указателем на автоматическую переменную, как в примере ниже:</p>
        <p>
          <code>void f(int i, std::string const&amp; s);</code>
        </p>
        <empty-line/>
        <p>
          <code>void oops(int some_param) {</code>
        </p>
        <p>
          <code> char buffer[1024];           &#8592;</code>
          <strong>(1)</strong>
        </p>
        <p>
          <code> sprintf(buffer, "%i", some_param);</code>
        </p>
        <p>
          <code><strong> std::thread t(f, 3, buffer);</strong> &#8592;</code>
          <strong>(2)</strong>
        </p>
        <p>
          <code> t.detach();</code>
        </p>
        <p>
          <code>}</code>
        </p>
        <p>В данном случае в новый поток передается <strong>(2)</strong> указатель на локальную переменную <code>buffer</code> <strong>(1)</strong>, и есть все шансы, что выход из функции oops произойдет раньше, чем буфер будет преобразован к типу <code>std::string</code> в новом потоке. В таком случае мы получим неопределенное поведение. Решение заключается в том, чтобы выполнить преобразование в <code>std::string</code> <emphasis>до</emphasis> передачи <code>buffer</code> конструктору <code>std::thread</code>:</p>
        <p>
          <code>void f(int i,std::string const&amp; s);</code>
        </p>
        <empty-line/>
        <p>
          <code>void not_oops(int some_param) {</code>
        </p>
        <p>
          <code> char buffer[1024];                         &#9474;</code>
          <strong>Использование</strong>
        </p>
        <p>
          <code> sprintf(buffer, "%i", some_param);         &#9474;</code>
          <strong>std::string</strong>
        </p>
        <p>
          <code><strong> std::thread t(f, 3, std::string(buffer));</strong> &#8592;&#9496;</code>
          <strong>позволяет избежать</strong>
        </p>
        <p><code> t.detach();                                 </code> <strong>висячего указателя</strong></p>
        <p>
          <code>}</code>
        </p>
        <p>В данном случае проблема была в том, что мы положились на неявное преобразование указателя на <code>buffer</code> к ожидаемому типу первого параметра <code>std::string</code>, а конструктор <code>std::thread</code> копирует переданные значения «как есть», без преобразования к ожидаемому типу аргумента.</p>
        <p>Возможен и обратный сценарий: копируется весь объект, а вы хотели бы получить ссылку Такое бывает, когда поток обновляет структуру данных, переданную по ссылке, например:</p>
        <p>
          <code>void update_data_for_widget(widget_id w,widget_data&amp; data); &#8592;</code>
          <strong>(1)</strong>
        </p>
        <empty-line/>
        <p>
          <code>void oops_again(widget_id w) {</code>
        </p>
        <p>
          <code> widget_data data;</code>
        </p>
        <p>
          <code> std::thread t(update_data_for_widget, w, data); &#8592;</code>
          <strong>(2)</strong>
        </p>
        <p>
          <code> display_status();</code>
        </p>
        <p>
          <code> t.join();</code>
        </p>
        <p>
          <code> process_widget_data(data);                      &#8592;</code>
          <strong>(3)</strong>
        </p>
        <p>
          <code>}</code>
        </p>
        <p>Здесь <code>update_data_for_widget</code> <strong>(1)</strong> ожидает, что второй параметр будет передан по ссылке, но конструктор <code>std::thread</code> <strong>(2)</strong> не знает об этом: он не в курсе того, каковы типы аргументов, ожидаемых функцией, и просто слепо копирует переданные значения. Поэтому функции <code>update_data_for_widget</code> будет передана ссылка на внутреннюю копию <code>data</code>, а не на сам объект <code>data</code>. Следовательно, по завершении потока от обновлений ничего не останется, так как внутренние копии переданных аргументов уничтожаются, и функция <code>process_widget_data</code> получит не обновленные данные, а исходный объект <code>data</code> <strong>(3)</strong>. Для читателя, знакомого с механизмом <code>std::bind</code>, решение очевидно: нужно обернуть аргументы, которые должны быть ссылками, объектом <code>std::ref</code>. В данном случае, если мы напишем</p>
        <p>
          <code>std::thread t(update_data_for_widget, w, <strong>std::ref(data)</strong>);</code>
        </p>
        <p>то функции <code>update_data_for_widget</code> будет правильно передана ссылка на <code>data</code>, а не <emphasis>копия</emphasis> data.</p>
        <p>Если вы знакомы с <code>std::bind</code>, то семантика передачи параметров вряд ли вызовет удивление, потому что работа конструктора <code>std::thread</code> и функции <code>std::bind</code> определяется в терминах одного и того же механизма. Это, в частности, означает, что в качестве функции можно передавать указатель на функцию-член при условии, что в первом аргументе передается указатель на правильный объект:</p>
        <p>
          <code>class X {</code>
        </p>
        <p>
          <code>public:</code>
        </p>
        <p>
          <code> void do_lengthy_work();</code>
        </p>
        <p>
          <code>};</code>
        </p>
        <empty-line/>
        <p>
          <code>X my_x;</code>
        </p>
        <p>
          <code>std::thread t(&amp;X::do_lengthy_work, &amp;my_x); &#8592;</code>
          <strong>(1)</strong>
        </p>
        <p>Здесь мы вызываем <code>my_x.do_lengthy_work()</code> в новом потоке, поскольку в качестве указателя на объект передан адрес <code>my_x</code> <strong>(1)</strong>. Так вызванной функции-члену можно передавать и аргументы: третий аргумент конструктора <code>std::thread</code>  станет первым аргументом функции-члена и т.д.</p>
        <p>Еще один интересный сценарий возникает, когда передаваемые аргументы нельзя копировать, а можно только <emphasis>перемещать</emphasis>: данные, хранившиеся в одном объекте, переносятся в другой, а исходный объект остается «пустым». Примером может служить класс <code>std::unique_ptr</code>, который обеспечивает автоматическое управление памятью для динамически выделенных объектов. В каждый момент времени на данный объект может указывать только один экземпляр <code>std::unique_ptr</code>, и, когда этот экземпляр уничтожается, объект, на который он указывает, удаляется. <emphasis>Перемещающий конструктор</emphasis> и <emphasis>перемещающий оператор присваивания</emphasis> позволяют передавать владение объектом от одного экземпляра <code>std::unique_ptr</code> другому (о семантике перемещения см. приложение А, раздел А.1.1). После такой передачи в исходном экземпляре остается указатель NULL. Подобное перемещение значений дает возможность передавать такие объекты в качестве параметров функций или возвращать из функций. Если исходный объект временный, то перемещение производится автоматически, а если это именованное значение, то передачу владения следует запрашивать явно, вызывая функцию <code>std::move()</code>. В примере ниже показано применение функции <code>std::move</code> для передачи владения динамическим объектом потоку:</p>
        <p>
          <code>void process_big_object(std::unique_ptr&lt;big_object&gt;);</code>
        </p>
        <empty-line/>
        <p>
          <code>std::unique_ptr&lt;big_object&gt; p(new big_object);</code>
        </p>
        <p>
          <code>p-&gt;prepare_data(42);</code>
        </p>
        <p>
          <code>std::thread t(process_big_object,std::move(p));</code>
        </p>
        <p>Поскольку мы указали при вызове конструктора <code>std::thread</code> функцию <code>std::move</code>, то владение объектом <code>big_object</code> передается объекту во внутренней памяти вновь созданного потока, а затем функции <code>process_big_object</code>.</p>
        <p>В стандартной библиотеке Thread Library есть несколько классов с такой же семантикой владения, как у <code>std::unique_ptr</code>, и <code>std::thread</code> — один из них. Правда, экземпляры <code>std::thread</code> не владеют динамическими объектами, как <code>std::unique_ptr</code>, зато они владеют ресурсами: каждый экземпляр отвечает за управление потоком выполнения. Это владение можно передавать от одного экземпляра другому, поскольку экземпляры <code>std::thread</code> <emphasis>перемещаемые</emphasis>, хотя и не <emphasis>копируемые</emphasis>. Тем самым гарантируется, что в каждый момент времени с данным потоком будет связан только один объект, но в то же время программист вправе передавать владение от одного объекта другому</p>
      </section>
      <section>
        <title>
          <p>2.3. Передача владения потоком</p>
        </title>
        <p>Предположим, что требуется написать функцию для создания потока, который должен работать в фоновом режиме, но при этом мы не хотим ждать его завершения, а хотим, чтобы владение новым потоком было передано вызывающей функции. Или требуется сделать обратное — создать поток и передать владение им некоторой функции, которая будет ждать его завершения. В обоих случаях требуется передать владение из одного места в другое.</p>
        <p>Именно здесь и оказывается полезной поддержка классом <code>std::thread</code> семантики перемещения. В предыдущем разделе отмечалось, что в стандартной библиотеке С++ есть много типов, владеющих ресурсами, например <code>std::ifstream</code> и <code>std::unique_ptr</code>, которые являются <emphasis>перемещаемыми</emphasis>, но не копируемыми, и один из них — <code>std::thread</code>. Это означает, что владение потоком можно передавать от одного экземпляра <code>std::thread</code> другому, как показано в примере ниже. В нем создается два потока выполнения, владение которыми передается между тремя объектами <code>std::thread</code>: <code>t1</code>, <code>t2</code> и <code>t3</code>.</p>
        <p>
          <code>void some_function();</code>
        </p>
        <p>
          <code>void some_other_function();</code>
        </p>
        <empty-line/>
        <p>
          <code>std::thread t1(some_function);         &#8592;</code>
          <strong>(1)</strong>
        </p>
        <p>
          <code>std::thread t2 = std::move(t1);        &#8592;</code>
          <strong>(2)</strong>
        </p>
        <p>
          <code>t1 = std::thread(some_other_function); &#8592;</code>
          <strong>(3)</strong>
        </p>
        <p>
          <code>std::thread t3;     &#8592;</code>
          <strong>(4)</strong>
        </p>
        <p>
          <code>t3 = std::move(t2); &#8592;</code>
          <strong>(5)</strong>
        </p>
        <p>
          <code>t1 = std::move(t3); &#8592;</code>
          <strong>(6) Это присваивание приводит</strong>
        </p>
        <p>
          <code>;                       </code>
          <strong>к аварийному завершению программы</strong>
        </p>
        <p>Сначала создастся новый поток <strong>(1)</strong> и связывается с объектом <code>t1</code>. Затем владение явно передается объекту <code>t2</code> в момент его конструирования путем вызова <code>std::move()</code> <strong>(2)</strong>. В этот момент с <code>t1</code> уже не связан никакой поток выполнения: поток, в котором исполняется функция <code>some_function</code>, теперь связан с <code>t2</code>.</p>
        <p>Далее создается еще один поток, который связывается с временным объектом типа <code>std::thread</code> <strong>(3)</strong>. Для последующей передачи владения объекту <code>t1</code> уже не требуется явный вызов <code>std::move()</code>, так как владельцем является временный объект, а передача владения от временных объектов производится автоматически и неявно.</p>
        <p>Объект <code>t3</code> конструируется по умолчанию <strong>(4)</strong>, а это означает, что в момент создания с ним не связывается никакой поток. Владение потоком, который в данный момент связан с <code>t2</code>, передастся объекту <code>t3</code> <strong>(5)</strong>, опять-таки путем явного обращения к <code>std::move()</code>, поскольку <code>t2</code> — именованный объект. После всех этих перемещений <code>t1</code> оказывается связан с потоком, исполняющим функцию <code>some_other_function</code>, <code>t2</code> не связан ни с каким потоком, a <code>t3</code> связан с потоком, исполняющим функцию <code>some_function</code> .</p>
        <p>Последнее перемещение <strong>(6)</strong> передает владение потоком, исполняющим <code>some_function</code>, обратно объекту <code>t1</code>, в котором исполнение этой функции началось. Однако теперь с <code>t1</code> уже связан поток (который исполнял функцию <code>some_other_function</code>), поэтому вызывается <code>std::terminate()</code>, и программа завершается. Так делается ради совместимости с поведением деструктора <code>std::thread</code>. В разделе 2.1.1 мы видели, что нужно либо явно ждать завершения потока, либо отсоединить его до момента уничтожения; то же самое относится и к присваиванию: нельзя просто «прихлопнуть» поток, присвоив новое значение объекту <code>std::thread</code>, который им управляет.</p>
        <p>Поддержка операции перемещения в классе <code>std::thread</code> означает, что владение можно легко передать при возврате из функции, как показано в листинге 2.5.</p>
        <empty-line/>
        <p><strong>Листинг 2.5.</strong> Возврат объекта <code>std::thread</code> из функции</p>
        <p>
          <code>std::thread f() {</code>
        </p>
        <p>
          <code> void some_function();</code>
        </p>
        <p>
          <code> return std::thread(some_function);</code>
        </p>
        <p>
          <code>}</code>
        </p>
        <empty-line/>
        <p>
          <code>std::thread g() {</code>
        </p>
        <p>
          <code> void some_other_function(int);</code>
        </p>
        <p>
          <code> std::thread t(some_other_function, 42);</code>
        </p>
        <p>
          <code> return t;</code>
        </p>
        <p>
          <code>}</code>
        </p>
        <p>Аналогично, если требуется передать владение внутрь функции, то достаточно, чтобы она принимала экземпляр <code>std::thread</code> по значению в качестве одного из параметров, например:</p>
        <p>
          <code>void f(std::thread t);</code>
        </p>
        <empty-line/>
        <p>
          <code>void g() {</code>
        </p>
        <p>
          <code> void some_function();</code>
        </p>
        <p>
          <code> f(std::thread(some_function));</code>
        </p>
        <p>
          <code> std::thread t(some_function);</code>
        </p>
        <p>
          <code> f(std::move(t));</code>
        </p>
        <p>
          <code>}</code>
        </p>
        <p>Одно из преимуществ, которые даёт поддержка перемещения в классе <code>std::thread</code>, заключается в том, что мы можем модифицировать класс <code>thread_guard</code> из листинга 2.3, так чтобы он принимал владение потоком. Это позволит избежать неприятностей в случае, когда время жизни объекта <code>thread_guard</code> оказывает больше, чем время жизни потока, на который он ссылается, а, кроме того, это означает, что никто другой не сможет присоединиться к потоку или отсоединить его, так как владение было передано объекту <code>thread_guard</code>. Поскольку основное назначение этого класса гарантировать завершение потока до выхода из области видимости, я назвал его <code>scoped_thread</code>. Реализация и простой пример использования приведены в листинге 2.6.</p>
        <empty-line/>
        <p><strong>Листинг 2.6.</strong> Класс <code>scoped_thread</code> и пример его использования</p>
        <p>
          <code>class scoped_thread {</code>
        </p>
        <p>
          <code> std::thread t;</code>
        </p>
        <p>
          <code>public:</code>
        </p>
        <p>
          <code> explicit scoped_thread(std::thread t_) : &#8592;</code>
          <strong>(1)</strong>
        </p>
        <p>
          <code> t(std::move(t_)) {</code>
        </p>
        <p>
          <code> if (!t.joinable()) &#8592;</code>
          <strong>(2)</strong>
        </p>
        <p>
          <code>  throw std::logic_error("No thread");</code>
        </p>
        <p>
          <code> }</code>
        </p>
        <p>
          <code> ~scoped_thread() {</code>
        </p>
        <p>
          <code>  t.join();         &#8592;</code>
          <strong>(3)</strong>
        </p>
        <p>
          <code> }</code>
        </p>
        <p>
          <code> scoped_thread(scoped_thread const&amp;)=delete;</code>
        </p>
        <p>
          <code> scoped_thread&amp; operator=(scoped_thread const&amp;)=delete;</code>
        </p>
        <p>
          <code>};</code>
        </p>
        <empty-line/>
        <p>
          <code>struct func; &#8592;</code>
          <strong>см. листинг 2.1</strong>
        </p>
        <empty-line/>
        <p>
          <code>void f() {</code>
        </p>
        <p>
          <code> int some_local_state;</code>
        </p>
        <p>
          <code> scoped_thread t(std::thread(func(some_local_state))); &#8592;</code>
          <strong>(4)</strong>
        </p>
        <p>
          <code> do_something_in_current_thread();</code>
        </p>
        <p>
          <code>}                   &#8592;</code>
          <strong>(5)</strong>
        </p>
        <p>Этот пример очень похож на приведенный в листинге 2.3, только новый поток теперь передается непосредственно конструктору <code>scoped_thread</code> <strong>(4)</strong>, вместо того чтобы создавать для него отдельную именованную переменную. Когда новый поток достигает конца <code>f</code> <strong>(5)</strong>, объект <code>scoped_thread</code> уничтожается, а затем поток соединяется <strong>(3)</strong> с потоком, переданным конструктору <strong>(1)</strong>. Если в классе <code>thread_guard</code> из листинга 2.3 деструктор должен был проверить, верно ли, что поток все еще допускает соединение, то теперь мы можем сделать это в конструкторе <strong>(2)</strong> и возбудить исключение, если это не так.</p>
        <p>Поддержка перемещения в классе <code>std::thread</code> позволяет также хранить объекты этого класса в контейнере при условии, что класс контейнера поддерживает перемещение (как, например, модифицированный класс <code>std::vector&lt;&gt;</code>). Это означает, что можно написать код, показанный в листинге 2.7, который запускает несколько потоков, а потом ждет их завершения.</p>
        <empty-line/>
        <p><strong>Листинг 2.7.</strong> Запуск нескольких потоков и ожидание их завершения</p>
        <p>
          <code>void do_work(unsigned id);</code>
        </p>
        <empty-line/>
        <p>
          <code>void f() {</code>
        </p>
        <p>
          <code> std::vector&lt;std::thread&gt; threads;</code>
        </p>
        <p>
          <code> for (unsigned i = 0; i &lt; 20; ++i) {           &#9474;</code>
          <strong>Запуск</strong>
        </p>
        <p>
          <code>  threads.push_back(std::thread(do_work(i))); &#8592;&#9496;</code>
          <strong>потоков</strong>
        </p>
        <p>
          <code> }                                            &#9474;</code>
          <strong>Поочередный</strong>
        </p>
        <p>
          <code> std::for_each(threads.begin(), threads.end(),&#9474;</code>
          <strong>вызов join()</strong>
        </p>
        <p>
          <code> std::mem_fn(&amp;std::thread::join));           &#8592;&#9496;</code>
          <strong>для каждого потока</strong>
        </p>
        <p>
          <code>}</code>
        </p>
        <p>Если потоки применяются для разбиения алгоритма на части, то зачастую такой подход именно то, что требуется: перед возвратом управления вызывающей программе все потоки должны завершиться. Разумеется, столь простая структура, как в листинге 2.7, предполагает, что каждый поток выполняет независимую работу, а единственным результатом является побочный эффект, заключающийся в изменении разделяемых данных. Если бы функция <code>f()</code> должна была вернуть вызывающей программе значение, зависящее от результатов операций, выполненных в потоках, то при такой организации получить это значение можно было бы только путем анализа разделяемых данных по завершении всех потоков. В главе 4 обсуждаются альтернативные схемы передачи результатов работы из одного потока в другой.</p>
        <p>Хранение объектов <code>std::thread</code> в векторе <code>std::vector</code> — шаг к автоматизации управления потоками: вместо тот чтобы создавать отдельные переменные для потоков и выполнять соединение напрямую, мы можем рассматривать группу потоков. Можно пойти еще дальше и создавать не фиксированное число потоков, как в листинге 2.7, а определять нужное количество динамически, во время выполнения.</p>
      </section>
      <section>
        <title>
          <p>2.4. Задание количества потоков во время выполнения</p>
        </title>
        <p>В стандартной библиотеке С++ есть функция <code>std::thread::hardware_concurrency()</code>, которая поможет нам решить эту задачу. Она возвращает число потоков, которые могут работать по-настоящему параллельно. В многоядерной системе это может быть, например, количество процессорных ядер. Возвращаемое значение всего лишь оценка; более того, функция может возвращать 0, если получить требуемую информацию невозможно. Однако эту оценку можно с пользой применить для разбиения задачи на несколько потоков.</p>
        <p>В листинге 2.8 приведена простая реализация параллельной версии <code>std::accumulate</code>. Она распределяет работу между несколькими потоками и, чтобы не создавать слишком много потоков, задает ограничение снизу на количество элементов, обрабатываемых одним потоком. Отмстим, что в этой реализации предполагается, что ни одна операция не возбуждает исключений, хотя в принципе исключения возможны; например, конструктор <code>std::thread</code> возбуждает исключение, если не может создать новый поток. Но если добавить в этот алгоритм обработку исключений, он перестанет быть таким простым; эту тему мы рассмотрим в главе 8.</p>
        <empty-line/>
        <p><strong>Листинг 2.8.</strong> Наивная реализация параллельной версии алгоритма <code>std::accumulate</code></p>
        <p>
          <code>template&lt;typename Iterator, typename T&gt;</code>
        </p>
        <p>
          <code> struct accumulate_block {</code>
        </p>
        <p>
          <code> void operator()(Iterator first, Iterator last, T&amp; result) {</code>
        </p>
        <p>
          <code>  result = std::accumulate(first, last, result);</code>
        </p>
        <p>
          <code> }</code>
        </p>
        <p>
          <code>};</code>
        </p>
        <empty-line/>
        <p>
          <code>template&lt;typename Iterator, typename T&gt;</code>
        </p>
        <p>
          <code>T parallel_accumulate(Iterator first, Iterator last, T init) {</code>
        </p>
        <p>
          <code> unsigned long const length = std::distance(first, last);</code>
        </p>
        <p>
          <code> if (!length) &#8592;</code>
          <strong>(1)</strong>
        </p>
        <p>
          <code>  return init;</code>
        </p>
        <empty-line/>
        <p>
          <code> unsigned long const min_per_thread = 25;</code>
        </p>
        <p>
          <code> unsigned long const max_threads =</code>
        </p>
        <p>
          <code>  (length+min_per_thread - 1) / min_per_thread; &#8592;</code>
          <strong>(2)</strong>
        </p>
        <empty-line/>
        <p>
          <code> unsigned long const hardware_threads =</code>
        </p>
        <p>
          <code>  std::thread::hardware_concurrency();</code>
        </p>
        <empty-line/>
        <p>
          <code> unsigned long const num_threads = &#8592;</code>
          <strong>(3)</strong>
        </p>
        <p>
          <code>  std::min(</code>
        </p>
        <p>
          <code>   hardware.threads != 0 ? hardware_threads : 2, max_threads);</code>
        </p>
        <empty-line/>
        <p>
          <code> unsigned long const block_size = length / num_threads; &#8592;</code>
          <strong>(4)</strong>
        </p>
        <empty-line/>
        <p>
          <code> std::vector&lt;T&gt; results(num_threads);</code>
        </p>
        <p>
          <code> std::vector&lt;std::thread&gt; threads(num_threads - 1); &#8592;</code>
          <strong>(5)</strong>
        </p>
        <empty-line/>
        <p>
          <code> Iterator block_start = first;</code>
        </p>
        <p>
          <code> for(unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
        </p>
        <p>
          <code>  Iterator block_end = block_start;</code>
        </p>
        <p>
          <code>  std::advance(block_end, block_size); &#8592;</code>
          <strong>(6)</strong>
        </p>
        <empty-line/>
        <p>
          <code>  threads[i] = std::thread( &#8592;</code>
          <strong>(7)</strong>
        </p>
        <p>
          <code>   accumulate_block&lt;Iterator, T&gt;(),</code>
        </p>
        <p>
          <code>   block_start, block_end, std::ref(results(i)));</code>
        </p>
        <p>
          <code>  block_start = block_end;  &#8592;</code>
          <strong>(8)</strong>
        </p>
        <p>
          <code> }</code>
        </p>
        <p>
          <code> accumulate_block()(</code>
        </p>
        <p>
          <code>  block_start, last, results[num_threads-1]); &#8592;</code>
          <strong>(9)</strong>
        </p>
        <empty-line/>
        <p>
          <code> std::for_each(threads.begin(), threads.end(),</code>
        </p>
        <p>
          <code> std::mem_fn(&amp;std::thread::join)); &#8592;</code>
          <strong>(10)</strong>
        </p>
        <empty-line/>
        <p>
          <code> return</code>
        </p>
        <p>
          <code>  std::accumulate(results.begin(), results.end(), init); &#8592;</code>
          <strong>(11)</strong>
        </p>
        <p>
          <code>}</code>
        </p>
        <p>Хотя функция довольно длинная, по существу она очень проста. Если входной диапазон пуст <strong>(1)</strong>, то мы сразу возвращаем начальное значение <code>init</code>. В противном случае диапазон содержит хотя бы один элемент, поэтому мы можем разделить количество элементов на минимальный размер блока и получить максимальное число потоков <strong>(2)</strong>.</p>
        <p>Это позволит избежать создания 32 потоков на 32-ядерной машине, если диапазон состоит всего из пяти элементов.</p>
        <p>Число запускаемых потоков равно минимуму из только что вычисленного максимума и количества аппаратных потоков <strong>(3)</strong>: мы не хотим запускать больше потоков, чем может поддержать оборудование (это называется <emphasis>превышением лимита</emphasis>), так как из-за контекстных переключений при большем количестве потоков производительность снизится. Если функция <code>std::thread::hardware_concurrency()</code> вернула 0, то мы берем произвольно выбранное число, я решил остановиться на 2. Мы не хотим запускать слишком много потоков, потому что на одноядерной машине это только замедлило бы программу. Но и слишком мало потоков тоже плохо, так как это означало бы отказ от возможного параллелизма.</p>
        <p>Каждый поток будет обрабатывать количество элементов, равное длине диапазона, поделенной на число потоков <strong>(4)</strong>. Пусть вас не пугает случай, когда одно число нацело не делится на другое, — ниже мы рассмотрим его.</p>
        <p>Теперь, зная, сколько необходимо потоков, мы можем создать вектор <code>std::vector&lt;T&gt;</code> для хранения промежуточных результатов и вектор <code>std::vector&lt;std::thread&gt;</code> для хранения потоков <strong>(5)</strong>. Отметим, что запускать нужно на один поток меньше, чем <code>num_threads</code>, потому что один поток у нас уже есть.</p>
        <p>Запуск потоков производится в обычном цикле: мы сдвигаем итератор <code>block_end</code> в конец текущего блока <strong>(6)</strong> и запускаем новый поток для аккумулирования результатов по этому блоку <strong>(7)</strong>. Начало нового блока совпадает с концом текущего <strong>(8)</strong>.</p>
        <p>После того как все потоки запущены, главный поток может обработать последний блок <strong>(9)</strong>. Именно здесь обрабатывается случай деления с остатком: мы знаем, что конец последнего блока — <code>last</code>, а сколько в нем элементов, не имеет значения.</p>
        <p>Аккумулировав результаты но последнему блоку, мы можем дождаться завершения всех запущенных потоков с помощью алгоритма <code>std::for_each</code> <strong>(10)</strong>, а затем сложить частичные результаты, обратившись к <code>std::accumulate</code> <strong>(11)</strong>.</p>
        <p>Прежде чем расстаться с этим примером, полезно отметить, что в случае, когда оператор сложения, определенный в типе <code>T</code>, не ассоциативен (например, если <code>T</code> — это <code>float</code> или <code>double</code>), результаты, возвращаемые алгоритмами <code>parallel_accumulate</code> и <code>std::accumulate</code>, могут различаться из-за разбиения диапазона на блоки. Кроме того, к итераторам предъявляются более жесткие требования: они должны быть по меньшей мере <emphasis>однонаправленными</emphasis>, тогда как алгоритм <code>std::accumulate</code> может работать и с однопроходными <emphasis>итераторами ввода</emphasis>. Наконец, тип <code>T</code> должен допускать конструирование по умолчанию (удовлетворять требованиям концепции <emphasis>DefaultConstructible</emphasis>), чтобы можно было создать вектор <code>results</code>. Такого рода изменения требований довольно типичны для параллельных алгоритмов: но самой своей природе они отличаются от последовательных алгоритмов, и это приводит к определенным последствиям в части как результатов, так и требований. Более подробно параллельные алгоритмы рассматриваются в главе 8. Стоит также отметить, что из-за невозможности вернуть значение непосредственно из потока, мы должны передавать ссылку на соответствующий элемент вектора <code>results</code>. Другой способ возврата значений из потоков, <emphasis>с помощью будущих результатов</emphasis>, рассматривается в главе 4.</p>
        <p>В данном случае вся необходимая потоку информация передавалась в момент его запуска <strong>—</strong> в том числе и адрес, но которому необходимо сохранить результат вычисления. Так бывает не всегда; иногда требуется каким-то образом идентифицировать потоки во время работы. Конечно, можно было бы передать какой-то идентификатор, например значение <code>i</code> в листинге 2.7, но если вызов функции, которой этот идентификатор нужен, находится несколькими уровнями стека глубже, и эта функция может вызываться из любого потока, то поступать так неудобно. Проектируя библиотеку С++ Thread Library, мы предвидели этот случай, поэтому снабдили каждый поток уникальным идентификатором.</p>
      </section>
      <section>
        <title>
          <p>2.5. Идентификация потоков</p>
        </title>
        <p>Идентификатор потока имеет тип <code>std::thread::id</code>, и получить его можно двумя способами. Во-первых, идентификатор потока, связанного с объектом <code>std::thread</code>, возвращает функция-член <code>get_id()</code> этого объекта. Если с объектом <code>std::thread</code> не связан никакой поток, то <code>get_id()</code> возвращает сконструированный по умолчанию объект типа <code>std::thread::id</code>, что следует интерпретировать как «не поток». Идентификатор текущего потока можно получить также, обратившись к функции <code>std::this_thread::get_id()</code>, которая также определена в заголовке <code>&lt;thread&gt;</code>.</p>
        <p>Объекты типа <code>std::thread::id</code> можно без ограничений копировать и сравнивать, в противном случае они вряд ли могли бы играть роль идентификаторов. Если два объекта типа <code>std::thread::id равны</code>, то либо они представляют один и тот же поток, либо оба содержат значение «не поток». Если же два таких объекта не равны, то либо они представляют разные потоки, либо один представляет поток, а другой содержит значение «не поток».</p>
        <p>Библиотека Thread Library не ограничивается сравнением идентификаторов потоков на равенство, для объектов типа <code>std::thread::id</code> определен полный спектр операторов сравнения, то есть на множестве идентификаторов потоков задан полный порядок. Это позволяет использовать их в качестве ключей ассоциативных контейнеров, сортировать и сравнивать любым интересующим программиста способом. Поскольку операторы сравнения определяют полную упорядоченность различных значений типа <code>std::thread::id</code>, то их поведение интуитивно очевидно: если <code>a&lt;b</code> и <code>b&lt;c</code> то <code>а&lt;с</code> и так далее. В стандартной библиотеке имеется также класс <code>std::hash&lt;std::thread::id&gt;</code>, поэтому значения типа <code>std::thread::id</code> можно использовать и в качестве ключей новых неупорядоченных ассоциативных контейнеров.</p>
        <p>Объекты <code>std::thread::id</code> часто применяются для того, чтобы проверить, должен ли поток выполнить некоторую операцию. Например, если потоки используются для разбиения задач, как в листинге 2.8, то начальный поток, который запускал все остальные, может вести себя несколько иначе, чем прочие. В таком случае этот поток мог бы сохранить значение <code>std::this_thread::get_id()</code> перед тем, как запускать другие потоки, а затем в основной части алгоритма (общей для всех потоков) сравнить собственный идентификатор с сохраненным значением.</p>
        <p>
          <code>std::thread::id master_thread;</code>
        </p>
        <empty-line/>
        <p>
          <code>void some_core_part_of_algorithm() {</code>
        </p>
        <p>
          <code> if (std::this_thread::get_id() == master_thread) {</code>
        </p>
        <p>
          <code>  do_master_thread_work();</code>
        </p>
        <p>
          <code> }</code>
        </p>
        <p>
          <code> do_common_work();</code>
        </p>
        <p>
          <code>}</code>
        </p>
        <p>Или можно было бы сохранить <code>std::thread::id</code> текущего потока в некоторой структуре данных в ходе выполнения какой-то операции. В дальнейшем при операциях с той же структурой данных можно было сравнить сохраненный идентификатор с идентификатором потока, выполняющего операцию, и решить, какие операции разрешены или необходимы.</p>
        <p>Идентификаторы потоков можно было бы также использовать как ключи ассоциативных контейнеров, если с потоком нужно ассоциировать какие-то данные, а другие механизмы, например поточно-локальная память, не подходят. Например, управляющий поток мог бы сохранить в таком контейнере информацию о каждом управляемом им потоке. Другое применение подобного контейнера — передавать информацию между потоками.</p>
        <p>Идея заключается в том, что в большинстве случаев <code>std::thread::id</code> вполне может служить обобщенным идентификатором потока и лишь, если с идентификатором необходимо связать какую-то семантику (например, использовать его как индекс массива), может потребоваться другое решение. Можно даже выводить объект <code>std::thread::id</code> в выходной поток, например <code>std::cout</code>:</p>
        <p>
          <code>std::cout &lt;&lt; std::this_thread::get_id();</code>
        </p>
        <p>Точный формат вывода зависит от реализации; стандарт лишь гарантирует, что результаты вывода одинаковых идентификаторов потоков будут одинаковы, а разных <strong>—</strong> различаться. Поэтому для отладки и протоколирования это может быть полезно, но так как никакой семантики у значений идентификаторов нет, то сделать на их основе какие-то другие выводы невозможно.</p>
      </section>
      <section>
        <title>
          <p>2.6. Резюме</p>
        </title>
        <p>В этой главе мы рассмотрели основные средства управления потоками, имеющиеся в стандартной библиотеке С++: запуск потоков, ожидание завершения потока и <emphasis>отказ</emphasis> от ожидания вследствие того, что поток работает в фоновом режиме. Мы также научились передавать аргументы функции потока при запуске и передавать ответственность за управление потоком из одной части программы в другую. Кроме того, мы видели, как можно использовать группы потоков для разбиения задачи на части. Наконец, мы обсудили механизм идентификации потоков, позволяющий ассоциировать с потоком данные или поведение в тех случаях, когда использовать другие средства неудобно. Даже совершенно независимые потоки позволяют сделать много полезного, как видно из листинга 2.8, но часто требуется, чтобы работающие потоки обращались к каким-то общим данным. В главе 3 рассматриваются проблемы, возникающие при разделении данных между потоками, а в главе 4 — более общие вопросы синхронизации операций с использованием и без использования разделяемых данных.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Глава 3.</p>
        <p>Разделение данных между потоками</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Проблемы разделения данных между потоками.</p>
        <p>&#9632; Защита данных с помощью мьютексов.</p>
        <p>&#9632; Альтернативные средства защиты разделяемых данных.</p>
      </annotation>
      <section>
        <p>Одно из основных достоинств применения потоков для реализации параллелизма — возможность легко и беспрепятственно разделять между ними данные, поэтому, уже зная, как создавать потоки и управлять ими, мы обратимся к вопросам, связанным с разделением данных.</p>
        <p>Представьте, что вы живете в одной квартире с приятелем. В квартире только одна кухня и только одна ванная. Если ваши отношения не особенно близки, то вряд ли вы будете пользоваться ванной одновременно, поэтому, когда сосед слишком долго занимает ванную, у вас возникает законное недовольство. Готовить два блюда одновременно, конечно, можно, но если у вас духовка совмещена с грилем, то ничего хорошего не выйдет, когда один пытается жарить сосиски, а другой — печь пирожные. Ну и все мы знаем, какую досаду испытываешь, когда, сделав половину работы, обнаруживаешь, что кто-то забрал нужный инструмент или изменил то, что вы уже сделали.</p>
        <p>То же самое и с потоками. Если потоки разделяют какие-то данные, то необходимы правила, регулирующие, какой поток в какой момент к каким данным может обращаться и как сообщить об изменениях другим потокам, использующим те же данные. Легкость, с которой можно разделять данные между потоками в одном процессе, может обернуться не только благословением, но проклятием. Некорректное использование разделяемых данных — одна из основных причин ошибок, связанных с параллелизмом, и последствия могут оказаться куда серьезнее, чем пропахшие сосисками пирожные.</p>
        <p>Эта глава посвящена вопросу о том, как безопасно разделять данные между потоками в программе на С++, чтобы избежать возможных проблем и достичь оптимального результата.</p>
      </section>
      <section>
        <title>
          <p>3.1. Проблемы разделения данных между потоками</p>
        </title>
        <section>
          <p>Все проблемы разделения данных между потоками связаны с последствиями модификации данных. <emphasis>Если разделяемые данные только читаются, то никаких сложностей не возникает, поскольку любой поток может читать данные независимо от того, читают их в то же самое время другие потоки или нет.</emphasis> Но стоит одному или нескольким потокам начать модифицировать разделяемые данные, как могут возникнуть неприятности. В таком случае ответственность за правильную работу ложится на программиста.</p>
          <p>При рассуждениях о поведении программы часто помогает понятие <emphasis>инварианта</emphasis> — утверждения о структуре данных, которое всегда должно быть истинным, например, «значение этой переменной равно числу элементов в списке». В процессе обновления инварианты часто нарушаются, особенно если структура данных сложна или обновление затрагивает несколько значений.</p>
          <p>Рассмотрим двусвязный список, в котором каждый узел содержит указатели на следующий и предыдущий узел. Один из инвариантов формулируется так: если «указатель на следующий» в узле А указывает на узел В, то «указатель на предыдущий» в узле В указывает на узел А. Чтобы удалить узел из списка, необходимо обновить узлы по обе стороны от него, так чтобы они указывали друг на друга. После обновления одного узла инвариант оказывается нарушен и остается таковым, пока не будет обновлен узел по другую сторону. После того как обновление завершено, инвариант снова выполняется.</p>
          <p>Шаги удаления узла из списка показаны на рис. 3.1:</p>
          <p>1. Найти подлежащий удалению узел (<emphasis>N</emphasis>).</p>
          <p>2. Изменить «указатель на следующий» в узле, предшествующем <emphasis>N</emphasis>, так чтобы он указывал на узел, следующий за <emphasis>N</emphasis>.</p>
          <p>3. Изменить «указатель на предыдущий» в узле, следующем за <emphasis>N</emphasis>, так чтобы он указывал на узел, предшествующий <emphasis>N</emphasis>.</p>
          <p>4. Удалить узел <emphasis>N</emphasis>.</p>
          <image l:href="#img_5_novyjjrazmer.png"/>
          <p><strong>Рис. 3.1</strong>. Удаление узла из двусвязного списка</p>
          <p>Как видите, между шагами <strong>b</strong> и <strong>с</strong> указатели в одном направлении не согласуются с указателями в другом направлении, и инвариант нарушается.</p>
          <p>Простейшая проблема, которая может возникнуть при модификации данных, разделяемых несколькими потоками, — нарушение инварианта. Если не предпринимать никаких мер, то в случае, когда один поток читает двусвязный список, а другой в это же время удаляет из списка узел, вполне может случиться, что читающий поток увидит список, из которого узел удален лишь частично (потому что изменен только один указатель, как на шаге <strong>b</strong> на рис. 3.1), так что инвариант нарушен. Последствия могут быть разными — если поток читает список слева направо, то он просто пропустит удаляемый узел. Но если другой поток пытается удалить самый правый узел, показанный на рисунке, то он может навсегда повредить структуру данных, и в конце концов это приведет к аварийному завершению программы. Как бы то ни было, этот пример иллюстрирует одну из наиболее распространенных причин ошибок в параллельном коде: <emphasis>состояние гонки</emphasis> (race condition).</p>
        </section>
        <section>
          <title>
            <p>3.1.1. Гонки</p>
          </title>
          <p>Предположим, вы покупаете билеты в кино. Если кинотеатр большой, то в нем может быть несколько касс, так что в каждый момент времени билеты могут покупать несколько человек. Если кто-то покупает билет на тот же фильм, что и вы, но в другой кассе, то какие места вам достанутся, зависит от того, кто был первым. Если осталось всего несколько мест, то разница может оказаться решающей: за последние билеты возникает гонка в самом буквальном смысле. Это и есть пример <emphasis>состояния гонки</emphasis>: какие места вам достанутся (да и достанутся ли вообще), зависит от относительного порядка двух покупок.</p>
          <p>В параллельном программировании под состоянием гонки понимается любая ситуация, исход которой зависит от относительного порядка выполнения операций в двух или более потоках — потоки конкурируют за право выполнить операции первыми. Как правило, ничего плохого в этом нет, потому что все исходы приемлемы, даже если их взаимный порядок может меняться. Например, если два потока добавляют элементы в очередь для обработки, то вообще говоря неважно, какой элемент будет добавлен первым, лишь бы не нарушались инварианты системы. Проблема возникает, когда гонка приводит к нарушению инвариантов, как в приведенном выше примере удаления из двусвязного списка. В контексте параллельного программирования <emphasis>состоянием гонки</emphasis> обычно называют именно такую <emphasis>проблематичную</emphasis> гонку — безобидные гонки не так интересны и к ошибкам не приводят. В стандарте С++ определен также термин <emphasis>гонка за данными</emphasis> (data race), означающий ситуацию, когда гонка возникает из-за одновременной модификации одного объекта (детали см. в разделе 5.1.2); гонки за данными приводят к внушающему ужас <emphasis>неопределенному поведению</emphasis>.</p>
          <p>Проблематичные состояния гонки обычно возникают, когда для завершения операции необходимо модифицировать два или более элементов данных, например два связующих указателя в примере выше. Поскольку элементов несколько, то их модификация производится разными командами, и может случиться, что другой поток обратится к структуре данных в момент, когда завершилась только одна команда. Зачастую состояние гонки очень трудно обнаружить и воспроизвести, поскольку она происходит в очень коротком интервале времени, — если модификации производятся последовательными командами процессора, то вероятность возникновения проблемы при конкретном прогоне очень мала, даже если к структуре данных одновременно обращается другой поток. По мере увеличения нагрузки на систему и количества выполнений операции вероятность проблематичной последовательности выполнения возрастает. И, разумеется, почти всегда такие ошибки проявляются в самый неподходящий момент. Поскольку состояние гонки так чувствительно ко времени, оно может вообще не возникнуть при запуске приложения под отладчиком, так как отладчик влияет на хронометраж программ, пусть и незначительно.</p>
          <p>При написании многопоточных программ гонки могут изрядно отравить жизнь — своей сложностью параллельные программы в немалой степени обязаны стараниям избежать проблематичных гонок.</p>
        </section>
        <section>
          <title>
            <p>3.1.2. Устранение проблематичных состояний гонки</p>
          </title>
          <p>Существует несколько способов борьбы с проблематичными гонками. Простейший из них - снабдить структуру данных неким защитным механизмом, который гарантирует, что только поток, выполняющий модификацию, может видеть промежуточные состояния, в которых инварианты нарушены; с точки зрения всех остальных потоков, обращающихся к той же структуре данных, модификация либо еще не началась, либо уже завершилась. В стандартной библиотеке С++ есть несколько таких механизмов, и в этой главе мы их опишем.</p>
          <p>Другой вариант — изменить дизайн структуры данных и ее инварианты, так чтобы модификация представляла собой последовательность неделимых изменений, каждое из которых сохраняет инварианты. Этот подход обычно называют <emphasis>программированием без блокировок</emphasis> (lock-free programming) и реализовать его правильно очень трудно; если вы работаете на этом уровне, то приходится учитывать нюансы модели памяти и разбираться, какие потоки потенциально могут увидеть те или иные наборы значений. Модель памяти обсуждается в главе 5, а программирование без блокировок — в главе 7.</p>
          <p>Еще один способ справиться с гонками — рассматривать изменения структуры данных как <emphasis>транзакцию</emphasis>, то есть так, как обрабатываются обновления базы данных внутри транзакции. Требуемая последовательность изменений и чтений данных сохраняется в журнале транзакций, а затем атомарно фиксируется. Если фиксация невозможна, потому что структуру данных в это время модифицирует другой поток, то транзакция перезапускается. Это решение называется <emphasis>программной транзакционной памятью</emphasis> (Software Transactional Memory — STM), в настоящее время в этой области ведутся активные исследования. Мы не будем рассматривать STM в этой книге, потому что в С++ для нее нет поддержки. Однако к самой идее о том, чтобы выполнить какую-то последовательность действий и за один шаг зафиксировать результаты, я еще вернусь.</p>
          <p>Самый простой механизм защиты разделяемых данных из описанных в стандарте С++ — это <emphasis>мьютекс,</emphasis> с него мы и начнем рассмотрение.</p>
        </section>
      </section>
      <section>
        <title>
          <p>3.2. Защита разделяемых данных с помощью мьютексов</p>
        </title>
        <section>
          <p>Итак, у нас есть разделяемая структура данных, например связанный список из предыдущего раздела, и мы хотим защитить его от гонки и нарушения инвариантов, к которым она приводит. Как было бы здорово, если бы мы могли пометить участки кода, в которых производятся обращения к этой структуре данных, <emphasis>взаимно исключающими</emphasis>, так что если один поток начинает выполнять такой участок, то все остальные потоки должны ждать, пока первый не завершит обработку данных. Тогда ни один поток, кроме выполняющего модификацию, не смог бы увидеть нарушенный инвариант.</p>
          <p>Что ж, это вовсе не сказка — именно такое поведение вы получаете при использовании примитива синхронизации, который называется <emphasis>мьютекс</emphasis> (слово mutex происходит от mutual exclusion — взаимное исключение). Перед тем как обратиться к структуре данных, программа <emphasis>захватывает</emphasis> (lock) мьютекс, а по завершении операций с ней <emphasis>освобождает</emphasis> (unlock) его. Библиотека Thread Library гарантирует, что если один поток захватил некоторый мьютекс, то все остальные потоки, пытающиеся захватить тот же мьютекс, будут вынуждены ждать, пока удачливый конкурент не освободит его. В результате все потоки видят согласованное представление разделяемых данных, без нарушенных инвариантов.</p>
          <p>Мьютексы — наиболее общий механизм защиты данных в С++, но панацеей они не являются; важно структурировать код так, чтобы защитить нужные данные (см. раздел 3.2.2), и избегать состояний гонки, внутренне присущих интерфейсам (см раздел 3.2.3). С мьютексами связаны и собственные проблемы, а именно: <emphasis>взаимоблокировки</emphasis> (deadlock) (см. раздел 3.2.4), а также защита слишком большого или слишком малого количества данных (см. раздел 3.2.8). Но начнем с простого.</p>
        </section>
        <section>
          <title>
            <p>3.2.1. Использование мьютексов в С++</p>
          </title>
          <p>В С++ для создания мьютекса следует сконструировать объект типа <code>std::mutex</code>, для захвата мьютекса служит функция-член <code>lock()</code>, а для освобождения — функция-член <code>unlock()</code>. Однако вызывать эти функции напрямую не рекомендуется, потому что в этом случае необходимо помнить о вызове <code>unlock()</code> на каждом пути выхода из функции, в том числе и вследствие исключений. Вместо этого в стандартной библиотеке имеется шаблон класса <code>std::lock_guard</code>, который реализует идиому RAII — захватывает мьютекс в конструкторе и освобождает в деструкторе, — гарантируя тем самым, что захваченный мьютекс обязательно будет освобожден. В листинге 3.1 показано, как с помощью классов <code>std::mutex</code> и <code>std::lock_guard</code> защитить список, к которому могут обращаться несколько потоков. Оба класса определены в заголовке <code>&lt;mutex&gt;</code>.</p>
          <empty-line/>
          <p><strong>Листинг 3.1.</strong> Защита списка с помощью мьютекса</p>
          <p>
            <code>#include &lt;list&gt;</code>
          </p>
          <p>
            <code>#include &lt;mutex&gt;</code>
          </p>
          <p>
            <code>#include &lt;algorithm&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::list&lt;int&gt; some_list; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>std::mutex some_mutex;    &#8592;</code>
            <strong>(2)</strong>
          </p>
          <empty-line/>
          <p>
            <code>void add_to_list(int new_value) {</code>
          </p>
          <p>
            <code> std::lock_guard&lt;std::mutex&gt; guard(some_mutex); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> some_list.push_back(new_value);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>bool list_contains(int value_to_find) {</code>
          </p>
          <p>
            <code> std::lock_guard&lt;std::mutex&gt; guard(some_mutex); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> return</code>
          </p>
          <p>
            <code>  std::find(some_list.begin(), some_list.end(), value_to_find) !=</code>
          </p>
          <p>
            <code>  some_list.end();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В листинге 3.1 есть глобальный список <strong>(1)</strong>, который защищен глобальным же объектом <code>std::mutex</code> <strong>(2)</strong>. Вызов <code>std::lock_guard&lt;std::mutex&gt;</code> в <code>add_to_list()</code> <strong>(3)</strong> и <code>list_contains()</code> <strong>(4)</strong> означает, что доступ к списку из этих двух функций является взаимно исключающим: <code>list_contains()</code> никогда не увидит промежуточного результата модификации списка, выполняемой в <code>add_to_list()</code>.</p>
          <p>Хотя иногда такое использование глобальных переменных уместно, в большинстве случаев мьютекс и защищаемые им данные помещают в один класс, а не в глобальные переменные. Это не что иное, как стандартное применение правил объектно-ориентированного проектирования; помещая обе сущности в класс, вы четко даете понять, что они взаимосвязаны, а, кроме того, обеспечиваете инкапсулирование функциональности и ограничение доступа. В данном случае функции <code>add_to_list</code> и <code>list_contains</code> следует сделать функциями-членами класса, а мьютекс и защищаемые им данные — закрытыми переменными-членами класса. Так будет гораздо проще понять, какой код имеет доступ к этим данным и, следовательно, в каких участках программы необходимо захватывать мьютекс. Если все функции-члены класса захватывают мьютекс перед обращением к каким-то другим данным-членам и освобождают по завершении действий, то данные оказываются надежно защищены от любопытствующих.</p>
          <p>Впрочем, это не <emphasis>совсем</emphasis> верно, проницательный читатель мог бы заметить, что если какая-нибудь функция-член возвращает указатель или ссылку на защищенные данные, то уже неважно, правильно функции-члены управляют мьютексом или нет, ибо вы проделали огромную брешь в защите. <emphasis>Любой код, имеющий доступ к этому указателю или ссылке, может прочитать (и, возможно, модифицировать) защищенные данные, не захватывая мьютекс.</emphasis> Таким образом, для защиты данных с помощью мьютекса требуется тщательно проектировать интерфейс, гарантировать, что перед любым доступном к защищенным данным производится захват мьютекса, и не оставлять черных ходов.</p>
        </section>
        <section>
          <title>
            <p>3.2.2. Структурирование кода для защиты разделяемых данных</p>
          </title>
          <p>Как мы только что видели, для защиты данных с помощью мьютекса недостаточно просто «воткнуть» объект <code>std::lock_guard</code> в каждую функцию-член: один-единственный «отбившийся» указатель или ссылка сводит всю защиту на нет. На некотором уровне проверить наличие таких отбившихся указателей легко — если ни одна функция-член не передает вызывающей программе указатель или ссылку на защищенные данные в виде возвращаемого значения или выходного параметра, то данные в безопасности. Но стоит копнуть чуть глубже, как выясняется, что всё не так просто, — а просто никогда не бывает. Недостаточно проверить, что функции-члены не возвращают указатели и ссылки вызывающей программе, нужно еще убедиться, что такие указатели и ссылки не передаются в виде <emphasis>входных</emphasis> параметров вызываемым ими функциям, которые вы не контролируете. Это ничуть не менее опасно — что, если такая функция сохранит где-то указатель или ссылку, а потом какой-то другой код обратится к данным, не захватив предварительно мьютекс? Особенно следует остерегаться функций, которые передаются во время выполнения в виде аргументов или иными способами, как показано в листинге 3.2.</p>
          <empty-line/>
          <p><strong>Листинг 3.2.</strong> Непреднамеренная передача наружу ссылки на защищённые данные</p>
          <p>
            <code>class some_data {</code>
          </p>
          <p>
            <code> int а;</code>
          </p>
          <p>
            <code> std::string b; </code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void do_something();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>class data_wrapper {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> some_data data;</code>
          </p>
          <p>
            <code> std::mutex m;</code>
          </p>
          <p>
            <code>public :</code>
          </p>
          <p>
            <code> template&lt;typename Function&gt;</code>
          </p>
          <p>
            <code> void process_data(Function func) </code>
            <strong>(1) Передаем</strong>
          </p>
          <p>
            <code> {                                 &#9474;</code>
            <strong>"защищенные"</strong>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; l(m);&#9474;</code>
            <strong>данные поль-</strong>
          </p>
          <p>
            <code>  func(data);                     &#8592;&#9496;</code>
            <strong>зовательской</strong>
          </p>
          <p><code> }                                  </code> <strong>функции</strong></p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>some_data* unprotected;</code>
          </p>
          <empty-line/>
          <p>
            <code>void malicious_function(some_data&amp; protected_data) {</code>
          </p>
          <p>
            <code> unprotected = &amp;protected_data;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>data_wrapper x;</code>
          </p>
          <empty-line/>
          <p>
            <code>void foo                             </code>
            <strong>(2) Передаем</strong>
          </p>
          <p>
            <code>{                                     &#9474;</code>
            <strong>вредоносную</strong>
          </p>
          <p>
            <code> x.process_data(malicious_function); &#8592;&#9496;</code>
            <strong>функцию</strong>
          </p>
          <p>
            <code> unprotected-&gt;do_something(); &#8592;</code>
            <strong>(3) Доступ к "защищенным"</strong>
          </p>
          <p>
            <code>}                                 </code>
            <strong>данным в обход защиты</strong>
          </p>
          <p>В этом примере функция-член <code>process_data</code> выглядит вполне безобидно, доступ к данным охраняется объектом <code>std::lock_guard</code>, однако наличие обращения к переданной пользователем функции <code>func</code> <strong>(1)</strong> означает, что <code>foo</code> может передать вредоносную функцию <code>malicious_function</code>, чтобы обойти защиту <strong>(2)</strong>, а затем вызвать <code>do_something()</code>, не захватив предварительно мьютекс <strong>(3)</strong>.</p>
          <p>Здесь фундаментальная проблема заключается в том, что мы не сделали того, что собирались сделать: пометить все участки кода, в которых имеется доступ к структуре данных, как <emphasis>взаимно исключающие</emphasis>. В данном случае мы забыли о коде внутри <code>foo()</code>, который вызывает <code>unprotected-&gt;do_something()</code>. К сожалению, в этом стандартная библиотека С++ нам помочь не в силах: именно программист должен позаботиться о том, чтобы защитить данные мьютексом. Но не всё так мрачно — следование приведенной ниже рекомендации выручит в таких ситуациях. <emphasis>Не передавайте указатели и ссылки на защищенные данные за пределы области видимости блокировки никаким способом, будь то возврат из функции, сохранение в видимой извне памяти или передача в виде аргумента пользовательской функции</emphasis>.</p>
          <p>Хотя описанная только что ситуация — самая распространенная ошибка при защите разделяемых данных, перечень подводных камней ей отнюдь не исчерпывается. В следующем разделе мы увидим, что гонка возможна даже, если данные защищены мьютексом.</p>
        </section>
        <section>
          <title>
            <p>3.2.3. Выявление состояний гонки, внутренне присущих интерфейсам</p>
          </title>
          <p>Тот факт, что вы пользуетесь мьютексами или другим механизмом для защиты разделяемых данных, еще не означает, что гонок можно не опасаться, — следить за тем, чтобы данные были защищены, все равно нужно. Вернемся снова к примеру двусвязного списка. Чтобы поток мог безопасно удалить узел, необходимо предотвратить одновременный доступ к трем узлам: удаляемому и двум узлам но обе стороны от него. Заблокировав одновременный доступ к указателям на каждый узел но отдельности, мы не достигнем ничего по сравнению с вариантом, где мьютексы вообще не используются, поскольку гонка по-прежнему возможна. Защищать нужно не отдельные узлы на каждом шаге, а структуру данных в целом на все время выполнения операции удаления. Простейшее решение в данном случае — завести один мьютекс, который будет защищать весь список, как в листинге 3.1.</p>
          <p>Однако и после обеспечения безопасности отдельных операций наши неприятности еще не закончились — гонки все еще возможны, даже для самого простого интерфейса. Рассмотрим структуру данных для реализации стека, например, адаптер контейнера <code>std::stack</code>, показанный в листинге 3.3. Помимо конструкторов и функции <code>swap()</code>, имеется еще пять операций со стеком: <code>push()</code> заталкивает в стек новый элемент, <code>pop()</code> выталкивает элемент из стека, <code>top()</code> возвращает элемент, находящийся на вершине стека, <code>empty()</code> проверяет, пуст ли стек, и <code>size()</code> возвращает размер стека. Если изменить <code>top()</code>, так чтобы она возвращала копию, а не ссылку (в соответствии с рекомендацией из раздела 3.2.2), и защитить внутренние данные мьютексом, то и тогда интерфейс уязвим для гонки. Проблема не в реализации на основе мьютексов, она присуща самому интерфейсу, то есть гонка может возникать даже в реализации без блокировок.</p>
          <empty-line/>
          <p><strong>Листинг 3.3</strong>. Интерфейс адаптера контейнера <code>std::stack</code></p>
          <p>
            <code>template&lt;typename T, typename Container = std::deque&lt;T&gt; &gt;</code>
          </p>
          <p>
            <code>class stack {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> explicit stack(const Container&amp;);</code>
          </p>
          <p>
            <code> explicit stack(Container&amp;&amp; = Container());</code>
          </p>
          <p>
            <code> template &lt;class Alloc&gt; explicit stack(const Alloc&amp;);</code>
          </p>
          <p>
            <code> template &lt;class Alloc&gt; stack(const Container&amp;, const Alloc&amp;);</code>
          </p>
          <p>
            <code> template &lt;class Alloc&gt; stack(Container&amp;&amp;, const Alloc&amp;);</code>
          </p>
          <p>
            <code> template &lt;class Alloc&gt; stack(stack&amp;&amp;, const Alloc&amp;);</code>
          </p>
          <p>
            <code> bool empty() const;</code>
          </p>
          <p>
            <code> size_t size() const;</code>
          </p>
          <p>
            <code> T&amp; top();</code>
          </p>
          <p>
            <code> T const&amp; top() const;</code>
          </p>
          <p>
            <code> void push(T const&amp;);</code>
          </p>
          <p>
            <code> void push(T&amp;&amp;);</code>
          </p>
          <p>
            <code> void pop();</code>
          </p>
          <p>
            <code> void swap(stack&amp;&amp;);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Проблема в том, что на результаты, возвращенные функциями <code>empty()</code> и <code>size()</code>, нельзя полагаться — хотя в момент вызова они, возможно, и были правильны, но после возврата из функции любой другой поток может обратиться к стеку и затолкнуть в него новые элементы, либо вытолкнуть существующие, причем это может произойти до того, как у потока, вызвавшего <code>empty()</code> или <code>size()</code>, появится шанс воспользоваться полученной информацией.</p>
          <p>Если экземпляр <code>stack</code> <emphasis>не является разделяемым,</emphasis> то нет ничего страшного в том, чтобы проверить, пуст ли стек с помощью <code>empty()</code>, а затем, если стек не пуст, вызвать <code>top()</code> для доступа к элементу на вершине стека:</p>
          <p>
            <code>stack&lt;int&gt; s;</code>
          </p>
          <p>
            <code>if (!s.empty())             &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>{</code>
          </p>
          <p>
            <code> int const value = s.top(); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> s.pop();                   &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> do_something(value);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Такой подход в однопоточном коде не только безопасен, но и единственно возможен: вызов <code>top()</code> для пустого стека приводит к неопределенному поведению. Но если объект <code>stack</code> является разделяемым, то <emphasis>такая последовательность операций уже не безопасна,</emphasis> так как между вызовами <code>empty()</code> <strong>(1)</strong> и <code>top()</code> <strong>(2)</strong> другой поток мог вызвать <code>pop()</code> и удалить из стека последний элемент. Таким образом, мы имеем классическую гонку, и использование внутреннего мьютекса для защиты содержимого стека ее не предотвращает. Это следствие дизайна интерфейса.</p>
          <p>И что же делать? Поскольку проблема коренится в дизайне интерфейса, то и решать ее надо путем изменения интерфейса. Но возникает вопроса — как его изменить? В простейшем случае мы могли бы просто декларировать, что <code>top()</code> возбуждает исключение, если в момент вызова в стеке нет ни одного элемента. Формально это решает проблему, но затрудняет программирование, поскольку теперь мы должны быть готовы к перехвату исключения, даже если вызов <code>empty()</code> вернул <code>false</code>. По сути дела, вызов <code>empty()</code> вообще оказывается ненужным.</p>
          <p>Внимательно присмотревшись к показанному выше фрагменту, мы обнаружим еще одну потенциальную гонку, на этот раз между вызовами <code>top()</code> <strong>(2)</strong> и <code>pop()</code> <strong>(3)</strong>. Представьте, что этот фрагмент исполняют два потока, ссылающиеся на один и тот же объект <code>s</code> типа <code>stack</code>. Ситуация вполне обычная: при использовании потока для повышения производительности часто бывает так, что несколько потоков исполняют один и тот же код для разных данных, и разделяемый объект <code>stack</code> идеально подходит для разбиения работы между потоками. Предположим, что первоначально в стеке находится два элемента, поэтому можно с уверенностью сказать, что между <code>empty()</code> и <code>top()</code> не будет гонки ни в одном потоке. Теперь рассмотрим возможные варианты выполнения программы.</p>
          <p>Если стек защищен внутренним мьютексом, то в каждый момент времени лишь один поток может исполнять любую функцию-член стека, поэтому обращения к функциям-членам строго чередуются, тогда как вызовы <code>do_something()</code> могут исполняться параллельно. Вот одна из возможных последовательностей выполнения:</p>
          <p>
            <strong>Поток А</strong>
            <code>-                    -</code>
            <strong>Поток В</strong>
          </p>
          <p>
            <code>if (!s.empty())</code>
          </p>
          <p>
            <code>                            if (!s.empty())</code>
          </p>
          <p>
            <code> int const value = s.top();</code>
          </p>
          <p>
            <code>                             int const value = s.top();</code>
          </p>
          <p>
            <code>s.pop();</code>
          </p>
          <p>
            <code>do_something(value);        s.pop();</code>
          </p>
          <p>
            <code>                            do_something(value);</code>
          </p>
          <p>Как видите, если работают только эти два потока, то между двумя обращениями к <code>top()</code> никто не может модифицировать стек, так что оба потока увидят одно и то же значение. Однако беда в том, что <emphasis>между обращениями к</emphasis> <code><emphasis>pop()</emphasis></code> <emphasis>нет обращений к</emphasis> <code><emphasis>top()</emphasis></code><emphasis>.</emphasis> Следовательно, одно из двух хранившихся в стеке значений никто даже не прочитает, оно будет просто отброшено, тогда как другое будет обработано дважды. Это еще одно состояние гонки, и куда более коварное, чем неопределенное поведение в случае гонки между <code>empty()</code> и <code>top()</code>, — на первый взгляд, ничего страшного не произошло, а последствия ошибки проявятся, скорее всего, далеко от места возникновения, хотя, конечно, всё зависит от того, что именно делает функция <code>do_something()</code>.</p>
          <p>Для решения проблемы необходимо более радикальное изменение интерфейса — выполнение обеих операций <code>top()</code> и <code>pop()</code> под защитой одного мьютекса. Том Каргилл<a l:href="#n4" type="note">[4]</a> указал, что такой объединенный вызов приводит к проблемам в случае, когда копирующий конструктор объектов в стеке может возбуждать исключения. С точки зрения безопасности относительно исключений, задачу достаточно полно решил Герб Саттер<a l:href="#n5" type="note">[5]</a>, однако возможность возникновения гонки вносит в нее новый аспект.</p>
          <p>Для тех, кто незнаком с историей вопроса, рассмотрим класс <code>stack&lt;vector&lt;int&gt;&gt;</code>. Вектор — это контейнер с динамически изменяемым размером, поэтому при копировании вектора библиотека должна выделить из кучи память. Если система сильно загружена или имеются жесткие ограничения на ресурсы, то операция выделения памяти может завершиться неудачно, и тогда копирующий конструктор вектора возбудит исключение <code>std::bad_alloc</code>. Вероятность такого развития событий особенно велика, если вектор содержит много элементов. Если бы функция <code>pop()</code> возвращала вытолкнутое из стека значение, а не только удаляла его из стека, то мы получили бы потенциальную проблему: вытолкнутое значение возвращается вызывающей программе только после модификации стека, но в процессе копирования возвращаемых данных может возникнуть исключение. Если такое случится, то только что вытолкнутые данные будут потеряны — из стека они удалены, но никуда не скопированы! Поэтому проектировщики интерфейса <code>std::stack</code> разбили операцию на две: получить элемент, находящийся на вершине (<code>top()</code>), а затем удалить его из стека (<code>pop()</code>). Теперь, данные, которые не удалось скопировать, остаются в стеке; если проблема связана с нехваткой памяти в куче, то, возможно, приложение сможет освободить немного памяти и попытаться выполнить операцию еще раз.</p>
          <p>Увы, это как раз то разбиение, которого мы пытались избежать в попытке уйти от гонки! К счастью, альтернативы имеются, но они не бесплатны.</p>
          <subtitle>Вариант 1: передавать ссылку</subtitle>
          <p>Первый вариант решения — передавать функции <code>pop()</code> ссылку на переменную, в которую она должна будет поместить вытолкнутое из стека значение:</p>
          <p>
            <code>std::vector&lt;int&gt; result;</code>
          </p>
          <p>
            <code>some_stack.pop(result);</code>
          </p>
          <p>Во многих случаях это приемлемо, но есть и очевидный недостаток: вызывающая программа должна до обращения к функции сконструировать объект того типа, которым конкретизирован стек, чтобы передать его в качестве аргумента. Для некоторых типов это не годится, так как конструирование дорого обходится с точки зрения времени или потребления ресурсов. Для других типов это вообще может оказаться невозможно, так как конструкторы требуют параметров, которые в данной точке программы могут быть недоступны. Наконец, требуется, чтобы хранящийся в стеке тип допускал присваивание. Это существенное ограничение, многие пользовательские типы не поддерживают присваивание, хотя могут поддерживать конструирование перемещением и даже копированием (и потому допускают возврат по значению).</p>
          <subtitle>Вариант 2: потребовать наличия копирующего конструктора, не возбуждающего исключений, или перемещающего конструктора</subtitle>
          <p>Проблема с безопасностью относительно исключений в варианте функции pop(), возвращающей значение, проявляется только тогда, когда исключение может возникать в процессе возврата значения. Во многих типах имеются копирующие конструкторы, которые не возбуждают исключений, а после поддержки в стандарте С++ ссылок на r-значения (см. приложение А, раздел А.1), появилось еще много типов, в которых перемещающий конструктор не возбуждает исключений, даже если копирующий конструктор может их возбуждать. Один из вариантов решения заключается в том, чтобы наложить на потокобезопасный стек ограничение: в нем можно хранить только типы, поддерживающие возврат по значению без возбуждения исключений.</p>
          <p>Это решение, пусть и безопасное, не идеально. Хотя на этапе компиляции можно узнать, существует ли копирующий или перемещающий конструктор, который не возбуждает исключений, — с помощью концепций <code>std::is_nothrow_copy_constructible</code>, <code>std::is_nothrow_move_constructible</code> и характеристик типов, но это слишком ограничительное требование. Пользовательских типов, в которых копирующий конструктор может возбуждать исключение и перемещающего конструктора нет, гораздо больше, чем типов, в которых копирующий и (или) перемещающий конструктор гарантированно не возбуждают исключений (хотя ситуация может измениться, когда разработчики привыкнут к появившейся в С++11 поддержке ссылок на r-значения). Было бы крайне нежелательно запрещать хранение таких объектов в потокобезопасном стеке.</p>
          <subtitle>Вариант 3: возвращать указатель на вытолкнутый элемент</subtitle>
          <p>Третий вариант — возвращать не копию вытолкнутого элемента по значению, а указатель на него. Его достоинство в том, указатели можно копировать, не опасаясь исключений, поэтому указанную Каргиллом проблему мы обходим. А недостаток в том, что возврат указателя заставляет искать средства для управления выделенной объекту памятью, так что для таких простых типов, как целые числа, накладные расходы на управление памятью могут превысить затраты на возврат типа по значению. В любом интерфейсе, где применяется этот вариант, в качестве типа указателя было бы разумно избрать <code>std::shared_ptr</code>; мало того что это предотвращает утечки памяти, поскольку объект уничтожается вместе с уничтожением последнего указателя на него, так еще и библиотека полностью контролирует схему распределения памяти и не требует использования <code>new</code> и <code>delete</code>. Это существенно с точки зрения оптимизации — требование, чтобы память для всякого хранящегося в стеке объекта выделялась с помощью <code>new</code>, повлекло бы заметные накладные расходы по сравнению с исходной версией, небезопасной относительно потоков.</p>
          <subtitle>Вариант 4: реализовать одновременно вариант 1 и один из вариантов 2 или 3</subtitle>
          <p>Никогда не следует пренебрегать гибкостью, особенно в обобщенном коде. Если остановиться на варианте 2 или 3, то будет сравнительно нетрудно реализовать и вариант 1, а это оставит пользователю возможность выбрать наиболее подходящее решение ценой очень небольших накладных расходов.</p>
          <p>
            <strong>Пример определения потокобезопасного стека</strong>
          </p>
          <p>В листинге 3.4 приведено определение класса стека со свободным от гонок интерфейсом. В нем реализованы приведенные выше варианты 1 и 3: имеется два перегруженных варианта функции-члена <code>pop()</code> — один принимает ссылку на переменную, в которой следует сохранить значение, а второй возвращает <code>std::shared_ptr&lt;&gt;</code>. Интерфейс предельно прост, он содержит только функции: <code>push()</code> и <code>pop()</code>.</p>
          <empty-line/>
          <p><strong>Листинг 3.4.</strong> Определение класса потокобезопасного стека</p>
          <p>
            <code>#include &lt;exception&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>struct empty_stack: std::exception {</code>
          </p>
          <p>
            <code> const char* what() const throw();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_stack {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_stack();</code>
          </p>
          <p>
            <code> threadsafe_stack(const threadsafe_stack&amp;);</code>
          </p>
          <p>
            <code> threadsafe_stack&amp; operator=(const threadsafe_stack&amp;)</code>
          </p>
          <p>
            <code>  = delete;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value);</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; pop();</code>
          </p>
          <p>
            <code> void pop(T&amp; value);</code>
          </p>
          <p>
            <code> bool empty() const;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Упростив интерфейс, мы добились максимальной безопасности — даже операции со стеком в целом ограничены: стек нельзя присваивать, так как оператор присваивания удален <strong>(1)</strong> (см. приложение А, раздел А.2) и функция <code>swap()</code> отсутствует. Однако стек можно копировать в предположении, что можно копировать его элементы. Обе функции <code>pop()</code> возбуждают исключение <code>empty_stack</code>, если стек пуст, поэтому программа будет работать, даже если стек был модифицирован после вызова <code>empty()</code>. В описании варианта 3 выше отмечалось, что использование <code>std::shared_ptr</code> позволяет стеку взять на себя распределение памяти и избежать лишних обращений к <code>new</code> и <code>delete</code>. Теперь из пяти операций со стеком осталось только три: <code>push()</code>, <code>pop()</code> и <code>empty()</code>. И даже <code>empty()</code> лишняя. Чем проще интерфейс, тем удобнее контролировать доступ к данным — можно захватывать мьютекс на все время выполнения операции. В листинге 3.5 приведена простая реализация в виде обертки вокруг класс <code>std::stack&lt;&gt;</code>.</p>
          <empty-line/>
          <p><strong>Листинг 3.5.</strong> Определение класса потокобезопасного стека</p>
          <p>
            <code>#include &lt;exception&gt;</code>
          </p>
          <p>
            <code>#include &lt;memory&gt;</code>
          </p>
          <p>
            <code>#include &lt;mutex&gt;</code>
          </p>
          <p>
            <code>#include &lt;stack&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>struct empty_stack: std::exception {</code>
          </p>
          <p>
            <code> const char* what() const throw();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> std::stack&lt;T&gt; data;</code>
          </p>
          <p>
            <code> mutable std::mutex m;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_stack(){}</code>
          </p>
          <p>
            <code> threadsafe_stack(const threadsafe_stack&amp; other) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(other.m);</code>
          </p>
          <p>
            <code>  data = other.data; &#8592;&#9488;</code>
            <strong>(1) Копирование производится в теле</strong>
          </p>
          <p>
            <code> }                    &#9474;</code>
            <strong>конструктора</strong>
          </p>
          <p>
            <code> threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(m);</code>
          </p>
          <p>
            <code>  data.push(new_value);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; pop()&#9474;</code>
            <strong>Перед тем как выталкивать значение,</strong>
          </p>
          <p>
            <code> {                      &#8592;&#9496;</code>
            <strong>проверяем, не пуст ли стек</strong>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(m);</code>
          </p>
          <p>
            <code>  if (data.empty()) throw empty_stack();</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; const res(std::make_shared&lt;T&gt;(data.top()));</code>
          </p>
          <p>
            <code>  data.pop(); &#8592;&#9488;</code>
            <strong>Перед тем как модифицировать стек</strong>
          </p>
          <p>
            <code>  return res;  &#9474;</code>
            <strong>в функции pop(), выделяем память</strong>
          </p>
          <p>
            <code> }             &#9474;</code>
            <strong>для возвращаемого значения</strong>
          </p>
          <empty-line/>
          <p>
            <code> void pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(m);</code>
          </p>
          <p>
            <code>  if (data.empty()) throw empty_stack();</code>
          </p>
          <p>
            <code>  value = data.top();</code>
          </p>
          <p>
            <code>  data.pop();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool empty() const {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(m);</code>
          </p>
          <p>
            <code>  return data.empty();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Эта реализация стека даже <emphasis>допускает копирование</emphasis> — копирующий конструктор захватывает мьютекс в объекте-источнике, а только потом копирует внутренний стек. Копирование производится в теле конструктора <strong>(1)</strong>, а не в списке инициализации членов, чтобы мьютекс гарантированно удерживался в течение всей операции.</p>
          <p>Обсуждение функций <code>top()</code> и <code>pop()</code> показывает, что проблематичные гонки в интерфейсе возникают из-за слишком малой гранулярности блокировки — защита не распространяется на выполняемую операцию в целом. Но при использовании мьютексов проблемы могут возникать также из-за слишком большой гранулярности, крайним проявление этого является применение одного глобального мьютекса для защиты всех разделяемых данных. В системе, где разделяемых данных много, такой подход может свести на нет все преимущества параллелизма, постольку потоки вынуждены работать но очереди, даже если обращаются к разным элементам данных. В первых версиях ядра Linux для многопроцессорных систем использовалась единственная глобальная блокировка ядра. Это решение работало, но получалось, что производительность одной системы с двумя процессорами гораздо ниже, чем двух однопроцессорных систем, а уж сравнивать производительность четырёхпроцессорной системы с четырьмя однопроцессорными вообще не имело смысла — конкуренция за ядро оказывалась настолько высока, что потоки, исполняемые дополнительными процессорами, не могли выполнять полезную работу. В последующих версиях Linux гранулярность блокировок ядра уменьшилась, и в результате производительность четырёхпроцессорной системы приблизилась к идеалу — четырехкратной производительности однопроцессорной системы, так как конкуренция за ядро значительно снизилась.</p>
          <p>При использовании мелкогранулярных схем блокирования иногда для защиты всех данных, участвующих в операции, приходится захватывать более одного мьютекса. Как отмечалось выше, бывают случаи, когда лучше повысить гранулярность защищаемых данных, чтобы для их защиты хватило одного мьютекса. Но это не всегда желательно, например, если мьютексы защищают отдельные экземпляры класса. В таком случае блокировка «на уровень выше» означает одно из двух: передать ответственность за блокировку пользователю или завести один мьютекс, который будет защищать все экземпляры класса. Ни одно из этих решений не вызывает восторга.</p>
          <p>Но когда для защиты одной операции приходится использовать два или более мьютексов, всплывает очередная проблема: <emphasis>взаимоблокировка</emphasis>. По природе своей она почти противоположна гонке: если в случае гонки два потока состязаются, кто придет первым, то теперь каждый поток ждет другого, и в результате ни тот, ни другой не могут продвинуться ни на шаг.</p>
        </section>
        <section>
          <title>
            <p>3.2.4. Взаимоблокировка: проблема и решение</p>
          </title>
          <p>Представьте игрушку, состоящую из двух частей, причем для игры необходимы обе части, — например, игрушечный барабан и палочки. Теперь вообразите двух ребятишек, которые любят побарабанить. Если одному дать барабан с палочками, то он будет радостно барабанить, пока не надоест. Если другой тоже хочет поиграть, то ему придётся подождать, как бы это ни было печально. А теперь представьте, что барабан и палочки закопаны где-то в ящике для игрушек (порознь), и оба малыша захотели поиграть с ними одновременно. Один отыскал барабан, а другой палочки. И оба оказались в тупике — если кто-то один не решится уступить и позволить поиграть другому, то каждый будет держаться за то, что имеет, требуя, чтобы другой отдал недостающее. В результате побарабанить не сможет никто.</p>
          <p>А теперь от детей и игрушек перейдём к потокам, ссорящимся по поводу захвата мьютексов, — оба потока для выполнения некоторой операции должны захватить два мьютекса, но сложилось так, что каждый поток захватил только один мьютекс и ждет другого. Ни один поток не может продолжить, так как каждый ждет, пока другой освободит нужный ему мьютекс. Такая ситуация называется <emphasis>взаимоблокировкой</emphasis>; это самая трудная из проблем, возникающих, когда для выполнения операции требуется захватить более одного мьютекса.</p>
          <p>Общая рекомендация, как избежать взаимоблокировок, заключается в том, чтобы всегда захватывать мьютексы в одном и том же порядке, — если мьютекс А всегда захватывается раньше мьютекса В, то взаимоблокировка не возникнет. Иногда это просто, потому что мьютексы служат разным целям, а иногда совсем не просто, например, если каждый мьютекс защищает отдельный объект одного и того же класса. Рассмотрим, к примеру, операцию сравнения двух объектов одного класса. Чтобы сравнению не мешала одновременная модификация, необходимо захватить мьютексы для обоих объектов. Однако, если выбрать какой-то определенный порядок (например, сначала захватывается мьютекс для объекта, переданного в первом параметре, а потом — для объекта, переданного во втором параметре), то легко можно получить результат, обратный желаемому: стоит двум потокам вызвать функцию сравнения, передав ей одни и те же объекты в разном порядке, как мы получим взаимоблокировку!</p>
          <p>К счастью, в стандартной библиотеке есть на этот случай лекарство в виде функции <code>std::lock</code>, которая умеет захватывать сразу два и более мьютексов без риска получить взаимоблокировку. В листинге 3.6 показано, как воспользоваться ей для реализации простой операции обмена.</p>
          <empty-line/>
          <p><strong>Листинг 3.6.</strong> Применение <code>std::lock</code> и <code>std::lock_guard</code> для реализации операции обмена</p>
          <p>
            <code>class some_big_object;</code>
          </p>
          <p>
            <code>void swap(some_big_object&amp; lhs, some_big_object&amp; rhs);</code>
          </p>
          <empty-line/>
          <p>
            <code>class X {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> some_big_object some_detail;</code>
          </p>
          <p>
            <code> std::mutex m;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> X(some_big_object const&amp; sd) : some_detail(sd) {}</code>
          </p>
          <p>
            <code> friend void swap(X&amp; lhs, X&amp; rhs) {</code>
          </p>
          <p>
            <code>  if (&amp;lhs == &amp;rhs)</code>
          </p>
          <p>
            <code>   return;</code>
          </p>
          <p>
            <code>  std::lock(lhs.m, rhs.m); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock_a(lhs.m, std::adopt_lock);&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock_b(rhs.m, std::adopt_lock);&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  swap(lhs.some_detail,rhs.some_detail);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Сначала проверяется, что в аргументах переданы разные экземпляры, постольку попытка захватить <code>std::mutex</code>, когда он уже захвачен, приводит к неопределенному поведению. (Класс мьютекса, допускающего несколько захватов в одном потоке, называется <code>std::recursive_mutex</code>. Подробности см. в разделе 3.3.3.) Затем мы вызываем <code>std::lock()</code> <strong>(1)</strong>, чтобы захватить оба мьютекса, и конструируем два экземпляра <code>std::lock_guard</code> <strong>(2)</strong>, <strong>(3)</strong> — по одному для каждого мьютекса. Помимо самого мьютекса, конструктору передается параметр <code>std::adopt_lock</code>, сообщающий объектам <code>std::lock_guard</code>, что мьютексы уже захвачены, и им нужно лишь принять владение существующей блокировкой, а не пытаться еще раз захватить мьютекс в конструкторе.</p>
          <p>Это гарантирует корректное освобождение мьютексов при выходе из функции даже в случае, когда защищаемая операция возбуждает исключение, а также возврат результата сравнения в случае нормального завершения. Стоит также отметить, что попытка захвата любого мьютекса <code>lhs.m</code> или <code>rhs.m</code> внутри <code>std::lock</code> может привести к исключению; в этом случае исключение распространяется на уровень функции, вызвавшей <code>std::lock</code>. Если <code>std::lock</code> успешно захватила первый мьютекс, но при попытке захватить второй возникло исключение, то первый мьютекс автоматически освобождается; <code>std::lock</code> обеспечивает семантику «все или ничего» в части захвата переданных мьютексов.</p>
          <p>Хотя <code>std::lock</code> помогает избежать взаимоблокировки в случаях, когда нужно захватить сразу два или более мьютексов, она не в силах помочь, если мьютексы захватываются порознь, — в таком случае остается полагаться только на дисциплину программирования. Это нелегко, взаимоблокировки — одна из самых неприятных проблем в многопоточной программе, часто они возникают непредсказуемо, хотя в большинстве случаев все работает нормально. Однако все же есть несколько относительно простых правил, помогающих писать свободный от взаимоблокировок код.</p>
        </section>
        <section>
          <title>
            <p>3.2.5. Дополнительные рекомендации, как избежать взаимоблокировок</p>
          </title>
          <p>Взаимоблокировка может возникать не только при захвате мьютексов, хотя это и наиболее распространенная причина. Нарваться на взаимоблокировку можно и тогда, когда есть два потока и никаких мьютексов; достаточно, чтобы каждый поток вызвал функцию <code>jоin()</code> объекта <code>std::thread</code>, связанного с другим потоком. В этом случае ни один поток не сможет продолжить выполнение, потому что будет ждать завершения другого потока, — точно так же, как дети, ссорящиеся по поводу игрушек. Такой простой цикл может возникнуть всюду, где один поток ждет завершения другого для продолжения работы, а этот другой поток одновременно ждет завершения первого. Причем потоков необязательно должно быть два — цикл, в котором участвуют три и более потоков, также приведёт к взаимоблокировке. Общая рекомендация во всех случаях одна: не ждите завершения другого потока, если есть малейшая возможность, что он будет дожидаться вас. Ниже приведены конкретные советы, как выявить и устранить такую возможность.</p>
          <subtitle>Избегайте вложенных блокировок</subtitle>
          <p>Идея проста — не захватывайте мьютекс, если уже захватили какой-то другой. Если строго придерживаться этой рекомендации, то взаимоблокировка, обусловленная одними лишь захватами мьютексов, никогда не возникнет, потому что каждый поток в любой момент времени владеет не более чем одним мьютексом. Конечно, можно получить взаимоблокировку по другим причинам (например, из-за взаимного ожидания потоков), но захват мьютексов — наиболее распространенная. Если требуется захватить сразу несколько мьютексов, делайте это атомарно с помощью <code>std::lock</code>, так вы сможете избежать взаимоблокировки.</p>
          <subtitle>Старайтесь не вызывать пользовательский код, когда удерживаете мьютекс</subtitle>
          <p>По существу, это простое развитие предыдущей рекомендации. Поскольку код написан пользователем, вы не можете знать, что он делает. А делать он может все, что угодно, в том числе захватывать мьютекс. Если вы вызываете пользовательский код, не освободив предварительно мьютекс, а этот код захватывает какой-то мьютекс, то оказывается нарушена рекомендация избегать вложенных блокировок, и может возникнуть взаимоблокировка. Иногда избежать этого невозможно: если вы пишете обобщенный код, например класс стека из раздела 3.2.3, то каждая операция над типом или типами параметров — не что иное, как пользовательский код. В таком случае прислушайтесь к следующему совету.</p>
          <subtitle>Захватывайте мьютексы в фиксированном порядке</subtitle>
          <p>Если без захвата нескольких мьютексов никак не обойтись и захватить их в одной операции типа <code>std::lock</code> не получается, то следует прибегнуть к другому способу — захватывать их во всех потоках в одном и том же порядке. Мы уже говорили об этом в разделе 3.2.4, как о способе избежать взаимоблокировки при захвате двух мьютексов; идея в том, чтобы четко определить порядок захвата и соблюдать его во всех потоках. Иногда это сравнительно просто. Например, в случае стека из раздела 3.2.3 мьютекс хранится в каждом экземпляре стека, но для операций над хранящимися в стеке элементами необходимо вызывать пользовательский код. Однако можно добавить ограничение: никакая операция над хранящимися в стеке данными не должна производить какие-либо действия с самим стеком. Это возлагает определенную ответственность на пользователя стека, но на практике редко бывает, чтобы хранящимся в контейнере данным нужно было обращаться к самому контейнеру, а если такое и случается, то сразу видно. Поэтому бремя ответственности не слишком тяжело.</p>
          <p>Но не всегда всё так просто, и пример мы видели при рассмотрении оператора сравнения в разделе 3.2.4. В этом конкретном случае есть возможность захватить мьютексы одновременно, но так бывает не всегда. Пример связанного списка из раздела 3.1 дает еще один способ защитить список — хранить мьютекс в каждом узле. Тогда, чтобы получить доступ к списку, поток должен будет захватить мьютекс для каждого интересующего его узла. Так, чтобы удалить элемент, надо будет захватить мьютексы трех узлов — удаляемого, предшествующего и последующего, — постольку все они так или иначе модифицируются. Аналогично для обхода списка поток должен удерживать мьютекс текущего узла, пока не захватит мьютекс следующего за ним; это гарантирует, что никто не может изменить указатель на следующий узел. Захватив мьютекс следующего узла, можно освободить мьютекс текущего, так как больше он не понадобится.</p>
          <p>Такой способ «передачи из рук в руки» позволяет нескольким потокам одновременно обходить список при условии, что разные потоки обращаются к разным узлам. Но чтобы предотвратить взаимоблокировку, узлы следует обходить в одном и том же порядке; если один поток обходит список в одном направлении, а другой в противоположном, то при передаче мьютексов «из рук в руки» в середине списка может произойти взаимоблокировка. Если узлы А и В соседние, то поток, который обходит список в прямом направлении, попытается захватить мьютекс В, удерживая мьютекс А. В то же время поток, который обходит список в обратном направлении, попытается захватить мьютекс А, удерживая мьютекс В. Вот мы и получили классическую взаимоблокировку.</p>
          <p>Рассмотрим еще ситуацию удаления узла В, расположенного между А и С. Если поток захватывает мьютекс В раньше, чем мьютексы А и С, то возможна взаимоблокировка с потоком, который обходит список. Такой поток попытается сначала захватить мьютекс А или С (в зависимости от направления обхода), но потом обнаружит, что не может захватить мьютекс В, потому что поток, выполняющий удаление, удерживает этот мьютекс, пытаясь в то же время захватить мьютексы А и С.</p>
          <p>Предотвратить в этом случае взаимоблокировку можно, определив порядок обхода, так что поток всегда должен захватывать мьютекс А раньше мьютекса В, а мьютекс В раньше мьютекса С. Это устранило бы возможность взаимоблокировки, но ценой запрета обхода в обратном направлении. Подобные соглашения можно принять и для других структур данных.</p>
          <subtitle>Пользуйтесь иерархией блокировок</subtitle>
          <p>Являясь частным случаем фиксированного порядка захвата мьютексов, иерархия блокировок в то же время позволяет проверить соблюдение данного соглашения во время выполнения. Идея в том, чтобы разбить приложение на отдельные слои и выявить все мьютексы, которые могут быть захвачены в каждом слое. Программе будет отказано в попытке захватить мьютекс, если она уже удерживает какой-то мьютекс из нижележащего слоя. Чтобы проверить это во время выполнения, следует приписать каждому мьютексу номер слоя и вести учет мьютексам, захваченным каждым потоком. В следующем листинге приведен пример двух потоков, пользующихся иерархическим мьютексом.</p>
          <empty-line/>
          <p><strong>Листинг 3.7.</strong> Использование иерархии блокировок для предотвращения взаимоблокировки</p>
          <p>
            <code>hierarchical_mutex high_level_mutex(10000); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>hierarchical_mutex low_level_mutex(5000);   &#8592;</code>
            <strong>(2)</strong>
          </p>
          <empty-line/>
          <p>
            <code>int do_low_level_stuff();</code>
          </p>
          <empty-line/>
          <p>
            <code>int low_level_func() {</code>
          </p>
          <p>
            <code> std::lock_guard&lt;hierarchical_mutex&gt; lk(low_level_mutex); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> return do_low_level_stuff();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void high_level_stuff(int some_param);</code>
          </p>
          <empty-line/>
          <p>
            <code>void high_level_func() {</code>
          </p>
          <p>
            <code> std::lock_guard&lt;hierarchical_mutex&gt; lk(high_level_mutex); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> high_level_stuff(low_level_func());                       &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void thread_a() { &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> high_level_func();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>hierarchical_mutex other_mutex(100); &#8592;</code>
            <strong>(7)</strong>
          </p>
          <empty-line/>
          <p>
            <code>void do_other_stuff();</code>
          </p>
          <empty-line/>
          <p>
            <code>void other_stuff() {</code>
          </p>
          <p>
            <code> high_level_func(); &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code> do_other_stuff();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void thread_b() { &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code> std::lock_guard&lt;hierarchical_mutex&gt; lk(other_mutex); &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code> other_stuff();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Поток <code>thread_a()</code> <strong>(6)</strong> соблюдает правила и выполняется беспрепятственно. Напротив, поток <code>thread_b()</code> <strong>(9)</strong> нарушает правила, поэтому во время выполнения столкнется с трудностями. Функция <code>thread_a()</code> вызывает <code>high_level_func()</code>, которая захватывает мьютекс <code>high_level_mutex</code> <strong>(4)</strong> (со значением уровня иерархии 10000 <strong>(1)</strong>), а затем вызывает <code>low_level_func()</code> <strong>(5)</strong> (мьютекс в этот момент уже захвачен), чтобы получить параметр, необходимый функции <code>high_level_stuff()</code>. Далее функция <code>low_level_func()</code> захватывает мьютекс <code>low_level_mutex</code> <strong>(3)</strong>, и в этом нет ничего плохого, так как уровень иерархии для него равен 5000 <strong>(2)</strong>, то есть меньше, чем для <code>high_level_mutex</code>.</p>
          <p>С другой стороны, функция <code>thread_b()</code> некорректна. Первым делом она захватывает мьютекс <code>other_mutex</code> <strong>(10)</strong>, для которого уровень иерархии равен всего 100 <strong>(7)</strong>. Это означает, что мьютекс призван защищать только данные очень низкого уровня. Следовательно, когда функция <code>other_stuff()</code> вызывает <code>high_level_func()</code> <strong>(8)</strong>, она нарушает иерархию — <code>high_level_func()</code> пытается захватить мьютекс <code>high_level_mutex</code>, уровень иерархии которого (10000) намного больше текущего уровня иерархии 100. Поэтому <code>hierarchical_mutex</code> сообщит об ошибке, возбудив исключение или аварийно завершив программу. Таким образом, взаимоблокировки между иерархическими мьютексами невозможны, так как они сами следят за порядком захвата. Это означает, что программа не может удерживать одновременно два мьютекса, находящихся на одном уровне иерархии, поэтому в схемах «передачи из рук в руки» требуется, чтобы каждый мьютекс в цепочке имел меньшее значение уровня иерархии, чем предыдущий, — на практике удовлетворить такому требованию не всегда возможно.</p>
          <p>На этом примере демонстрируется еще один момент — использование шаблона <code>std::lock_guard&lt;&gt;</code>, конкретизированного определенным пользователем типом мьютекса. Тип <code>hierarchical_mutex</code> не определен в стандарте, но написать его несложно — простая реализация приведена в листинге 3.8. Хотя этот тип определен пользователем, его можно употреблять совместно с <code>std::lock_guard&lt;&gt;</code>, потому что в нем имеются все три функции-члена, необходимые для удовлетворения требований концепции мьютекса: <code>lock()</code>, <code>unlock()</code> и <code>try_lock()</code>. Мы еще не видели, как используется функция t<code>ry_lock()</code>, но ничего хитрого в ней нет — если мьютекс захвачен другим потоком, то функция сразу возвращает <code>false</code>, а не блокирует вызывающий поток в ожидании освобождения мьютекса. Она может вызываться также из функции <code>std::lock()</code> для реализации алгоритма предотвращения взаимоблокировок.</p>
          <empty-line/>
          <p><strong>Листинг 3.8.</strong> Простая реализация иерархического мьютекса</p>
          <p>
            <code>class hierarchical_mutex {</code>
          </p>
          <p>
            <code> std::mutex internal_mutex;</code>
          </p>
          <p>
            <code> unsigned long const hierarchy_value;</code>
          </p>
          <p>
            <code> unsigned previous_hierarchy_value;</code>
          </p>
          <p>
            <code> static thread_local</code>
          </p>
          <p>
            <code>  unsigned long this_thread_hierarchy_value;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code> void check_for_hierarchy_violation() {</code>
          </p>
          <p>
            <code>  if (this_thread_hierarchy_value &lt;= hierarchy_value) &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  {</code>
          </p>
          <p>
            <code>   throw std::logic_error("mutex hierarchy violated");</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void update_hierarchy_value() {</code>
          </p>
          <p>
            <code>  previous_hierarchy_value = this_thread_hierarchy_value; &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  this_thread_hierarchy_value = hierarchy_value;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> explicit hierarchical_mutex(unsigned long value):</code>
          </p>
          <p>
            <code>  hierarchy_value(value),</code>
          </p>
          <p>
            <code>  previous_hierarchy_value(0) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void lock() {</code>
          </p>
          <p>
            <code>  check_for_hierarchy_violation();</code>
          </p>
          <p>
            <code>  internal_mutex.lock();    &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  update_hierarchy_value(); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void unlock() {</code>
          </p>
          <p>
            <code>  this_thread_hierarchy_value = previous_hierarchy_value; &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  internal_mutex.unlock();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool try_lock() {</code>
          </p>
          <p>
            <code>  check_for_hierarchy_violation();</code>
          </p>
          <p>
            <code>  if (!internal_mutex.try_lock()) &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>   return false;</code>
          </p>
          <p>
            <code>  update_hierarchy_value();</code>
          </p>
          <p>
            <code>  return true;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>thread_local unsigned long</code>
          </p>
          <p>
            <code>hierarchical_mutex::this_thread_hierarchy_value(ULONG_MAX);&#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>Главное здесь — использование значения типа <code>thread_local</code> для представления уровня иерархии в текущем потоке, <code>this_thread_hierarchy_value</code> <strong>(1)</strong>. Оно инициализируется максимально возможным значением <strong>(8)</strong>, так что в начальный момент можно захватить любой мьютекс. Поскольку переменная имеет тип <code>thread_local</code>, то в каждом потоке хранится отдельная ее копия, то есть состояние этой переменной в одном потоке не зависит от ее состояния в любом другом. Дополнительные сведения о <code>thread_local</code> см. в разделе А.8 приложения А.</p>
          <p>Итак, при первом захвате потоком объекта <code>hierarchical_mutex</code> значение <code>this_thread_hierarchy_value</code> в нем будет равно <code>ULONG_MAX</code>. Это число по определению больше любого другого представимого в программе, потому проверка в функции <code>check_for_hierarchy_violation()</code> <strong>(2)</strong> проходит. Раз так, то функция <code>lock()</code> просто захватывает внутренний мьютекс <strong>(4)</strong>. Успешно выполнив эту операцию, мы можем изменить значение уровня иерархии <strong>(5)</strong>.</p>
          <p>Если теперь попытаться захватить <emphasis>другой</emphasis> объект <code>hierarchical_mutex</code>, не освободив первый, то в переменной <code>this_thread_hierarchy_value</code> будет находиться уровень иерархии первого мьютекса. Чтобы проверка <strong>(2)</strong> завершилась успешно, уровень иерархии второго мьютекса должен быть меньше уровня уже удерживаемого.</p>
          <p>Теперь мы должны сохранить предыдущее значение уровня иерархии в текущем потоке, чтобы его можно было восстановить в функции <code>unlock()</code> <strong>(6)</strong>. В противном случае нам больше никогда не удалось бы захватить мьютекс с более высоким уровнем иерархии, даже если поток не удерживает ни одного мьютекса. Поскольку мы сохраняем предыдущий уровень иерархии только в случае, когда удерживаем <code>internal_mutex</code> <strong>(3)</strong>, и восстанавливаем его <emphasis>перед</emphasis> тем, как освободить этот внутренний мьютекс <strong>(6)</strong>, то можем безопасно сохранить его в самом объекте <code>hierarchical_mutex</code>, где его защищает захваченный внутренний мьютекс.</p>
          <p>Функция <code>try_lock()</code> работает так же, как <code>lock()</code>, с одним отличием — если вызов <code>try_lock()</code> для <code>internal_mutex</code> завершается ошибкой <strong>(7)</strong>, то мы не владеем мьютексом и, следовательно, не изменяем уровень иерархии, а вместо <code>true</code> возвращаем <code>false</code>.</p>
          <p>Все проверки производятся на этапе выполнения, но, по крайней мере, они не зависят от времени — нет нужды дожидаться, пока сложатся редкие условия, при которых возникает взаимоблокировка. Кроме того, ход мыслей проектировщика, направленный на подобное отделение логики приложения от мьютексов, помогает предотвратить многие возможные причины взаимоблокировок еще до того, как они прокрадутся в код. Такое мысленное упражнение полезно проделать даже в том случае, когда проектировщик не собирается фактически кодировать проверки во время выполнения.</p>
          <subtitle>Применение данных рекомендаций не ограничивается блокировками</subtitle>
          <p>Я уже упоминал в начале этого раздела, что взаимоблокировка может возникать не только вследствие захвата мьютекса, а вообще в любой конструкции синхронизации, сопровождающейся циклом ожидания. Поэтому стоит обобщить приведенные выше рекомендации и на такие случаи. Например, мы говорили, что следует по возможности избегать вложенных блокировок, и точно так же не рекомендуется ждать поток, удерживая мьютекс, потому что этому потоку может потребоваться тот же самый мьютекс для продолжения работы. Аналогично, если вы собираетесь ждать завершения потока, то будет разумно определить иерархию потоков, так чтобы любой поток мог ждать только завершения потоков, находящихся ниже него в иерархии. Простой способ реализовать эту идею — сделать так, чтобы присоединение потоков происходило в той же функции, которая их запускала (как описано в разделах 3.1.2 и 3.3).</p>
          <p>Функция <code>std::lock()</code> и шаблон класса <code>std::lock_guard</code> покрывают большую часть простых случаев блокировки, по иногда этого недостаточно. Поэтому в стандартную библиотеку включен также шаблон <code>std::unique_lock</code>. Подобно <code>std::lock_guard</code>, этот шаблон класса параметризован типом мьютекса и реализует такое же управление блокировками в духе RAII, что и <code>std::lock_guard</code>, однако обладает чуть большей гибкостью.</p>
        </section>
        <section>
          <title>
            <p>3.2.6. Гибкая блокировка с помощью <code>std::unique_lock</code></p>
          </title>
          <p>Шаблон <code>std::unique_lock</code> обладает большей гибкостью, чем <code>std::lock_guard</code>, потому что несколько ослабляет инварианты — экземпляр <code>std::unique_lock</code> не обязан владеть ассоциированным с ним мьютексом. Прежде всего, в качестве второго аргумента конструктору можно передавать не только объект <code>std::adopt_lock</code>, заставляющий объект управлять захватом мьютекса, но и объект <code>std::defer_lock</code>, означающий, что в момент конструирования мьютекс не должен захватываться. Захватить его можно будет позже, вызвав функцию-член <code>lock()</code> объекта <code>std::unique_lock</code> (а <emphasis>не</emphasis> самого мьютекса) или передав функции <code>std::lock()</code> сам объект <code>std::unique_lock</code>. Код в листинге 3.6 можно было бы с тем же успехом написать, как показало в листинге 3.9, с применением <code>std::unique_lock</code> и <code>std::defer_lock()</code> <strong>(1)</strong> вместо <code>std::lock_guard</code> и <code>std::adopt_lock</code>. В новом варианте столько же строк, и он эквивалентен исходному во всем, кроме одной детали, — <code>std::unique_lock</code> потребляет больше памяти и выполняется чуть дольше, чем <code>std::lock_guard</code>. Та гибкость, которую мы получаем, разрешая экземпляру <code>std::unique_lock</code> <emphasis>не</emphasis> владеть мьютексом, обходится не бесплатно — дополнительную информацию надо где-то хранить и обновлять.</p>
          <empty-line/>
          <p><strong>Листинг 3.9.</strong> Применение <code>std::lock()</code> и <code>std::unique_guard</code> для реализации операции обмена</p>
          <p>
            <code>class some_big_object;</code>
          </p>
          <p>
            <code>void swap(some_big_object&amp; lhs,some_big_object&amp; rhs);</code>
          </p>
          <empty-line/>
          <p>
            <code>class X {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> some_big_object some_detail;</code>
          </p>
          <p>
            <code> std::mutex m;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> X(some_big_object const&amp; sd): some_detail(sd) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> friend void swap(X&amp; lhs, X&amp; rhs) {</code>
          </p>
          <p>
            <code>  if (&amp;lhs == &amp;rhs)                    </code>
            <strong>std::defer_lock оставляет</strong>
          </p>
          <p>
            <code>   return;                             </code>
            <strong>мьютексы не захваченными (1)</strong>
          </p>
          <p>
            <code>
              <strong>   std::unique_lock&lt;std::mutex&gt; lock_a(lhs.m, std::defer_lock);&#8592;&#9508;</strong>
            </code>
          </p>
          <p>
            <code>
              <strong>   std::unique_lock&lt;std::mutex&gt; lock_b(rhs.m, std::defer_lock);&#8592;&#9496;</strong>
            </code>
          </p>
          <p>
            <code>
              <strong>   std::lock(lock_a, lock_b); &#8592;</strong>
            </code>
            <strong>(2) Мьютексы захватываются</strong>
          </p>
          <p>
            <code>   swap(lhs.some_detail, rhs.some_detail);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В листинге 3.9 объекты <code>std::unique_lock</code> можно передавать функции <code>std::lock()</code> <strong>(2)</strong>, потому что в классе <code>std::unique_lock</code> имеются функции-члены <code>lock()</code>, <code>try_lock()</code> и <code>unlock()</code>. Для выполнения реальной работы они вызывают одноименные функции контролируемого мьютекса, а сами только поднимают в экземпляре <code>std::unique_lock</code> флаг, показывающий, что в данный момент этот экземпляр владеет мьютексом. Флаг необходим для того, чтобы деструктор знал, вызывать ли функцию <code>unlock()</code>. Если экземпляр <emphasis>действительно</emphasis> владеет мьютексом, то деструктор <emphasis>должен</emphasis> вызвать <code>unlock()</code>, в противном случае — <emphasis>не должен</emphasis>. Опросить состояние флага позволяет функция-член <code>owns_lock()</code>.</p>
          <p>Естественно, этот флаг необходимо где-то хранить. Поэтому размер объекта <code>std::unique_lock</code> обычно больше, чем объекта <code>std::lock_guard</code>, и работает <code>std::unique_lock</code> чуть медленнее <code>std::lock_guard</code>, потому что флаг нужно проверять и обновлять. Если класс <code>std::lock_guard</code> отвечает вашим нуждам, то я рекомендую использовать его. Тем не менее, существуют ситуации, когда <code>std::unique_lock</code> лучше отвечает поставленной задаче, так как без свойственной ему дополнительной гибкости не обойтись. Один из примеров — показанный выше отложенный захват; другой — необходимость передавать владение мьютексом из одного контекста в другой.</p>
        </section>
        <section>
          <title>
            <p>3.2.7. Передача владения мьютексом между контекстами</p>
          </title>
          <p>Поскольку экземпляры <code>std::unique_lock</code> не владеют ассоциированными мьютексами, то можно передавать владение от одного объекта другому путем <emphasis>перемещения</emphasis>. В некоторых случаях передача производится автоматически, например при возврате объекта из функции, а иногда это приходится делать явно, вызывая <code>std::move()</code>. Ситуация зависит от того, является ли источник <emphasis>l-значением</emphasis> — именованной переменной или ссылкой на нее — или <emphasis>r-значением</emphasis> — временным объектом. Если источник — r-значение, то передача владения происходит автоматически, в случае же l-значение это нужно делать явно, чтобы не получилось так, что переменная потеряет владение непреднамеренно. Класс <code>std::unique_lock</code> дает пример <emphasis>перемещаемого</emphasis>, но не <emphasis>копируемого</emphasis> типа. Дополнительные сведения о семантике перемещения см. в разделе А.1.1 приложения А.</p>
          <p>Одно из возможных применений — разрешить функции захватить мьютекс, а потом передать владение им вызывающей функции, чтобы та могла выполнить дополнительные действия под защитой того же мьютекса. Ниже приведен соответствующий пример — функция <code>get_lock()</code> захватывает мьютекс, подготавливает некоторые данные, а потом возвращает мьютекс вызывающей программе:</p>
          <p>
            <code>std::unique_lock&lt;std::mutex&gt; get_lock() {</code>
          </p>
          <p>
            <code> extern std::mutex some_mutex;</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt; lk(some_mutex);</code>
          </p>
          <p>
            <code> prepare_data();</code>
          </p>
          <p>
            <code> return lk; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void process_data() {</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt; lk(get_lock()); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> do_something();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Поскольку <code>lk</code> — автоматическая переменная, объявленная внутри функции, то ее можно возвращать непосредственно <strong>(1)</strong>, не вызывая <code>std:move()</code>; компилятор сам позаботится о вызове перемещающего конструктора. Затем функция <code>process_data()</code> может передать владение своему экземпляру <code>std::unique_lock</code> <strong>(2)</strong>, и <code>do_something()</code> может быть уверена, что подготовленные данные не были изменены каким-то другим потоком.</p>
          <p>Обычно подобная схема применяется, когда подлежащий захвату мьютекс зависит от текущего состояния программы или от аргумента, переданного функции, которая возвращает объект <code>std::unique_lock</code>. Например, так имеет смысл делать, когда блокировка возвращается не напрямую, а является членом какого-то класса-привратника, обеспечивающего корректный доступ к разделяемым данным под защитой мьютекса. В таком случае любой доступ к данным производится через привратник, то есть предварительно необходимо получить его экземпляр (вызвав функцию, подобную <code>get_lock()</code> в примере выше), который захватит мьютекс. Затем для доступа к данным вызываются функции-члены объекта-привратника. По завершении операции привратник уничтожается, при этом мьютекс освобождается, открывая другим потокам доступ к защищенным данным. Такой объект-привратник вполне может быть перемещаемым (чтобы его можно было возвращать из функции), и тогда тот его член, в котором хранится блокировка, также должен быть перемещаемым.</p>
          <p>Класс <code>std::unique_lock</code> также позволяет экземпляру освобождать блокировку без уничтожения. Для этого служит функция-член <code>unlock()</code>, как и в мьютексе; <code>std::unique_lock</code> поддерживает тот же базовый набор функций-членов для захвата и освобождения, что и мьютекс, чтобы его можно было использовать в таких обобщенных функциях, как <code>std::lock</code>. Наличие возможности освобождать блокировку до уничтожения объекта <code>std::unique_lock</code> означает, что освобождение можно произвести досрочно в какой-то ветке кода, если ясно, что блокировка больше не понадобится. Иногда это позволяет повысить производительность приложения, ведь, удерживая блокировку дольше необходимого, вы заставляете другие потоки впустую ждать, когда они могли бы работать.</p>
        </section>
        <section>
          <title>
            <p>3.2.8. Выбор правильной гранулярности блокировки</p>
          </title>
          <p>О гранулярности блокировок я уже упоминал в разделе 3.2.3: под этим понимается объем данных, защищаемых блокировкой. Мелкогранулярные блокировки защищают мало данных, крупногранулярные — много. Важно не только выбрать подходящую гранулярность, но и позаботиться о том, чтобы блокировка удерживалась не дольше, чем реально необходимо. Все мы сталкивались с ситуацией, когда очередь к кассе в супермаркете перестает двигаться из-за того, что обслуживаемый покупатель вдруг выясняет, что забыл прихватить баночку соуса, и отправляется за ней, заставляя всех ждать, или из-за того, что кассирша уже готова принять деньги, а покупатель только— только полез за кошельком. Насколько было бы проще, если бы каждый подходил к кассе только после того, как купил все необходимое и подготовился оплатить покупки.</p>
          <p>Вот так и с потоками: если несколько потоков ждут одного ресурса (кассира), то, удерживая блокировку дольше необходимого, они заставляют другие потоки проводить в очереди больше времени (не начинайте искать баночку соуса, когда уже подошли к кассе). По возможности захватывайте мьютекс непосредственно перед доступом к разделяемым данным; старайтесь производить обработку данных, не находясь под защитой мьютекса. В частности, не начинайте длительных операций, например файловый ввод/вывод, когда удерживаете мьютекс. Ввод/вывод обычно выполняется в сотни (а то и в тысячи) раз медленнее чтения или записи того же объема данных в памяти. Поэтому если блокировка не нужна для защиты доступа к файлу, то удерживание блокировки заставляет другие потоки ждать без необходимости (так как они не могут захватить мьютекс), и тем самым вы можете свести на нет весь выигрыш от многопоточной работы.</p>
          <p>Объект <code>std::unique_lock</code> отлично приспособлен для таких ситуаций, потому что можно вызвать его метод <code>unlock()</code>, когда программе не нужен доступ к разделяемым данным, а затем вызвать <code>lock()</code>, если доступ снова понадобится:</p>
          <p>
            <code>void get_and_process_data()</code>
            <strong>(1) Во время работы process() зах-</strong>
          </p>
          <p>
            <code>{                          &#8592;&#9496;</code>
            <strong>ватывать мьютекс не нужно</strong>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt; my_lock(the_mutex);</code>
          </p>
          <p>
            <code> some_class data_to_process = get_next_data_chunk();</code>
          </p>
          <p>
            <code> my_lock.unlock();</code>
          </p>
          <p>
            <code> result_type result = process(data_to_process);</code>
          </p>
          <p>
            <code> my_lock.lock();                      &#8592;&#9488;</code>
            <strong>Снова захватить мью-</strong>
          </p>
          <p>
            <code> write_result(data_to_process, result);&#9474;</code>
            <strong>текс перед записью</strong>
          </p>
          <p>
            <code>}                                      </code>
            <strong>(2) результатов</strong>
          </p>
          <p>Удерживать мьютекс на время выполнения <code>process()</code> нет необходимости, поэтому мы вручную освобождаем его перед вызовом <strong>(1)</strong> и снова захватываем после возврата <strong>(2)</strong>.</p>
          <p>Очевидно, что если один мьютекс защищает структуру данных целиком, то не только возрастает конкуренция за него, но и шансов снизить время удержания остается меньше. Поскольку под защитой одного мьютекса приходится выполнять больше операций, то и удерживать его нужно дольше. Такая двойная угроза должна вдвое усилить стремление всюду, где возможно, использовать мелкогранулярные блокировки.</p>
          <p>Как следует из примера, выбор подходящей гранулярности определяется не только объемом защищаемых данных, но и временем удержания блокировки и тем, какие операции выполняются под ее защитой. <emphasis>В общем случае блокировку следует удерживать ровно столько времени, сколько необходимо для завершения требуемых операций.</emphasis> Это также означает, что длительные операции, например захват другой блокировки (даже если известно, что это не приведет к взаимоблокировке) или ожидание завершения ввода/вывода, не следует выполнять под защитой блокировки, если только это не является абсолют пой необходимостью.</p>
          <p>В листингах 3.6 и 3.9 мы захватывали два мьютекса для операции обмела, которая очевидно требует одновременного доступа к обоим объектам. Предположим, однако, что требуется произвести сравнение простых членов данных типа <code>int</code>. В чем разница? Копирование целых чисел — дешевая операция, поэтому вполне можно было бы скопировать данные из каждого объекта под защитой мьютекса, а затем сравнить копии. Тогда мьютекс удерживался бы минимальное время, и к тому же не пришлось бы захватывать новый мьютекс, когда один уже удерживается. В следующем листинге показам как раз такой класс <code>Y</code> и пример реализации в нем оператора сравнения на равенство.</p>
          <empty-line/>
          <p><strong>Листинг 3.10</strong>. Поочерёдный захват мьютексов в операторе сравнения</p>
          <p>
            <code>class Y {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> int some_detail;</code>
          </p>
          <p>
            <code> mutable std::mutex m;</code>
          </p>
          <empty-line/>
          <p>
            <code> int get_detail() const {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock_a(m); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  return some_detail;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> Y(int sd): some_detail(sd) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> friend bool operator==(Y const&amp; lhs, Y const&amp; rhs) {</code>
          </p>
          <p>
            <code>  if (&amp;lhs == &amp;rhs)</code>
          </p>
          <p>
            <code>   return true;</code>
          </p>
          <p>
            <code>  int const lhs_value = lhs.get_detail(); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  int const rhs_value = rhs.get_detail(); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  return lhs_value == rhs_value; &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В данном случае оператор сравнения сначала получает сравниваемые значения, вызывая функцию-член <code>get_detail()</code> <strong>(2)</strong>, <strong>(3)</strong>. Эта функция извлекает значение, находясь под защитой мьютекса <strong>(1)</strong>. После этого оператор сравнивает полученные значения <strong>(4)</strong>. Отметим, однако, что наряду с уменьшением времени удержания блокировки за счет того, что в каждый момент захвачен только один мьютекс (и, стало быть, исключена возможность взаимоблокировки), мы немного изменили семантику операции по сравнению с реализацией, в которой оба мьютекса захватываются вместе. Если оператор в листинге 3.10 возвращает <code>true</code>, то это означает лишь, что значение <code>lhs.some_detail</code> в один момент времени равно значению <code>rhs.some_detail</code> в другой момент времени. Между двумя операциями считывания значения могли измениться как угодно; например, между точками <strong>(2)</strong> и <strong>(3)</strong> программа могла обменять их местами, и тогда сравнение оказалось бы вообще бессмысленным. Таким образом, возврат оператором сравнения значения <code>true</code>, означает, что значения были равны, пусть даже ни в какой момент времени фактическое равенство не наблюдалось. Очень важно следить, чтобы такие изменения семантики операций не приводили к проблемам: <emphasis>если блокировка не удерживается на протяжении всей операции, то возникает риск гонки</emphasis>.</p>
          <p>Иногда подходящего уровня гранулярности просто не существует, потому что не все операции доступа к структуре данных требуют одного и того же уровня защиты. В таком случае вместо простого класса <code>std::mutex</code> стоит поискать альтернативный механизм.</p>
        </section>
      </section>
      <section>
        <title>
          <p>3.3. Другие средства защиты разделяемых данных</p>
        </title>
        <section>
          <p>Хотя мьютексы и представляют собой наиболее общий механизм, но они не единственные игроки на поле защиты разделяемых данных. Есть и другие механизмы, обеспечивающие защиту в специальных случаях.</p>
          <p>Один такой крайний (но на удивление распространенный) случай возникает, когда разделяемые данные нуждаются в защите от одновременного доступа только на этапе инициализации, а потом уже никакой синхронизации не требуется. Так может быть, например, потому что после инициализации данные только читаются или потому что необходимая защита обеспечивается неявно как часть операций над данными. Как бы то ни было, захватывать мьютекс после того, как данные инициализированы, совершенно не нужно, это только снизило бы производительность. Поэтому в стандарте С++ предусмотрен механизм, служащий исключительно для защиты разделяемых данных во время инициализации.</p>
        </section>
        <section>
          <title>
            <p>3.3.1. Защита разделяемых данных во время инициализации</p>
          </title>
          <p>Предположим, имеется разделяемый ресурс, конструирование которого обходится настолько дорого, что мы хотим делать это, лишь когда действительно возникает необходимость; быть может, конструктор открывает базу данных или выделяет очень много памяти. Такая <emphasis>отложенная инициализация</emphasis> часто встречает в однопоточных программах — всякая операция, нуждающаяся в ресурсе, сначала проверяет, инициализирован ли он, и, если нет, выполняет инициализацию:</p>
          <p>
            <code>std::shared_ptr&lt;some_resource&gt; resource_ptr;</code>
          </p>
          <p>
            <code>void foo() {</code>
          </p>
          <p>
            <code> if (!resource_ptr) {</code>
          </p>
          <p>
            <code>  resource_ptr.reset(new some_resource); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> resource_ptr-&gt;do_something();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Если сам разделяемый ресурс безопасен относительно одновременного доступа, то при переходе к многопоточной реализации единственная нуждающаяся в защите часть — инициализация <strong>(1)</strong>, однако наивный подход, показанный в листинге ниже, может привести к ненужной сериализации использующих ресурс потоков. Дело в том, что каждый поток должен ждать освобождения мьютекса, чтобы проверить, был ли ресурс уже инициализирован.</p>
          <empty-line/>
          <p><strong>Листинг 3.11.</strong> Потокобезопасная отложенная инициализация с помощью мьютекса</p>
          <p>
            <code>std::shared_ptr&lt;some_resource&gt; resource_ptr;</code>
          </p>
          <p>
            <code>std::mutex resource_mutex; &#8592;&#9488;</code>
            <strong>В этой точке все потоки</strong>
          </p>
          <p>
            <code>                            &#9474;</code>
            <strong>сериализуются</strong>
          </p>
          <p>
            <code>void foo() {</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt; lk(resource_mutex);</code>
          </p>
          <p>
            <code> if (!resource_ptr) {</code>
          </p>
          <p>
            <code>  resource_ptr.reset(new some_resource); &#8592;&#9488;</code>
            <strong>в защите нуж-</strong>
          </p>
          <p>
            <code> }                                        &#9474;</code>
            <strong>дается только</strong>
          </p>
          <p>
            <code> lk.unlock();                             &#9474;</code>
            <strong>инициализация</strong>
          </p>
          <p>
            <code> resource_ptr-&gt;do_something();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Этот код встречается настолько часто, а ненужная сериализация вызывает столько проблем, что многие предпринимали попытки найти более приемлемое решение, в том числе печально известный паттерн <emphasis>блокировка с двойной проверкой</emphasis> (Double-Checked Locking): сначала указатель читается без захвата мьютекса <strong>(1)</strong> (см. код ниже), а захват производится, только если оказалось, что указатель равен <code>NULL</code>. Затем, когда мьютекс захвачен <strong>(2)</strong>, указатель проверяется <emphasis>еще раз</emphasis> (отсюда и слова «двойная проверка») на случай, если какой-то другой поток уже выполнил инициализацию в промежутке между первой проверкой и захватом мьютекса:</p>
          <p>
            <code>void undefined_behaviour_with_double_checked_locking() {</code>
          </p>
          <p>
            <code> if (!resource_ptr)                     &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(resource_mutex);</code>
          </p>
          <p>
            <code>  if (!resource_ptr)                     &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  {</code>
          </p>
          <p>
            <code>   resource_ptr.reset(new some_resource);&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> resource_ptr-&gt;do_something();           &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>«Печально известным» я назвал этот паттерн не без причины: он открывает возможность для крайне неприятного состояния гонки, потому что чтение без мьютекса <strong>(1)</strong> не синхронизировано с записью в другом потоке с уже захваченным мьютексом <strong>(3)</strong>. Таким образом, возникает гонка, угрожающая не самому указателю, а объекту, на который он указывает; даже если один поток видит, что указатель инициализирован другим потоком, он может не увидеть вновь созданного объекта <code>some_resource</code>, и, следовательно, вызов <code>do_something()</code> <strong>(4)</strong> будет применен не к тому объекту, что нужно. Такого рода гонка в стандарте С++ называется <emphasis>гонкой за данными</emphasis> (<emphasis>data race</emphasis>), она отнесена к категории <emphasis>неопределенного поведения</emphasis>.</p>
          <p>Комитет по стандартизации С++ счел этот случай достаточно важным, поэтому в стандартную библиотеку включен класс <code>std::once_flag</code> и шаблон функции <code>std::call_once</code>. Вместо того чтобы захватывать мьютекс и явно проверять указатель, каждый поток может просто вызвать функцию <code>std::call_once</code>, твердо зная, что к моменту возврата из нее указатель уже инициализирован каким-то потоком (без нарушения синхронизации). Обычно издержки, сопряженные с использованием <code>std::call_once</code>, ниже, чем при явном применении мьютекса, поэтому такое решение следует предпочесть во всех случаях, когда оно не противоречит требованиям задачи. В примере ниже код из листинга 3.11 переписан с использованием <code>std::call_once</code>. В данном случае инициализация производится путем вызова функции, но ничто не мешает завести для той же цели класс, в котором определен оператор вызова. Как и большинство функций в стандартной библиотеке, принимающих в качестве аргументов функции или предикаты, <code>std::call_once</code> работает как с функциями, так и с объектами, допускающими вызов.</p>
          <p>
            <code>std::shared_ptr&lt;some_resource&gt; resource_ptr;</code>
          </p>
          <p>
            <code>std::once_flag resource_flag;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code>void init_resource() {</code>
          </p>
          <p>
            <code> resource_ptr.reset(new some_resource);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <code>              &#9474;</code>
            <strong>Инициализация производится</strong>
          </p>
          <p>
            <code>void foo() { &#8592;&#9496;</code>
            <strong>ровно один раз</strong>
          </p>
          <p>
            <code> std::call_once(resource_flag, init_resource);</code>
          </p>
          <p>
            <code> resource_ptr-&gt;do_something();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Здесь переменная типа <code>std::once_flag</code> <strong>(1)</strong> и инициализируемый объект определены в области видимости пространства имен, но <code>std::call_once()</code> вполне можно использовать и для отложенной инициализации членов класса, как показано в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 3.12.</strong> Потокобезопасная отложенная инициализация члена класса с помощью функции <code>std::call_once()</code></p>
          <p>
            <code>class X {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> connection_infо connection_details;</code>
          </p>
          <p>
            <code> connection_handle connection;</code>
          </p>
          <p>
            <code> std::once_flag connection_init_flag;</code>
          </p>
          <empty-line/>
          <p>
            <code> void open_connection() {</code>
          </p>
          <p>
            <code>  connection = connection_manager.open(connection_details);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> X(connection_info const&amp; connection_details_):</code>
          </p>
          <p>
            <code>  connection_details(connection_details_) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void send_data(data_packet const&amp; data)&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> {</code>
          </p>
          <p>
            <code>  std::call_once(</code>
          </p>
          <p>
            <code>   connection_init_flag, &amp;X::open_connection, this);&#8592;&#9488;</code>
          </p>
          <p>
            <code>  connection.send_data(data);                        &#9474;</code>
          </p>
          <p>
            <code> }                                                   &#9474;</code>
          </p>
          <p>
            <code> data_packet receive_data() { &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  std::call_once(                                    &#9474;</code>
          </p>
          <p>
            <code>   connection_init_flag, &amp;X::open_connection, 2)    </code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   this);                                           &#8592;&#9496;</code>
          </p>
          <p>
            <code>  return connection.receive_data();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В этом примере инициализация производится либо при первом обращении к <code>send_data()</code> <strong>(1)</strong>, либо при первом обращении к <code>receive_data()</code> <strong>(3)</strong>. Поскольку данные инициализируются функцией-членом <code>open_connection()</code>, то требуется передавать также указатель <code>this</code>. Как и во всех функциях из стандартной библиотеки, которые принимают объекты, допускающие вызов, (например, конструктор <code>std::thread</code> и функция <code>std::bind()</code>), это делается путем передачи <code>std::call_once()</code> дополнительного аргумента <strong>(2)</strong>.</p>
          <p>Следует отметить, что, как и в случае <code>std:mutex</code>, объекты типа <code>std::once_flag</code> нельзя ни копировать, ни перемещать, поэтому, если вы собираетесь использовать их как члены классы, то соответствующие конструкторы придется определить явно (если это необходимо).</p>
          <p>Возможность гонки при инициализации возникает, в частности, при объявлении локальной переменной с классом памяти <code>static</code>. По определению, инициализация такой переменной происходит, когда поток управления программы первый раз проходит через ее объявление. Но если функция вызывается в нескольких потоках, то появляется потенциальная возможность гонки за то, кто определит переменную первым. Во многих компиляторах, выпущенных до утверждения стандарта С++11, эта гонка действительно приводит к проблемам, потому что любой из нескольких потоков, полагая, что успел первым, может попытаться инициализировать переменную. Может также случиться, что некоторый поток попытается использовать переменную после того, как инициализация началась в другом потоке, но до того, как она закончилась. В С++11 эта проблема решена: по определению, инициализация производится ровно в одном потоке, и никакому другому потоку не разрешено продолжать выполнение, пока инициализация не завершится, поэтому потоки конкурируют лишь за право выполнить инициализацию первым, ничего более серьёзного случиться не может. Это свойство можно использовать как альтернативу функции <code>std::call_once</code>, когда речь идет об инициализации единственной глобальной переменной:</p>
          <p>
            <code>class my_class;</code>
          </p>
          <p>
            <code> my_class&amp; get_my_class_instance() {</code>
          </p>
          <p>
            <code> static my_class instance; &#8592;&#9488;</code>
            <strong>Гарантируется, что инициализация</strong>
          </p>
          <p>
            <code> return instance;          </code>
            <strong>(1) потокобезопасна</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Теперь несколько потоков могут вызывать функцию <code>get_my_class_instance()</code> <strong>(1)</strong>, не опасаясь гонки при инициализации.</p>
          <p>Защита данных только на время инициализации — частный случай более общего сценария: доступ к редко обновляемой структуре данных. Обычно к такой структуре обращаются для чтения, когда ни о какой синхронизации можно не беспокоиться. Но иногда требуется обновить данные в ней. Нам необходим такой механизм защиты, который учитывал бы эти особенности.</p>
        </section>
        <section>
          <title>
            <p>3.3.2. Защита редко обновляемых структур данных</p>
          </title>
          <p>Рассмотрим таблицу, в которой хранится кэш записей DNS, необходимых для установления соответствия между доменными именами и IP-адресами. Как правило, записи DNS остаются неизменными в течение длительного времени — зачастую многих лет. Новые записи, конечно, добавляются — скажем, когда открывается новый сайт — но на протяжении всей своей жизни обычно не меняются. Периодически необходимо проверять достоверность данных в кэше, но и тогда обновление требуется, лишь если данные действительно изменились.</p>
          <p>Но хотя обновления происходят редко, они все же случаются, и если к кэшу возможен доступ со стороны нескольких потоков, то необходимо обеспечить надлежащую защиту, чтобы ни один поток, читающий кэш, не увидел наполовину обновленной структуры данных. Если структура данных не специализирована для такого способа использования (как описано в главах 6 и 7), то поток, который хочет обновить данные, должен получить монопольный доступ к структуре на все время выполнения операции. После того как операция обновления завершится, структуру данных снова смогут одновременно читать несколько потоков.</p>
          <p>Использование <code>std::mutex</code> для защиты такой структуры данных излишне пессимистично, потому что при этом исключается даже возможность одновременного чтения, когда никакая модификация не производится. Нам необходим какой-то другой вид мьютекса. Такой мьютекс есть, и обычно его называют мьютексом <emphasis>чтения-записи</emphasis> (reader-writer mutex), потому что он допускает два режима: монопольный доступ со стороны одного «потока-писателя» и параллельный доступ со стороны нескольких «потоков-читателей».</p>
          <p>В новой стандартной библиотеке С++ такой мьютекс не предусмотрен, хотя комитету и было подано предложение<a l:href="#n6" type="note">[6]</a>. Поэтому в этом разделе мы будем пользоваться реализацией из библиотеки Boost, которая основана на отвергнутом предложении. В главе 8 вы увидите, что использование такого мьютекса — не панацея, а его производительность зависит от количества участвующих процессоров и относительного распределения нагрузки между читателями и писателями. Поэтому важно профилировать работу программу в целевой системе и убедиться, что добавочная сложность действительно дает какой-то выигрыш.</p>
          <p>Итак, вместо <code>std::mutex</code> мы воспользуемся для синхронизации объектом <code>boost::shared_mutex</code>. При выполнении обновления мы будем использовать для захвата мьютекса шаблоны <code>std::lock_guard&lt;boost::shared_mutex&gt;</code> и <code>std::unique_lock&lt;boost::shared_mutex&gt;</code>, параметризованные классом <code>boost::shared_mutex</code>, а не <code>std::mutex</code>. Они точно так же гарантируют монопольный доступ. Те же потоки, которым не нужно обновлять структуру данных, могут воспользоваться классом <code>boost::shared_lock&lt;boost::shared_mutex&gt;</code> для получения <emphasis>разделяемого</emphasis> доступа. Применяется он так же, как <code>std::unique_lock</code>, но в семантике имеется одно важное отличие: несколько потоков могут одновременно получить разделяемую блокировку на один и тот же объект <code>boost::shared_mutex</code>. Однако если какой-то поток уже захватил разделяемую блокировку, то любой поток, который попытается захватить монопольную блокировку, будет приостановлен до тех пор, пока все прочие потоки не освободят свои блокировки. И наоборот, если какой-то поток владеет монопольной блокировкой, то никакой другой поток не сможет получить ни разделяемую, ни монопольную блокировку, пока первый поток не освободит свою.</p>
          <p>В листинге ниже приведена реализация простого DNS-кэша, в котором данные хранятся в контейнере <code>std::map</code>, защищенном с помощью <code>boost::shared_mutex</code>.</p>
          <empty-line/>
          <p><strong>Листинг 3.13.</strong> Защита структуры данных с помощью <code>boost::shared_mutex</code></p>
          <p>
            <code>#include &lt;map&gt;</code>
          </p>
          <p>
            <code>#include &lt;string&gt;</code>
          </p>
          <p>
            <code>#include &lt;mutex&gt;</code>
          </p>
          <p>
            <code>#include &lt;boost/thread/shared_mutex.hpp&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>class dns_entry;</code>
          </p>
          <p>
            <code>class dns_cache {</code>
          </p>
          <p>
            <code> std::map&lt;std::string, dns_entry&gt; entries;</code>
          </p>
          <p>
            <code> mutable boost::shared_mutex entry_mutex;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> dns_entry find_entry(std::string const&amp; domain) const {</code>
          </p>
          <p>
            <code>  boost::shared_lock&lt;boost::shared_mutex&gt; lk(entry_mutex); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  std::map&lt;std::string, dns_entry&gt;::const_iterator const it =</code>
          </p>
          <p>
            <code>   entries.find(domain);</code>
          </p>
          <p>
            <code>  return (it == entries.end()) ? dns_entry() : it-&gt;second;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void update_or_add_entry(std::string const&amp; domain,</code>
          </p>
          <p>
            <code>  dns_entry const&amp; dns_details) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;boost::shared_mutex&gt; lk(entry_mutex); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  entries[domain] = dns_details;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В листинге 3.13 в функции <code>find_entry()</code> используется объект <code>boost::shared_lock&lt;&gt;</code>, обеспечивающий разделяемый доступ к данным для чтения <strong>(1)</strong>; следовательно, ее можно спокойно вызывать одновременно из нескольких потоков. С другой стороны, в функции <code>update_or_add_entry()</code> используется объект <code>std::lock_guard&lt;&gt;</code>, который обеспечивает монопольный доступ на время обновления таблицы <strong>(2)</strong>, и, значит, блокируются не только другие потоки, пытающиеся одновременно выполнить <code>update_or_add_entry()</code>, но также потоки, вызывающие <code>find_entry()</code>.</p>
        </section>
        <section>
          <title>
            <p>3.3.3. Рекурсивная блокировка</p>
          </title>
          <p>Попытка захватить <code>std::mutex</code> в потоке, который уже владеет им, является ошибкой и приводит к <emphasis>неопределенному поведению</emphasis>. Однако бывают случаи, когда потоку желательно повторно захватывать один и тот же мьютекс, не освобождая его предварительно. Для этого в стандартной библиотеке С++ предусмотрен класс <code>std::recursive_mutex</code>. Работает он аналогично <code>std::mutex</code>, но с одним отличием: один и тот же поток может многократно захватывать данный мьютекс. Но перед тем как этот мьютекс сможет захватить другой поток, его нужно освободить столько раз, сколько он был захвачен. Таким образом, если функция <code>lock()</code> вызывалась три раза, то и функцию unlock() нужно будет вызвать трижды. При правильном использовании <code>std::lock_guard&lt;std::recursive_mutex&gt;</code> и <code>std::unique_lock&lt;std::recursive_mutex&gt;</code> это гарантируется автоматически.</p>
          <p>Как правило, программу, в которой возникает необходимость в рекурсивном мьютексе, лучше перепроектировать. Типичный пример использования рекурсивного мьютекса возникает, когда имеется класс, к которому могут обращаться несколько потоков, так что для защиты его данных необходим мьютекс. Каждая открытая функция-член захватывает мьютекс, что-то делает, а затем освобождает его. Но бывает, что одна открытая функция-член вызывает другую, и в таком случае вторая также попытается захватить мьютекс, что приведет к неопределенному поведению. Тогда, чтобы решить проблему по-быстрому, обычный мьютекс заменяют рекурсивным. Это позволит второй функции захватить мьютекс и продолжить работу.</p>
          <p>Однако такое решение <emphasis>не рекомендуется</emphasis>, потому что является признаком небрежного и плохо продуманного проектирования. В частности, при работе под защитой мьютекса часто нарушаются инварианты класса, а это означает, что вторая функция-член должна правильно работать даже в условиях, когда некоторые инварианты не выполняются. Обычно лучше завести новую закрытую функцию-член, которая вызывается из обеих открытых и не захватывает мьютекс (то есть предполагает, что мьютекс уже захвачен). Затем следует тщательно продумать, при каких условиях эта новая функция может вызываться и в каком состоянии будут при этом находиться данные.</p>
        </section>
      </section>
      <section>
        <title>
          <p>3.4. Резюме</p>
        </title>
        <p>В этой главе мы рассмотрели, к каким печальным последствиям могут приводить проблематичные гонки, когда возможно разделение данных между потоками, и как с помощью класса <code>std::mutex</code> и тщательного проектирования интерфейса этих неприятностей можно избежать. Мы видели, что мьютексы — не панацея, поскольку им свойственны собственные проблемы в виде взаимоблокировки, хотя стандартная библиотека С++ содержит средство, позволяющее избежать их — класс <code>std::lock()</code>. Затем мы обсудили другие способы избежать взаимоблокировок и кратко обсудили передачу владения блокировкой и вопросы, касающиеся выбора подходящего уровня гранулярности блокировки. Наконец, я рассказал об альтернативных механизмах защиты данных, применяемых в специальных случаях: <code>std::call_once()</code> и <code>boost::shared_mutex</code>.</p>
        <p>А вот чего мы пока не рассмотрели, так это ожидание поступления входных данных из других потоков. Наш потокобезопасный стек просто возбуждает исключение при попытке извлечения из пустого стека. Поэтому если один поток хочет дождаться, пока другой поток поместит в стек какие-то данные (а это, собственно, и есть основное назначение потокобезопасного стека), то должен будет раз за разом пытаться извлечь значение, повторяя попытку в случае исключения. Это приводит лишь к бесцельной трате процессорного времени на проверку; более того, такая повторяющаяся проверка может замедлить работу программы, поскольку не дает выполняться другим потокам. Нам необходим какой-то способ, который позволил бы одному потоку ждать завершения операции в другом потоке, не потребляя процессорное время. В главе 4, которая опирается на рассмотренные выше средства защиты разделяемых данных, мы познакомимся с различными механизмами синхронизации операций между потоками в С++, а в главе 6 увидим, как с помощью этих механизмов можно строить более крупные структуры данных, допускающие повторное использование.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Глава 4.</p>
        <p>Синхронизация параллельных операций</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Ожидание события.</p>
        <p>&#9632; Ожидание однократного события с будущими результатами</p>
        <p>&#9632; Ожидание с ограничением по времени.</p>
        <p>&#9632; Использование синхронизации операций для упрощения программы.</p>
      </annotation>
      <section>
        <p>В предыдущей главе мы рассмотрели различные способы защиты данных, разделяемых между потоками. Но иногда требуется не только защитить данные, но и синхронизировать действия, выполняемые в разных потоках. Например, возможно, что одному потоку перед тем как продолжить работу, нужно дождаться, пока другой поток завершит какую-то операцию. В общем случае, часто возникает ситуация, когда поток должен ожидать какого-то события или истинности некоторого условия. Конечно, это можно сделать, периодически проверяя разделяемый флаг «задача завершена» или что-то в этом роде, но такое решение далеко от идеала. Необходимость в синхронизации операций — настолько распространенный сценарий, что в стандартную библиотеку С++ включены специальные механизмы для этой цели — <emphasis>условные переменные</emphasis> и <emphasis>будущие результаты</emphasis> (future).</p>
        <p>В этой главе мы рассмотрим, как реализуется ожидание событий с помощью условных переменных и будущих результатов и как ими можно воспользоваться, чтобы упростить синхронизацию операций.</p>
      </section>
      <section>
        <title>
          <p>4.1. Ожидание события или иного условия</p>
        </title>
        <section>
          <p>Представьте, что вы едете на поезде ночью. Чтобы не пропустить свою станцию, можно не спать всю ночь и читать названия всех пунктов, где поезд останавливается. Так вы, конечно, не проедете мимо, но сойдете с поезда сильно уставшим. Есть и другой способ — заранее посмотреть в расписании, когда поезд прибывает в нужный вам пункт, поставить будильник и улечься спать. Так вы тоже свою остановку не пропустите, но если поезд задержится в пути, то проснётесь слишком рано. И еще одно — если в будильнике сядут батарейки, то вы можете проспать и проехать мимо нужной станции. В идеале хотелось бы, чтобы кто-то или что-то разбудило вас, когда поезд подъедет к станции, — не раньше и не позже.</p>
          <p>Какое отношение всё это имеет к потокам? Самое непосредственное — если один поток хочет дождаться, когда другой завершит некую операцию, то может поступить несколькими способами. Во-первых, он может просто проверять разделяемый флаг (защищенный мьютексом), полагая, что второй поток поднимет этот флаг, когда завершит свою операцию. Это расточительно но двум причинам: на опрос флага уходит процессорное время, и мьютекс, захваченный ожидающим потоком, не может быть захвачен никаким другим потоком. То и другое работает против ожидающего потока, поскольку ограничивает ресурсы, доступные потоку, которого он так ждет, и даже не дает ему возможность поднять флаг, когда работа будет завершена. Это решение сродни бодрствованию всю ночь, скрашиваемому разговорами с машинистом: он вынужден вести поезд медленнее, потому что вы его постоянно отвлекаете, и, значит, до пункта назначения вы доберетесь позже. Вот и ожидающий поток потребляет ресурсы, которые пригодились бы другим потокам, в результате чего ждет дольше, чем необходимо.</p>
          <p>Второй вариант — заставить ожидающий поток спать между проверками с помощью функции <code>std::this_thread::sleep_for()</code> (см. раздел 4.3):</p>
          <p>
            <code>bool flag;</code>
          </p>
          <p>
            <code>std::mutex m;</code>
          </p>
          <empty-line/>
          <p>
            <code>void wait_for_flag() {</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt; lk(m); &#8592;</code>
            <strong>(1) Освободить мьютекс</strong>
          </p>
          <p>
            <code> while (!flag) {</code>
          </p>
          <p>
            <code>  lk.unlock(); &#8592;</code>
            <strong>(2) Спать 100 мс</strong>
          </p>
          <p>
            <code>  std::this_thread::sleep_for(std::chrono::milliseconds(100));</code>
          </p>
          <p>
            <code>  lk.lock();   &#8592;</code>
            <strong>(3) Снова захватить мьютекс</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В этом цикле функция освобождает мьютекс <strong>(1)</strong> перед тем, как заснуть <strong>(2)</strong>, и снова захватывает его, проснувшись, <strong>(3)</strong>, оставляя другому потоку шанс захватить мьютекс и поднять флаг.</p>
          <p>Это уже лучше, потому что во время сна поток не расходует процессорное время. Но трудно выбрать подходящий промежуток времени. Если он слишком короткий, то поток все равно впустую тратит время на проверку; если слишком длинный — то поток будет спать и после того, как ожидание завершилось, то есть появляется ненужная задержка. Редко бывает так, что слишком длительный сон прямо влияет на работу программу, но в динамичной игре это может привести к пропуску кадров, а в приложении реального времени — к исчерпанию выделенного временного кванта.</p>
          <p>Третий — и наиболее предпочтительный - способ состоит в том, чтобы воспользоваться средствами из стандартной библиотеки С++, которые позволяют потоку ждать события. Самый простой механизм ожидания события, возникающего в другом потоке (например, появления нового задания в упоминавшемся выше конвейере), дают <emphasis>условные переменные</emphasis>. Концептуально условная переменная ассоциирована с каким-то событием или иным <emphasis>условием</emphasis>, причём один или несколько потоков могут <emphasis>ждать</emphasis>, когда это условие окажется выполненным. Если некоторый поток решит, что условие выполнено, он может <emphasis>известить</emphasis> об этом один или несколько потоков, ожидающих условную переменную, в результате чего они возобновят работу.</p>
        </section>
        <section>
          <title>
            <p>4.1.1. Ожидание условия с помощью условных переменных</p>
          </title>
          <p>Стандартная библиотека С++ предоставляет не одну, а <emphasis>две</emphasis> реализации условных переменных: <code>std::condition_variable</code> и <code>std::condition_variable_any</code>. Оба класса объявлены в заголовке <code>&lt;condition_variable&gt;</code>. В обоих случаях для обеспечения синхронизации необходимо взаимодействие с мьютексом; первый класс может работать только с <code>std::mutex</code>, второй — с любым классом, который отвечает минимальным требованиям к «мьютексоподобию», отсюда и суффикс <code>_any</code>. Поскольку класс <code>std::condition_variable_any</code> более общий, то его использование может обойтись дороже с точки зрения объема потребляемой памяти, производительности и ресурсов операционной системы. Поэтому, если дополнительная гибкость не требуется, то лучше ограничиться классом <code>std::condition_variable</code>.</p>
          <p>Ну и как же воспользоваться классом <code>std::condition_variable</code> в примере, упомянутом во введении, — как сделать, чтобы поток, ожидающий работу, спал, пока не поступят данные? В следующем листинге приведён пример реализации с использованием условной переменной.</p>
          <empty-line/>
          <p><strong>Листинг 4.1</strong>. Ожидание данных с помощью <code>std::condition_variable</code></p>
          <p>
            <code>std::mutex mut;</code>
          </p>
          <p>
            <code>std::queue&lt;data_chunk&gt; data_queue; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>std::condition_variable data_cond;</code>
          </p>
          <empty-line/>
          <p>
            <code>void data_preparation_thread() {</code>
          </p>
          <p>
            <code> while (more_data_to_prepare()) {</code>
          </p>
          <p>
            <code>  data_chunk const data = prepare_data();</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_queue.push(data);  &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  data_cond.notify_one(); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void data_processing_thread() {</code>
          </p>
          <p>
            <code> while(true) {</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(mut); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  data_cond.wait(</code>
          </p>
          <p>
            <code>   lk, []{ return !data_queue.empty(); }); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  data_chunk data = data_queue.front();</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  lk.unlock(); &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  process(data);</code>
          </p>
          <p>
            <code>  if (is_last_chunk(data))</code>
          </p>
          <p>
            <code>   break;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Итак, мы имеем очередь <strong>(1)</strong>, которая служит для передачи данных между двумя потоками. Когда данные будут готовы, поток, отвечающий за их подготовку, помещает данные в очередь, предварительно захватив защищающий ее мьютекс с помощью <code>std::lock_guard</code>. Затем он вызывает функцию-член <code>notify_one()</code> объекта <code>std::condition_variable</code>, чтобы известить ожидающий поток (если таковой существует) <strong>(3)</strong>.</p>
          <p>По другую сторону забора находится поток, обрабатывающий данные. Он в самом начале захватывает мьютекс, но с помощью <code>std::unique_lock</code>, а не <code>std::lock_guard</code> <strong>(4)</strong> — почему, мы скоро увидим. Затем поток вызывает функцию-член <code>wait()</code> объекта <code>std::condition_variable</code>, передавая ей объект-блокировку и лямбда-функцию, выражающую ожидаемое условие <strong>(5)</strong>. Лямбда-функции — это нововведение в С++11, они позволяют записать анонимную функцию как часть выражения и идеально подходят для задания предикатов для таких стандартных библиотечных функций, как <code>wait()</code>. В данном случае простая лямбда-функция <code>[]{ return !data_queue.empty(); }</code> проверяет, что очередь <code>data_queue</code> не пуста (вызывая ее метод <code>empty()</code>), то есть что в ней имеются данные для обработки. Подробнее лямбда-функции описаны в разделе А.5 приложения А.</p>
          <p>Затем функция <code>wait()</code> проверяет условие (вызывая переданную лямбда-функцию) и возвращает управление, если оно выполнено (то есть лямбда-функция вернула <code>true</code>). Если условие не выполнено (лямбда-функция вернула <code>false</code>), то <code>wait()</code> освобождает мьютекс и переводит поток в состояние ожидания. Когда условная переменная получит извещение, отправленное потоком подготовки данных с помощью <code>notify_one()</code>, поток обработки пробудится, вновь захватит мьютекс и еще раз проверит условие. Если условие выполнено, то <code>wait()</code> вернет управление, причём мьютекс в этот момент будет захвачен. Если же условие не выполнено, то поток снова освобождает мьютекс и возобновляет ожидание. Именно поэтому нам необходим <code>std::unique_lock</code>, а не <code>std::lock_guard</code> — ожидающий поток должен освобождать мьютекс, когда находится в состоянии ожидания, и захватывать его но выходе из этого состояния, a <code>std::lock_guard</code> такой гибкостью не обладает. Если бы мьютекс оставался захваченным в то время, когда поток обработки спит, поток подготовки данных не смог бы захватить его, чтобы поместить новые данные в очередь, а, значит, ожидаемое условие никогда не было бы выполнено.</p>
          <p>В листинге 4.1 используется простая лямбда-функция <strong>(5)</strong>, которая проверяет, что очередь не пуста. Однако с тем же успехом можно было бы передать любую функцию или объект, допускающий вызов. Если функция проверки условия уже существует (быть может, она сложнее показанного в примере простенького теста), то передавайте ее напрямую — нет никакой необходимости обертывать ее лямбда-функцией. Внутри <code>wait()</code> условная переменная может проверять условие многократно, но всякий раз это делается после захвата мьютекса, и, как только функция проверки условия вернет <code>true</code> (и лишь в этом случае), <code>wait()</code> возвращает управление вызывающей программе. Ситуация, когда ожидающий поток захватывает мьютекс и проверяет условие не в ответ на извещение от другого потока, называется <emphasis>ложным пробуждением</emphasis> (spurious wake). Поскольку количество и частота ложных пробуждений по определению недетерминированы, нежелательно использовать для проверки условия функцию с побочными эффектами. В противном случае будьте готовы к тому, что побочный эффект может возникать более одного раза.</p>
          <p>Присущая <code>std::unique_lock</code> возможность освобождать мьютекс используется не только при обращении к <code>wait()</code>, но и непосредственно перед обработкой поступивших данных <strong>(6)</strong>. Обработка может занимать много времени, а, как было отмечено в главе 3, удерживать мьютекс дольше необходимого неразумно.</p>
          <p>Применение очереди для передачи данных между потоками (как в листинге 4.1) — весьма распространенный прием. При правильной реализации синхронизацию можно ограничить только самой очередью, что уменьшает количество потенциальных проблем и состояний гонки. Поэтому покажем, как на основе листинга 4.1 построить обобщенную потокобезопасную очередь.</p>
        </section>
        <section>
          <title>
            <p>4.1.2. Потокобезопасная очередь на базе условных переменных</p>
          </title>
          <p>Приступая к проектированию обобщенной очереди, стоит потратить некоторое время на обдумывание того, какие понадобятся операции. Именно так мы подходили к разработке потокобезопасного стека в разделе 3.2.3. Возьмем в качестве образца адаптер контейнера <code>std::queue&lt;&gt;</code> из стандартной библиотеки С++, интерфейс которого показан в листинге ниже.</p>
          <empty-line/>
          <p><strong>Листинг 4.2.</strong> Интерфейс класса <code>std::queue</code></p>
          <p>
            <code>template &lt;class T, class Container = std::deque&lt;T&gt;&gt;</code>
          </p>
          <p>
            <code>class queue {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> explicit queue(const Container&amp;);</code>
          </p>
          <p>
            <code> explicit queue(Container&amp;&amp; = Container());</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;class Alloc&gt; explicit queue(const Alloc&amp;);</code>
          </p>
          <p>
            <code> template &lt;class Alloc&gt; queue(const Container&amp;, const Alloc&amp;);</code>
          </p>
          <p>
            <code> template &lt;class Alloc&gt; queue(Container&amp;&amp;, const Alloc&amp;);</code>
          </p>
          <p>
            <code> template &lt;class Alloc&gt; queue(queue&amp;&amp;, const Alloc&amp;);</code>
          </p>
          <empty-line/>
          <p>
            <code> void swap(queue&amp; q);</code>
          </p>
          <empty-line/>
          <p>
            <code> bool empty() const;</code>
          </p>
          <p>
            <code> size_type size() const;</code>
          </p>
          <empty-line/>
          <p>
            <code> T&amp; front();</code>
          </p>
          <p>
            <code> const T&amp; front() const;</code>
          </p>
          <p>
            <code> T&amp; back();</code>
          </p>
          <p>
            <code> const T&amp; back() const;</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(const T&amp; x);</code>
          </p>
          <p>
            <code> void push(T&amp;&amp; x);</code>
          </p>
          <p>
            <code> void pop();</code>
          </p>
          <p>
            <code> template &lt;class... Args&gt; void emplace(Args&amp;&amp;... args);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Если не обращать внимания на конструирование, присваивание и обмен, то останется три группы операций: опрос состояния очереди в целом (<code>empty()</code> и <code>size()</code>), опрос элементов очереди (<code>front()</code> и <code>back()</code>) модификация очереди (<code>push()</code>, <code>pop()</code> и <code>emplace()</code>). Ситуация аналогична той, что мы видели в разделе 3.2.3 для стека, поэтому возникают те же — внутренне присущие интерфейсу — проблемы с гонкой. Следовательно, <code>front()</code> и <code>pop()</code> необходимо объединить в одной функции — точно так же, как мы постудили с <code>top()</code> и <code>pop()</code> в случае стека. Но в коде в листинге 4.1 есть дополнительный нюанс: если очередь используется для передачи данных между потоками, то поток-получатель часто будет ожидать поступления данных. Поэтому включим два варианта <code>pop()</code>: <code>try_pop()</code> пытается извлечь значение из очереди, но сразу возвращает управление (с указанием ошибки), если в очереди ничего не было, a <code>wait_and_pop()</code> ждет, когда появятся данные. Взяв за образец сигнатуры функций из примера стека, представим интерфейс в следующем виде:</p>
          <empty-line/>
          <p><strong>Листинг 4.3.</strong> Интерфейс класса <code>threadsafe_queue</code></p>
          <p>
            <code>#include &lt;memory&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_queue {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_queue();</code>
          </p>
          <p>
            <code> threadsafe_queue(const threadsafe_queue&amp;);</code>
          </p>
          <p>
            <code> threadsafe_queue&amp; operator=(</code>
          </p>
          <p>
            <code>  const threadsafe_queue&amp;) = delete; &#8592;&#9488;</code>
            <strong>Для простоты</strong>
          </p>
          <p>
            <code> void push(T new_value);              &#9474;</code>
            <strong>запрещаем присваивание</strong>
          </p>
          <empty-line/>
          <p>
            <code> bool try_pop(T&amp; value);       &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; try_pop(); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <empty-line/>
          <p>
            <code> void wait_and_pop(T&amp; value);</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; wait_and_pop();</code>
          </p>
          <empty-line/>
          <p>
            <code> bool empty() const;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Как и в случае стека, мы для простоты уменьшили число конструкторов и запретили присваивание. И, как и раньше, предлагаем по два варианта функций <code>try_pop()</code> и <code>wait_for_pop()</code>. Первый перегруженный вариант <code>try_pop()</code> <strong>(1)</strong> сохраняет извлеченное значение в переданной по ссылке переменной, а возвращаемое значение использует для индикации ошибки: оно равно <code>true</code>, если значение получено, и <code>false</code> — в противном случае (см. раздел А.2). Во втором перегруженном варианте <strong>(2)</strong> так поступить нельзя, потому что возвращаемое значение — это данные, извлеченные из очереди. Однако же можно возвращать указатель <code>NULL</code>, если в очереди ничего не оказалось.</p>
          <p>Ну и как же всё это соотносится с листингом 4.1? В следующем листинге показано, как перенести оттуда код в методы <code>push()</code> и <code>wait_and_pop()</code>.</p>
          <empty-line/>
          <p><strong>Листинг 4.4.</strong> Реализация функций <code>push()</code> и <code>wait_and_pop()</code> на основе кода из листинга 4.1</p>
          <p>
            <code>#include &lt;queue&gt;</code>
          </p>
          <p>
            <code>#include &lt;mutex&gt;</code>
          </p>
          <p>
            <code>#include &lt;condition_variable&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> std::mutex mut;</code>
          </p>
          <p>
            <code> std::queue&lt;T&gt; data_queue;</code>
          </p>
          <p>
            <code> std::condition_variable data_cond;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_queue.push(new_value);</code>
          </p>
          <p>
            <code>  data_cond.notify_one();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void wait_and_pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_cond.wait(lk, [this]{return !data_queue.empty();});</code>
          </p>
          <p>
            <code>  value = data_queue.front();</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>threadsafe_queue&lt;data_chunk&gt; data_queue; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code>void data_preparation_thread() {</code>
          </p>
          <p>
            <code> while (more_data_to_prepare()) {</code>
          </p>
          <p>
            <code>  data_chunk const data = prepare_data();</code>
          </p>
          <p>
            <code>  data_queue.push(data); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void data_processing_thread() {</code>
          </p>
          <p>
            <code> while (true) {</code>
          </p>
          <p>
            <code>  data_chunk data;</code>
          </p>
          <p>
            <code>  data_queue.wait_and_pop(data); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  process(data);</code>
          </p>
          <p>
            <code>  if (is_last_chunk(data))</code>
          </p>
          <p>
            <code>   break;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Теперь мьютекс и условная переменная находятся в экземпляре <code>threadsafe_queue</code>, поэтому не нужно ни отдельных переменных <strong>(1)</strong>, ни внешней синхронизации при обращении к функции <code>push()</code> <strong>(2)</strong>. Кроме того, <code>wait_and_pop()</code> берет на себя заботу об ожидании условной переменной <strong>(3)</strong>.</p>
          <p>Второй перегруженный вариант <code>wait_and_pop()</code> тривиален, а остальные функции можно почти без изменений скопировать из кода стека в листинге 3.5. Ниже приведена окончательная реализация.</p>
          <empty-line/>
          <p><strong>Листинг 4.5</strong>. Полное определение класса потокобезопасной очереди на базе условных переменных</p>
          <p>
            <code>#include &lt;queue&gt;</code>
          </p>
          <p>
            <code>#include &lt;memory&gt;</code>
          </p>
          <p>
            <code>#include &lt;mutex&gt;</code>
          </p>
          <p>
            <code>#include &lt;condition_variable&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> mutable std::mutex mut;&#8592;</code>
            <strong>(1) Мьютекс должен быть изменяемым</strong>
          </p>
          <p>
            <code> std::queue&lt;T&gt; data_queue;</code>
          </p>
          <p>
            <code> std::condition_variable data_cond;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_queue() {}</code>
          </p>
          <p>
            <code> threadsafe_queue(threadsafe_queue const&amp; other) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(other.mut);</code>
          </p>
          <p>
            <code>  data_queue = other.data_queue;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_queue.push(new_value);</code>
          </p>
          <p>
            <code>  data_cond.notify_one();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void wait_and_pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_cond.wait(lk, [this]{ return !data_queue.empty(); });</code>
          </p>
          <p>
            <code>  value = data_queue.front();</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; wait_and_pop() {</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_cond.wait(lk, [this]{ return !data_queue.empty(); });</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt;</code>
          </p>
          <p>
            <code>   res(std::make_shared&lt;T&gt;(data_queue.front()));</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool try_pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  if (data_queue.empty())</code>
          </p>
          <p>
            <code>   return false;</code>
          </p>
          <p>
            <code>  value = data_queue.front();</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  return true;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; try_pop() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  if (data_queue.empty())</code>
          </p>
          <p>
            <code>   return std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt;</code>
          </p>
          <p>
            <code>   res(std::make_shared&lt;T&gt;(data_queue.front()));</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool empty() const {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  return data_queue.empty();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Хотя <code>empty()</code> — константная функция-член, а параметр копирующего конструктора — <code>const</code>-ссылка, другие потоки могут хранить неконстантные ссылки на объект и вызывать изменяющие функции-члены, которые захватывают мьютекс. Поэтому захват мьютекса — это изменяющая операция, следовательно, член <code>mut</code> необходимо пометить как <code>mutable</code> <strong>(1)</strong>, чтобы его можно было захватить в функции <code>empty()</code> и в копирующем конструкторе.</p>
          <p>Условные переменные полезны и тогда, когда есть несколько потоков, ожидающих одного события. Если потоки используются для разделения работы и, следовательно, на извещение должен реагировать только один поток, то применима точно такая же структура программы, как в листинге 4.1; нужно только запустить несколько потоков обработки данных. При поступлении новых данных функция <code>notify_one()</code> разбудит только один поток, который проверяет условие внутри <code>wait()</code>, и этот единственный поток вернет управление из <code>wait()</code> (в ответ на помещение нового элемента в очередь <code>data_queue</code>). Заранее нельзя сказать, какой поток получит извещение и есть ли вообще ожидающие потоки (не исключено, что все они заняты обработкой ранее поступивших данных).</p>
          <p>Альтернативный сценарий — когда несколько потоков ожидают одного события, и отреагировать должны все. Так бывает, например, когда инициализируются разделяемые данные, и все работающие с ними потоки должны ждать, пока инициализация завершится (хотя для этого случая существуют более подходящие механизмы, см. раздел 3.3.1 главы 3), или когда потоки должны ждать обновления разделяемых данных, например, в случае периодической повторной инициализации. В таких ситуациях поток, отвечающий за подготовку данных, может вызвать функцию-член <code>notify_all()</code> условной переменной вместо <code>notify_one()</code>. Эта функция извещает <emphasis>все</emphasis> потоки, ожидающие внутри функции <code>wait()</code>, о том, что они должны проверить ожидаемое условие.</p>
          <p>Если ожидающий поток собирается ждать условия только один раз, то есть после того как оно станет истинным, он не вернется к ожиданию той же условной переменной, то лучше применить другой механизм синхронизации. В особенности это относится к случаю, когда ожидаемое условие — доступность каких-то данных. Для такого сценария больше подходят так называемые <emphasis>будущие результаты</emphasis> (future).</p>
        </section>
      </section>
      <section>
        <title>
          <p>4.2. Ожидание одноразовых событий с помощью механизма будущих результатов</p>
        </title>
        <section>
          <p>Предположим, вы летите самолетом в отпуск за границу. Вы приехали в аэропорт, прошли регистрацию и прочие процедуры, но должны ждать объявления о посадке — быть может, несколько часов. Можно, конечно, найти себе занятие — например, почитать книжку, побродить в Интернете, поесть в кафе за бешеные деньги, но суть от этого не меняется: вы ждете сигнала о том, что началась посадка в самолет. И есть еще одна особенность — данный рейс вылетает всего один раз; в следующий отпуск вы будете ждать посадки на другой рейс.</p>
          <p>В стандартной библиотеке С++ такие одноразовые события моделируются с помощью <emphasis>будущего результата</emphasis>. Если поток должен ждать некоего одноразового события, то он каким-то образом получает представляющий его объект-будущее. Затем поток может периодически в течение очень короткого времени ожидать этот объект-будущее, проверяя, произошло ли событие (посмотреть на табло вылетов), а между проверками заниматься другим делом (вкушать в кафе аэропортовскую пищу по несуразным ценам). Можно поступить и иначе — выполнять другую работу до тех пор, пока не наступит момент, когда без наступления ожидаемого события двигаться дальше невозможно, и вот тогда ждать <emphasis>готовности</emphasis> будущего результата. С будущим результатом могут быть ассоциированы какие-то данные (например, номер выхода в объявлении на посадку), но это необязательно. После того как событие произошло (то есть будущий результат <emphasis>готов</emphasis>), сбросить объект-будущее в исходное состояние уже невозможно.</p>
          <p>В стандартной библиотеке С++ есть две разновидности будущих результатов, реализованные в форме двух шаблонов классов, которые объявлены в заголовке <code>&lt;future&gt;</code>: <emphasis>уникальные будущие результаты</emphasis> (<code>std::future&lt;&gt;</code>) и <emphasis>разделяемые будущие результаты</emphasis> (<code>std::shared_future&lt;&gt;</code>). Эти классы устроены по образцу <code>std::unique_ptr</code> и <code>std::shared_ptr</code>. На одно событие может ссылаться только один экземпляр <code>std::future</code>, но несколько экземпляров <code>std::shared_future</code>. В последнем случае все экземпляры оказываются <emphasis>готовы</emphasis> одновременно и могут обращаться к ассоциированным с событием данным. Именно из-за ассоциированных данных будущие результаты представлены шаблонами, а не обычными классами; точно так же шаблоны <code>std::unique_ptr</code> и <code>std::shared_ptr</code> параметризованы типом ассоциированных данных. Если ассоциированных данных нет, то следует использовать специализации шаблонов <code>std::future&lt;void&gt;</code> и <code>std::shared_future&lt;void&gt;</code>. Хотя будущие результаты используются как механизм межпоточной коммуникации, сами по себе они не обеспечивают синхронизацию доступа. Если несколько потоков обращаются к единственному объекту-будущему, то они должны защитить доступ с помощью мьютекса или какого-либо другого механизма синхронизации, как описано в главе 3. Однако, как будет показано в разделе 4.2.5, каждый из нескольких потоков может работать с собственной копией <code>std::shared_future&lt;&gt;</code> безо всякой синхронизации, даже если все они ссылаются на один и тот же асинхронно получаемый результат.</p>
          <p>Самое простое одноразовое событие — это результат вычисления, выполненного в фоновом режиме. В главе 2 мы видели, что класс <code>std::thread</code> не предоставляет средств для возврата вычисленного значения, и я обещал вернуться к этому вопросу в главе 4. Исполняю обещание.</p>
        </section>
        <section>
          <title>
            <p>4.2.1. Возврат значения из фоновой задачи</p>
          </title>
          <p>Допустим, вы начали какое-то длительное вычисление, которое в конечном итоге должно дать полезный результат, но пока без него можно обойтись. Быть может, вы нашли способ получить ответ на «Главный возрос жизни, Вселенной и всего на свете» из книги Дугласа Адамса<a l:href="#n7" type="note">[7]</a>. Для вычисления можно запустить новый поток, но придётся самостоятельно позаботиться о передаче в основную программу результата, потому что в классе <code>std::thread</code> такой механизм не предусмотрен. Тут-то и приходит на помощь шаблон функции <code>std::async</code> (также объявленный в заголовке <code>&lt;future&gt;</code>).</p>
          <p>Функция s<code>td::async</code> позволяет запустить <emphasis>асинхронную задачу</emphasis>, результат которой прямо сейчас не нужен. Но вместо объекта <code>std::thread</code> она возвращает объект <code>std::future</code>, который будет содержать возвращенное значение, когда оно станет доступно. Когда программе понадобится значение, она вызовет функцию-член <code>get()</code> объекта-будущего, и тогда поток будет приостановлен до готовности будущего результата, после чего вернет значение. В листинге ниже оказан простой пример.</p>
          <empty-line/>
          <p><strong>Листинг 4.6.</strong> Использование <code>std::future</code> для получения результата асинхронной задачи</p>
          <p>
            <code>#include &lt;future&gt;</code>
          </p>
          <p>
            <code>#include &lt;iostream&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>int find_the_answer_to_ltuae();</code>
          </p>
          <p>
            <code>void do_other_stuff();</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> std::future&lt;int&gt; the_answer =</code>
          </p>
          <p>
            <code>  std::async(find_the_answer_to_ltuae);</code>
          </p>
          <p>
            <code> do_other_stuff();</code>
          </p>
          <p>
            <code> std::cout &lt;&lt; "Ответ равен " &lt;&lt; the_answer.get() &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Шаблон <code>std::async</code> позволяет передать функции дополнительные параметры, точно так же, как <code>std::thread</code>. Если первым аргументом является указатель на функцию-член, то второй аргумент должен содержать объект, от имени которого эта функция-член вызывается (сам объект, указатель на него или обертывающий его <code>std::ref</code>), а все последующие аргументы передаются без изменения функции-члену. В противном случае второй и последующие аргументы передаются функции или допускающему вызов объекту, заданному в первом аргументе. Как и в <code>std::thread</code>, если аргументы представляют собой <emphasis>r</emphasis>-значения, то создаются их копии посредством <emphasis>перемещения</emphasis> оригинала. Это позволяет использовать в качестве объекта-функции и аргументов типы, допускающие только перемещение. Пример см. в листинге ниже.</p>
          <empty-line/>
          <p><strong>Листинг 4.7.</strong> Передача аргументов функции, заданной в <code>std::async</code></p>
          <p>
            <code>#include &lt;string&gt;</code>
          </p>
          <p>
            <code>#include &lt;future&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>struct X {</code>
          </p>
          <p>
            <code> void foo(int, std::string const&amp;);</code>
          </p>
          <p>
            <code> std::string bar(std::string const&amp;);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>                                                &#9474;</code>
            <strong>Вызывается</strong>
          </p>
          <p>
            <code>X x;                                            &#9474;</code>
            <strong>p-&gt;foo(42,"hello"),</strong>
          </p>
          <p>
            <code>auto f1 = std::async(&amp;X::foo, &amp;x, 42, "hello");&#8592;&#9496;</code>
            <strong>где p=&amp;x</strong>
          </p>
          <p>
            <code>auto f2 = std::async(&amp;X::bar, x, "goodbye");&#8592;&#9488;</code>
            <strong> вызывается</strong>
          </p>
          <p>
            <code>                                             &#9474;</code>
            <strong>tmpx.bar("goodbye"),</strong>
          </p>
          <p>
            <code>struct Y {                                   &#9474;</code>
            <strong>где tmpx — копия x</strong>
          </p>
          <p>
            <code> double operator()(double);</code>
          </p>
          <p>
            <code>};                               &#9474;</code>
            <strong>Вызывается tmpy(3.141),</strong>
          </p>
          <p>
            <code>                                 &#9474;</code>
            <strong>где tmpy создается</strong>
          </p>
          <p>
            <code>Y y;                             &#9474;</code>
            <strong>из Y перемещающим</strong>
          </p>
          <p>
            <code>auto f3 = std::async(Y(), 3.141)&#8592;&#9496;</code>
            <strong>конструктором</strong>
          </p>
          <p>
            <code>auto f4 = std::async(std::ref(y), 2.718);&#8592;</code>
            <strong>Вызывается y(2.718)</strong>
          </p>
          <empty-line/>
          <p>
            <code>X baz(X&amp;);</code>
          </p>
          <p>
            <code>std::async(baz, std::ref(x); &#8592;</code>
            <strong>Вызывается baz(x)</strong>
          </p>
          <empty-line/>
          <p>
            <code>class move_only {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> move_only();</code>
          </p>
          <p>
            <code> move_only(move_only&amp;&amp;);</code>
          </p>
          <p>
            <code> move_only(move_only const&amp;) = delete;</code>
          </p>
          <p>
            <code> move_only&amp; operator=(move_only&amp;&amp;);</code>
          </p>
          <p>
            <code> move_only&amp; operator=(move_only const&amp;) = delete;</code>
          </p>
          <p>
            <code> void operator()();                &#9474;</code>
            <strong>Вызывается tmp(), где tmp</strong>
          </p>
          <p>
            <code>};                                 &#9474;</code>
            <strong>конструируется с помощью</strong>
          </p>
          <p>
            <code>auto f5 = std::async(move_only());&#8592;&#9496;</code>
            <strong>std::move(move_only())</strong>
          </p>
          <p>По умолчанию реализации предоставлено право решать, запускает ли <code>std::async</code> новый поток или задача работает синхронно, когда программа ожидает будущего результата. В большинстве случаев такое поведение вас устроит, но можно задать требуемый режим в дополнительном параметре <code>std::async</code> перед вызываемой функцией. Этот параметр имеет тип <code>std::launch</code> и может принимать следующие значения: <code>std::launch::deferred</code> — отложить вызов функции до того момента, когда будет вызвана функция-член <code>wait()</code> или <code>get()</code> объекта-будущего; <code>std::launch::async</code> — запускать функцию в отдельном потоке; <code>std::launch::deferred | std::launch::async</code> — оставить решение на усмотрение реализации. Последний вариант подразумевается по умолчанию. В случае отложенного вызова функция может вообще никогда не выполниться. Например:</p>
          <p>
            <code>auto f6 =                                  &#9474;</code>
            <strong>Выполнять в</strong>
          </p>
          <p>
            <code> std::async(std::launch::async, Y(), 1.2);&#8592;&#9496;</code>
            <strong>новом потоке</strong>
          </p>
          <p>
            <code>auto f7 =</code>
          </p>
          <p>
            <code> std::async(</code>
          </p>
          <p>
            <code>  std::launch::deferred, baz, std::ref(x)); &#8592;&#9488;</code>
          </p>
          <p>
            <code>auto f8 = std::async(                      &#8592;&#9488;&#9474;</code>
            <strong>Выполнять</strong>
          </p>
          <p>
            <code> std::launch::deferred | std::launch::async,&#9474;&#9474;</code>
            <strong>при вызове</strong>
          </p>
          <p>
            <code> baz, std::ref(x));                         &#9474;&#9474;</code>
            <strong>wait() или get()</strong>
          </p>
          <p>
            <code>auto f9 = std::async(baz, std::ref(x));    &#8592;&#9532;</code>
            <strong>Оставить на</strong>
          </p>
          <p>
            <code>                                            &#9474;</code>
            <strong>усмотрение реализации</strong>
          </p>
          <p>
            <code>f7.wait();&#8592;</code>
            <strong>Вызвать отложенную функцию</strong>
          </p>
          <p>Ниже в этой главе и далее в главе 8 мы увидим, что с помощью <code>std::async</code> легко разбивать алгоритм на параллельно выполняемые задачи. Однако это не единственный способ ассоциировать объект <code>std::future</code> с задачей; можно также обернуть задачу объектом шаблонного класса <code>std::packaged_task&lt;&gt;</code> или написать код, который будет явно устанавливать значения с помощью шаблонного класса <code>std::promise&lt;&gt;</code>. Шаблон <code>std::packaged_task</code> является абстракцией более высокого уровня, чем <code>std::promise</code>, поэтому начнем с него.</p>
        </section>
        <section>
          <title>
            <p>4.2.2. Ассоциирование задачи с будущим результатом</p>
          </title>
          <p>Шаблон класса <code>std::packaged_task&lt;&gt;</code> связывает будущий результат с функцией или объектом, допускающим вызов. При вызове объекта <code>std::packaged_task&lt;&gt;</code> ассоциированная функция или допускающий вызов объект вызывается и делает будущий результат <emphasis>готовым</emphasis>, сохраняя возвращенное значение в виде ассоциированных данных. Этот механизм можно использовать для построение пулов потоков (см. главу 9) и иных схем управления, например, запускать каждую задачу в отдельном потоке или запускать их все последовательно в выделенном фоновом потоке. Если длительную операцию можно разбить на автономные подзадачи, то каждую из них можно обернуть объектом <code>std::packaged_task&lt;&gt;</code> и передать этот объект планировщику задач или пулу потоков. Таким образом, мы абстрагируем специфику задачи — планировщик имеет дело только с экземплярами <code>std::packaged_task&lt;&gt;</code>, а не с индивидуальными функциями.</p>
          <p>Параметром шаблона класса <code>std::packaged_task&lt;&gt;</code> является сигнатура функции, например <code>void()</code> для функции, которая не принимает никаких параметров и не возвращает значения, или <code>int(std::string&amp;, double*)</code> для функции, которая принимает неконстантную ссылку на <code>std::string</code> и указатель на <code>double</code> и возвращает значение типа <code>int</code>. При конструировании экземпляра <code>std::packaged_task</code> вы обязаны передать функцию или допускающий вызов объект, который принимает параметры указанных типов и возвращает значение типа, преобразуемого в указанный тип возвращаемого значения. Точного совпадения типов не требуется; можно сконструировать объект <code>std::packaged_task&lt;double (double)&gt;</code> из функции, которая принимает <code>int</code> и возвращает <code>float</code>, потому что между этими типами существуют неявные преобразования.</p>
          <p>Тип возвращаемого значения, указанный в сигнатуре функции, определяет тип объекта <code>std::future&lt;&gt;</code>, возвращаемого функцией-членом <code>get_future()</code>, а заданный в сигнатуре список аргументов используется для определения сигнатуры оператора вызова в классе упакованной задачи. Например, в листинге ниже приведена часть определения класса <code>std::packaged_task&lt;std::string(std::vector&lt;char&gt;*, int)&gt;</code>.</p>
          <empty-line/>
          <p><strong>Листинг 4.8.</strong> Определение частичной специализации <code>std::packaged_task</code></p>
          <p>
            <code>template&lt;&gt;</code>
          </p>
          <p>
            <code>class packaged_task&lt;std::string(std::vector&lt;char&gt;*, int)&gt; {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> template&lt;typename Callable&gt;</code>
          </p>
          <p>
            <code> explicit packaged_task(Callable&amp;&amp; f);</code>
          </p>
          <empty-line/>
          <p>
            <code> std::future&lt;std::string&gt; get_future();</code>
          </p>
          <p>
            <code> void operator()(std::vector&lt;char&gt;*, int);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Таким образом, <code>std::packaged_task</code> — допускающий вызов объект, и, значит, его можно обернуть объектом <code>std::function</code>, передать <code>std::thread</code> в качестве функции потока, передать любой другой функции, которая ожидает допускающий вызов объект, или даже вызвать напрямую. Если <code>std::packaged_task</code> вызывается как объект-функция, то аргументы, переданные оператору вызова, без изменения передаются обернутой им функции, а возвращенное значение сохраняется в виде асинхронного результата в объекте <code>std::future</code>, полученном от <code>get_future()</code>. Следовательно, мы можем обернуть задачу в <code>std::packaged_task</code> и извлечь будущий результат перед тем, как передавать объект <code>std::packaged_task</code> в то место, из которого он будет в свое время вызван. Когда результат понадобится, нужно будет подождать готовности будущего результата. В следующем примере показано, как всё это делается на практике.</p>
          <subtitle>Передача задач между потоками</subtitle>
          <p>Во многих каркасах для разработки пользовательского интерфейса требуется, чтобы интерфейс обновлялся только в специально выделенных потоках. Если какому-то другому потоку потребуется обновить интерфейс, то он должен послать сообщение одному из таких выделенных потоков, чтобы тот выполнил операцию. Шаблон <code>std::packaged_task</code> позволяет решить эту задачу, не заводя специальных сообщений для каждой относящейся к пользовательскому интерфейсу операции.</p>
          <empty-line/>
          <p><strong>Листинг 4.9.</strong> Выполнение кода в потоке пользовательского интерфейса с применением <code>std::packaged_task</code></p>
          <p>
            <code>#include &lt;deque&gt;</code>
          </p>
          <p>
            <code>#include &lt;mutex&gt;</code>
          </p>
          <p>
            <code>#include &lt;future&gt;</code>
          </p>
          <p>
            <code>#include &lt;thread&gt;</code>
          </p>
          <p>
            <code>#include &lt;utility&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::mutex m;</code>
          </p>
          <p>
            <code>std::deque&lt;std::packaged_task&lt;void()&gt;&gt; tasks;</code>
          </p>
          <empty-line/>
          <p>
            <code>bool gui_shutdown_message_received();</code>
          </p>
          <p>
            <code>void get_and_process_gui_message();</code>
          </p>
          <empty-line/>
          <p>
            <code>void gui_thread() {                         &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> while (!gui_shutdown_message_received()) { &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  get_and_process_gui_message();            &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  std::packaged_task&lt;void()&gt; task; {</code>
          </p>
          <p>
            <code>   std::lock_guard&lt;std::mutex&gt; lk(m);</code>
          </p>
          <p>
            <code>   if (tasks empty())                       &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>    continue;</code>
          </p>
          <p>
            <code>   task = std::move(tasks.front());         &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>   tasks.pop_front();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> task();                                    &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>std::thread gui_bg_thread(gui_thread);</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Func&gt;</code>
          </p>
          <p>
            <code>std::future&lt;void&gt; post_task_for_gui_thread(Func f) {</code>
          </p>
          <p>
            <code> std::packaged_task&lt;void()&gt; task(f);       &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code> std::future&lt;void&gt; res = task.get_future();&#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code> std::lock_guard&lt;std::mutex&gt; lk(m);</code>
          </p>
          <p>
            <code> tasks.push_back(std::move(task));         &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code> return res;                               &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Код очень простой: поток пользовательского интерфейса <strong>(1)</strong> повторяет цикл, пока не будет получено сообщение о необходимости завершить работу <strong>(2)</strong>. На каждой итерации проверяется, есть ли готовые для обработки сообщения GUI <strong>(3)</strong>, например события мыши, или новые задачи в очереди. Если задач нет <strong>(4)</strong>, программа переходит на начало цикла; в противном случае извлекает задачу из очереди <strong>(5)</strong>, освобождает защищающий очередь мьютекс и исполняет задачу <strong>(6)</strong>. По завершении задачи будет готов ассоциированный с ней будущий результат.</p>
          <p>Помещение задачи в очередь ничуть не сложнее: по предоставленной функции создается новая упакованная задача <strong>(7)</strong>, для получения ее будущего результата вызывается функция-член <code>get_future()</code> <strong>(8)</strong>, после чего задача помещается в очередь <strong>(9)</strong> еще до того, как станет доступен будущий результат <strong>(10)</strong>. Затем часть программы, которая отправляла сообщение потоку пользовательского интерфейса, может дождаться будущего результата, если хочет знать, как завершилась задача, или отбросить его, если это несущественно.</p>
          <p>В этом примере мы использовали класс <code>std::packaged_task&lt;void()&gt;</code> для задач, обертывающих функцию или иной допускающий вызов объект, который не принимает параметров и возвращает <code>void</code> (если он вернет что-то другое, то возвращенное значение будет отброшено). Это простейшая из всех возможных задач, но, как мы видели ранее, шаблон <code>std::packaged_task</code> применим и в более сложных ситуациях — задав другую сигнатуру функции в качестве параметра шаблона, вы сможете изменить тип возвращаемого значения (и, стало быть, тип данных, которые хранятся в состоянии, ассоциированном с будущим объектом), а также типы аргументов оператора вызова. Наш пример легко обобщается на задачи, которые должны выполняться в потоке GUI и при этом принимают аргументы и возвращают в <code>std::future</code> какие-то данные, а не только индикатор успешности завершения.</p>
          <p>А как быть с задачами, которые нельзя выразить в виде простого вызова функции, или такими, где результат может поступать из нескольких мест? Эти проблемы решаются с помощью еще одного способа создания будущего результата: явного задания значения с помощью шаблона класса <code>std::promise</code><a l:href="#n8" type="note">[8]</a>.</p>
        </section>
        <section>
          <title>
            <p>4.2.3. Использование <code>std::promise</code></p>
          </title>
          <p>При написании сетевых серверных программ часто возникает искушение обрабатывать каждый запрос на соединение в отдельном потоке, поскольку при такой структуре порядок коммуникации становится нагляднее и проще для программирования. Этот подход срабатывает, пока количество соединений (и, следовательно, потоков) не слишком велико. Но с ростом числа потоков увеличивается и объем потребляемых ресурсов операционной системы, а равно частота контекстных переключений (если число потоков превышает уровень аппаратного параллелизма), что негативно сказывается на производительности. В предельном случае у операционной системы могут закончиться ресурсы для запуска новых потоков, хотя пропускная способность сети еще не исчерпана. Поэтому в приложениях, обслуживающих очень большое число соединений, обычно создают совсем немного потоков (быть может, всего один), каждый из которых одновременно обрабатывает несколько запросов.</p>
          <p>Рассмотрим один из таких потоков. Пакеты данных приходят по разным соединениям в случайном порядке, а потому и порядок помещения исходящих пакетов в очередь отправки тоже непредсказуем. Часто будет складываться ситуация, когда другие части приложения ждут либо успешной отправки данных, либо поступления нового пакета по конкретному сетевому соединению.</p>
          <p>Шаблон <code>std::promise&lt;T&gt;</code> дает возможность задать значение (типа <code>T</code>), которое впоследствии можно будет прочитать с помощью ассоциированного объекта <code>std::future&lt;T&gt;</code>. Пара <code>std::promise</code>/<code>std::future</code> реализует один из возможных механизмов такого рода; ожидающий поток приостанавливается в ожидании будущего результата, тогда как поток, поставляющий данные, может с помощью <code>promise</code> установить ассоциированное значение и сделать будущий результат <emphasis>готовым</emphasis>.</p>
          <p>Чтобы получить объект <code>std::future</code>, ассоциированный с данным обещанием <code>std::promise</code>, мы должны вызвать функцию-член <code>get_future()</code> — так же, как в случае <code>std::packaged_task</code>. После установки значения обещания (с помощью функции-члена <code>set_value()</code>) будущий результат становится <emphasis>готовым</emphasis>, и его можно использовать для получения установленного значения. Если уничтожить объект <code>std::promise</code>, не установив значение, то в будущем результате будет сохранено исключение. О передаче исключений между потоками см. раздел 4.2.4.</p>
          <p>В листинге 4.10 приведен код потока обработки соединений, написанный по только что изложенной схеме. В данном случае для уведомления об успешной передаче блока исходящих данных применяется пара <code>std::promise&lt;bool&gt;</code>/<code>std::future&lt;bool&gt;</code>; ассоциированное с будущим результатом значение — это просто булевский флаг успех/неудача. Для входящих пакетов в качестве ассоциированных данных могла бы выступать полезная нагрузка пакета.</p>
          <empty-line/>
          <p><strong>Листинг 4.10.</strong> Обработка нескольких соединений в одном потоке с помощью объектов-обещаний</p>
          <p>
            <code>#include &lt;future&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>void process_connections(connection_set&amp; connections) {</code>
          </p>
          <p>
            <code> while(!done(connections)) {             &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  for (connection_iterator               &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   connection = connections.begin(), end = connections.end();</code>
          </p>
          <p>
            <code>   connection != end;</code>
          </p>
          <p>
            <code>   ++connection) {</code>
          </p>
          <p>
            <code>   if (connection-&gt;has_incoming_data()) {&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>    data_packet data = connection-&gt;incoming();</code>
          </p>
          <p>
            <code>    std::promise&lt;payload_type&gt;&amp; p =</code>
          </p>
          <p>
            <code>     connection-&gt;get_promise(data.id);   &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>    p.set_value(data.payload);</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   if (connection-&gt;has_outgoing_data()) {&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>    outgoing_packet data =</code>
          </p>
          <p>
            <code>     connection-&gt;top_of_outgoing_queue();</code>
          </p>
          <p>
            <code>    connection-&gt;send(data.payload);</code>
          </p>
          <p>
            <code>    data.promise.set_value(true);        &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Функция <code>process_connections()</code> повторяет цикл, пока <code>done()</code> возвращает <code>true</code> <strong>(1)</strong>. На каждой итерации поочередно проверяется каждое соединение <strong>(2)</strong>; если есть входящие данные, они читаются <strong>(3)</strong>, а если в очереди имеются исходящие данные, они отсылаются <strong>(5)</strong>. При этом предполагается, что в каждом входящем пакете хранится некоторый идентификатор и полезная нагрузка, содержащая собственно данные. Идентификатору сопоставляется объект <code>std::promise</code> (возможно, путем поиска в ассоциативном контейнере) <strong>(4)</strong>, значением которого является полезная нагрузка пакета. Исходящие пакеты просто извлекаются из очереди отправки и передаются но соединению. После завершения передачи в обещание, ассоциированное с исходящими данными, записывается значение <code>true</code>, обозначающее успех <strong>(6)</strong>. Насколько хорошо эта схема ложится на фактический сетевой протокол, зависит от самого протокола; в конкретном случае схема обещание/будущий результат может и не подойти, хотя структурно она аналогична поддержке асинхронного ввода/вывода в некоторых операционных системах.</p>
          <p>В коде выше мы полностью проигнорировали возможные исключения. Хотя мир, в котором всё всегда работает правильно, был бы прекрасен, действительность не так радужна. Переполняются диски, не находятся искомые данные, отказывает сеть, «падает» база данных — всякое бывает. Если бы операция выполнялась в том потоке, которому нужен результат, программа могла бы просто сообщить об ошибке с помощью исключения. Но было бы неоправданным ограничением требовать, чтобы всё работало правильно только потому, что мы захотели воспользоваться классами <code>std::packaged_task</code> или <code>std::promise</code>.</p>
          <p>Поэтому в стандартной библиотеке С++ имеется корректный способ учесть возникновение исключений в таком контексте и сохранить их как часть ассоциированного результата.</p>
        </section>
        <section>
          <title>
            <p>4.2.4. Сохранение исключения в будущем результате</p>
          </title>
          <p>Рассмотрим следующий коротенький фрагмент. Если передать функции <code>square_root()</code> значение <code>-1</code>, то она возбудит исключение, которое увидит вызывающая программа:</p>
          <p>
            <code>double square_root(double x) {</code>
          </p>
          <p>
            <code> if (x&lt;0) {</code>
          </p>
          <p>
            <code>  throw std::out_of_range("x&lt;0");</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> return sqrt(x);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>А теперь предположим, что вместо вызова <code>square_root()</code> в текущем потоке</p>
          <p>
            <code>double y = square_root(-1);</code>
          </p>
          <p>мы вызываем ее асинхронно:</p>
          <p>
            <code>std::future&lt;double&gt; f = std::async(square_root,-1);</code>
          </p>
          <p>
            <code>double y = f.get();</code>
          </p>
          <p>В идеале хотелось бы получить точно такое же поведение: чтобы поток, вызывающий <code>f.get()</code>, мог увидеть не только нормальное значение <code>y</code>, но и исключение — как в однопоточной программе.</p>
          <p>Что ж, именно так на самом деле и происходит: если функция, вызванная через <code>std::async</code>, возбуждает исключение, то это исключение сохраняется в будущем результате вместо значения, а когда будущий результат оказывается <emphasis>готовым</emphasis>, вызов <code>get()</code> повторно возбуждает сохраненное исключение. (Примечание: стандарт ничего не говорит о том, возбуждается ли исходное исключение или его копия; различные компиляторы и библиотеки вправе решать этот вопрос по-разному.) То же самое происходит, когда функция обернута объектом <code>std::packaged_task</code>, — если при вызове задачи обернутая функция возбуждает исключение, то объект исключения сохраняется в будущем результате вместо значения, и это исключение повторно возбуждается при обращении к <code>get()</code>.</p>
          <p>Разумеется, <code>std::promise</code> обеспечивает те же возможности в случае явного вызова функции. Чтобы сохранить исключение вместо значения, следует вызвать функцию-член <code>set_exception()</code>, а не <code>set_value()</code>. Обычно это делается в блоке <code>catch</code>:</p>
          <p>
            <code>extern std::promise&lt;double&gt; some_promise;</code>
          </p>
          <empty-line/>
          <p>
            <code>try {</code>
          </p>
          <p>
            <code> some_promise.set_value(calculate_value());</code>
          </p>
          <p>
            <code>} catch (...) {</code>
          </p>
          <p>
            <code> some_promise.set_exception(std::current_exception());</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Здесь мы воспользовались функцией <code>std::current_exception()</code>, которая возвращает последнее возбужденное исключение, но могли вызвать <code>std::copy_exception()</code>, чтобы поместить в объект-обещание новое исключение, которое никем не возбуждалось:</p>
          <p>
            <code>some_promise.set_exception(</code>
          </p>
          <p>
            <code> std::copy_exception(std::logic_error("foo"));</code>
          </p>
          <p>Если тип исключения заранее известен, то это решение гораздо чище, чем использование блока <code>try/catch</code>; мы не только упрощаем код, но и оставляем компилятору возможности для его оптимизации.</p>
          <p>Есть еще один способ сохранить исключение в будущем результате: уничтожить ассоциированный с ним объект <code>std::promise</code> или <code>std::packaged_task</code>, не вызывая функцию установки значения в случае обещания или не обратившись к упакованной задаче. В любом случае деструктор <code>std::promise</code> или <code>std::packaged_task</code> сохранит в ассоциированном состоянии исключение типа <code>std::future_error</code>, в котором код ошибки равен <code>std::future_errc::broken_promise</code>, если только будущий результат еще не <emphasis>готов</emphasis>; создавая объект-будущее, вы даете обещание предоставить значение или исключение, а, уничтожая объект, не задав ни того, ни другого, вы это обещание нарушаете. Если бы компилятор в этом случае не сохранил ничего в будущем результате, то ожидающие потоки могли бы никогда не выйти из состояния ожидания.</p>
          <p>До сих пор мы во всех примерах использовали <code>std::future</code>. Однако у этого шаблонного класса есть ограничения, и не в последнюю очередь тот факт, что результата может ожидать только один поток. Если требуется, чтобы одного события ждали несколько потоков, то придётся воспользоваться классом <code>std::shared_future</code>.</p>
        </section>
        <section>
          <title>
            <p>4.2.5. Ожидание в нескольких потоках</p>
          </title>
          <p>Хотя класс <code>std::future</code> сам заботится о синхронизации, необходимой для передачи данных из одного потока в другой, обращения к функциям-членам одного и того же экземпляра <code>std::future</code> не синхронизированы между собой. Работа с одним объектом <code>std::future</code> из нескольких потоков без дополнительной синхронизации может закончиться <emphasis>гонкой за данными</emphasis> и неопределенным поведением. Так и задумано: <code>std::future</code> моделирует единоличное владение результатом асинхронного вычисления, и одноразовая природа <code>get()</code> в любом случае делает параллельный доступ бессмысленным — извлечь значение может только один поток, поскольку после первого обращения к <code>get()</code> никакого значения не остается.</p>
          <p>Но если дизайн вашей фантастической параллельной программы требует, чтобы одного события могли ждать несколько потоков, то не отчаивайтесь: на этот случай предусмотрен шаблон класса <code>std::shared_future</code>. Если <code>std::future</code> допускает только <emphasis>перемещение</emphasis>, чтобы владение можно было передавать от одного экземпляра другому, но в каждый момент времени на асинхронный результат ссылался лишь один экземпляр, то экземпляры <code>std::shared_future</code> допускают и <emphasis>копирование</emphasis>, то есть на одно и то же ассоциированное состояние могут ссылать несколько объектов.</p>
          <p>Но и функции-члены объекта <code>std::shared_future</code> не синхронизированы, поэтому во избежание гонки за данными при доступе к одному объекту из нескольких потоков вы сами должны обеспечить защиту. Но более предпочтительный способ — скопировать объект, так чтобы каждый поток работал со своей копией. Доступ к разделяемому асинхронному состоянию из нескольких потоков безопасен, если каждый поток обращается к этому состоянию через свой собственный объект <code>std::shared_future</code>. См. Рис. 4.1.</p>
          <image l:href="#img_6_novyjjrazmer.png"/>
          <p><strong>Рис. 4.1.</strong> Использование нескольких объектов <code>std::shared_future</code>, чтобы избежать гонки за данными</p>
          <p>Одно из потенциальных применений <code>std::shared_future</code> — реализация параллельных вычислений наподобие применяемых в сложных электронных таблицах: у каждой ячейки имеется единственное окончательное значение, на которое могут ссылаться формулы, хранящиеся в нескольких других ячейках. Формулы для вычисления значений в зависимых ячейках могут использовать <code>std::shared_future</code> для ссылки на первую ячейку. Если формулы во всех ячейках вычисляются параллельно, то задачи, которые могут дойти до конца, дойдут, а те, что зависят от результатов вычислений других ячеек, окажутся заблокированы до разрешения зависимостей. Таким образом, система сможет но максимуму задействовать доступный аппаратный параллелизм.</p>
          <p>Экземпляры <code>std::shared_future</code>, ссылающиеся на некоторое асинхронное состояние, конструируются из экземпляров <code>std::future</code>, ссылающихся на то же состояние. Поскольку объект <code>std::future</code> не разделяет владение асинхронным состоянием ни с каким другим объектом, то передавать владение объекту <code>std::shared_future</code> необходимо с помощью <code>std::move</code>, что оставляет <code>std::future</code> с пустым состоянием, как если бы он был сконструирован по умолчанию:</p>
          <p>
            <code>std::promise&lt;int&gt; p;</code>
          </p>
          <p>
            <code>std::future&lt;int&gt; f(p.get_future())&#8592;</code>
            <strong>(1) Будущий результат f</strong>
          </p>
          <p>
            <code>assert(f.valid());                 </code>
            <strong>действителен</strong>
          </p>
          <empty-line/>
          <p>
            <code>std::shared_future&lt;int&gt; sf(std::move(f));</code>
          </p>
          <p>
            <code>assert(!f.valid());&#8592;</code>
            <strong>(2) f больше не действителен</strong>
          </p>
          <p>
            <code>assert(sf.valid());&#8592;</code>
            <strong>(3) sf теперь действителен</strong>
          </p>
          <p>Здесь будущий результат <code>f</code> в начальный момент действителен <code>(1)</code>, потому что ссылается на асинхронное состояние обещания <code>p</code>, но после передачи состояния объекту <code>sf</code> результат <code>f</code> оказывается недействительным <strong>(2)</strong>, a <code>sf</code> — действительным <strong>(3)</strong>.</p>
          <p>Как и для других перемещаемых объектов, передача владения для r-значения производится неявно, поэтому объект <code>std::shared_future</code> можно сконструировать прямо из значения, возвращаемого функцией-членом <code>get_future()</code> объекта <code>std::promise</code>, например:</p>
          <p>
            <code>std::promise&lt;std::string&gt; p;&#8592;</code>
            <strong>(1) Неявная передача владения</strong>
          </p>
          <p>
            <code>std::shared_future&lt;std::string&gt; sf(p.get_future());</code>
          </p>
          <p>Здесь передача владения неявная; объект <code>std::shared_future&lt;&gt;</code> конструируется из r-значения типа <code>std::future&lt;std::string&gt;</code> <strong>(1)</strong>.</p>
          <p>У шаблона <code>std::future</code> есть еще одна особенность, которая упрощает использование <code>std::shared_future</code> совместно с новым механизмом автоматического выведения типа переменной из ее инициализатора (см. приложение А, раздел А.6). В шаблоне <code>std::future</code> имеется функция-член <code>share()</code>, которая создает новый объект <code>std::shared_future</code> и сразу передаёт ему владение. Это позволяет сделать код короче и проще для изменения:</p>
          <p>
            <code>std::promise&lt;</code>
          </p>
          <p>
            <code> std::map&lt;SomeIndexType, SomeDataType, SomeComparator,</code>
          </p>
          <p>
            <code>          SomeAllocator&gt;::iterator&gt; p;</code>
          </p>
          <p>
            <code>auto sf = p.get_future().share();</code>
          </p>
          <p>В данном случае для <code>sf</code> выводится тип <code>std::shared_future&lt;std::map&lt;SomeIndexType, SomeDataType, SomeComparator, SomeAllocator&gt;::iterator&gt;</code>, такое название произнести-то трудно. Если компаратор или распределитель изменятся, то вам нужно будет поменять лишь тип обещания, а тип будущего результата изменится автоматически.</p>
          <p>Иногда требуется ограничить время ожидания события — либо потому что на время исполнения некоторого участка кода наложены жесткие ограничения, либо потому что поток может заняться другой полезной работой, если событие долго не возникает. Для этого во многих функциях ожидания имеются перегруженные варианты, позволяющие задать величину таймаута.</p>
        </section>
      </section>
      <section>
        <title>
          <p>4.3. Ожидание с ограничением по времени</p>
        </title>
        <section>
          <p>Все блокирующие вызовы, рассмотренные до сих пор, приостанавливали выполнение потока на неопределенно долгое время — до тех пор, пока не произойдёт ожидаемое событие. Часто это вполне приемлемого в некоторых случаях время ожидания желательно ограничить. Например, это может быть полезно, когда нужно отправить сообщение вида «Я еще жив» интерактивному пользователю или другому процессу или когда ожидание действительно необходимо прервать, потому что пользователь устал ждать и нажал <strong>Cancel</strong>.</p>
          <p>Можно задать таймаут одного из двух видов: <emphasis>интервальный</emphasis>, когда требуется ждать в течение определённого промежутка времени (к примеру, 30 миллисекунд) или <emphasis>абсолютный</emphasis>, когда требуется ждать до наступления указанного момента (например, 17:30:15.045987023 UTC 30 ноября 2011 года). У большинства функций ожидания имеются оба варианта. Варианты, принимающие интервальный таймаут, оканчиваются словом <code>_for</code>, а принимающие абсолютный таймаут — словом <code>_until</code>.</p>
          <p>Например, в классе <code>std::condition_variable</code> есть по два перегруженных варианта функций-членов <code>wait_for()</code> и <code>wait_until()</code>, соответствующие двум вариантам <code>wait()</code> — первый ждет поступления сигнала или истечения таймаута или ложного пробуждения, второй проверяет при пробуждении переданный предикат и возвращает управление, только если предикат равен <code>true</code> (и условной переменной поступил сигнал) или истек таймаут.</p>
          <p>Прежде чем переходить к детальному обсуждению функций с таймаутами, рассмотрим, как в С++ задается время, и начнем с часов.</p>
        </section>
        <section>
          <title>
            <p>4.3.1. Часы</p>
          </title>
          <p>С точки зрения стандартной библиотеки С++, часы — это источник сведений о времени. Точнее, класс часов должен предоставлять четыре элемента информации:</p>
          <p>• текущее время <emphasis>now</emphasis>;</p>
          <p>• тип значения для представления времени, полученного от часов;</p>
          <p>• величина такта часов;</p>
          <p>• признак равномерного хода времени, такие часы называются <emphasis>стабильными</emphasis>.</p>
          <p>Получить от часов текущее время можно с помощью статической функции-члена <code>now()</code>; например, функция <code>std::chrono::system_clock::now()</code> возвращает текущее время по системным часам. Тип точки во времени для конкретного класса часов определяется с помощью члена <code>typedef time_point</code>, поэтому значение, возвращаемое функцией <code>some_clock::now()</code> имеет тип <code>some_clock::time_point</code>.</p>
          <p>Тактовый период часов задается в виде числа долей секунды, которое определяется членом класса <code>typedef period</code>; например, если часы тикают 25 раз в секунду, то член <code>period</code> будет определён как <code>std::ratio&lt;1, 25&gt;</code>, тогда как в часах, тикающих один раз в 2,5 секунды, член <code>period</code> определён как <code>std::ratio&lt;5, 2&gt;</code>. Если тактовый период не известен до начала выполнения программы или может изменяться во время работы, то <code>period</code> можно определить как средний период, наименьший период или любое другое значение, которое сочтет нужным автор библиотеки. Нет гарантии, что тактовый период, наблюдаемый в любом конкретном прогоне программы, соответствует периоду, определённому с помощью члена period.</p>
          <p>Если часы <emphasis>ходят с постоянной частотой</emphasis> (вне зависимости от того, совпадает эта частота с <code>period</code> или нет) и <emphasis>не допускают подведения</emphasis>, то говорят, что часы <emphasis>стабильны</emphasis>. Статический член <code>is_steady</code> класса часов равен <code>true</code>, если часы стабильны, и <code>false</code> в противном случае. Как правило, часы <code>std::chrono::system_clock</code> нестабильны, потому что их можно подвести, даже если такое подведение производится автоматически, чтобы учесть локальный дрейф. Из-за подведения более позднее обращение к <code>now()</code> может вернуть значение, меньшее, чем более раннее, а это нарушение требования к равномерному ходу часов. Как мы скоро увидим, стабильность важна для вычислений с таймаутами, поэтому в стандартной библиотеке С++ имеется класс стабильных часов — <code>std::chrono::steady_clock</code>. Помимо него, стандартная библиотека содержит класс <code>std::chrono::system_clock</code> (уже упоминавшийся выше), который представляет системный генератор «реального времени» и имеет функции для преобразования моментов времени в тип <code>time_t</code> и обратно, и класс <code>std::chrono::high_resolution_clock</code>, который представляет наименьший возможный тактовый период (и, следовательно, максимально возможное разрешение). Может статься, что этот тип на самом деле является псевдонимом <code>typedef</code> какого-то другого класса часов. Все эти классы определены в заголовке <code>&lt;chrono&gt;</code> наряду с прочими средствами работы со временем.</p>
          <p>Чуть ниже мы рассмотрим представления моментов времени, но сначала познакомимся с представлением интервалов.</p>
        </section>
        <section>
          <title>
            <p>4.3.2. Временные интервалы</p>
          </title>
          <p>Интервалы — самая простая часть подсистемы поддержки времени; они представлены шаблонным классом <code>std::chrono::duration&lt;&gt;</code> (все имеющиеся в С++ средства работы со временем, которые используются в библиотеке Thread Library, находятся в пространстве имен <code>std::chrono</code>). Первый параметр шаблона — это тип представления (<code>int</code>, <code>long</code> или <code>double</code>), второй — дробь, показывающая, сколько секунд представляет один интервал. Например, число минут, хранящееся в значении типа <code>short</code>, равно <code>std::chrono::duration&lt;short, std::ratio&lt;60,1&gt;&gt;</code>, потому что в одной минуте 60 секунд. С другой стороны, число миллисекунд, хранящееся в значении типа <code>double</code>, равно <code>std::chrono::duration&lt;double, std::ratio&lt;1, 1000&gt;&gt;</code>, потому что миллисекунда — это 1/1000 секунды.</p>
          <p>В пространстве имен <code>std::chrono</code> имеется набор предопределенных <code>typedef</code>'ов для различных интервалов: <code>nanoseconds</code>, <code>microseconds</code>, <code>milliseconds</code>, <code>seconds</code>, <code>minutes</code> и <code>hours</code>. В них используется достаточно широкий целочисленный тип, подобранный так, чтобы можно было представить в выбранных единицах интервал продолжительностью свыше 500 лет. Имеются также <code>typedef</code> для всех определенных в системе СИ степеней 10 — от <code>std::atto</code> (10<sup>-18</sup>) до <code>std::exa</code> (10<sup>18</sup>) (и более, если платформа поддерживает 128-разрядные целые числа) — чтобы можно было определить нестандартные интервалы, например <code>std::duration&lt;double, std::centi&gt;</code> (число сотых долей секунды, хранящееся в значении типа <code>double</code>).</p>
          <p>Между типами интервалов существует неявное преобразование, если не требуется отсечение (то есть неявно преобразовать часы в секунды можно, а секунды в часы нельзя). Для явного преобразования предназначен шаблон функции <code>std::chrono::duration_cast&lt;&gt;</code>:</p>
          <p>
            <code>std::chrono::milliseconds ms(54802);</code>
          </p>
          <p>
            <code>std::chrono::seconds s =</code>
          </p>
          <p>
            <code> std::chrono::duration_cast&lt;std::chrono::seconds&gt;(ms);</code>
          </p>
          <p>Результат отсекается, а не округляется, поэтому в данном примере <code>s</code> будет равно 54.</p>
          <p>Для интервалов определены арифметические операции, то есть сложение и вычитание интервалов, а также умножение и деление на константу базового для представления типа (первый параметр шаблона) дает новый интервал. Таким образом, <code>5*seconds(1)</code> — то же самое, что <code>seconds(5)</code> или <code>minutes(1) - seconds(55)</code>. Количество единиц в интервале возвращает функция-член <code>count()</code>. Так, <code>std::chrono::milliseconds(1234).count()</code> равно 1234.</p>
          <p>Чтобы задать ожидание в течение интервала времени, используется функция <code>std::chrono::duration&lt;&gt;</code>. Вот, например, как задается ожидание готовности будущего результата в течение 35 миллисекунд:</p>
          <p>
            <code>std::future&lt;int&gt; f = std::async(some_task);</code>
          </p>
          <p>
            <code>if (f.wait_for(std::chrono::milliseconds(35)) ==</code>
          </p>
          <p>
            <code>    std::future_status::ready)</code>
          </p>
          <p>
            <code> do_something_with(f.get());</code>
          </p>
          <p>Все функции ожидания возвращают код, показывающий, истек ли таймаут или произошло ожидаемое событие. В примере выше мы ожидаем будущий результат, поэтому функция вернет <code>std::future_status::timeout</code>, если истек таймаут, <code>std::future_status::ready</code> — если результат готов, и <code>std::future_status::deferred</code> — если будущая задача отложена. Время ожидания измеряется с помощью библиотечного класса стабильных часов, поэтому 35 мс — это всегда 35 мс, даже если системные часы были подведены (вперёд или назад) в процессе ожидания. Разумеется, из-за особенностей системного планировщика и варьирующейся точности часов ОС фактическое время между вызовом функции в потоке и возвратом из нее может оказаться значительно больше 35 мс.</p>
          <p>Разобравшись с интервалами, мы можем перейти к моментам времени.</p>
        </section>
        <section>
          <title>
            <p>4.3.3. Моменты времени</p>
          </title>
          <p>Момент времени представляется конкретизацией шаблона класса <code>std::chrono::time_point&lt;&gt;</code>, в первом параметре которой задаются используемые часы, а во втором — единица измерения (специализация шаблона <code>std::chrono::duration&lt;&gt;</code>). Значением момента времени является промежуток времени (измеряемый в указанных единицах) с некоторой конкретной точки на временной оси, которая называется <emphasis>эпохой</emphasis> часов. Эпоха часов — это основополагающее свойство, однако напрямую его запросить нельзя, и в стандарте С++ оно не определено. Из типичных эпох можно назвать полночь (00:00) 1 января 1970 года и момент, когда в последний раз был загружен компьютер, на котором исполняется приложение. У разных часов может быть общая или независимые эпохи. Если у двух часов общая эпоха, то псевдоним типа <code>typedef time_point</code> в одном классе может ссылаться на другой класс как на тип, ассоциированный с <code>time_point</code>. Хотя узнать, чему равна эпоха, невозможно, вы <emphasis>можете</emphasis> получить время между данным моментом <code>time_point</code> и эпохой с помощью функции-члена <code>time_since_epoch()</code>, которая возвращает интервал.</p>
          <p>Например, можно задать момент времени <code>std::chrono::time_point &lt;std::chrono::system_clock, std::chrono::minutes&gt;</code>. Он представляет время по системным часам, выраженное в минутах, а не в естественных для этих часов единицах (как правило, секунды или доли секунды).</p>
          <p>К объекту <code>std::chrono::time_point&lt;&gt;</code> можно прибавить интервал или вычесть из него интервал — в результате получится новый момент времени. Например, <code>std::chrono::high_resolution_clock::now() + std::chrono::nanoseconds(500)</code> соответствует моменту времени в будущем, который отстоит от текущего момента на 500 наносекунд. Это удобно для вычисления абсолютного таймаута, когда известна максимально допустимая продолжительность выполнения некоторого участка программы, и внутри этого участка есть несколько обращений к функциям с ожиданием или обращения к функциям, которые ничего не ждут, но предшествуют функции с ожиданием и занимают часть отведенного времени.</p>
          <p>Можно также вычесть один момент времени из другого при условии, что они относятся к одним и тем же часам. В результате получиться интервал между двумя моментами. Это полезно для хронометража участков программы, например:</p>
          <p>
            <code>auto start = std::chrono::high_resolution_clock::now();</code>
          </p>
          <p>
            <code>do_something();</code>
          </p>
          <p>
            <code>auto stop = std::chrono::high_resolution_clock::now();</code>
          </p>
          <p>
            <code>std::cout &lt;&lt; "do_something() заняла "</code>
          </p>
          <p>
            <code> &lt;&lt; std::chrono::duration&lt;</code>
          </p>
          <p>
            <code>     double, std::chrono::seconds&gt;(stop-start).count()</code>
          </p>
          <p>
            <code> &lt;&lt; " секунд" &lt;&lt; std::endl;</code>
          </p>
          <p>Однако параметр <code>clock</code> объекта <code>std::chrono::time_point&lt;&gt;</code> не только определяет эпоху. Если передать момент времени функции с ожиданием, принимающей абсолютный таймаут, то указанный в нем параметр <code>clock</code> используется для измерения времени. Это существенно в случае, когда часы подводятся, потому что механизм ожидания замечает, что наказания часов изменились, и не дает функции вернуть управление, пока функция-член часов <code>now()</code> не вернет значение, большее, чем задано в таймауте. Если часы подведены вперёд, то это может уменьшить общее время ожидания (измеренное но стабильным часам), а если назад — то увеличить.</p>
          <p>Как и следовало ожидать, моменты времени применяются в вариантах функций с ожиданием, имена которых заканчиваются словом <code>_until</code>. Как правило, таймаут задается в виде смещения от значения <code><emphasis>some-clock</emphasis>::now()</code>, вычисленного в определенной точке программы, хотя моменты времени, ассоциированные с системными часами, можно получить из <code>time_t</code> с помощью статической функции-члена <code>std::chrono::system_clock::to_time_point()</code>, если при планировании операций требуется использовать время в понятном пользователю масштабе. Например, если на ожидание события, связанного с условной переменной, отведено не более 500 мс, то можно написать такой код.</p>
          <empty-line/>
          <p><strong>Листинг 4.11.</strong> Ожидание условной переменной с таймаутом</p>
          <p>
            <code>#include &lt;condition_variable&gt;</code>
          </p>
          <p>
            <code>#include &lt;mutex&gt;</code>
          </p>
          <p>
            <code>#include &lt;chrono&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::condition_variable cv;</code>
          </p>
          <p>
            <code>bool done;</code>
          </p>
          <p>
            <code>std::mutex m;</code>
          </p>
          <empty-line/>
          <p>
            <code>bool wait_loop() {</code>
          </p>
          <p>
            <code> auto const timeout = std::chrono::steady_clock::now() +</code>
          </p>
          <p>
            <code>                      std::chrono::milliseconds(500);</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt; lk(m);</code>
          </p>
          <p>
            <code> while(!done) {</code>
          </p>
          <p>
            <code>  if (cv.wait_until(lk, timeout) == std::cv_status::timeout)</code>
          </p>
          <p>
            <code>   break;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> return done;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Это рекомендуемый способ ожидания условной переменной с ограничением по времени в случае, когда предикат не указывается. При этом ограничивается общее время выполнения цикла. В разделе 4.1.1 мы видели, что при использовании условных переменных без предиката цикл необходим для защиты от ложных пробуждений. Но если вызывать в цикле <code>wait_for()</code>, то может получиться, что функция прождёт почти все отведенное время, а затем произойдёт ложное пробуждение, после чего на следующей итерации отсчет времени начнется заново. И так может происходить сколько угодно раз, в результате чего общее время ожидания окажется неограниченным.</p>
          <p>Вооружившись знаниями о том, как задавать таймауты, рассмотрим функции, в которых таймауты используются.</p>
        </section>
        <section>
          <title>
            <p>4.3.4. Функции, принимающие таймаут</p>
          </title>
          <p>Простейший случай использования таймаута — задание паузы в потоке, чтобы он не отнимал у других потоков время, когда ему нечего делать. Соответствующий пример был приведён в разделе 4.1, где мы в цикле опрашивали флаг «done». Для этого использовались функции <code>std::this_thread::sleep_for()</code> и <code>std::this_thread::sleep_until()</code>. Обе работают как будильник: поток засыпает либо на указанный интервал (в случае <code>sleep_for()</code>), либо до указанного момента времени (в случае <code>sleep_until()</code>). Функцию <code>sleep_for()</code> имеет смысл применять в ситуации, описанной в разделе 4.1, когда что-то необходимо делать периодически и важна лишь продолжительность периода. С другой стороны, функция <code>sleep_until()</code> позволяет запланировать пробуждение потока в конкретный момент времени, например: запустить в полночь резервное копирование, начать в 6 утра распечатку платёжной ведомости или приостановить поток до момента следующего обновления кадра при воспроизведении видео.</p>
          <p>Разумеется, таймаут принимают не только функции типа <code>sleep</code>. Выше мы видели, что таймаут можно задавать при ожидании условных переменных и будущих результатов. А также при попытке захватить мьютекс, если сам мьютекс такую возможность поддерживает. Обычные классы <code>std::mutex</code> и <code>std::recursive_mutex</code> не поддерживают таймаут при захвате, зато его поддерживают классы <code>std::timed_mutex</code> и <code>std::recursive_timed_mutex</code>. В том и в другом имеются функции-члены <code>try_lock_for()</code> и <code>try_lock_until()</code>, которые пытаются получить блокировку в течение указанного интервала или до наступления указанного момента времени. В табл. 4.1 перечислены функции из стандартной библиотеки С++, которые принимают таймауты, их параметры и возвращаемые значения. Параметр <code><emphasis><strong>duration</strong></emphasis></code> должен быть объектом типа <code>std::duration&lt;&gt;</code>, а параметр <code><emphasis><strong>time_point</strong></emphasis></code> — объектом типа <code>std::time_point&lt;&gt;</code>.</p>
          <empty-line/>
          <p><strong>Таблица 4.1</strong>. Функции, принимающие таймаут</p>
          <table>
            <tr align="left">
              <th align="center" valign="top">Класс / пространство имен</th>
              <th align="left" valign="top">Функции</th>
              <th align="center" valign="top">Возвращаемые значения</th>
            </tr>
            <tr align="left">
              <td align="left" valign="top"><code>std::this_thread</code> пространство имен</td>
              <td align="left" valign="top">
                <code>sleep_for(<emphasis><strong>duration</strong></emphasis>) sleep_until(<emphasis><strong>time_point</strong></emphasis>)</code>
              </td>
              <td align="left" valign="top">Неприменимо</td>
            </tr>
            <tr align="left">
              <td align="left" valign="top"><code>std::condition_variable</code> или <code>std::condition_variable_any</code></td>
              <td align="left" valign="top">
                <code>wait_for(<emphasis><strong>lock</strong></emphasis>, <emphasis><strong>duration</strong></emphasis>) wait_until(<emphasis><strong>lock</strong></emphasis>, <emphasis><strong>time_point</strong></emphasis>)</code>
              </td>
              <td align="left" valign="top"><code>std::cv_status::timeout</code> или <code>std::cv_status::no_timeout</code></td>
            </tr>
            <tr align="left">
              <td align="left" valign="top"/>
              <td align="left" valign="top">
                <code>wait_for(<emphasis><strong>lock</strong></emphasis>, <emphasis><strong>duration</strong></emphasis>, <emphasis><strong>predicate</strong></emphasis>) wait_until(<emphasis><strong>lock</strong></emphasis>, <emphasis><strong>time_point</strong></emphasis>, <emphasis><strong>predicate</strong></emphasis>)</code>
              </td>
              <td align="left" valign="top"><code>bool</code> — значение, возвращенное предикатом <code><emphasis><strong>predicate</strong></emphasis></code> при пробуждении</td>
            </tr>
            <tr align="left">
              <td align="left" valign="top"><code>std::timed_mutex</code> или <code>std::recursive_timed_mutex</code></td>
              <td align="left" valign="top">
                <code>try_lock_for(<emphasis><strong>duration</strong></emphasis>) try_lock_until(<emphasis><strong>time_point</strong></emphasis>)</code>
              </td>
              <td align="center" valign="top"><code>bool</code> — <code>true</code>, если мьютекс захвачен, иначе <code>false</code></td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::unique_lock&lt;<strong>TimedLockable</strong>&gt;</code>
              </td>
              <td align="left" valign="top">
                <code>unique_lock(<emphasis><strong>lockable</strong></emphasis>, <emphasis><strong>duration</strong></emphasis>) unique_lock(<emphasis><strong>lockable</strong></emphasis>, <emphasis><strong>time_point</strong></emphasis>)</code>
              </td>
              <td align="left" valign="top">Неприменимо — функция <code>owns_lock()</code> для вновь сконструированного объекта возвращает <code>true</code>, если мьютекс захвачен, иначе <code>false</code></td>
            </tr>
            <tr align="left">
              <td align="left" valign="top"/>
              <td align="left" valign="top">
                <code>try_lock_for(<emphasis><strong>duration</strong></emphasis>) try_lock_until(<emphasis><strong>time_point</strong></emphasis>)</code>
              </td>
              <td align="left" valign="top"><code>bool</code> — <code>true</code>, если мьютекс захвачен, иначе <code>false</code></td>
            </tr>
            <tr align="left">
              <td align="left" valign="top"><code>std::future&lt;ValueType&gt;</code> или <code>std::shared_future&lt;ValueType&gt;</code></td>
              <td align="left" valign="top">
                <code>wait_for(<emphasis><strong>duration</strong></emphasis>) wait_until(<emphasis><strong>time_point</strong></emphasis>)</code>
              </td>
              <td align="left" valign="top"><code>std::future_status::timeout</code>, если истек таймаут, <code>std::future_status::ready</code>, если будущий результат готов, <code>std::future_status::deferred</code>, если в будущем результате хранится отложенная функция, которая еще не начала исполняться</td>
            </tr>
          </table>
          <p>Теперь, когда мы рассмотрели условные переменные, будущие результаты, обещания и упакованные задачи, настало время представить более широкую картину их применения для синхронизации операций, выполняемых в разных потоках.</p>
        </section>
      </section>
      <section>
        <title>
          <p>4.4. Применение синхронизации операций для упрощения кода</p>
        </title>
        <section>
          <p>Использование описанных выше средств синхронизации в качестве строительных блоков позволяет сосредоточиться на самих нуждающихся в синхронизации операциях, а не на механизмах реализации. В частности, код можно упростить, применяя более <emphasis>функциональный</emphasis> (в смысле <emphasis>функционального программирования</emphasis>) подход к программированию параллелизма. Вместо того чтобы напрямую разделять данные между потоками, мы можем снабдить каждый поток необходимыми ему данными, а результаты вычисления предоставить другим потокам, которые в них заинтересованы, с помощью будущих результатов.</p>
        </section>
        <section>
          <title>
            <p>4.4.1. Функциональное программирование с применением будущих результатов</p>
          </title>
          <p>Термином <emphasis>функциональное программирование</emphasis> (ФП) называют такой стиль программирования, при котором результат функции зависит только от ее параметров, но не от внешнего состояния. Это напрямую соотносится с понятием функции в математике и означает, что если два раза вызвать функцию с одними и теми же параметрами, то получатся одинаковые результаты. Таким свойством обладают многие математические функции в стандартной библиотеке С++, например <code>sin</code>, <code>cos</code> и <code>sqrt</code>, а также простые операции над примитивными типами, например <code>3+3</code>, <code>6*9</code> или <code>1.3/4.7</code>. <emphasis>Чистая</emphasis> функция не <emphasis>модифицирует</emphasis> никакое внешнее состояние, она воздействует только на возвращаемое значение.</p>
          <p>При таком подходе становится проще рассуждать о функциях, особенно в присутствии параллелизма, поскольку многие связанные с разделяемой памятью проблемы, обсуждавшиеся в главе 3, просто не возникают. Если разделяемые данные не модифицируются, то не может быть никакой гонки и, стало быть, не нужно защищать данные с помощью мьютексов. Это упрощение настолько существенно, что в программировании параллельных систем все более популярны становятся такие языки, как Haskell<a l:href="#n9" type="note">[9]</a>, где все функции чистые <emphasis>по умолчанию</emphasis>. В таком окружении <emphasis>нечистые</emphasis> функции, которые все же модифицируют разделяемые данные, отчетливо выделяются, поэтому становится проще рассуждать о том, как они укладываются в общую структуру приложения.</p>
          <p>Но достоинства функционального программирования проявляются не только в языках, где эта парадигма применяется по умолчанию. С++ — мультипарадигменный язык, и на нем, безусловно, можно писать программы в стиле ФП. С появлением в С++11 лямбда-функций (см. приложение А, раздел А.6), включением шаблона <code>std::bind</code> из Boost и TR1 и добавлением автоматического выведения типа переменных (см. приложение А, раздел А.7) это стало даже проще, чем в С++98. Будущие результаты — это последний элемент из тех, что позволяют реализовать на С++ параллелизм в стиле ФП; благодаря передаче будущих результатов результат одного вычисления можно сделать зависящим от результата другого <emphasis>без явного доступа к разделяемым данным</emphasis>.</p>
          <subtitle>Быстрая сортировка в духе ФП</subtitle>
          <p>Чтобы продемонстрировать использование будущих результатов при написании параллельных программ в духе ФП, рассмотрим простую реализацию алгоритма быстрой сортировки Quicksort. Основная идея алгоритма проста: имея список значений, выбрать некий опорный элемент и разбить список на две части — в одну войдут элементы, меньшие опорного, в другую — большие или равные опорному. Отсортированный список получается путем сортировки обоих частей и объединения трех списков: отсортированного множества элементов, меньших опорного элемента, самого опорного элемента и отсортированного множества элементов, больших или равных опорному элементу. На рис. 4.2 показано, как этот алгоритм сортирует список из 10 целых чисел. В листинге ниже приведена последовательная реализация алгоритма в духе ФП; в ней список принимается и возвращается по значению, а не сортируется по месту в <code>std::sort()</code>.</p>
          <image l:href="#img_7_novyjjrazmer.png"/>
          <p><strong>Рис. 4.2.</strong> Рекурсивная сортировка в духе ФП</p>
          <empty-line/>
          <p><strong>Листинг 4.12</strong>. Последовательная реализация Quicksort в духе ФП</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>std::list&lt;T&gt; sequential_quick_sort(std::list&lt;T&gt; input) {</code>
          </p>
          <p>
            <code> if (input.empty()) {</code>
          </p>
          <p>
            <code>  return input;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> std::list&lt;T&gt; result;</code>
          </p>
          <p>
            <code> result.splice(result.begin(), input, input.begin());&#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code> T const&amp; pivot = *result.begin();                   &#8592;</code>
            <strong>(2)</strong>
          </p>
          <empty-line/>
          <p>
            <code> auto divide_point = std::partition(input.begin(), input.end(),</code>
          </p>
          <p>
            <code>  [&amp;](T const&amp; t) { return t &lt; pivot; });&#8592;</code>
            <strong>(3)</strong>
          </p>
          <empty-line/>
          <p>
            <code> std::list&lt;T&gt; lower_part;</code>
          </p>
          <p>
            <code> lower_part.splice(</code>
          </p>
          <p>
            <code>  lower_part.end(), input, input.begin(), divide_point); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <empty-line/>
          <p>
            <code> auto new_lower(</code>
          </p>
          <p>
            <code>  sequential_quick_sort(std::move(lower_part)));         &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code> auto new_higher(</code>
          </p>
          <p>
            <code>  sequential_quick_sort(std::move(input)));              &#8592;</code>
            <strong>(6)</strong>
          </p>
          <empty-line/>
          <p>
            <code> result.splice(result.end(), new_higher);  &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code> result.splice(result.begin(), new_lower); &#8592;</code>
            <strong>(8)</strong>
          </p>
          <empty-line/>
          <p>
            <code> return result;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Хотя интерфейс выдержан в духе ФП, прямое применение ФП привело бы к неоправданно большому числу операций копирования, поэтому внутри мы используем «обычный» императивный стиль. В качестве опорного мы выбираем первый элемент и отрезаем его от списка с помощью функции <code>splice()</code> <strong>(1)</strong>. Потенциально это может привести к неоптимальной сортировке (в терминах количества операций сравнения и обмена), но любой другой подход при работе с <code>std::list</code> может существенно увеличить время за счет обхода списка. Мы знаем, что этот элемент должен войти в результат, поэтому можем сразу поместить его в список, где результат будет храниться. Далее мы хотим использовать этот элемент для сравнения, поэтому берем ссылку на него, чтобы избежать копирования <strong>(2)</strong>. Теперь можно с помощью алгоритма <code>std::partition</code> разбить последовательность на две части: <emphasis>меньшие</emphasis> опорного элемента и <emphasis>не меньшие</emphasis> опорного элемента <strong>(3)</strong>. Критерий разбиения проще всего задать с помощью лямбда-функции; мы запоминаем ссылку в замыкании, чтобы не копировать значение <code>pivot</code> (подробнее о лямбда-функциях см. в разделе А.5 приложения А).</p>
          <p>Алгоритм <code>std::partition()</code> переупорядочивает список на месте и возвращает итератор, указывающий на первый элемент, который <emphasis>не</emphasis> меньше опорного значения. Полный тип итератора довольно длинный, поэтому мы используем спецификатор типа <code>auto</code>, чтобы компилятор вывел его самостоятельно (см. приложение А, раздел А.7).</p>
          <p>Раз уж мы выбрали интерфейс в духе ФП, то для рекурсивной сортировки обеих «половин» нужно создать два списка. Для этого мы снова используем функцию <code>splice()</code>, чтобы переместить значения из списка <code>input</code> до <code>divide_point</code> включительно в новый список <code>lower_part</code> <strong>(4)</strong>. После этого <code>input</code> будет со держать только оставшиеся значения. Далее оба списка можно отсортировать путем рекурсивных вызовов <strong>(5)</strong>, <strong>(6)</strong>. Применяя <code>std::move()</code> для передачи списков, мы избегаем копирования — результат в любом случае неявно перемещается. Наконец, мы еще раз вызываем <code>splice()</code>, чтобы собрать result в правильном порядке. Значения из списка <code>new_higher</code> попадают в конец списка <strong>(7)</strong>, после опорного элемента, а значения из списка <code>new_lower</code> — в начало списка, до опорного элемента <strong>(8)</strong>.</p>
          <subtitle>Параллельная реализация Quicksort в духе ФП</subtitle>
          <p>Раз уж мы все равно применили функциональный стиль программирования, можно без труда распараллелить этот код с помощью будущих результатов, как показано в листинге ниже. Набор операций тот же, что и раньше, только некоторые из них выполняются параллельно.</p>
          <empty-line/>
          <p><strong>Листинг 4.13.</strong> Параллельная реализация Quicksort с применением будущих результатов</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>std::list&lt;T&gt; parallel_quick_sort(std::list&lt;T&gt; input) {</code>
          </p>
          <p>
            <code> if (input.empty()) {</code>
          </p>
          <p>
            <code>  return input;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::list&lt;T&gt; result;</code>
          </p>
          <p>
            <code> result.splice(result.begin(), input, input.begin());</code>
          </p>
          <p>
            <code> T const&amp; pivot = *result.begin();</code>
          </p>
          <empty-line/>
          <p>
            <code> auto divide_point = std::partition(input.begin(), input.end(),</code>
          </p>
          <p>
            <code>  [&amp;](T const&amp; t) {return t&lt;pivot;});</code>
          </p>
          <p>
            <code> std::list&lt;T&gt; lower_part;</code>
          </p>
          <p>
            <code> lower_part.splice(</code>
          </p>
          <p>
            <code>  lower_part.end(), input, input.begin(), divide_point);</code>
          </p>
          <empty-line/>
          <p>
            <code> std::future&lt;std::list&lt;T&gt; &gt; new_lower( &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  std::async(&amp;parallel_quick_sort&lt;T&gt;, std::move(lower_part)));</code>
          </p>
          <empty-line/>
          <p>
            <code> auto new_higher(</code>
          </p>
          <p>
            <code>  parallel_quick_sort(std::move(input))); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <empty-line/>
          <p>
            <code> result.splice(result.end(), new_higher); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <empty-line/>
          <p>
            <code> result.splice(result.begin(), new_lower.get()); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> return result;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Существенное изменение здесь заключается в том, что сортировка нижней части списка производится не в текущем, а в отдельном потоке — с помощью <code>std::async()</code> <strong>(1)</strong>. Верхняя часть списка сортируется путем прямой рекурсии, как и раньше <strong>(2)</strong>. Рекурсивно вызывая <code>parallel_quick_sort()</code>, мы можем задействовать доступный аппаратный параллелизм. Если <code>std::async()</code> создает новый поток при каждом обращении, то после трех уровней рекурсии мы получим восемь работающих потоков, а после 10 уровней (когда в списке примерно 1000 элементов) будет работать 1024 потока, если оборудование позволяет. Если библиотека решит, что запущено слишком много задач (быть может, потому что количество задач превысило уровень аппаратного параллелизма), то может перейти в режим синхронного запуска новых задач. Тогда новая задача будет работать в том же потоке, который обратился к <code>get()</code>, а не в новом, так что мы не будем нести издержки на передачу задачи новому потоку, если это не увеличивает производительность. Стоит отметить, что в соответствии со стандартом реализация <code>std::async</code> вправе как создавать новый поток для каждой задачи (даже при значительном превышении лимита), если явно не задан флаг <code>std::launch::deferred</code>, так и запускать все задачи синхронно, если явно не задан флаг <code>std::launch::async</code>. Рассчитывая, что библиотека сама позаботится об автоматическом масштабировании, изучите, что говорится на эту тему в документации, поставляемой вместе с библиотекой.</p>
          <p>Можно не использовать <code>std::async()</code>, а написать свою функцию <code>spawn_task()</code>, которая будет служить оберткой вокруг <code>std::packaged_task</code> и <code>std::thread</code>, как показано в листинге 4.14; нужно создать объект <code>std::packaged_task</code> для хранения результата вызова функции, получить из него будущий результат, запустить задачу в отдельном потоке и вернуть будущий результат. Само по себе это не дает большого преимущества (и, скорее всего, приведёт к значительному превышению лимита), но пролагает дорогу к переходу на более хитроумную реализацию, которая помещает задачу в очередь, обслуживаемую пулом потоков. Рассмотрение пулов потоков мы отложим до главы 9. Но идти по такому пути вместо использования <code>std::async</code> имеет смысл только в том случае, когда вы точно знаете, что делаете, и хотите полностью контролировать, как пул потоков строится и выполняет задачи.</p>
          <p>Но вернемся к функции <code>parallel_quick_sort</code>. Поскольку для получения <code>new_higher</code> мы применяли прямую рекурсию, то и срастить (splice) его можно на месте, как и раньше <strong>(3)</strong>. Но <code>new_lower</code> теперь представляет собой не список, а объект <code>std::future&lt;std::list&lt;T&gt;&gt;</code>, поэтому сначала нужно извлечь значение с помощью <code>get()</code>, а только потом вызывать <code>splice()</code> <strong>(4)</strong>. Таким образом, мы дождемся завершения фоновой задачи, а затем <emphasis>переместим</emphasis> результат в параметр <code>splice()</code>; функция <code>get()</code> возвращает ссылку на r-значение — хранимый результат, следовательно, его можно переместить (подробнее о ссылках на r-значения и семантике перемещения см. в разделе А.1.1 приложения А).</p>
          <p>Даже в предположении, что <code>std::async()</code> оптимально использует доступный аппаратный параллелизм, приведённая реализация Quicksort все равно не идеальна. Основная проблема в том, что <code>std::partition</code> делает много работы и остается последовательной операцией, но пока остановимся на этом. Если вас интересует максимально быстрая параллельная реализация, обратитесь к научной литературе.</p>
          <empty-line/>
          <p><strong>Листинг 4.14.</strong> Простая реализация функции <code>spawn_task</code></p>
          <p>
            <code>template&lt;typename F, typename A&gt;</code>
          </p>
          <p>
            <code>std::future&lt;std::result_of&lt;F(A&amp;&amp;)&gt;::type&gt;</code>
          </p>
          <p>
            <code>spawn_task(F&amp;&amp; f, A&amp;&amp; a) {</code>
          </p>
          <p>
            <code> typedef std::result_of&lt;F(A&amp;&amp;)&gt;::type result_type;</code>
          </p>
          <p>
            <code> std::packaged_task&lt;result_type(A&amp;&amp;)&gt;</code>
          </p>
          <p>
            <code> task(std::move(f)));</code>
          </p>
          <p>
            <code> std::future&lt;result_type&gt; res(task.get_future());</code>
          </p>
          <p>
            <code> std::thread t(std::move(task), std::move(a));</code>
          </p>
          <p>
            <code> t.detach();</code>
          </p>
          <p>
            <code> return res;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Функциональное программирование — не единственная парадигма параллельного программирования, позволяющая избежать модификации разделяемых данных. Альтернативой является парадигма CSP (Communicating Sequential Processes — взаимодействующие последовательные процессы)<a l:href="#n10" type="note">[10]</a>, в которой потоки концептуально рассматриваются как полностью независимые сущности, без каких бы то ни было разделяемых данных, но соединенные коммуникационными каналами, по которым передаются сообщения. Эта парадигма положена в основу языка программирования Erlang (http://www.erlang.org/) и среды MPI (Message Passing Interface) (http://www.mpi-forum.org/), широко используемой для высокопроизводительных вычислений на С и С++. Уверен, что теперь вы не удивитесь, узнав, что и эту парадигму можно поддержать на С++, если соблюдать определенную дисциплину; в следующем разделе показано, как это можно сделать.</p>
        </section>
        <section>
          <title>
            <p>4.4.2. Синхронизация операций с помощью передачи сообщений</p>
          </title>
          <p>Идея CSP проста: если никаких разделяемых данных нет, то каждый поток можно рассматривать независимо от остальных, учитывая лишь его поведение в ответ на получаемые сообщения. Таким образом, поток по существу является конечным автоматом: получив сообщение, он как-то изменяет свое состояние, возможно, посылает одно или несколько сообщений другим потокам и выполняет то или иное вычисление, зависящее от начального состояния. Один из способов такого способа программирования потоков — формализовать это описание и реализовать модель конечного автомата, но этот путь не единственный — конечный автомат может неявно присутствовать в самой структуре приложения. Какой метод будет работать лучше в конкретном случае, зависит от требований к поведению приложения и от опыта разработчиков. Но каким бы образом ни был реализован поток, у разбиения на независимые процессы есть несомненное преимущество — потенциальное устранение многих сложностей, связанных с параллельным доступом к разделяемым данным, и, следовательно, упрощение программирования и снижение количества ошибок.</p>
          <p>У настоящих последовательных взаимодействующих процессов вообще нет разделяемых данных, а весь обмен информацией производится через очереди сообщений. Но, поскольку в С++ потоки имеют общее адресное пространство, то обеспечить строгое соблюдение этого требования невозможно. Тут-то и приходит на выручку дисциплина: следить за тем, чтобы никакие данные не разделялись между потоками, — обязанность автора приложения или библиотеки. Разумеется, сами очереди сообщений должны разделяться, иначе потоки не смогут взаимодействовать, но детали этого механизма можно вынести в библиотеку. Представьте, что вам нужно написать программу для банкомата. Она должна поддерживать взаимодействие с человеком, который хочет снять деньги, с соответствующим банком, а также управлять оборудованием, которое принимает платёжную карту, выводит на экран сообщения, обрабатывает нажатия клавиш, выдает деньги и возвращает карту.</p>
          <p>Чтобы воплотить все это в жизнь, можно было бы разбить код на три независимых потока: один будет управлять оборудованием, второй — реализовывать логику работы банкомата, а третий — обмениваться информацией с банком. Эти потоки могут взаимодействовать между собой посредством передачи сообщений, а не за счет разделения данных. Например, поток, управляющий оборудованием, будет посылать сообщение потоку логики банкомата о том, что человек вставил карту или нажал кнопку. Поток логики будет посылать потоку, управляющему оборудованием, сообщение о том, сколько денег выдать. И так далее.</p>
          <p>Смоделировать логику банкомата можно, например, с помощью конечного автомата. В каждом состоянии поток ждет сообщение, которое затем обрабатывает. Это может привести к переходу в новое состояние, после чего цикл продолжится. На рис. 4.3 показаны состояния, присутствующие в простой реализации программы. Здесь система ждет, пока будет вставлена карта. Когда это произойдёт, система ждет, что пользователь введет свой ПИН-код, по одной цифре за раз. Последнюю введенную цифру пользователь может удалить. После того как будет введено нужное количество цифр, система проверяет ПИН-код. Если он введен неправильно, больше делать нечего — клиенту нужно вернуть карту и ждать, пока будет вставлена следующая карта. Если ПИН-код правильный, то система ждет либо отмены транзакции, либо выбора снимаемой суммы. Если пользователь отменил операцию, ему нужно вернуть карту и закончить работу. Если он выбрал сумму, то система ждет подтверждения от банка, а затем либо выдает наличные и возвращает карту, либо выводит сообщение «недостаточно средств на счете» и тоже возвращает карту. Понятно, что реальный банкомат гораздо сложнее, но и этого достаточно для иллюстрации идеи.</p>
          <image l:href="#img_8_novyjjrazmer.png"/>
          <p><strong>Рис. 4.3.</strong> Модель простого конечного автомата для банкомата</p>
          <p>Спроектировав конечный автомат для реализации логики банкомата, мы можем оформить его в виде класса, в котором каждому состоянию соответствует функция-член. Каждая такая функция ждет поступления одного из допустимых сообщений, обрабатывает его и, возможно, инициирует переход в новое состояние. типы сообщений представлены структурами <code>struct</code>. В листинге 4.15 приведена часть простой реализации логики банкомата в такой системе — главный цикл и код первого состояния, в котором программа ожидает вставки карты.</p>
          <p>Как видите, вся синхронизация, необходимая для передачи сообщений, целиком скрыта в библиотеке (ее простая реализация приведена в приложении С вместе с полным кодом этого примера).</p>
          <empty-line/>
          <p><strong>Листинг 4.15.</strong> Простая реализация класса, описывающего логику работы банкомата</p>
          <p>
            <code>struct card_inserted {</code>
          </p>
          <p>
            <code> std::string account;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>class atm {</code>
          </p>
          <p>
            <code> messaging::receiver incoming;</code>
          </p>
          <p>
            <code> messaging::sender bank;</code>
          </p>
          <p>
            <code> messaging::sender interface_hardware;</code>
          </p>
          <p>
            <code> void (atm::*state)();</code>
          </p>
          <empty-line/>
          <p>
            <code> std::string account;</code>
          </p>
          <p>
            <code> std::string pin;</code>
          </p>
          <p>
            <code> void waiting_for_card() {                      &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  interface_hardware.send(display_enter_card());&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  incoming.wait()                               &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>   .handle&lt;card_inserted&gt;(</code>
          </p>
          <p>
            <code>    [&amp;](card_inserted const&amp; msg) {             &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>    account = msg.account;</code>
          </p>
          <p>
            <code>    pin = "";</code>
          </p>
          <p>
            <code>    interface_hardware.send(display_enter_pin());</code>
          </p>
          <p>
            <code>    state = &amp;atm::getting_pin;</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  );</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void getting_pin();</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void run() {                     &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  state = &amp;atm::waiting_for_card; &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  try {</code>
          </p>
          <p>
            <code>   for(;;) {</code>
          </p>
          <p>
            <code>    (this-&gt;*state)();             &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  catch(messaging::close_queue const&amp;) {}</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Мы уже говорили, что эта реализация неизмеримо проще логики работы реального банкомата, но она все же дает представление о программировании на основе передачи сообщений. Не нужно думать о проблемах параллельности и синхронизации, наша основная забота — понять, какие входные сообщения допустимы в данной точке и какие сообщения посылать в ответ. Конечный автомат, реализующий логику банкомата, работает в одном потоке, а прочие части системы, например интерфейс с банком и с терминалом, — в других потоках. Такой принцип проектирования программ называется <emphasis>моделью акторов</emphasis> — в системе есть несколько акторов (каждый работает в своем потоке), которые посылают друг другу сообщения с просьбой выполнить определённое задание, и никакого разделяемого состояния, помимо передаваемого в составе сообщений, не существует.</p>
          <p>Выполнение начинается в функции-члене <code>run()</code> <strong>(5)</strong>, которая устанавливает начальное состояние <code>waiting_for_card</code> <strong>(6)</strong>, а затем в цикле вызывает функции-члены, представляющие текущее состояние (каким бы оно ни было) <strong>(7)</strong>. Функции состояния — это просто функции-члены класса <code>atm</code>. Функция <code>waiting_for_card</code> <strong>(1)</strong> тоже не представляет сложности: она посылает сообщение интерфейсу с просьбой вывести сообщение «Вставьте карту» <strong>(2)</strong>, а затем ожидает сообщения, которое могла бы обработать <strong>(3)</strong>. Единственное допустимое в этой точке сообщение — <code>card_inserted</code>; оно обрабатывается лямбда-функцией <strong>(4)</strong>. Функции <code>handle</code> можно передать любую функцию или объект-функцию, но в таком простом случае лямбда-функции вполне достаточно. Отметим, что вызов функции <code>handle()</code> сцеплен с вызовом <code>wait()</code>; если получено сообщение недопустимого типа, оно отбрасывается, и поток ждет, пока не придёт подходящее сообщение.</p>
          <p>Сама лямбда-функция просто запоминает номер карточного счета в переменной-члене, очищает текущий ПИН-код и переходит в состояние «получение ПИН». По завершении обработчика сообщений функция состояния возвращает управление главному циклу, который вызывает функцию следующего состояния <strong>(7)</strong>.</p>
          <p>Функция состояния <code>getting_pin</code> несколько сложнее, потому что может обрабатывать сообщения разных типов, как следует из рис. 4.3. Ниже приведён ее код.</p>
          <empty-line/>
          <p><strong>Листинг 4.16.</strong> Функция состояния <code>getting_pin</code> для простой реализации банкомата</p>
          <p>
            <code>void atm::getting_pin() {</code>
          </p>
          <p>
            <code> incoming.wait()</code>
          </p>
          <p>
            <code> .handle&lt;digit_pressed&gt;(     &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  [&amp;](digit_pressed const&amp; msg) {</code>
          </p>
          <p>
            <code>   unsigned const pin_length = 4;</code>
          </p>
          <p>
            <code>   pin += msg.digit;</code>
          </p>
          <p>
            <code>   if (pin.length() == pin_length) {</code>
          </p>
          <p>
            <code>    bank.send(verify_pin(account, pin, incoming));</code>
          </p>
          <p>
            <code>    state = &amp;atm::verifying_pin;</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> )</code>
          </p>
          <p>
            <code> .handle&lt;clear_last_pressed&gt;(&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  [&amp;](clear_last_pressed const&amp; msg) {</code>
          </p>
          <p>
            <code>   if (!pin.empty()) {</code>
          </p>
          <p>
            <code>    pin.resize(pin.length() - 1);</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> )</code>
          </p>
          <p>
            <code> .handle&lt;cancel_pressed&gt;(    &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  [&amp;](cancel_pressed const&amp; msg) {</code>
          </p>
          <p>
            <code>   state = &amp;atm::done_processing;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> );</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Поскольку теперь допустимы сообщения трех типов, то с функцией <code>wait()</code> сцеплены три вызова функции <code>handle()</code> <strong>(1)</strong>, <strong>(2)</strong>, <strong>(3)</strong>. В каждом вызове <code>handle()</code> в качестве параметра шаблона указан тип сообщения, а в качестве параметра самой функции — лямбда-функция, которая принимает сообщение этого типа. Поскольку вызовы сцеплены, функция <code>wait()</code> знает, что может ожидать сообщений <code>digit_pressed</code>, <code>clear_last_pressed</code> или <code>cancel_pressed</code>. Сообщения всех прочих типов игнорируются.</p>
          <p>Как видим, теперь состояние изменяется не всегда. Например, при получении сообщения <code>digit_pressed</code> мы просто дописываем цифру в конец <code>pin</code>, если эта цифра не последняя. Затем главный цикл (<strong>(7)</strong> в листинге 4.15) снова вызовет функцию <code>getting_pin()</code>, чтобы ждать следующую цифру (или команду очистки либо отмены).</p>
          <p>Это соответствует поведению, изображенному на рис. 4.3. Каждое состояние реализовано отдельной функцией-членом, которая ждет сообщений определенных типов и при необходимости обновляет состояние.</p>
          <p>Как видите, такой стиль программирования может заметно упростить проектирование параллельной системы, поскольку все потоки рассматриваются как абсолютно независимые. Таким образом, мы имеем пример использования нескольких потоков для разделения обязанностей, а, значит, от нас требуется явно решить, как распределять между ними задачи.</p>
        </section>
      </section>
      <section>
        <title>
          <p>4.5. Резюме</p>
        </title>
        <p>Синхронизация операций между потоками — важная часть написания параллельного приложения. Если синхронизации нет, то потоки ведут себя независимо, и их вполне можно было бы реализовать как отдельные приложения, запускаемые группой, потому что выполняют взаимосвязанные действия. В этой главе мы рассмотрели различные способы синхронизации операций — простые условные переменные, будущие результаты, обещания и упакованные задачи. Мы также обсудили несколько подходов к решению проблем синхронизации: функциональное программирование, когда каждая задача порождает результат, зависящий только от входных данных, но не от внешнего состояния, и передачу сообщений, когда взаимодействие потоков осуществляется за счет асинхронного обмена сообщениями с помощью какой-либо подсистемы передачи сообщений, играющей роль посредника.</p>
        <p>Теперь, когда мы обсудили многие высокоуровневые средства, имеющиеся в С++, настало время познакомиться с низкоуровневыми механизмами, которые приводят всю систему в движение: модель памяти С++ и атомарные операции.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Глава 5.</p>
        <p>Модель памяти С++ и атомарные операции</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Детальные сведения о модели памяти С++.</p>
        <p>&#9632; Атомарные типы в стандартной библиотеке С++.</p>
        <p>&#9632; Операции над атомарными типами.</p>
        <p>&#9632; Как можно использовать эти операции для синхронизации потоков.</p>
      </annotation>
      <section>
        <p>Одна из самых важных особенностей стандарта С++11 — та, которую большинство программистов даже не замечают. Это не новые синтаксические конструкции и не новые библиотечные средства, а новая модель памяти, учитывающая многопоточность. Без модели памяти, которая точно определяет, как должны работать основополагающие строительные блоки, ни на одно из описанных выше средств нельзя было бы полагаться. Понятно, почему большинство программистов этого не замечают: если вы пользуетесь для защиты данных мьютексами, а для сигнализации о событиях — условными переменными или будущими результатам, то вопрос о том, <emphasis>почему</emphasis> они работают, не так уж важен. И лишь когда вы подбираетесь «ближе к железу», становятся существенны точные детали модели памяти.</p>
        <p>С++ используется для решения разных задач, но одна из основных — системное программирование. Поэтому комитет по стандартизации в числе прочих целей ставил и такую: сделать так, чтобы в языке более низкого уровня, чем С++, не возникало необходимости. С++ должен обладать достаточной гибкостью, чтобы программист мог сделать то, что хочет, без помех со стороны языка, в том числе и работать «на уровне железа». Атомарные типы и операции — шаг именно в этом направлении, поскольку они предоставляют низкоуровневые механизмы синхронизации, которые обычно транслируются в одну-две машинные команды.</p>
        <p>В этой главе мы начнем с рассмотрения основ модели памяти, затем перейдем к атомарным типам и операциям и в конце обсудим различные виды синхронизации, реализуемые с помощью операций над атомарными типами. Это довольно сложная тема; если вы не планируете писать код, в котором атомарные операции используются для синхронизации (например, структуры данных без блокировок, рассматриваемые в главе 7), то все эти детали вам ни к чему. Но давайте потихоньку двинемся вперёд и начнем с модели памяти.</p>
      </section>
      <section>
        <title>
          <p>5.1. Основы модели памяти</p>
        </title>
        <section>
          <p>У модели памяти есть две стороны: базовые <emphasis>структурные</emphasis> аспекты, относящиеся к размещению программы в памяти, и аспекты, связанные с <emphasis>параллелизмом.</emphasis> Структурные аспекты важны для параллелизма, особенно если опуститься на низкий уровень атомарных операций, поэтому с них я и начну. В С++ всё вращается вокруг объектов и ячеек памяти.</p>
        </section>
        <section>
          <title>
            <p>5.1.1. Объекты и ячейки памяти</p>
          </title>
          <p>Любые данные в программе на С++ состоят из объектов. Это не значит, что можно создать новый класс, производный от <code>int</code>, или что у фундаментальных типов есть функции-члены, или вообще нечто такое, что часто имеют в виду, когда говорят «нет ничего, кроме объектов» при обсуждении таких языков, как Smalltalk или Ruby. Это утверждение просто означает, что в С++ данные строятся из объектов. В стандарте С++ объект определяется как «область памяти», хотя далее речь идет о таких свойствах объектов, как тип и время жизни.</p>
          <p>Некоторые объекты являются простыми значениями таких фундаментальных типов, как <code>int</code> или <code>float</code>, другие — экземплярами определенных пользователем классов. У некоторых объектов (например, массивов, экземпляров производных классов и экземпляров классов с нестатическими данными-членами) есть подобъекты, у других — нет.</p>
          <p>Вне зависимости от типа объект хранится в одной или нескольких <emphasis>ячейках памяти</emphasis>. Каждая такая ячейка — это либо объект (или подобъект) скалярного типа, например <code>unsigned short</code> или <code>my_class*</code>, либо последовательность соседних битовых полей. Если вы пользуетесь битовыми полями, то имейте в виду один важный момент: хотя соседние битовые поля является различными объектами, они тем не менее считаются одной ячейкой памяти. На рис. 5.1 показано, как структура <code>struct</code> представлена в виде совокупности объектов и ячеек памяти.</p>
          <image l:href="#img_9_novyjjrazmer.png"/>
          <p><strong>Рис. 5.1.</strong> Разбиение <code>struct</code> на объекты и ячейки памяти</p>
          <p>Во-первых, вся структура — это один объект, который состоит из нескольких подобъектом, по одному для каждого члена данных. Битовые поля <code>bf1</code> и <code>bf2</code> занимают одну ячейку памяти, объект <code>s</code> типа <code>std::string</code> занимает несколько ячеек памяти, а для каждого из остальных членов отведена своя ячейка. Обратите внимание, что битовое поле нулевой длины <code>bf3</code> заставляет отвести для <code>bf4</code> отдельную ячейку.</p>
          <p>Отсюда можно сделать несколько важных выводов:</p>
          <p>• каждая переменная — объект, в том числе и переменные, являющиеся членами других объектов;</p>
          <p>• каждый объект занимает <emphasis>по меньшей мере</emphasis> одну ячейку памяти;</p>
          <p>• переменные фундаментальных типов, например <code>int</code> или <code>char</code>, занимают <emphasis>в точности</emphasis> одну ячейку памяти вне зависимости от размера, даже если являются соседними или элементами массива;</p>
          <p>• соседние битовые поля размещаются в одной ячейке памяти.</p>
          <p>Уверен, что вы недоумеваете, какое отношение всё это имеет к параллелизму. Давайте разберемся.</p>
        </section>
        <section>
          <title>
            <p>5.1.2. Объекты, ячейки памяти и параллелизм</p>
          </title>
          <p>Для многопоточных приложений на С++ понятие ячейки памяти критически важно. Если два потока обращаются к <emphasis>разным</emphasis> ячейкам памяти, то никаких проблем не возникает и всё работает, как надо. Но если потоки обращаются к <emphasis>одной и той же</emphasis> ячейке, то необходима осторожность. Если ни один поток не обновляет ячейку памяти, то всё хорошо — доступ к данным для чтения не нуждается ни в защите, ни в синхронизации. Если же какой-то поток модифицирует данные, то возможно состояние гонки, описанное в главе 3.</p>
          <p>Чтобы избежать гонки, необходимо принудительно упорядочить обращения из двух потоков. Один из возможных способов такого упорядочения дают мьютексы (см. главу 3) — если захватывать один и тот же мьютекс перед каждым обращением, то одновременно получить доступ к ячейке памяти сможет только один поток, так что упорядочение налицо. Другой способ упорядочить доступ из двух потоков — воспользоваться свойствами синхронизации, присущими атомарным операциям (о том, что это такое, см. раздел 5.2) над теми же или другими ячейками памяти. Такое использование атомарных операций описано в разделе 5.3. Если к одной и той же ячейке обращаются более двух потоков, то упорядочение должно быть определено для каждой пары.</p>
          <p>Если два обращения к одной и той же ячейке памяти из разных потоков не упорядочены и одно или оба обращения не являются атомарными и одно или оба обращения являются операциями записи, то имеет место гонка за данными, что приводит к неопределенному поведению.</p>
          <p>Эта фраза критически важна: неопределенное поведение — один из самых грязных закоулков С++. Согласно стандарту языка, любое неопределенное поведение отменяет всякие гарантии — поведение всего приложения становится неопределённым, и оно может делать все, что угодно. Я знаю один пример неопределённого поведения, в результате которого загорелся монитор. Хотя маловероятно, что такое приключится с вами, гонка за данными безусловно является серьезной ошибкой, которой следует всеми силами избегать.</p>
          <p>В этой фразе есть и еще один важный момент: избежать неопределенного поведения поможет использование атомарных операций для доступа к ячейке памяти, за которую возможна гонка. Саму гонку это не предотвращает — какая именно атомарная операция первой получит доступ к ячейке памяти, все равно не определено, — но программа тем не менее возвращается в область определённого поведения.</p>
          <p>Прежде чем мы перейдем к атомарным операциям, нужно разобраться еще в одной важной концепции, касающейся объектов и ячеек памяти: порядке модификации.</p>
        </section>
        <section>
          <title>
            <p>5.1.3. Порядок модификации</p>
          </title>
          <p>Для каждого объекта в программе на С++ определён <emphasis>порядок модификации,</emphasis> состоящий из всех операций записи в объект из всех потоков программы, начиная с инициализации объекта. В большинстве случаев порядок меняется от запуска к запуску, но при любом выполнении программы все имеющиеся в системе потоки должны договориться о порядке модификации. Если объект не принадлежит одному из описанных в разделе 5.2 атомарных типов, то вы сами отвечаете за обеспечение синхронизации, достаточной для того, чтобы потоки могли договориться о порядке модификации каждой переменной. Если разные потоки видят разные последовательности значений одной и той же переменной, то имеет место гонка за данными и, как следствие, неопределённое поведение (см. раздел 5.1.2). Если вы используете атомарные операции, то за обеспечение необходимой синхронизации отвечает компилятор.</p>
          <p>Это требование означает, что некоторые виды спекулятивного исполнения<a l:href="#n11" type="note">[11]</a> не разрешены, потому что после того как некоторый поток увидел определённое значение объекта при данном порядке модификации, последующие операции чтения в том же потоке должны возвращать более поздние значения, а последующие операции записи в тот же объект в этом потоке должны происходить позже при данном порядке модификации. Кроме того, операция чтения объекта, следующая за операцией записи в этот объект, должна вернуть либо записанное значение, либо другое значение, которое было записано позже при данном порядке модификации этого объекта. Хотя все потоки обязаны договориться о порядке модификации каждого объекта в программе, не требуется, чтобы они договаривались об относительном порядке операций над разными объектами. Дополнительные сведения об упорядочении операций, выполняемых в разных потоках, см. в разделе 5.3.3.</p>
          <p>Итак, что понимается под атомарной операцией и как ими можно воспользоваться для принудительного упорядочения?</p>
        </section>
      </section>
      <section>
        <title>
          <p>5.2. Атомарные операции и типы в С++</p>
        </title>
        <section>
          <p>Под <emphasis>атомарными</emphasis> понимаются неделимые операции. Ни из одного потока в системе невозможно увидеть, что такая операция выполнена наполовину, — она либо выполнена целиком, либо не выполнена вовсе. Если операция загрузки, которая читает значение объекта, <emphasis>атомарна</emphasis>, и все операции модификации этого объекта также <emphasis>атомарны</emphasis>, то в результате загрузки будет получено либо начальное значение объекта, либо значение, сохраненное в нем после одной из модификаций.</p>
          <p>И наоборот, если операция не атомарная, то другой поток может видеть, что она выполнена частично. Если это операция сохранения, то значение, наблюдаемое другим потоком, может не совпадать ни со значением до начала сохранения, ни с сохраненным значением. С другой стороны, операция загрузки может извлечь часть объекта, после чего значение будет модифицировано другим потоком, а затем операция прочитает оставшуюся часть объекта. В результате будет извлечено значение, которое объект не имел ни до, ни после модификации. Это простая проблематичная гонка, описанная в главе 3, но на этом уровне она может представлять собой <emphasis>гонку за данными</emphasis> (см. раздел 5.1) и, стало быть, являться причиной неопределённого поведения.</p>
          <p>В С++ для того чтобы операция была атомарной, обычно необходимы атомарные типы. Давайте познакомимся с ними.</p>
        </section>
        <section>
          <title>
            <p>5.2.1. Стандартные атомарные типы</p>
          </title>
          <p>Все стандартные <emphasis>атомарные типы</emphasis> определены в заголовке <code>&lt;atomic&gt;</code>. Любые операции над такими типами атомарны, и только операции над этими типами атомарны в смысле принятого в языке определения, хотя мьютексы позволяют реализовать <emphasis>кажущуюся</emphasis> атомарность других операций. На самом деле, и сами стандартные атомарные типы могут пользоваться такой эмуляцией: почти во всех имеется функция-член <code>is_lock_free()</code>, которая позволяет пользователю узнать, выполняются ли операции над данным типом с помощью действительно атомарных команд (<code>x.is_lock_free()</code> возвращает <code>true</code>) или с применением некоторой внутренней для компилятора и библиотеки блокировки (<code>x.is_lock_free()</code> возвращает <code>false</code>).</p>
          <p>Единственный тип, в котором функция-член <code>is_lock_free()</code> отсутствует, — это <code>std::atomic_flag</code>. В действительности это по-настоящему простой булевский флаг, а операции над этим типом <emphasis>обязаны</emphasis> быть свободными от блокировок; если имеется простой свободный от блокировок булевский флаг, то на его основе можно реализовать простую блокировку и, значит, все остальные атомарные типы. Говоря <emphasis>по-настоящему простой</emphasis>, я именно это и имел в виду: после инициализации объект типа <code>std::atomic_flag</code> сброшен, и для него определены всего две операции: проверить и установить (функция-член <code>test_and_set()</code>) и очистить (функция-член <code>clear()</code>). Это всё — нет ни присваивания, ни копирующего конструктора, ни операции «проверить и очистить», вообще ничего больше.</p>
          <p>Доступ ко всем остальным атомарным типам производится с помощью специализаций шаблона класса <code>std::atomic&lt;&gt;</code>; их функциональность несколько богаче, но они необязательно свободны от блокировок (как было объяснено выше). На самых распространенных платформах можно ожидать, что атомарные варианты всех встроенных типов (например, <code>std::atomic&lt;int&gt;</code> и <code>std::atomic&lt;void*&gt;</code>) действительно будут свободны от блокировок, но такого требования не предъявляется. Как мы скоро увидим, интерфейс каждой специализации отражает свойства типа; например, поразрядные операции, например <code>&amp;=</code>, не определены для простых указателей, поэтому они не определены и для атомарных указателей.</p>
          <p>Помимо прямого использования шаблона класса <code>std::atomic&lt;&gt;</code>, разрешается использовать имена, приведённые в табл. 5.1, которые ссылаются на определенные в конкретной реализации атомарные типы. Из-за исторических особенностей добавления атомарных типов в стандарт С++ альтернативные имена типов могут ссылаться либо на соответствующую специализацию <code>std::atomic&lt;&gt;</code>, либо на базовый класс этой специализации. Поэтому смешение альтернативных имен и прямых имен специализаций <code>std::atomic&lt;&gt;</code> может сделать программу непереносимой.</p>
          <empty-line/>
          <p><strong>Таблица 5.1.</strong> Альтернативные имена стандартных атомарных типов и соответствующие им специализации <code>std::atomic&lt;&gt;</code></p>
          <table>
            <tr align="left">
              <th align="left" valign="top">Атомарный тип</th>
              <th align="left" valign="top">Соответствующая специализация</th>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_bool</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;bool&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_char</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;char&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_schar</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;signed char&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uhar</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned char&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_int</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;int&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uint</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_short</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;short&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_ushort</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned short&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_long</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;long&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_ulong</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned long&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_llong</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;long long&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_ullong</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned long long&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_char16_t</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;char16_t&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_char32_t</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;char32_t&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_wchar_t</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;wchar_t&gt;</code>
              </td>
            </tr>
          </table>
          <p>Помимо основных атомарных типов, в стандартной библиотеке С++ определены также псевдонимы <code>typedef</code> для атомарных типов, соответствующих различным неатомарным библиотечным <code>typedef</code>, например <code>std::size_t</code>. Они перечислены в табл. 5.2.</p>
          <empty-line/>
          <p><strong>Таблица 5.2.</strong> Соответствие между стандартными атомарными и встроенными <code>typedef</code></p>
          <table>
            <tr align="left">
              <th align="left" valign="top">Атомарный <code>typedef</code></th>
              <th align="right" valign="top">Соответствующий <code>typedef</code> из стандартной библиотеки</th>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_int_least8_t</code>
              </td>
              <td align="left" valign="top">
                <code>int_least8_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uint_least8_t</code>
              </td>
              <td align="left" valign="top">
                <code>uint_least8_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_int_least16_t</code>
              </td>
              <td align="left" valign="top">
                <code>int_least16_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uint_least16_t</code>
              </td>
              <td align="left" valign="top">
                <code>uint_least16_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_int_least32_t</code>
              </td>
              <td align="left" valign="top">
                <code>int_least32_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uint_least32_t</code>
              </td>
              <td align="left" valign="top">
                <code>uint_least32_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_int_least64_t</code>
              </td>
              <td align="left" valign="top">
                <code>int_least64_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uint_least64_t</code>
              </td>
              <td align="left" valign="top">
                <code>uint_least64_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_int_fast8_t</code>
              </td>
              <td align="left" valign="top">
                <code>int_fast8_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uint_fast8_t</code>
              </td>
              <td align="left" valign="top">
                <code>uint_fast8_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_int_fast16_t</code>
              </td>
              <td align="left" valign="top">
                <code>int_fast16_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uint_fast16_t</code>
              </td>
              <td align="left" valign="top">
                <code>uint_fast16_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_int_fast32_t</code>
              </td>
              <td align="left" valign="top">
                <code>int_fast32_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uint_fast32_t</code>
              </td>
              <td align="left" valign="top">
                <code>uint_fast32_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_int_fast64_t</code>
              </td>
              <td align="left" valign="top">
                <code>int_fast64_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uint_fast64_t</code>
              </td>
              <td align="left" valign="top">
                <code>uint_fast64_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_intptr_t</code>
              </td>
              <td align="left" valign="top">
                <code>intptr_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uintptr_t</code>
              </td>
              <td align="left" valign="top">
                <code>uintptr_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_size_t</code>
              </td>
              <td align="left" valign="top">
                <code>size_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_ptrdiff_t</code>
              </td>
              <td align="left" valign="top">
                <code>ptrdiff_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_intmax_t</code>
              </td>
              <td align="left" valign="top">
                <code>intmax_t</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>atomic_uintmax_t</code>
              </td>
              <td align="left" valign="top">
                <code>uintmax_t</code>
              </td>
            </tr>
          </table>
          <p>Да уж, типов немало! Но есть простая закономерность — атомарный тип, соответствующий стандартному <code>typedef T</code>, имеет такое же имя с префиксом <code>atomic_</code>: <code>atomic_T</code>. То же самое относится и к встроенным типам с тем исключением, что <code>signed</code> сокращается до <code>s</code>, <code>unsigned</code> — до <code>u</code>, a <code>long long</code> — до <code>llong</code>. Вообще говоря, проще написать <code>std::atomic&lt;T&gt;</code> для нужного вам типа <code>T</code>, чем пользоваться альтернативными именами.</p>
          <p>Стандартные атомарные типы не допускают копирования и присваивания в обычном смысле, то есть не имеют копирующих конструкторов и операторов присваивания. Однако им все же можно присваивать значения соответствующих встроенных типов, и они поддерживают неявные преобразования в соответствующие встроенные типы. Кроме того, в них определены функции-члены <code>load()</code>, <code>store()</code>, <code>exchange()</code>, <code>compare_exchange_weak()</code> и <code>compare_exchange_strong()</code>. Поддерживаются также составные операторы присваивания (там, где это имеет смысл) <code>+=</code>, <code>-=</code>, <code>*=</code>, <code>|=</code> и т.д., а для целочисленных типов и специализаций <code>std::atomic&lt;&gt;</code> для указателей — еще и операторы <code>++</code> и <code>--</code>. Этим операторам соответствуют также именованные функции-члены с идентичной функциональностью: <code>fetch_add()</code>, <code>fetch_or()</code> и т.д. Операторы присваивания возвращают сохраненное значение, а именованные функции-члены — значение, которое объект имел до начала операции. Это позволяет избежать потенциальных проблем, связанных с тем, что обычно операторы присваивания возвращают ссылку на объект в левой части. Чтобы получить из такой ссылки сохраненное значение, программа должна была бы выполнить еще одну операцию чтения, но тогда между присваиванием и чтением другой поток мог бы модифицировать значение, открывая дорогу гонке.</p>
          <p>Но шаблон класса <code>std::atomic&lt;&gt;</code> — не просто набор специализаций. В нем есть основной шаблон, который можно использовать для создания атомарного варианта пользовательского типа. Поскольку это обобщенный шаблон класса, определены только операции <code>load()</code>, <code>store()</code> (а также присваивание значения пользовательского типа и преобразования в пользовательский тип), <code>exchange()</code>, <code>compare_exchange_weak()</code> и <code>compare_exchange_strong()</code>.</p>
          <p>У любой операции над атомарными типами имеется необязательный аргумент, задающий требования к семантике упорядочения доступа к памяти. Точный смысл различных вариантов упорядочения обсуждается в разделе 5.3. Пока же достаточно знать, что операции разбиты на три категории.</p>
          <p>• Операции <emphasis>сохранения</emphasis>, для которых можно задавать упорядочение <code>memory_order_relaxed</code>, <code>memory_order_release</code> и <code>memory_оrder_sеq_cst</code>.</p>
          <p>• Операции <emphasis>загрузки</emphasis>, для которых можно задавать упорядочение <code>memory_order_relaxed</code>, <code>memory_order_consume</code>, <code>memory_order_acquire</code> и <code>memory_order_seq_cst</code>.</p>
          <p>• Операции <emphasis>чтения-модификации-записи</emphasis>, для которых можно задавать упорядочение <code>memory_order_relaxed</code>, <code>memory_order_consume</code>, <code>memory_order_acquire</code>, <code>memory_order_release</code>, <code>memory_order_acq_rel</code> и <code>memory_order_seq_cst</code>.</p>
          <p>По умолчанию для всех операций подразумевается упорядочение <code>memory_оrder_sеq_cst</code>.</p>
          <p>Теперь рассмотрим, какие операции можно производить над каждым из стандартных атомарных типов, начиная с <code>std::atomic_flag</code>.</p>
        </section>
        <section>
          <title>
            <p>5.2.2. Операции над <code>std::atomic_flag</code></p>
          </title>
          <p>Простейший стандартный атомарный тип <code>std::atomic_flag</code> представляет булевский флаг. Объекты этого типа могут находиться в одном из двух состояний: установлен или сброшен. Этот тип намеренно сделан максимально простым, рассчитанным только на применение в качестве строительного блока. Поэтому увидеть его в реальной программе можно лишь в очень специфических обстоятельствах. Тем не менее, он послужит нам отправной точкой для обсуждения других атомарных типов, потому что на его примере отчетливо видны общие относящиеся к ним стратегии.</p>
          <p>Объект типа <code>std::atomic_flag</code> <emphasis>должен</emphasis> быть инициализирован значением <code>ATOMIC_FLAG_INIT</code>. При этом флаг оказывается в состоянии <emphasis>сброшен</emphasis>. Никакого выбора тут не предоставляется — флаг всегда должен начинать существование в сброшенном состоянии:</p>
          <p>
            <code>std::atomic_flag f = ATOMIC_FLAG_INIT;</code>
          </p>
          <p>Требование применяется вне зависимости от того, где и в какой области видимости объект объявляется. Это единственный атомарный тип, к инициализации которого предъявляется столь специфическое требование, зато при этом он является также единственным типом, гарантированно свободным от блокировок. Если у объекта <code>std::atomic_flag</code> статический класс памяти, то он гарантированно инициализируется статически, и, значит, никаких проблем с порядком инициализации не будет — объект всегда оказывается инициализированным к моменту первой операции над флагом.</p>
          <p>После инициализации с флагом можно проделать только три вещи: уничтожить, очистить или установить, одновременно получив предыдущее значение. Им соответствуют деструктор, функция-член <code>clear()</code> и функция-член <code>test_and_set()</code>. Для обеих функций <code>clear()</code> и <code>test_and_set()</code> можно задать упорядочение памяти. <code>clear()</code> — операция <emphasis>сохранения</emphasis>, поэтому варианты упорядочения <code>memory_order_acquire</code> и <code>memory_order_acq_rel</code> к ней неприменимы, a <code>test_and_set()</code> — операция чтения-модификации-записи, так что к ней применимы любые варианты упорядочения. Как и для любой атомарной операции, по умолчанию подразумевается упорядочение <code>memory_order_seq_cst</code>. Например:</p>
          <p>
            <code>f.clear(std::memory_order_release);&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>bool x = f.test_and_set();         &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>Здесь при вызове <code>clear()</code> <strong>(1)</strong> явно запрашивается сброс флага с семантикой освобождения, а при вызове <code>test_and_set()</code> <strong>(2)</strong> подразумевается стандартное упорядочение для операции установки флага и получения прежнего значения.</p>
          <p>Объект <code>std::atomic_flag</code> нельзя сконструировать копированием из другого объекта, не разрешается также присваивать один <code>std::atomic_flag</code> другому. Это не особенность типа <code>std::atomic_flag</code>, а свойство, общее для всех атомарных типов. Любые операции над атомарным типом должны быть атомарными, а для присваивания и конструирования копированием нужны два объекта. Никакая операция над двумя разными объектами не может быть атомарной. В случае копирования и присваивания необходимо сначала прочитать значение первого объекта, а потом записать его во второй. Это две отдельные операции над двумя различными объектами, и их комбинация не может быть атомарной. Поэтому такие операции запрещены.</p>
          <p>Такая ограниченность функциональности делает тип <code>std::atomic_flag</code> идеальным средством для реализации мьютексов-спинлоков. Первоначально флаг сброшен и мьютекс свободен. Чтобы захватить мьютекс, нужно в цикле вызывать функцию <code>test_and_set()</code>, пока она не вернет прежнее значение <code>false</code>, означающее, что теперь в <emphasis>этом</emphasis> потоке установлено значение флага <code>true</code>. Для освобождения мьютекса нужно просто сбросить флаг. Реализация приведена в листинге ниже.</p>
          <empty-line/>
          <p><strong>Листинг 5.1.</strong> Реализация мьютекса-спинлока с использованием <code>std::atomic_flag</code></p>
          <p>
            <code>class spinlock_mutex {</code>
          </p>
          <p>
            <code> std::atomic_flag flag;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> spinlock_mutex():</code>
          </p>
          <p>
            <code>  flag(ATOMIC_FLAG_INIT) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void lock() {</code>
          </p>
          <p>
            <code>  while (flag.test_and_set(std::memory_order_acquire));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void unlock() {</code>
          </p>
          <p>
            <code>  flag.clear(std::memory_order_release);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Это очень примитивный мьютекс, но даже его достаточно для использования в сочетании с шаблоном <code>std::lock_guard&lt;&gt;</code> (см. главу 3). По своей природе, он активно ожидает в функции-члене <code>lock()</code>, поэтому не стоит использовать его, если предполагается хоть какая-то конкуренция, однако задачу взаимного исключения он решает. Когда дело дойдет до семантики упорядочения доступа к памяти, мы увидим, как гарантируется принудительное упорядочение, необходимое для захвата мьютекса. Пример будет приведён в разделе 5.3.6.</p>
          <p>Тип <code>std::atomic_flag</code> настолько ограничен, что его даже нельзя использовать в качестве обычного булевского флага, так как он не допускает проверки без изменения значения. На эту роль больше подходит тип <code>std::atomic&lt;bool&gt;</code>, который я рассмотрю ниже.</p>
        </section>
        <section>
          <title>
            <p>5.2.3. Операции над <code>std::atomic&lt;bool&gt;</code></p>
          </title>
          <p>Из атомарных целочисленных типов простейшим является <code>std::atomic&lt;bool&gt;</code>. Как и следовало ожидать, его функциональность в качестве булевского флага богаче, чем у <code>std::atomic_flag</code>. Хотя копирующий конструктор и оператор присваивания по-прежнему не определены, но можно сконструировать объект из неатомарного <code>bool</code>, поэтому в начальном состоянии он может быть равен как <code>true</code>, так и <code>false</code>. Разрешено также присваивать объектам типа <code>std::atomic&lt;bool&gt;</code> значения неатомарного типа <code>bool</code>:</p>
          <p>
            <code>std::atomic&lt;bool&gt; b(true);</code>
          </p>
          <p>
            <code>b = false;</code>
          </p>
          <p>Что касается оператора присваивания с неатомарным <code>bool</code> в правой части, нужно еще отметить отход от общепринятого соглашения о возврате ссылки на объект в левой части — этот оператор возвращает присвоенное значение типа <code>bool</code>. Такая практика обычна для атомарных типов: все поддерживаемые ими операторы присваивания возвращают значения (соответствующего неатомарного типа), а не ссылки. Если бы возвращалась ссылка на атомарную переменную, то программа, которой нужен результат присваивания, должна была бы явно загрузить значение, открывая возможность для модификации результата другим потоком в промежутке между присваиванием и чтением. Получая же результат присваивания в виде неатомарного значения, мы обходимся без дополнительной операции загрузки и можем быть уверены, что получено именно то значение, которое было сохранено.</p>
          <p>Запись (любого значения: <code>true</code> или <code>false</code>) производится не чрезмерно ограничительной функцией <code>clear()</code> из класса <code>std::atomic_flag</code>, а путём вызова функции-члена <code>store()</code>, хотя семантику упорядочения доступа к памяти по-прежнему можно задать. Аналогично вместо <code>test_and_set()</code> используется более общая функция-член <code>exchange()</code>, которая позволяет атомарно заменить ранее сохраненное значение новым и вернуть прежнее значение. Тип <code>std::atomic&lt;bool&gt;</code> поддерживает также проверку значения без модификации посредством неявного преобразования к типу <code>bool</code> или явного обращения к функции <code>load()</code>. Как нетрудно догадаться, <code>store()</code> — это операция сохранения, <code>load()</code> — операция загрузки, a <code>exchange()</code> — операция чтения-модификации-записи:</p>
          <p>
            <code>std::atomic&lt;bool&gt; b;</code>
          </p>
          <p>
            <code>bool x = b.load(std::memory_order_acquire);</code>
          </p>
          <p>
            <code>b.store(true);</code>
          </p>
          <p>
            <code>x = b.exchange(false, std::memory_order_acq_rel);</code>
          </p>
          <p>Функция <code>exchange()</code> — не единственная операция чтения-модификации-записи, которую поддерживает тип <code>std::atomic&lt;bool&gt;</code>; в нем также определена операция сохранения нового значения, если текущее совпадает с ожидаемым.</p>
          <subtitle>Сохранение (или несохранение) нового значения в зависимости от текущего</subtitle>
          <p>Новая операция называется «сравнить и обменять» и реализована в виде функций-членов <code>compare_exchange_weak()</code> и <code>compare_exchange_strong()</code>. Эта операция — краеугольный камень программирования с использованием атомарных типов; она сравнивает значение атомарной переменной с указанным ожидаемым значением и, если они совпадают, то сохраняет указанное новое значение. Если же значения не совпадают, то ожидаемое значение заменяется фактическим значением атомарной переменной. Функции сравнения и обмена возвращают значение типа <code>bool</code>, равное <code>true</code>, если сохранение было произведено, и <code>false</code> — в противном случае.</p>
          <p>В случае <code>compare_exchange_weak()</code> сохранение может не произойти, даже если текущее значение совпадает с ожидаемым. В таком случае значение переменной не изменится, а функция вернет <code>false</code>. Такое возможно на машинах, не имеющих аппаратной команды сравнить-и-обменять, если процессор не может гарантировать атомарности операции — например, потому что поток, в котором операция выполнялась, был переключён в середине требуемой последовательности команд и замещен другим потоком (когда потоков больше, чем процессоров). Эта ситуация называется <emphasis>ложным отказом</emphasis>, потому что причиной отказа являются не значения переменных, а хронометраж выполнения функции.</p>
          <p>Поскольку <code>compare_exchange_weak()</code> может стать жертвой ложного отказа, обычно ее вызывают в цикле:</p>
          <p>
            <code>bool expected = false;</code>
          </p>
          <p>
            <code>extern atomic&lt;bool&gt; b; // установлена где-то в другом месте</code>
          </p>
          <p>
            <code>while (!b.compare_exchange_weak(expected, true) &amp;&amp; !expected);</code>
          </p>
          <p>Этот цикл продолжается, пока <code>expected</code> равно <code>false</code>, что указывает на ложный отказ <code>compare_exchange_weak()</code>.</p>
          <p>С другой стороны, <code>compare_exchange_strong()</code> гарантированно возвращает <code>false</code> только в том случае, когда текущее значение не было равно ожидаемому (<code>expected</code>). Это устраняет необходимость в показанном выше цикле, когда нужно только узнать, удалось ли нам изменить переменную или другой поток добрался до нее раньше.</p>
          <p>Если мы хотим изменить переменную, каким бы ни было ее текущее значение (при этом новое значение может зависеть от текущего), то обновление <code>expected</code> оказывается полезной штукой; на каждой итерации цикла <code>expected</code> перезагружается, так что если другой поток не модифицирует значение в промежутке, то вызов <code>compare_exchange_weak()</code> или <code>compare_exchange_strong()</code> должен оказаться успешным на следующей итерации. Если новое сохраняемое значение вычисляется просто, то выгоднее использовать <code>compare_exchange_weak()</code>, чтобы избежать двойного цикла на платформах, где <code>compare_exchange_weak()</code> <emphasis>может</emphasis> давать ложный отказ (и, следовательно, <code>compare_exchange_strong()</code> содержит цикл). С другой стороны, если вычисление нового значения занимает длительное время, то имеет смысл использовать <code>compare_exchange_strong()</code>, чтобы не вычислять значение заново, когда <code>expected</code> не изменилась. Для типа <code>std::atomic&lt;bool&gt;</code> это не столь существенно — в конце концов, есть всего два возможных значения — но для более широких атомарных типов различие может оказаться заметным.</p>
          <p>Функции сравнения и обмена необычны еще и тем, что могут принимать <emphasis>два</emphasis> параметра упорядочения доступа к памяти. Это позволяет по-разному задавать семантику упорядочения в случае успеха и отказа; быть может, при успешном вызове требуется семантика <code>memory_order_acq_rel</code>, а при неудачном — <code>memory_order_relaxed</code>. В случае отказа функция сохранить-и-обменять не производит сохранение, поэтому семантика <code>memory_order_release</code> или <code>memory_order_acq_rel</code> неприменима. Поэтому задавать эти варианты упорядочения для отказа не разрешается. Кроме того, нельзя задавать для отказа более строгое упорядочение, чем для успеха; если вы требуете семантику <code>memory_order_acquire</code> или <code>memory_order_seq_cst</code> в случае отказа, то должны потребовать такую же и в случае успеха.</p>
          <p>Если упорядочение для отказа не задано, то предполагается, что оно такое же, как для успеха, с тем отличием, что часть release заменяется: <code>memory_order_release</code> становится <code>memory_order_relaxed</code>, a <code>memory_order_acq_rel</code> — <code>memory_order_acquire</code>. Если не задано ни одно упорядочение, то как обычно предполагается <code>memory_order_seq_cst</code>, то есть полное последовательное упорядочение доступа как в случае успеха, так и в случае отказа. Следующие два вызова <code>compare_exchange_weak()</code> эквивалентны:</p>
          <p>
            <code>std::atomic&lt;bool&gt; b;</code>
          </p>
          <p>
            <code>bool expected;</code>
          </p>
          <p>
            <code>b.compare_exchange_weak(expected, true,</code>
          </p>
          <p>
            <code>memory_order_acq_rel, memory_order_acquire);</code>
          </p>
          <p>
            <code>b.compare_exchange_weak(expected, true, memory_order_acq_rel);</code>
          </p>
          <p>К чему приводит задание того или иного упорядочения, я расскажу в разделе 5.3.</p>
          <p>Еще одно отличие <code>std::atomic&lt;bool&gt;</code> от <code>std::atomic_flag</code> заключается в том, что тип <code>std::atomic&lt;bool&gt;</code> не обязательно свободен от блокировок; для обеспечения атомарности реализация библиотеки может захватывать внутренний мьютекс. В тех редких случаях, когда это важно, можно с помощью функции-члена <code>is_lock_free()</code> узнать, являются ли операции над <code>std::atomic&lt;bool&gt;</code> свободными от блокировок. Это еще одна особенность, присущая всем атомарным типам, кроме <code>std::atomic_flag</code>.</p>
          <p>Следующими по простоте являются атомарные специализации указателей <code>std::atomic&lt;T*&gt;</code>.</p>
        </section>
        <section>
          <title>
            <p>5.2.4. Операции над <code>std::atomic&lt;T*&gt;</code>: арифметика указателей</p>
          </title>
          <p>Атомарная форма указателя на тип <code>T</code> — <code>std::atomic&lt;T*&gt;</code> — выглядит так же, как атомарная форма <code>bool</code> (<code>std::atomic&lt;bool&gt;</code>). Интерфейс по существу такой же, только операции применяются к указателям на значения соответствующего типа, а не к значениям типа <code>bool</code>. Как и в случае <code>std::atomic&lt;bool&gt;</code>, копирующие конструктор и оператор присваивания не определены, но разрешено конструирование и присваивание на основе подходящих указателей. Помимо обязательной функции <code>is_lock_free()</code>, тип <code>std::atomic&lt;T*&gt;</code> располагает также функциями <code>load()</code>, <code>store(</code>), <code>exchange()</code>, <code>compare_exchange_weak()</code> и <code>compare_exchange_strong()</code> с такой же семантикой, как <code>std::atomic&lt;bool&gt;</code>, но принимаются и возвращаются значения типа <code>T*</code>, а не <code>bool</code>.</p>
          <p>Новыми в типе <code>std::atomic&lt;T*&gt;</code> являются арифметические операции над указателями. Базовые операции предоставляются функциями-членами <code>fetch_add()</code> и <code>fetch_sub()</code>, которые прибавляют и вычитают целое число из сохраненного адреса, а также операторы <code>+=</code>, <code>-=</code>, <code>++</code> и <code>--</code> (последние в обеих формах — пред и пост), представляющие собой удобные обертки вокруг этих функций. Операторы работают так же, как для встроенных типов: если <code>x</code> — указатель <code>std::atomic&lt;Foo*&gt;</code> на первый элемент массива объектов типа <code>Foo</code>, то после выполнения оператора <code>x+=3</code> <code>x</code> будет указывать на четвертый элемент и при этом возвращается простой указатель <code>Foo*</code>, который также указывает на четвертый элемент. Функции <code>fetch_add()</code> и <code>fetch_sub()</code> отличаются от операторов тем, что возвращают старое значение (то есть <code>x.fetch_add(3)</code> изменит <code>x</code>, так что оно будет указывать на четвертый элемент, но вернет указатель на первый элемент массива). Эту операцию еще называют <emphasis>обменять-и-прибавить</emphasis>, она относится к категории атомарных операций чтения-модификации-записи, наряду с <code>exchange()</code>, <code>compare_exchange_weak()</code> и <code>compare_exchange_strong()</code>. Как и другие операции такого рода, <code>fetch_add()</code> возвращает простой указатель <code>T*</code>, а не ссылку на объект <code>std::atomic&lt;T*&gt;</code>, поэтому вызывающая программа может выполнять действия над прежним значением:</p>
          <p>
            <code>class Foo{};</code>
          </p>
          <p>
            <code>Foo some_array[5];              &#9474;</code>
            <strong>Прибавить 2 к p</strong>
          </p>
          <p>
            <code>std::atomic&lt;Foo*&gt; p(some_array);&#9474;</code>
            <strong>и вернуть старое</strong>
          </p>
          <p>
            <code>Foo* x = p.fetch_add(2);       &#8592;&#9496;</code>
            <strong>значение</strong>
          </p>
          <p>
            <code>assert(x == some_array);</code>
          </p>
          <p>
            <code>assert(p.load() == &amp;some_array[2]);</code>
          </p>
          <p>
            <code>x = (p -= 1);                     &#8592;&#9488; </code>
            <strong>Вычесть 1 из p</strong>
          </p>
          <p>
            <code>assert(x == &amp;some_array[1]);       &#9474;</code>
            <strong>и вернуть новое</strong>
          </p>
          <p>
            <code>assert(p.load() == &amp;some_array[1]);&#9474;</code>
            <strong>значение</strong>
          </p>
          <p>Функциям можно также передать в дополнительном аргументе семантику упорядочения доступа к памяти:</p>
          <p>
            <code>p.fetch_add(3, std::memory_order_release);</code>
          </p>
          <p>Поскольку <code>fetch_add()</code> и <code>fetch_sub()</code> — операции чтения-модификации-записи, то они принимают любую семантику упорядочения и могут участвовать в <emphasis>последовательности освобождений</emphasis>. Для операторных форм задать семантику невозможно, поэтому предполагается семантика <code>memory_order_sеq_cst</code>.</p>
          <p>Все прочие атомарные типы по существу одинаковы: это атомарные целочисленные типы с общим интерфейсом, различаются они только ассоциированными встроенными типами. Поэтому я опишу их все сразу.</p>
        </section>
        <section>
          <title>
            <p>5.2.5. Операции над стандартными атомарными целочисленными типами</p>
          </title>
          <p>Помимо обычного набора операций (<code>load()</code>, <code>store()</code>, <code>exchange()</code>, <code>compare_exchange_weak()</code> и <code>compare_exchange_strong()</code>), атомарные целочисленные типы такие, как <code>std::atomic&lt;int&gt;</code> или <code>std::atomic&lt;unsigned long long&gt;</code>) обладают целым рядом дополнительных операций: <code>fetch_add()</code>, <code>fetch_sub()</code>, <code>fetch_and()</code>, <code>fetch_or()</code>, <code>fetch_xor()</code>, их вариантами в виде составных операторов присваивания (<code>+=</code>, <code>-=</code>, <code>&amp;=</code>, <code>|=</code>, <code>^=</code>) и операторами пред- и постинкремента и декремента (<code>++x</code>, <code>x++</code>, <code>--x</code>, <code>x--</code>). Это не весь набор составных операторов присваивания, имеющихся у обычного целочисленного типа, но близко к тому — отсутствуют лишь операторы умножения, деления и сдвига. Поскольку атомарные целочисленные значения обычно используются в качестве счетчиков или битовых масок, потеря не слишком велика, а в случае необходимости недостающие операции можно реализовать с помощью вызова функции <code>compare_exchange_weak()</code> в цикле.</p>
          <p>Семантика операций близка к семантике функций <code>fetch_add()</code> и <code>fetch_sub()</code> в типе <code>std::atomic&lt;T*&gt;</code>; именованные функции выполняют свои операции атомарно и возвращают <emphasis>старое</emphasis> значение, а составные операторы присваивания возвращают <emphasis>новое</emphasis> значение. Операторы пред- и постинкремента и декремента работают как обычно: <code>++x</code> увеличивает значение переменной на единицу и возвращает новое значение, а <code>x++</code> увеличивает значение переменной на единицу и возвращает старое значение. Как вы теперь уже понимаете, результатом в обоих случаях является значение ассоциированного целочисленного типа.</p>
          <p>Мы рассмотрели все простые атомарные типы; остался только основной обобщенный шаблон класса <code>std::atomic&lt;&gt;</code> без специализации.</p>
        </section>
        <section>
          <title>
            <p>5.2.6. Основной шаблон класса <code>std::atomic&lt;&gt;</code></p>
          </title>
          <p>Наличие основного шаблона позволяет создавать атомарные варианты пользовательских типов, в дополнение к стандартным атомарным типам. Однако в качестве параметра шаблона <code>std::atomic&lt;&gt;</code> может выступать только тип, удовлетворяющий определенным условиям. Точнее, чтобы тип <code>UDT</code> мог использоваться в конструкции <code>std::atomic&lt;UDT&gt;</code>, в нем должен присутствовать <emphasis>тривиальный</emphasis> оператор присваивания. Это означает, что в типе не должно быть виртуальных функций или виртуальных базовых классов, а оператор присваивания должен генерироваться компилятором. Более того, в каждом базовом классе и нестатическом члене данных также должен быть тривиальный оператор присваивания. Это позволяет компилятору использовать для присваивания функцию <code>memcpy()</code> или эквивалентную ей, поскольку исполнять написанный пользователем код не требуется.</p>
          <p>Наконец, тип должен допускать <emphasis>побитовое сравнение на равенство</emphasis>. Это требование из того же разряда, что требования к присваиванию — должна быть не только возможность колировать объекты с помощью <code>memcpy()</code>, но и сравнивать их с помощью <code>memcmp()</code>. Это необходимо для правильной работы операции сравнить-и-обменять.</p>
          <p>Чтобы понять, чем вызваны такие ограничения, вспомните рекомендацию из главы 3: не передавать ссылки и указатели на защищенные данные за пределы области видимости в виде аргументов предоставленной пользователем функции. В общем случае компилятор не в состоянии сгенерировать свободный от блокировок код для типа s<code>td::atomic&lt;UDT&gt;</code>, поэтому он вынужден применять внутренние блокировки. Если бы пользовательские операторы присваивания и сравнения были разрешены, то пришлось бы передавать ссылку на защищенные данные в пользовательскую функцию, нарушая тем самым приведённую выше рекомендацию. Кроме того, библиотека вправе использовать единую блокировку для всех нуждающихся в ней атомарных операций, поэтому, разрешив вызывать пользовательские функции в момент, когда эта блокировка удерживается, мы могли бы получить взаимоблокировку или надолго задержать другие потоки, если сравнение занимает много времени. Наконец, эти ограничения повышают шансы на то, что компилятор сумеет сгенерировать для <code>std::atomic&lt;UDT&gt;</code> код, содержащий истинно атомарные команды (и тем самым обойтись в данной конкретизации вообще без блокировок), поскольку в этой ситуации он вправе рассматривать определенный пользователем тип как неструктурированную последовательность байтов.</p>
          <p>Отметим, что несмотря на то, что типы <code>std::atomic&lt;float&gt;</code> и <code>std::atomic&lt;double&gt;</code> формально разрешены, так как встроенные типы с плавающей точкой удовлетворяют сформулированным выше критериям на использование <code>memcpy</code> и <code>memcmp</code>, их поведение в части функции <code>compare_exchange_strong</code> может оказаться неожиданным. Операция может завершиться отказом, даже если ранее сохраненное значение численно равно ожидаемому, но имеет другое внутреннее представление. Отметим также, что над числами с плавающей точкой не определены атомарные арифметические операции. Аналогичное поведение <code>compare_exchange_strong</code> вы получите, если конкретизируете <code>std::atomic&lt;&gt;</code> пользовательским типом, в котором оператор сравнения на равенство определён, но отличается от сравнения с помощью <code>memcmp</code> — операция может завершиться отказом, потому что равные значения имеют различное представление.</p>
          <p>Если размер пользовательского типа <code>UDT</code> равен (или меньше) размеру <code>int</code> или <code>void*</code>, то на большинстве платформ для типа <code>std::atomic&lt;UDT&gt;</code> можно сгенерировать код, содержащий только атомарные команды. На некоторых платформах подобный код можно сгенерировать и в случае, когда размер пользовательского типа в два раза превышает размер <code>int</code> или <code>void*</code>. Обычно это платформы, на которых имеется команда сравнения и обмена двойных слов <emphasis>double-word-compare-and-swap (DWCAS)</emphasis>, соответствующая функциям <code>compare_exchange_xxx</code>.</p>
          <p>В главе 7 мы увидим, что такая поддержка может быть полезна для написания кода без блокировок. В силу описанных ограничений вы не можете создать, к примеру, тип <code>std::atomic&lt;std::vector&lt;int&gt;&gt;</code>, но можете использовать для параметризации классы, содержащие счетчики, флаги, указатели и даже массивы простых элементов. Обычно это не проблема; чем сложнее структура данных, тем больше вероятность, что в ней нужно будет определить какие-то другие операции, помимо простейшего присваивания и сравнения. Но в таком случае лучше воспользоваться классом <code>std::mutex</code>, который гарантирует надлежащую защиту данных при выполнении этих операций (см. главу 3).</p>
          <p>Интерфейс шаблона <code>std::atomic&lt;T&gt;</code>, конкретизированного пользовательским типом <code>T</code>, ограничен набором операций, доступных классу <code>std::atomic&lt;bool&gt;</code>: <code>load()</code>, <code>store()</code>, <code>exchange()</code>, <code>compare_exchange_weak()</code>, <code>compare_exchange_strong()</code>, присваивание значения типа <code>T</code> и преобразование в значение типа <code>T</code>.</p>
          <p>В табл. 5.3 перечислены операции, доступные для всех атомарных типов.</p>
          <empty-line/>
          <p><strong>Таблица 5.3.</strong> Операции над атомарными типами</p>
          <table>
            <tr align="left">
              <th align="left" valign="top">Операция</th>
              <th align="left" valign="top">
                <code>atomic_ flag</code>
              </th>
              <th align="left" valign="top">
                <code>atomic &lt;bool&gt;</code>
              </th>
              <th align="left" valign="top">
                <code>atomic &lt;T*&gt;</code>
              </th>
              <th align="center" valign="top">
                <code>atomic &lt;integral- type&gt;</code>
              </th>
              <th align="left" valign="top">
                <code>atomic &lt;other-type&gt;</code>
              </th>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>test_and_set</code>
              </td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>clear</code>
              </td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>is_lock_free</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>load</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>store</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>exchange</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>compare_exchange_weak, compare_exchange_strong</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>fetch_add, +=</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top"/>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>fetch_sub, -=</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top"/>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>fetch_or, |=</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top"/>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>fetch_and, &amp;=</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top"/>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>fetch_xor, ^=</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top"/>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>++, --</code>
              </td>
              <td align="left" valign="top"/>
              <td align="left" valign="top"/>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top">&#8730;</td>
              <td align="left" valign="top"/>
            </tr>
          </table>
        </section>
        <section>
          <title>
            <p>5.2.7. Свободные функции для атомарных операций</p>
          </title>
          <p>До сих пор я описывал только те операции над атомарными типами, которые реализованы функциями-членами. Однако для всех этих операций существуют также эквивалентные функции, не являющиеся членами классов. Как правило, имена свободных функций строятся по единому образцу: имя соответствующей функции-члена с префиксом <code>atomic_</code> (например, <code>std::atomic_load()</code>). Затем эти функции перегружаются для каждого атомарного типа. Если имеется возможность задать признак упорядочения доступа к памяти, то предлагаются две разновидности функции: одна без признака, другая — ее имя заканчивается суффиксом <code>_explicit</code> — с одним или несколькими дополнительными параметрами для задания признаков (например, <code>std::atomic_store(&amp;atomic_var, new_value)</code> и <code>std::atomic_store_explicit(&amp;atomic_var, new_value, std::memory_order_release)</code>. Если в случае функций-членов объект атомарного типа задается неявно, то все свободные функции принимают в первом параметре указатель на такой объект.</p>
          <p>Например, для функции <code>std::atomic_is_lock_free()</code> есть только одна разновидность (хотя и перегруженная для всех типов), причём <code>std::atomic_is_lock_free(&amp;a)</code> возвращает то же значение, что <code>a.is_lock_free()</code> для объекта <code>а</code> атомарного типа. Аналогично <code>std::atomic_load(&amp;a)</code> — то же самое, что <code>a.load()</code>, а эквивалентом <code>a.load(std::memory_order_acquire)</code> является <code>std::atomic_load_explicit(&amp;a, std::memory_order_acquire)</code>.</p>
          <p>Свободные функции совместимы с языком С, то есть во всех случаях принимают указатели, а не ссылки. Например, первый параметр функций-членов <code>compare_exchange_weak()</code> и <code>compare_exchange_strong()</code> (ожидаемое значение) — ссылка, но вторым параметром <code>std::atomic_compare_exchange_weak()</code> (первый — это указатель на объект) является указатель. Функция <code>std::atomic_compare_exchange_weak_explicit()</code> также требует задания двух параметров, определяющих упорядочение доступа к памяти в случае успеха и отказа, тогда как функции-члены для сравнения с обменом имеют варианты как с одним параметром (второй по умолчанию равен <code>std::memory_order_seq_cst</code>), так и с двумя.</p>
          <p>Операции над типом <code>std::atomic_flag</code> нарушают традицию, поскольку в именах функций присутствует дополнительное слово «flag»: <code>std::atomic_flag_test_and_set()</code>, <code>std::atomic_flag_clear()</code>, но у вариантов с параметрами, задающими упорядочение доступа, суффикс <code>_explicit</code> по-прежнему имеется: <code>std::atomic_flag_test_and_set_explicit()</code> и <code>std::atomic_flag_clear_explicit()</code>.</p>
          <p>В стандартной библиотеке С++ имеются также свободные функции для атомарного доступа к экземплярам типа <code>std::shared_ptr&lt;&gt;</code>. Это отход от принципа, согласно которому атомарные операции поддерживаются только для атомарных типов, поскольку тип <code>std::shared_ptr&lt;&gt;</code> заведомо <emphasis>не</emphasis> атомарный. Однако комитет по стандартизации С++ счел этот случай достаточно важным, чтобы предоставить дополнительные функции. К числу определенных для него атомарных операций относятся <emphasis>загрузка</emphasis>, <emphasis>сохранение</emphasis>, <emphasis>обмен</emphasis> и <emphasis>сравнение с обменом</emphasis>, и реализованы они в виде перегрузок тех же операций над стандартными атомарными типами, в которых первым аргументом является указатель <code>std::shared_ptr&lt;&gt;*</code>:</p>
          <p>
            <code>std::shared_ptr&lt;my_data&gt; p;</code>
          </p>
          <empty-line/>
          <p>
            <code>void process_global_data() {</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;my_data&gt; local = std::atomic_load(&amp;p);</code>
          </p>
          <p>
            <code> process_data(local);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void update_global_data() {</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;my_data&gt; local(new my_data);</code>
          </p>
          <p>
            <code> std::atomic_store(&amp;p, local);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Как и для атомарных операций над другими типами, предоставляются <code>_explicit</code>-варианты, позволяющие задать необходимое упорядочение, а для проверки того, используется ли в реализации внутренняя блокировка, имеется функция <code>std::atomic_is_lock_free()</code>.</p>
          <p>Как отмечалось во введении, стандартные атомарные типы позволяют не только избежать неопределённого поведения, связанного с гонкой за данные; они еще дают возможность задать порядок операций в потоках. Принудительное упорядочение лежит в основе таких средств защиты данных и синхронизации операций, как <code>std::mutex</code> и <code>std::future&lt;&gt;</code>. Помня об этом, перейдём к материалу, составляющему главное содержание этой главы: аспектам модели памяти, относящимся к параллелизму, и тому, как с помощью атомарных операций можно синхронизировать данные и навязать порядок доступа к памяти.</p>
        </section>
      </section>
      <section>
        <title>
          <p>5.3. Синхронизация операций и принудительное упорядочение</p>
        </title>
        <section>
          <p>Пусть имеются два потока, один из которых заполняет структуру данных, а другой читает ее. Чтобы избежать проблематичного состояния гонки, первый поток устанавливает флаг, означающий, что данные готовы, а второй не приступает к чтению данных, пока этот флаг не установлен. Описанный сценарий демонстрируется в листинге ниже.</p>
          <empty-line/>
          <p><strong>Листинг 5.2.</strong> Запись и чтение переменной в разных потоках</p>
          <p>
            <code>#include &lt;vector&gt;</code>
          </p>
          <p>
            <code>#include &lt;atomic&gt;</code>
          </p>
          <p>
            <code>#include &lt;iostream&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::vector&lt;int&gt; data;</code>
          </p>
          <p>
            <code>std::atomic&lt;bool&gt; data_ready(false);</code>
          </p>
          <empty-line/>
          <p>
            <code>void reader_thread() {</code>
          </p>
          <p>
            <code> while (!data_ready.load()) {            &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  std::this_thread::sleep(std::milliseconds(1));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> std::cout &lt;&lt; "Ответ=" &lt;&lt; data[0] &lt;&lt; "\n";&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void writer_thread() {</code>
          </p>
          <p>
            <code> data.push_back(42); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> data_ready = true;  &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Оставим пока в стороне вопрос о неэффективности цикла ожидания готовности данных <strong>(1)</strong>. Для работы этой программы он действительно необходим, потому что в противном случае разделение данных между потоками становится практически бесполезным: каждый элемент данных должен быть атомарным. Вы уже знаете, что неатомарные операции чтения <strong>(2)</strong> и записи <strong>(3)</strong> одних и тех же данных без принудительного упорядочения приводят к неопределённому поведению, поэтому где-то упорядочение должно производиться, иначе ничего работать не будет.</p>
          <p>Требуемое упорядочение обеспечивают операции с переменной <code>data_ready</code> типа <code>std::atomic&lt;bool&gt;</code> и делается это благодаря отношениям <emphasis>происходит-раньше</emphasis> и <emphasis>синхронизируется-с</emphasis>, заложенным в модель памяти. Запись данных <strong>(3)</strong> происходит-раньше записи флага <code>data_ready</code> <strong>(4)</strong>, а чтение флага <strong>(1)</strong> происходит-раньше чтения данных <strong>(2)</strong>. Когда прочитанное значение <code>data_ready</code> <strong>(1)</strong> равно <code>true</code>, операция записи синхронизируется-с этой операцией чтения, что приводит к порождению отношения происходит-раньше. Поскольку отношение происходит-раньше транзитивно, то запись данных <strong>(3)</strong> происходит-раньше записи флага <strong>(4)</strong>, которая происходит-раньше чтения значения <code>true</code> из этого флага <strong>(1)</strong>, которое в свою очередь происходит-раньше чтения данных <strong>(2)</strong>. И таким образом мы получаем принудительное упорядочение: запись данных происходит-раньше чтения данных, и программа работает правильно. На рис. 5.2 изображены важные отношения происходит-раньше в обоих потоках. Я включил две итерации цикла <code>while</code> в потоке-читателе.</p>
          <image l:href="#img_10_novyjjrazmer.png"/>
          <p><strong>Рис. 5.2.</strong> Принудительное задание упорядочения неатомарных операций с помощью атомарных</p>
          <p>Все это может показаться интуитивно очевидным — разумеется, операция записи значения происходит раньше операции его чтения! В случае атомарных операций по умолчанию это действительно так (на то и умолчания), однако подчеркну: у атомарных операций есть и другие возможности для задания требований к упорядочению, и скоро я о них расскажу.</p>
          <p>Теперь, когда вы видели, как отношения происходит-раньше и синхронизируется-с работают на практике, имеет смысл поговорить о том, что же за ними стоит. Начнем с отношения синхронизируется-с.</p>
        </section>
        <section>
          <title>
            <p>5.3.1. Отношение синхронизируется-с</p>
          </title>
          <p>Отношение синхронизируется-с возможно только между операциями над атомарными типами. Операции над структурой данных (например, захват мьютекса) могут обеспечить это отношение, если в структуре имеются атомарные типы и определенные в ней операции выполняют необходимые атомарные операции. Однако реальным источником синхронизации всегда являются операции над атомарными типами.</p>
          <p>Идея такова: подходящим образом помеченная атомарная операция записи <code>W</code> над переменной <code>x</code> синхронизируется-с подходящим образом помеченной атомарной операцией чтения над переменной <code>x</code>, которая читает значение, сохраненное либо данной операцией записи (<code>W</code>), либо следующей за ней атомарной операцией записи над <code>x</code> в том же потоке, который выполнил первоначальную операцию <code>W,</code> либо последовательностью атомарных операций чтения-модификации-записи над <code>x</code> (например, <code>fetch_add()</code> или <code>compare_exchange_weak()</code>) в любом потоке, при условии, что значение, прочитанное первым потоком в этой последовательности, является значением, записанным операцией <code>W</code> (см. раздел 5.3.4).</p>
          <p>Пока оставим в стороне слова «подходящим образом помеченная», потому что по умолчанию все операции над атомарными типами помечены подходящим образом. По существу сказанное выше означает ровно то, что вы ожидаете: если поток А сохраняет значение, а поток В читает это значение, то существует отношение синхронизируется-с между сохранением в потоке А и загрузкой в потоке В — как в листинге 5.2.</p>
          <p>Уверен, вы догадались, что нюансы как раз и скрываются за словами «подходящим образом помеченная». Модель памяти в С++ допускает применение различных ограничений на упорядочение к операциям над атомарными типами, и именно это и называется пометкой. Варианты упорядочения доступа к памяти и их связь с отношением синхронизируется-с рассматриваются в разделе 5.3.3. А пока отступим на один шаг и поговорим об отношении происходит-раньше.</p>
        </section>
        <section>
          <title>
            <p>5.3.2. Отношение происходит-раньше</p>
          </title>
          <p>Отношение происходит-раньше — основной строительный блок механизма упорядочения операций в программе. Оно определяет, какие операции видят последствия других операций и каких именно. В однопоточной программе всё просто: если в последовательности выполняемых операций одна стоит раньше другой, то она и происходит-раньше. Иначе говоря, если операция А в исходном коде предшествует операции В, то А происходит-раньше В. Это мы видели в листинге 5.2: запись в переменную <code>data</code> <strong>(3)</strong> происходит-раньше записи в переменную <code>data_ready</code> <strong>(4)</strong>. В общем случае между операциями, которые входят в состав одного предложения языка, нет отношения происходит-раньше, поскольку они не упорядочены. По-другому то же самое можно выразить, сказав, что порядок не определён. Мы знаем, что программа, приведённая в следующем листинге, напечатает "<code>1,2</code>" или "<code>2,1</code>", но что именно, неизвестно, потому что порядок двух обращений к <code>get_num()</code> не определён.</p>
          <empty-line/>
          <p><strong>Листинг 5.3.</strong> Порядок определения аргументов функции не определён</p>
          <p>
            <code>#include &lt;iostream&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>void foo(int a, int b) {</code>
          </p>
          <p>
            <code> std::cout &lt;&lt; a &lt;&lt; "," &lt;&lt; b &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int get_num() {</code>
          </p>
          <p>
            <code> static int i = 0;</code>
          </p>
          <p>
            <code> return ++i;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> foo(get_num(), get_num());&#8592;&#9488;</code>
            <strong>Порядок обращений</strong>
          </p>
          <p>
            <code>}                           &#9474;</code>
            <strong>к get_num() не определен</strong>
          </p>
          <p>Существуют случаи, когда порядок операций внутри одного предложения точно известен, например, если используется встроенный оператор «занятая» или результат одного выражения является аргументом другого выражения. Но в общем случае никакого отношения расположено-перед (а, значит, и отношения происходит-раньше) между ними не существует. Разумеется, все операции в одном предложении происходят раньше всех операций в следующем за ним предложении.</p>
          <p>Но это просто пересказ другими словами давно известных вам правил упорядочения в однопоточной программе. А где же новое? Новым является взаимодействие между потоками: если операция А в одном потоке межпоточно происходит-раньше операции В в другом потоке, то А происходит-раньше В. Вроде бы толку немного, мы просто добавили новое отношение (межпоточно происходит-раньше), но при написании многопоточной программы это отношение оказывается очень важным.</p>
          <p>На понятийном уровне отношение межпоточно происходит-раньше довольно простое, оно опирается на отношение синхронизируется-с, введенное в разделе 5.3.1: если операция А в одном потоке синхронизируется-с операцией В в другом потоке, то А межпоточно происходит-раньше В. Это отношение также транзитивно: если А межпоточно происходит-раньше В, а В межпоточно происходит-раньше С, то А межпоточно происходит-раньше С. Это мы тоже видели в листинге 5.2.</p>
          <p>Отношение межпоточно происходит-раньше также комбинируется с отношением расположено-перед: если операция А расположена перед операцией В и операция В межпоточно происходит-раньше операции С, то А межпоточно происходит-раньше С. Аналогично, если А синхронизируется-с В и В расположена-перед С, то А межпоточно происходит-раньше С. В совокупности эти два утверждения означают, что если произведена серия изменений данных в одном потоке, то нужно только одно отношение синхронизируется-с, чтобы данные стали видимы последующим операциям в потоке, где выполнена С.</p>
          <p>Именно эти критически важные правила и обеспечивают упорядоченность операций между потоками, благодаря чему программа в листинге 5.2 работает правильно. Как мы скоро увидим, существуют дополнительные нюансы, связанные с зависимостями между данными. Чтобы разобраться в них, мне нужно будет рассмотреть признаки упорядочения доступа к памяти, используемые в атомарных операциях, и рассказать, как они связаны с отношением синхронизируется-с.</p>
        </section>
        <section>
          <title>
            <p>5.3.3. Упорядочение доступа к памяти для атомарных операций</p>
          </title>
          <p>Существует шесть вариантов упорядочения доступа к памяти, которые можно задавать в операциях над атомарными типами: <code>memory_order_relaxed</code>, <code>memory_order_consume</code>, <code>memory_order_acquire</code>, <code>memory_order_release</code>, <code>memory_order_acq_rel</code> и <code>memory_order_seq_cst</code>. Если не указано противное, то для любой операции над атомарными типами подразумевается упорядочение <code>memory_order_seq_cst</code> — самое ограничительное из всех. Хотя вариантов шесть, представляют они всего три модели: <emphasis>последовательно согласованное</emphasis> упорядочение (<code>memory_order_seq_cst</code>), упорядочение <emphasis>захват-освобождение</emphasis> (<code>memory_order_consume</code>, <code>memory_order_acquire</code>, <code>memory_order_release</code> и <code>memory_order_acq_rel</code>) и <emphasis>ослабленное</emphasis> упорядочение (<code>memory_order_relaxed</code>).</p>
          <p>Эти три модели упорядочения доступа к памяти влекут за собой различные издержки для процессоров с разной архитектурой. Например, в системах с точным контролем над видимостью операций процессорами, отличными от произведшего изменения, могут потребоваться дополнительные команды синхронизации для обеспечения последовательно согласованного упорядочения по сравнению с ослабленным или упорядочением захват-освобождение, а также для обеспечения упорядочения захват-освобождение по сравнению с ослабленным. Если в такой системе много процессоров, то на выполнение дополнительных команд синхронизации может уходить заметное время, что приведет к снижению общей производительности системы. С другой стороны, процессоры с архитектурой x86 или x86-64 (в частности, Intel и AMD, столь распространенные в настольных ПК) не требуют никаких дополнительных команд для обеспечения упорядочения захват-освобождение, помимо необходимых для гарантий атомарности, и даже последовательно согласованное упорядочение не нуждается в каких-то специальных действиях на операциях загрузки, хотя операции сохранения все же требуют некоторых добавочных затрат.</p>
          <p>Наличие различных моделей упорядочения доступа к памяти позволяет эксперту добиться повышения производительности за счет более точного управления отношениями упорядочения там, где это имеет смысл, и в то же время использовать последовательно согласованное упорядочение (которое гораздо проще для понимания) в случаях, когда такой выигрыш не критичен.</p>
          <p>Чтобы выбрать подходящую модель, нужно понимать, каковы последствия того или иного решения для поведения программы. Поэтому рассмотрим, какое влияние оказывают различные модели на упорядочение операций и отношение синхронизируется-с.</p>
          <subtitle>Последовательно согласованное упорядочение</subtitle>
          <p>Упорядочение по умолчанию называется <emphasis>последовательно согласованным</emphasis>, потому что оно предполагает, что поведение программы согласовано с простым последовательным взглядом на мир. Если все операции над экземплярами атомарных типов последовательно согласованы, то поведение многопоточной программы такое же, как если бы эти операции выполнялись в какой-то определенной последовательности в одном потоке. Это самое простое для понимания упорядочение доступа к памяти, потому оно и подразумевается по умолчанию: все потоки должны видеть один и тот же порядок операций. Таким образом, становится достаточно легко рассуждать о поведении программы, написанной с использованием атомарных переменных. Можно выписать все возможные последовательности операций, выполняемых разными потоками, отбросить несогласованные и проверить, что в остальных случаях программа ведет себя, как и ожидалось. Это также означает, что порядок операций нельзя изменять; если в каком-то потоке одна операция предшествует другой, то этот порядок должен быть виден всем остальным потокам.</p>
          <p>С точки зрения синхронизации, последовательно согласованное сохранение синхронизируется-с последовательно согласованной операцией загрузки той же переменной, в которой читается сохраненное значение. Тем самым мы получаем одно ограничение на упорядочение операций в двух или более потоках. Однако этим последовательная согласованность не исчерпывается. Любая последовательно согласованная операция, выполненная после этой загрузки, должна быть видна всякому другому потоку в системе с последовательно согласованными атомарными операциями именно как следующая за загрузкой. Пример в листинге 5.4 демонстрирует это ограничение на упорядочение в действии. Однако это ограничение не распространяется на потоки, в которых для атомарных операций задано ослабленное упорядочение — они по-прежнему могут видеть операции в другом порядке. Поэтому, чтобы получить пользу от последовательного согласования операций, его надо использовать во всех потоках.</p>
          <p>Но за простоту понимания приходится платить. На машине со слабым упорядочением и большим количеством процессоров может наблюдаться заметное снижение производительности, потому что для поддержания согласованной последовательности операций, возможно, придётся часто выполнять дорогостоящие операции синхронизации процессоров. Вместе с тем следует отметить, что некоторые архитектуры процессоров (в частности, такие распространенные, как x86 и x86-64) обеспечивают последовательную согласованность с относительно низкими издержками, так что если вас волнует влияние последовательно согласованного упорядочения на производительность, ознакомьтесь с документацией но конкретному процессору.</p>
          <p>В следующем листинге последовательная согласованность демонстрируется на примере. Операции загрузки и сохранения переменных <code>x</code> и <code>y</code> явно помечены признаком <code>memory_order_seq_cst</code>, хотя его можно было бы и опустить, так как он подразумевается по умолчанию.</p>
          <empty-line/>
          <p><strong>Листинг 5.4.</strong> Из последовательной согласованности вытекает полная упорядоченность</p>
          <p>
            <code>#include &lt;atomic&gt;</code>
          </p>
          <p>
            <code>#include &lt;thread&gt;</code>
          </p>
          <p>
            <code>#include &lt;assert.h&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::atomic&lt;bool&gt; x, y;</code>
          </p>
          <p>
            <code>std::atomic&lt;int&gt; z;</code>
          </p>
          <empty-line/>
          <p>
            <code>void write_x() {</code>
          </p>
          <p>
            <code> x.store(true, std::memory_order_seq_cst); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void write_y() {</code>
          </p>
          <p>
            <code> y.store(true, std::memory_order_seq_cst); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void read_x_then_y() {</code>
          </p>
          <p>
            <code> while (!x.load(std::memory_order_seq_cst));&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> if (y.load(std::memory_order_seq_cst))</code>
          </p>
          <p>
            <code>  ++z;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void read_y_then_x() {</code>
          </p>
          <p>
            <code> while (!y.load(std::memory_order_seq_cst));&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> if (x.load(std::memory_order_seq_cst))</code>
          </p>
          <p>
            <code>  ++z;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> x = false;</code>
          </p>
          <p>
            <code> y = false;</code>
          </p>
          <p>
            <code> z = 0;</code>
          </p>
          <p>
            <code> std::thread a(write_x);</code>
          </p>
          <p>
            <code> std::thread b(write_y);</code>
          </p>
          <p>
            <code> std::thread с(read_x_then_y);</code>
          </p>
          <p>
            <code> std::thread d(read_y_then_x);</code>
          </p>
          <p>
            <code> a.join();</code>
          </p>
          <p>
            <code> b.join();</code>
          </p>
          <p>
            <code> c.join();</code>
          </p>
          <p>
            <code> d.join();</code>
          </p>
          <p>
            <code> assert(z.load() != 0); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Утверждение <code>assert</code> <strong>(5)</strong> не может сработать, потому что первым должно произойти сохранение <code>x</code> <strong>(1)</strong> или сохранение <code>y</code> <strong>(2)</strong>, пусть даже точно не сказано, какое именно. Если загрузка <code>y</code> в функции <code>read_x_then_y</code> <strong>(3)</strong> возвращает <code>false</code>, то сохранение <code>x</code> должно было произойти раньше сохранения <code>y</code>, и в таком случае загрузка <code>x</code> в <code>read_y_then_x</code> <strong>(4)</strong> должна вернуть <code>true</code>, потому что наличие цикла <code>while</code> гарантирует, что в этой точке <code>у</code> равно <code>true</code>. Поскольку семантика <code>memory_order_seq_cst</code> требует полного упорядочения всех операций, помеченных признаком <code>memory_order_seq_cst</code>, то существует подразумеваемое отношение порядка между операцией загрузки <code>y</code>, которая возвращает <code>false</code> <strong>(3)</strong>, и операцией сохранения <code>y</code> <strong>(1)</strong>. Чтобы имело место единственное полное упорядочение в случае, когда некоторый поток сначала видит <code>x==true</code>, затем <code>y==false</code>, необходимо, чтобы при таком упорядочении сохранение <code>x</code> происходило раньше сохранения <code>y</code>.</p>
          <p>Разумеется, поскольку всё симметрично, могло бы произойти и ровно наоборот: загрузка <code>x</code> <strong>(4)</strong> возвращает <code>false</code>, и тогда загрузка <code>y</code> <strong>(3)</strong> обязана вернуть <code>true</code>. В обоих случаях <code>z</code> равно 1. Может быть и так, что обе операции вернут <code>true</code>, и тогда <code>z</code> будет равно 2. Но ни в каком случае <code>z</code> не может оказаться равным нулю.</p>
          <p>Операции и отношения происходит-раньше для случая, когда <code>read_x_then_y</code> видит, что <code>x</code> равно <code>true</code>, а <code>y</code> равно <code>false</code>, изображены на рис. 5.3. Пунктирная линия от операции загрузки <code>y</code> в <code>read_x_then_y</code> к операции сохранения <code>y</code> в <code>write_y</code> показывает наличие неявного отношения порядка, необходимого для поддержания последовательной согласованности: загрузка должна произойти раньше сохранения в глобальном порядке операций, помеченных признаком <code>memory_order_seq_cst</code>, — только тогда получится показанный на рисунке результат.</p>
          <image l:href="#img_11_novyjjrazmer.png"/>
          <p><strong>Рис. 5.3.</strong> Последовательная согласованность и отношения происходит-раньше</p>
          <p>Последовательная согласованность — самое простое и интуитивно понятное упорядочение, но оно же является и самым накладным из- за необходимости глобальной синхронизации между всеми потоками. В многопроцессорной системе это потребовало бы многочисленных и затратных по времени взаимодействий между процессорами. Чтобы избежать затрат на синхронизацию, необходимо выйти за пределы мира последовательной согласованности и рассмотреть другие модели упорядочения доступа к памяти.</p>
          <subtitle>Не последовательно согласованное упорядочение доступа к памяти</subtitle>
          <p>За пределами уютного последовательно согласованного мирка нас встречает более сложная реальность. И, пожалуй, самое трудное — смириться с тем фактом, что <emphasis>единого глобального порядка событий больше не существует</emphasis>. Это означает, что разные потоки могут по-разному видеть одни и те же операции, и с любой умозрительной моделью, предполагающей, что операции, выполняемые в разных потоках, строго перемежаются, следует распрощаться. Вы должны учитывать не только то, что события могут происходить по-настоящему одновременно, но и то, что <emphasis>потоки не обязаны согласовывать порядок событий между собой</emphasis>. Чтобы написать (или хотя бы понять) код, в котором используется упорядочение, отличное от <code>memory_order_seq_cst</code>, абсолютно необходимо уложить этот факт в мозгу. Мало того что компилятор вправе изменять порядок команд. Даже если потоки исполняют один и тот же код, они могут видеть события в разном порядке, потому что в отсутствие явных ограничений на упорядочение кэши различных процессоров и внутренние буферы могут содержать различные значения для одной и той же ячейки памяти. Это настолько важно, что я еще раз повторю: потоки <emphasis>не обязаны согласовывать порядок событий между собой</emphasis>.</p>
          <p>Вы должны отбросить мысленные модели, основанные не только на идее чередования операций, но и на представлении о том, что компилятор или процессор изменяет порядок команд. <emphasis>В отсутствие иных ограничений на упорядочение, единственное требование заключается в том, что все потоки согласны относительно порядка модификации каждой отдельной переменной.</emphasis> Операции над различными переменными могут быть видны разным потокам в разном порядке при условии, что видимые значения согласуются с наложенными дополнительными ограничениями на упорядочение.</p>
          <p>Проще всего это продемонстрировать, перейдя от последовательной согласованности к ее полной противоположности — упорядочению <code>memory_order_relaxed</code> для всех операций. Освоив этот случай, мы сможем вернуться к упорядочению захват-освобождение, которое позволяет избирательно вводить некоторые отношения порядка между операциями. Это хоть как-то поможет собрать разлетевшиеся мозги в кучку.</p>
          <subtitle>Ослабленное упорядочение</subtitle>
          <p>Операции над атомарными типами, выполняемые в режиме ослабленного упорядочения, не участвуют в отношениях синхронизируется-с. Операции над одной и той же переменной в одном потоке по-прежнему связаны отношением происходит-раньше, но на относительный порядок операций в разных потоках не накладывается почти никаких ограничений. Есть лишь одно требование: операции доступа к одной атомарной переменной в одном и том же потоке нельзя переупорядочивать — если данный поток видел определенное значение атомарной переменной, то последующая операция чтения не может извлечь предыдущее значение этой переменной. В отсутствие дополнительной синхронизации порядок модификации отдельных переменных — это единственное, что объединяет потоки, использующие модель <code>memory_order_relaxed</code>.</p>
          <p>Чтобы продемонстрировать, до какой степени могут быть «ослаблены» операции в этой модели, достаточно всего двух потоков (см. листинг 5.5).</p>
          <empty-line/>
          <p><strong>Листинг 5.5.</strong> К ослабленным операциям предъявляются очень слабые требования</p>
          <p>
            <code>#include &lt;atomic&gt;</code>
          </p>
          <p>
            <code>#include &lt;thread&gt;</code>
          </p>
          <p>
            <code>#include &lt;assert.h&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::atomic&lt;bool&gt; x,y;</code>
          </p>
          <p>
            <code>std::atomic&lt;int&gt; z;</code>
          </p>
          <empty-line/>
          <p>
            <code>void write_x_then_y() {</code>
          </p>
          <p>
            <code> x.store(true, std::memory_order_relaxed); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> y.store(true, std::memory_order_relaxed); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void read_y_then_x() {</code>
          </p>
          <p>
            <code> while (!y.load(std::memory_order_relaxed));&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> if (x.load(std::memory_order_relaxed))     &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  ++z;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> x = false;</code>
          </p>
          <p>
            <code> y = false;</code>
          </p>
          <p>
            <code> z = 0;</code>
          </p>
          <p>
            <code> std::thread а(write_x_then_y);</code>
          </p>
          <p>
            <code> std::thread b(read_y_then_x);</code>
          </p>
          <p>
            <code> a.join();</code>
          </p>
          <p>
            <code> b.join();</code>
          </p>
          <p>
            <code> assert (z.load() != 0); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>На этот раз утверждение <strong>(5)</strong> <emphasis>может</emphasis> сработать, потому что операция загрузки <code>x</code> <strong>(4)</strong> может прочитать <code>false</code>, даже если загрузка <code>y</code> <strong>(3)</strong> прочитает <code>true</code>, а сохранение <code>x</code> <strong>(1)</strong> происходит-раньше сохранения <code>y</code> <strong>(2)</strong>. <code>x</code> и <code>y</code> — разные переменные, поэтому нет никаких гарантий относительно порядка видимости результатов операций над каждой из них.</p>
          <p>Ослабленные операции над разными переменными можно как угодно переупорядочивать при условии, что они подчиняются ограничивающим отношениям происходит-раньше (например, действующим внутри одного потока). Никаких отношений синхронизируется-с не возникает. Отношения происходит-раньше, имеющиеся в листинге 5.5, изображены на рис. 5.4, вместе с возможным результатом. Несмотря на то, что существует отношение происходит-раньше отдельно между операциями сохранения и операциями загрузки, не существует ни одного такого отношения между любым сохранением и любой загрузкой, поэтому операция загрузки может увидеть операции сохранения не в том порядке, в котором они происходили.</p>
          <image l:href="#img_12_novyjjrazmer.png"/>
          <p><strong>Рис. 5.4.</strong> Ослабленные атомарные операции и отношения происходит-раньше</p>
          <p>Рассмотрим чуть более сложный пример с тремя переменными и пятью потоками.</p>
          <empty-line/>
          <p><strong>Листинг 5.6.</strong> Ослабленные операции в нескольких потоках</p>
          <p>
            <code>#include &lt;thread&gt;</code>
          </p>
          <p>
            <code>#include &lt;atomic&gt;</code>
          </p>
          <p>
            <code>#include &lt;iostream&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::atomic&lt;int&gt; x(0), y(0), z(0);&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>std::atomic&lt;bool&gt; go(false);      &#8592;</code>
            <strong>(2)</strong>
          </p>
          <empty-line/>
          <p>
            <code>unsigned const loop_count = 10;</code>
          </p>
          <empty-line/>
          <p>
            <code>struct read_values {</code>
          </p>
          <p>
            <code> int x, y, z;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>read_values values1[loop_count];</code>
          </p>
          <p>
            <code>read_values values2[loop_count];</code>
          </p>
          <p>
            <code>read_values values3[loop_count];</code>
          </p>
          <p>
            <code>read_values values4[loop_count];</code>
          </p>
          <p>
            <code>read_values values5[loop_count];</code>
          </p>
          <empty-line/>
          <p>
            <code>void increment(</code>
          </p>
          <p>
            <code> std::atomic&lt;int&gt;* var_to_inc, read_values* values) {</code>
          </p>
          <p>
            <code> while (!go) &#8592;</code>
            <strong>(3) В цикле ждем сигнала</strong>
          </p>
          <p>
            <code>  std::this_thread::yield();</code>
          </p>
          <p>
            <code> for (unsigned i = 0; i &lt; loop_count; ++i) {</code>
          </p>
          <p>
            <code>  values[i].x = x.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  values[i].y = y.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  values[i].z = z.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  var_to_inc-&gt;store(i + 1, std::memory_order_relaxed);&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  std::this_thread::yield();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void read_vals(read_values* values) {</code>
          </p>
          <p>
            <code> while (!go) &#8592;</code>
            <strong>(5) В цикле ждем сигнала</strong>
          </p>
          <p>
            <code> std::this_thread::yield();</code>
          </p>
          <p>
            <code> for (unsigned i = 0; i &lt; loop_count; ++i) {</code>
          </p>
          <p>
            <code>  values[i].x = x.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  values[i].y = y.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  values[i].z = z.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  std::this_thread::yield();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void print(read_values* v) {</code>
          </p>
          <p>
            <code> for (unsigned i = 0; i &lt; loop_count; ++i) {</code>
          </p>
          <p>
            <code>  if (i)</code>
          </p>
          <p>
            <code>   std::cout &lt;&lt; ",";</code>
          </p>
          <p>
            <code>  std::cout &lt;&lt;</code>
          </p>
          <p>
            <code>   "(" &lt;&lt; v [i] .x &lt;&lt; "," &lt;&lt; v[i].y &lt;&lt; "," &lt;&lt; v[i].z &lt;&lt; ")";</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> std::cout &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> std::thread t1(increment, &amp;x, values1);</code>
          </p>
          <p>
            <code> std::thread t2(increment, &amp;y, values2);</code>
          </p>
          <p>
            <code> std::thread t3(increment, &amp;z, values3);</code>
          </p>
          <p>
            <code> std::thread t4(read_vals, values4);</code>
          </p>
          <p>
            <code> std::thread t5(read_vals, values5);</code>
          </p>
          <empty-line/>
          <p>
            <code> go = true; &#8592;&#9488;</code>
            <strong>Сигнал к началу выполнения</strong>
          </p>
          <p>
            <code>
              <strong>             &#9474;</strong>
            </code>
            <strong>(6) главного цикла</strong>
          </p>
          <empty-line/>
          <p>
            <code> t5.join();</code>
          </p>
          <p>
            <code> t4.join();</code>
          </p>
          <p>
            <code> t3.join();</code>
          </p>
          <p>
            <code> t2.join();</code>
          </p>
          <p>
            <code> t1.join();</code>
          </p>
          <empty-line/>
          <p>
            <code> print(values1);&#8592;&#9488;</code>
          </p>
          <p>
            <code> print(values2); &#9474;</code>
            <strong>Печатаем получившиеся</strong>
          </p>
          <p>
            <code> print(values3);</code>
            <strong>(7) значения</strong>
          </p>
          <p>
            <code> print(values4);</code>
          </p>
          <p>
            <code> print(values5);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>По существу, это очень простая программа. У нас есть три разделяемых глобальных атомарных переменных <strong>(1)</strong> и пять потоков. Каждый поток выполняет 10 итераций цикла, читая значения трех атомарных переменных в режиме <code>memory_order_relaxed</code> и сохраняя их в массиве. Три из пяти потоков обновляют одну из атомарных переменных при каждом проходе по циклу <strong>(4)</strong>, а остальные два только читают ее. После присоединения всех потоков мы распечатываем массивы, заполненные каждым из них <strong>(7)</strong>.</p>
          <p>Атомарная переменная <code>go</code> <strong>(2)</strong> служит для того, чтобы все потоки начали работу по возможности одновременно. Запуск потока — накладная операция и, не будь явной задержки, первый поток мог бы завершиться еще до того, как последний зачал работать. Каждый поток ждет, пока переменная <code>go</code> станет равна <code>true</code>, и только потом входит в главный цикл <strong>(3)</strong>, <strong>(5)</strong>, а переменная <code>go</code> устанавливается в <code>true</code> только после запуска всех потоков <strong>(6)</strong>.</p>
          <p>Ниже показан один из возможных результатов прогона этой прогона:</p>
          <p>
            <code>(0,0,0),(1,0,0),(2,0,0),(3,0,0),(4,0,0),(5,7,0),(6,7,8),(7,9,8),(8,9,8),(9,9,10)</code>
          </p>
          <p>
            <code>(0,0,0),(0,1,0),(0,2,0),(1,3,5),(8,4,5),(8,5,5),(8,6,6),(8,7,9),(10,8,9),(10,9,10)</code>
          </p>
          <p>
            <code>(0,0,0),(0,0,1),(0,0,2),(0,0,3),(0,0,4),(0,0,5),(0,0,6),(0,0,7),(0,0,8),(0,0,9)</code>
          </p>
          <p>
            <code>(1,3,0),(2,3,0),(2,4,1),(3,6,4),(3,9,5),(5,10,6),(5,10,8),(5,10,10),(9,10,10),(10,10,10)</code>
          </p>
          <p>
            <code>(0,0,0),(0,0,0),(0,0,0),(6,3,7),(6,5,7),(7,7,7),(7,8,7),(8,8,7),(8,8,9),(8,8,9)</code>
          </p>
          <p>Первые три строки относятся к потокам, выполнявшим обновление, последние две — к потокам, которые занимались только чтением. Каждая тройка — это значения переменных <code>x</code>, <code>y</code>, <code>z</code> в порядке итераций цикла. Следует отметить несколько моментов.</p>
          <p>• В первом наборе значения <code>x</code> увеличиваются на 1 в каждой тройке, во втором наборе на 1 увеличиваются значения <code>y</code>, а в третьем — значения <code>z</code>.</p>
          <p>• Значения <code>x</code> (а равно <code>y</code> и <code>z</code>) увеличиваются только в пределах данного набора, но приращения неравномерны и относительный порядок в разных наборах различен.</p>
          <p>• Поток 3 не видит обновлений <code>x</code> и <code>y</code>, ему видны только обновления <code>z</code>. Но это не мешает другим потокам видеть обновления <code>z</code> наряду с обновлениями <code>x</code> и <code>y</code>.</p>
          <p>Это всего лишь один из возможных результатов выполнения ослабленных операций. Вообще говоря, возможен любой результат, в котором каждая из трех переменных принимает значения от 0 до 10, и в каждом потоке, обновляющем некоторую переменную, ее значения монотонно изменяются от 0 до 9.</p>
          <subtitle>Механизм ослабленного упорядочения</subtitle>
          <p>Чтобы попять, как всё это работает, представьте, что каждая переменная — человек с блокнотом, сидящий в отдельном боксе. В блокноте записана последовательность значений. Вы можете позвонить сидельцу и попросить либо прочитать вслух какое-нибудь значение, либо записать новое. Новое значение он записывает в конец последовательности.</p>
          <p>При первой просьбе дать значение человек может прочитать <emphasis>любое</emphasis> значение из списка, имеющегося в данный момент. В ответ на следующую просьбу он может прочитать либо то же самое значение, либо значение, расположенное позже него в списке, но никогда — значение, расположенное раньше уже прочитанного. Если вы просили записать значение, а потом прочитать, то он может сообщить либо значение, записанное в ответ на вашу просьбу, либо расположенное позже него в списке.</p>
          <p>Теперь представьте, что в начале списка находятся значения 5, 10, 23, 3, 1, 2. Человек может прочитать любое из них. Если он скажет 10, то в следующий раз он может прочитать также 10 или любое последующее число, но не 5. Если вы позвоните пять раз, то может услышать, например, последовательность «10, 10, 1, 2, 2». Если вы попросите записать 42, он добавит это число в конец списка. Если вы затем будете просить прочитать число, то он будет повторять «42», пока в списке не появится новое число и он не захочет назвать его.</p>
          <p>Предположим далее, что у Карла тоже есть телефон этого человека. Карл тоже может позволить ему с просьбой либо прочитать, либо записать число. При этом к Карлу применяются те же правила, что и к вам. Телефон только один, поэтому в каждый момент времени человек общается только с одним из вас, так что список в его блокноте растет строго последовательно. Но из того, что вы попросили записать его новое число, вовсе не следует, что он должен сообщить его Карлу. и наоборот. Если Карл попросил назвать число и услышал в ответ «23», то из того, что вы попросили записать число 42, не вытекает, что в следующий раз Карл услышит его. Человек может назвать Карлу любое из чисел 23, 3, 1, 2, 42 или даже 67, если после вас позвонил Фред и попросил записать это число. Он даже может назвать Карлу последовательность «23, 3, 3, 1, 67», и это не будет противоречить тому, что услышали вы. Можно представить себе, что человек запоминает, какое число кому назвал, сдвигая указатели, на которых написано имя спрашивающего, как показано на рис. 5.5.</p>
          <image l:href="#img_13.png"/>
          <p><strong>Рис. 5.5.</strong> Блокнот человека, сидящего в боксе</p>
          <p>Теперь представьте, что имеется целый ряд боксов, в каждом из которых сидит по человеку с блокнотом и телефоном. Это всё наши атомарные переменные. У каждой переменной свой порядок модификации (список значений в блокноте), по между ними нет никакой связи. Если каждый звонящий (вы, Карл, Анна, Дэйв и Фред) представляет поток, то именно такая картина наблюдается, когда все операции работают в режиме <code>memory_order_relaxed</code>. К человеку, сидящему в боксе, можно обращаться и с другими просьбами, например: «запиши это число и скажи мне, что находится в конце списка» (<code>exchange</code>) или «запиши <emphasis>это</emphasis> число, если число в конце списка равно <emphasis>тому</emphasis>, в противном случае скажи мне, что я должен был бы предположить» (<code>compare_exchange_strong</code>), но общий принцип при этом не изменяется.</p>
          <p>Применив эту метафору к программе в листинге 5.5, можно сказать, что <code>write_x_then_y</code> означает, что некто позвонил человеку в боксе <code>x</code>, попросил его записать <code>true</code>, а потом позвонил человеку в боксе <code>y</code> и попросил <emphasis>его</emphasis> записать <code>true</code>. Поток, выполняющий функцию <code>read_y_then_x</code>, раз за разом звонит человеку в боксе <code>y</code> и спрашивает значение, пока не услышит <code>true</code>, после чего звонит человеку в боксе <code>x</code> и спрашивает значение у него. Человек в боксе <code>x</code> не обязан сообщать вам какое-то конкретное значение из своего списка и с полным правом может назвать <code>false</code>.</p>
          <p>Из-за этого с ослабленными атомарными операциями трудно иметь дело. Чтобы они были полезны для межпоточной синхронизации, их нужно сочетать с атомарными операциями, работающими в режиме с более строгой семантикой упорядочения. Я настоятельно рекомендую вообще избегать ослабленных атомарных операций, если без них можно обойтись, а, если никак нельзя, то использовать крайне осторожно. Учитывая, насколько интуитивно неочевидные результаты получились в листинге 5.5 при наличии всего двух потоков и двух переменных, нетрудно представить себе сложности, с которыми придется столкнуться, когда потоков и переменных станет больше.</p>
          <p>Один из способов организовать дополнительную синхронизацию, не прибегая к последовательной согласованности, — воспользоваться упорядочением захват-освобождение.</p>
          <subtitle>Упорядочение захват-освобождение</subtitle>
          <p>Упорядочение захват-освобождение — шаг от ослабленного упорядочения в сторону большего порядка; полной упорядоченности операций еще нет, но какая-то синхронизация уже возможна. При такой модели атомарные операции загрузки являются операциями <emphasis>захвата</emphasis> (<code>memory_order_acquire</code>), атомарные операции сохранения — операциями <emphasis>освобождения</emphasis> (<code>memory_order_release</code>), а атомарные операции чтения-модификации-записи (например, <code>fetch_add()</code> или <code>exchange()</code>) — операциями <emphasis>захвата</emphasis>, <emphasis>освобождения</emphasis> или того и другого (<code>memory_order_acq_rel</code>). Синхронизация попарная — между потоком, выполнившим захват, и потоком, выполнившим освобождение. <emphasis>Операция освобождения синхронизируется-с операцией захвата, которая читает записанное значение.</emphasis> Это означает, что различные потоки <emphasis>могут</emphasis> видеть операции в разном порядке, но возможны все-таки не любые порядки. В следующем листинге показала программа из листинга 5.4, переработанная под семантику захвата-освобождения вместо семантики последовательной согласованности.</p>
          <empty-line/>
          <p><strong>Листинг 5.7.</strong> Из семантики захвата-освобождения не вытекает полная упорядоченность</p>
          <p>
            <code>#include &lt;atomic&gt;</code>
          </p>
          <p>
            <code>#include &lt;thread&gt;</code>
          </p>
          <p>
            <code>#include &lt;assert.h&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::atomic&lt;bool&gt; x, y;</code>
          </p>
          <p>
            <code>std::atomic&lt;int&gt; z;</code>
          </p>
          <empty-line/>
          <p>
            <code>void write_x() {</code>
          </p>
          <p>
            <code> x.store(true, std::memory_order_release);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void write_y() {</code>
          </p>
          <p>
            <code> y.store(true, std::memory_order_release);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void read_x_then_y() {</code>
          </p>
          <p>
            <code> while (!x.load(std::memory_order_acquire));</code>
          </p>
          <p>
            <code> if (y.load(std::memory_order_acquire)) &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  ++z;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void read_y_then_x() {</code>
          </p>
          <p>
            <code> while (!y.load(std::memory_order_acquire));</code>
          </p>
          <p>
            <code> if (x.load(std::memory_order_acquire)) &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  ++z;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> x = false;</code>
          </p>
          <p>
            <code> y = false;</code>
          </p>
          <p>
            <code> z = 0;</code>
          </p>
          <p>
            <code> std::thread a(write_x);</code>
          </p>
          <p>
            <code> std::thread b(write_y);</code>
          </p>
          <p>
            <code> std::thread с(read_x_then_y);</code>
          </p>
          <p>
            <code> std::thread d(read_y_then_x);</code>
          </p>
          <p>
            <code> a.join();</code>
          </p>
          <p>
            <code> b.join();</code>
          </p>
          <p>
            <code> c.join();</code>
          </p>
          <p>
            <code> d.join();</code>
          </p>
          <p>
            <code> assert(z.load() != 0); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В данном случае утверждение <strong>(3)</strong> <emphasis>может</emphasis> сработать (как и в случае ослабленного упорядочения), потому что обе операции загрузки — <code>x</code> <strong>(2)</strong> и <code>y</code> <strong>(1)</strong> могут прочитать значение <code>false</code>. Запись в переменные <code>x</code> и <code>y</code> производится из разных потоков, но упорядоченность между освобождением и захватом в одном потоке никак не отражается на операциях в других потоках.</p>
          <p>На рис. 5.6 показаны отношения происходит-раньше, имеющие место в программе из листинга 5.7, а также возможный исход, когда два потока-читателя имеют разное представление о мире. Это возможно, потому что, как уже было сказано, не существует отношения происходит-раньше, которое вводило бы упорядочение.</p>
          <image l:href="#img_14_novyjjrazmer.png"/>
          <p><strong>Рис. 5.6.</strong> Захват-освобождение и отношения происходит-раньше</p>
          <p>Чтобы осознать преимущества упорядочения захват-освобождение, нужно рассмотреть две операции сохранения в одном потоке, как в листинге 5.5. Если при сохранении <code>y</code> задать семантику <code>memory_order_release</code>, а при загрузке <code>y</code> — семантику <code>memory_order_acquire</code>, как в листинге ниже, то операции над <code>x</code> станут упорядоченными.</p>
          <empty-line/>
          <p><strong>Листинг 5.8.</strong> Операции с семантикой захвата-освобождения могут упорядочить ослабленные операции</p>
          <p>
            <code>#include &lt;atomic&gt;</code>
          </p>
          <p>
            <code>#include &lt;thread&gt;</code>
          </p>
          <p>
            <code>#include &lt;assert.h&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::atomic&lt;bool&gt; x, y;</code>
          </p>
          <p>
            <code>std::atomic&lt;int&gt; z;</code>
          </p>
          <empty-line/>
          <p>
            <code>void write_x_then_y() {</code>
          </p>
          <p>
            <code> x.store(true,std::memory_order_relaxed);   &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> y.store(true,std::memory_order_release);   &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void read_y_then_x() {</code>
          </p>
          <p>
            <code> while (!y.load(std::memory_order_acquire));&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> if (x.load(std::memory_order_relaxed))     &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  ++z;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> x = false;</code>
          </p>
          <p>
            <code> y = false;</code>
          </p>
          <p>
            <code> z = 0;</code>
          </p>
          <p>
            <code> std::thread a(write_x_then_y);</code>
          </p>
          <p>
            <code> std::thread b(read_y_then_x);</code>
          </p>
          <p>
            <code> a.join();</code>
          </p>
          <p>
            <code> b.join();</code>
          </p>
          <p>
            <code> assert(z.load() != 0); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В конечном итоге операция загрузки <code>y</code> <strong>(3)</strong> увидит значение <code>true</code>, записанное операцией сохранения <strong>(2)</strong>. Поскольку сохранение производится в режиме <code>memory_order_release</code>, а загрузка — в режиме <code>memory_order_acquire</code>, то сохранение синхронизируется-с загрузкой. Сохранение <code>x</code> <strong>(1)</strong> происходит-раньше сохранения <code>y</code> <strong>(2)</strong>, потому что обе операции выполняются в одном потоке. Поскольку сохранение <code>y</code> синхронизируется-с загрузкой <code>y</code>, то сохранение <code>x</code> также происходит-раньше загрузки <code>y</code>, и, следовательно, происходит-раньше загрузки <code>x</code> <strong>(4)</strong>. Таким образом, операция загрузки <code>x</code> <emphasis>должна</emphasis> прочитать <code>true</code>, и, значит, утверждение <strong>(5)</strong> <emphasis>не может</emphasis> сработать. Если бы загрузка <code>y</code> не повторялась в цикле <code>while</code>, то высказанное утверждение могло бы оказаться неверным; операция загрузки <code>y</code> могла бы прочитать <code>false</code>, и тогда не было бы никаких ограничений на значение, прочитанное из <code>x</code>. Для обеспечения синхронизации операции захвата и освобождения должны употребляться парами. Значение, сохраненное операций восстановления, должно быть видно операции захвата, иначе ни та, ни другая не возымеют эффекта. Если бы сохранение в предложении <strong>(2)</strong> или загрузка в предложении <strong>(3)</strong> выполнялись в ослабленной операции, то обращения к <code>x</code> не были бы упорядочены, и, значит, нельзя было бы гарантировать, что операция загрузки в предложении <strong>(4)</strong> прочитает значение <code>true</code>, поэтому утверждение <code>assert</code> могло бы сработать.</p>
          <p>К упорядочению захват-освобождение можно применить метафору человека с блокнотом в боксе, если ее немного дополнить. Во-первых, допустим, что каждое сохранение является частью некоторого пакета обновлений, поэтому, обращаясь к человеку с просьбой записать число, вы заодно сообщается ему идентификатор пакета, например: «Запиши 99 как часть пакета 423». Если речь идет о последнем сохранении в пакете, то мы сообщаем об этом: «Запиши 147, отметив, что это последнее сохранение в пакете 423». Человек в боксе честно записывает эту информацию вместе с указанным вами значением. Так моделируется операция сохранения с освобождением. Когда вы в следующий раз попросите записать значение, помер пакета нужно будет увеличить: «Запиши 41 как часть пакета 424».</p>
          <p>Теперь, когда вы просите сообщить значение, у вас есть выбор: узнать только значение (это аналог ослабленной загрузки) или значение и сведения о том, является ли оно последним в пакете (это аналог загрузки с захватом). Если информация о пакете запрашивается, по значение не последнее в пакете, то человек ответит: «Число равно 987, и это 'обычное' значение»; если же значение последнее, то ответ прозвучит так: «Число 987, последнее в пакете 956 от Анны». Тут-то и проявляется семантика захвата-освобождения: если, запрашивая значение, вы сообщите человеку номера всех пакетов, о которых знаете, то он найдёт в своем списке последнее значение из всех известных вам пакетов и назовёт либо его, либо какое-нибудь следующее за ним в списке.</p>
          <p>Как эта метафора моделирует семантику захвата-освобождения? Взгляните на наш пример — и поймете. В самом начале поток <code>а</code> вызывает функцию <code>write_x_then_y</code> и говорит человеку в боксе <code>x</code>: «Запиши <code>true</code>, как часть пакета 1 от потока <code>а</code>». Затем поток <code>а</code> говорит человеку в боксе <code>y</code>: «Запиши <code>true</code>, как последнюю операцию записи в пакете 1 от потока <code>а</code>». Тем временем поток <code>b</code> выполняет функцию <code>read_y_then_x</code>. Он раз за разом просит человека в боксе <code>y</code> сообщить значение вместе с информацией о пакете, пока не услышит в ответ «<code>true</code>». Возможно, спросить придется много раз, но в конце концов человек обязательно ответит «<code>true</code>». Однако человек в боксе <code>y</code> говорит не просто «<code>true</code>», а еще добавляет: «Это последняя операция записи в пакете 1 от потока <code>а</code>».</p>
          <p>Далее поток <code>b</code> просит человека в боксе <code>x</code> назвать значение, но на это раз говорит: «Сообщи мне значение и, кстати, я знаю о пакете 1 от потока <code>а</code>». Человек в боксе x ищет в своем списке последнее упоминание о пакете 1 от потока <code>а</code>. Он находит единственное значение <code>true</code>, которое стоит последним в списке, поэтому он <emphasis>обязан</emphasis> сообщить именно это значение, иначе нарушит правила игры.</p>
          <p>Вспомнив определение отношения <emphasis>межпоточно происходит раньше</emphasis> в разделе 5.3.2, вы обнаружите, что одно из его существенных свойств — транзитивность: <emphasis>если А межпоточно происходит-раньше В</emphasis> и <emphasis>В межпоточно происходит-раньше С</emphasis>, то <emphasis>А межпоточно происходит-раньше С</emphasis>. Это означает, что упорядочение захват-освобождение можно использовать для синхронизации данных между несколькими потоками, даже если «промежуточные» потоки на самом деле не обращались к данным.</p>
          <subtitle>Транзитивная синхронизация с помощью упорядочения захват-освобождение</subtitle>
          <p>Для рассуждений о транзитивном упорядочении нужны по меньшей мере три потока. Первый модифицирует какие-то разделяемые переменные и выполняет операцию сохранения с освобождением в одну из них. Второй читает переменную, записанную операцией сохранения с освобождением, с помощью операции загрузки с захватом и выполняет сохранение с освобождением во вторую разделяемую переменную. Наконец, третий поток выполняет операцию загрузки с захватом для второй разделяемой переменной. При условии, что операции загрузки с захватом видят значения, записанные операциями сохранения с освобождением, и тем самым поддерживают отношения синхронизируется-с, третий поток может прочитать значения других переменных, сохраненные первым потоком, даже если промежуточный поток к ним не обращался. Этот сценарий иллюстрируется в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 5.9.</strong> Транзитивная синхронизация с помощью упорядочения захват-освобождение</p>
          <p>
            <code>std::atomic&lt;int&gt; data[5];</code>
          </p>
          <p>
            <code>std::atomic&lt;bool&gt; sync1(false), sync2(false);</code>
          </p>
          <empty-line/>
          <p>
            <code>void thread_1() {</code>
          </p>
          <p>
            <code> data[0].store(42, std::memory_order_relaxed);</code>
          </p>
          <p>
            <code> data[1].store(97, std::memory_order_relaxed);</code>
          </p>
          <p>
            <code> data[2].store(17, std::memory_order_relaxed);</code>
          </p>
          <p>
            <code> data[3].store(-141, std::memory_order_relaxed);</code>
          </p>
          <p>
            <code> data[4].store(2003, std::memory_order_relaxed);&#8592;&#9488;</code>
            <strong>Установить</strong>
          </p>
          <p>
            <code> sync1.store(true, std::memory_order_release);  </code>
            <strong>(1)sync1</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void thread_2()                                 </code>
            <strong>(2)Цикл до</strong>
          </p>
          <p>
            <code>{                                                &#9474;</code>
            <strong>установки</strong>
          </p>
          <p>
            <code> while (!sync1.load(std::memory_order_acquire));&#8592;&#9496;</code>
            <strong>sync1</strong>
          </p>
          <p>
            <code> sync2.store(true, std::memory_order_release); &#8592;&#9488;</code>
            <strong>Установить</strong>
          </p>
          <p>
            <code>}                                              </code>
            <strong>(3) sync2</strong>
          </p>
          <empty-line/>
          <p>
            <code>void thread_3()                                 </code>
            <strong>(4)Цикл до</strong>
          </p>
          <p>
            <code>{                                                &#9474;</code>
            <strong>установки</strong>
          </p>
          <p>
            <code> while (!sync2.load(std::memory_order_acquire));&#8592;&#9496;</code>
            <strong>sync2</strong>
          </p>
          <p>
            <code> assert(data[0].load(std::memory_order_relaxed) == 42);</code>
          </p>
          <p>
            <code> assert(data[1].load(std::memory_order_relaxed) == 97);</code>
          </p>
          <p>
            <code> assert(data[2].load(std::memory_order_relaxed) == 17);</code>
          </p>
          <p>
            <code> assert(data[3].load(std::memory_order_relaxed) == -141);</code>
          </p>
          <p>
            <code> assert(data[4].load(std::memory_order_relaxed) == 2003);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Хотя поток <code>thread_2</code> обращается только к переменным <code>sync1</code> <strong>(2)</strong> и <code>sync2</code> <strong>(3)</strong>, этого достаточно для синхронизации между <code>thread_1</code> и <code>thread_3</code> и, стало быть, гарантии несрабатывания утверждений <code>assert</code>. Прежде всего, операции сохранения в элементы массива <code>data</code> в потоке <code>thread_1</code> происходят-раньше сохранения <code>sync1</code> <strong>(1)</strong>, потому что они связаны отношением расположено-перед в одном потоке. Поскольку операция загрузки <code>sync1</code> <strong>(2)</strong> находится внутри цикла <code>while</code>, она в конце концов увидит значение, сохраненное в <code>thread_1</code> и, значит, образует вторую половину пары освобождение-захват. Поэтому сохранение <code>sync1</code> происходит-раньше последней загрузки <code>sync1</code> в цикле <code>while</code>. Эта операция загрузки расположена-перед (и, значит, происходит-раньше) операцией сохранения <code>sync2</code> <strong>(3)</strong>, которая образует пару освобождение-захват вместе с последней операцией загрузки в цикле <code>while</code> в потоке <code>thread_3</code> <strong>(4)</strong>. Таким образом, сохранение <code>sync2</code> <strong>(3)</strong> происходит-раньше загрузки <strong>(4)</strong>, которая происходит-раньше загрузок <code>data</code>. В силу транзитивности отношения происходит-раньше всю эту цепочку можно соединить: операции сохранения <code>data</code> происходят-раньше операций сохранения <code>sync1</code> <strong>(1)</strong>, которые происходят-раньше загрузки <code>sync1</code> <strong>(2)</strong>, которая происходит-раньше сохранения <code>sync2</code> <strong>(3)</strong>, которая происходит-раньше загрузки <code>sync2</code> <strong>(4)</strong>, которая происходит-раньше загрузок <code>data</code>. Следовательно, операции сохранения <code>data</code> в потоке <code>thread_1</code> происходят-раньше операций загрузки <code>data</code> в потоке <code>thread_3</code>, и утверждения <code>assert</code> сработать не могут.</p>
          <p>В этом случае можно было бы объединить <code>sync1</code> и <code>sync2</code> в одну переменную, воспользовавшись операцией чтения-модификации-записи с семантикой <code>memory_order_acq_rel</code> в потоке <code>thread_2</code>. Один из вариантов — использовать функцию <code>compare_exchange_strong()</code>, гарантирующую, что значение будет обновлено только после того, как поток <code>thread_2</code> увидит результат сохранения в потоке <code>thread_1</code>:</p>
          <p>
            <code>std::atomic&lt;int&gt; sync(0);</code>
          </p>
          <empty-line/>
          <p>
            <code>void thread_1() {</code>
          </p>
          <p>
            <code> // ...</code>
          </p>
          <p>
            <code> sync.store(1, std::memory_order_release);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void thread_2() {</code>
          </p>
          <p>
            <code> int expected = 1;</code>
          </p>
          <p>
            <code> while (!sync.compare_exchange_strong(expected, 2,</code>
          </p>
          <p>
            <code>         std::memory_order_acq_rel))</code>
          </p>
          <p>
            <code>  expected = 1;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void thread_3() {</code>
          </p>
          <p>
            <code> while(sync.load(std::memory_order_acquire) &lt; 2);</code>
          </p>
          <p>
            <code> // ...</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>При использовании операций чтения-модификации-записи важно выбрать нужную семантику. В данном случае нам нужна одновременно семантика захвата и освобождения, поэтому подойдет <code>memory_order_acq_rel</code>, но можно было бы применить другие виды упорядочения. Операция <code>fetch_sub</code> с семантикой <code>memory_order_acquire</code> не синхронизируется ни с чем, хотя и сохраняет значение, потому что это не операция освобождения. Аналогично сохранение не может синхронизироваться-с операцией <code>fetch_or</code> с семантикой <code>memory_order_release</code>, потому что часть «чтение» <code>fetch_or</code> не является операцией захвата. Операции чтения-модификации-записи с семантикой <code>memory_order_acq_rel</code> ведут себя как операции захвата и освобождения одновременно, поэтому предшествующее сохранение может синхронизироваться-с такой операцией и с последующей загрузкой, как и обстоит дело в примере выше.</p>
          <p>Если вы сочетаете операции захвата-освобождения с последовательно согласованными операциями, то последовательно согласованные операции загрузки ведут себя, как загрузки с семантикой захвата, а последовательно согласованные операции сохранения — как сохранения с семантикой освобождения. Последовательно согласованные операции чтения-модификации-записи ведут себя как операции, наделенные одновременно семантикой захвата и освобождения. Ослабленные операции так и остаются ослабленными, но связаны дополнительными отношениями синхронизируется-с и последующими отношениями происходит-раньше, наличие которых обусловлено семантикой захвата-освобождения.</p>
          <p>Несмотря на интуитивно неочевидные результаты, всякий, кто использовал блокировки, вынужденно имел дело с вопросами упорядочения: блокировка мьютекса — это операция захвата, а его разблокировка — операция освобождения. Работая с мьютексами, вы на опыте узнаете, что при чтении значения необходимо захватывать тот же мьютекс, который захватывался при его записи. Точно так же обстоит дело и здесь — для обеспечения упорядочения операции захвата и освобождения должны применяться к одной и той же переменной. Если данные защищены мьютексом, то взаимно исключающая природа блокировки означает, что результат неотличим от того, который получился бы, если бы операции блокировки и разблокировки были последовательно согласованы. Аналогично, если для построения простой блокировки к атомарным переменным применяется упорядочение захват-освобождение, то с точки зрения программы, <emphasis>использующей</emphasis> такую блокировку, поведение кажется последовательно согласованным, хотя внутренние операции таковыми не являются.</p>
          <p>Если для выполняемых в вашей программе атомарных операций не нужна строгость последовательно согласованного упорядочения, то попарная синхронизация с помощью упорядочения захват-освобождение может обеспечить синхронизацию со значительно меньшими издержками, чем необходимое для последовательно согласованных операций глобальное упорядочение. Ценой компромисса являются мысленные усилия, необходимые для того, чтобы удостовериться в том, что упорядочение работает правильно, а интуитивно неочевидное поведение нескольких потоков не вызывает проблем.</p>
          <subtitle>Зависимости по данным, упорядочение захват-освобождение и семантика <code>memory_order_consume</code></subtitle>
          <p>Во введении к этому разделу я говорил, что семантика <code>memory_order_consume</code> является частью модели упорядочения захват-освобождение, но из предшествующего описания она полностью выпала. Дело в том, что семантика <code>memory_order_consume</code> особая: она связана с зависимостями по данным и позволяет учесть соответствующие нюансы в отношении <emphasis>межпоточно происходит-раньше</emphasis>, о котором шла речь в разделе 5.3.2.</p>
          <p>С зависимостями по данным связаны два новых отношения: <emphasis>предшествует-по-зависимости</emphasis> (dependency-ordered-before) и <emphasis>переносит-зависимость-в</emphasis> (carries-a-dependency-to). Как и отношение расположено-перед, отношение переносит-зависимость-в применяется строго внутри одного потока и моделирует зависимость по данным между операциями — если результат операции А используется в качестве операнда операции В, то А переносит-зависимость-в В. Если результатом операции А является значение скалярного типа, например <code>int</code>, то отношение применяется и тогда, когда результат А сохраняется в переменной, которая затем используется в качестве операнда В. Эта операция также транзитивна, то есть если А переносит-зависимость-в В и В переносит-зависимость-в С, то А переносит-зависимость-в С.</p>
          <p>С другой стороны, отношение предшествует-по-зависимости может применяться к разным потокам. Оно вводится с помощью атомарных операций загрузки, помеченных признаком <code>memory_order_consume</code>. Это частный случай семантики <code>memory_order_acquire</code>, в котором синхронизированные данные ограничиваются прямыми зависимостями; операция сохранения А, помеченная признаком <code>memory_order_release</code>, <code>memory_order_acq_rel</code> или <code>memory_order_seq_cst</code>, предшествует-по-зависимости операции загрузки В, помеченной признаком <code>memory_order_consume</code>, если потребитель читает сохраненное значение. Это противоположность отношению синхронизируется-с, которое образуется, если операция загрузки помечена признаком <code>memory_order_acquire</code>. Если такая операция В затем переносит-зависимость-в некоторую операцию С, то А также предшествует-по-зависимости С.</p>
          <p>Это не дало бы ничего полезного для целей синхронизации, если бы не было связано с отношением межпоточно происходит-раньше. Однако же справедливо следующее утверждение: если А предшествует-по-зависимости В, то А межпоточно происходит-раньше В.</p>
          <p>Одно из важных применений такого упорядочения доступа к памяти связано с атомарной операцией загрузки указателя на данные. Пометив операцию загрузки признаком <code>memory_order_consume</code>, а предшествующую ей операцию сохранения — признаком <code>memory_order_release</code>, можно гарантировать, что данные, адресуемые указателем, правильно синхронизированы, даже не накладывая никаких требований к синхронизации с другими независимыми данными. Этот сценарий иллюстрируется в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 5.10.</strong> Использование <code>std::memory_order_consume</code> для синхронизации данных</p>
          <p>
            <code>struct X {</code>
          </p>
          <p>
            <code> int i;</code>
          </p>
          <p>
            <code> std::string s;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>std::atomic&lt;X*&gt; p;</code>
          </p>
          <p>
            <code>std::atomic&lt;int&gt; a;</code>
          </p>
          <empty-line/>
          <p>
            <code>void create_x() {</code>
          </p>
          <p>
            <code> X* x = new X;</code>
          </p>
          <p>
            <code> x-&gt;i = 42;</code>
          </p>
          <p>
            <code> x-&gt;s = "hello";</code>
          </p>
          <p>
            <code> a.store(99, std::memory_order_relaxed);&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> p.store(x, std::memory_order_release); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void use_x() {</code>
          </p>
          <p>
            <code> X* x;</code>
          </p>
          <p>
            <code> while (!(x = p.load(std::memory_order_consume)))&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> std::this_thread::sleep(std::chrono::microseconds(1));</code>
          </p>
          <p>
            <code> assert(x-&gt;i == 42);                             &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> assert(x-&gt;s =="hello");                         &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code> assert(a.load(std::memory_order_relaxed) == 99);&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> std::thread t1(create_x);</code>
          </p>
          <p>
            <code> std::thread t2(use_x);</code>
          </p>
          <p>
            <code> t1.join();</code>
          </p>
          <p>
            <code> t2.join();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Хотя сохранение <code>а</code> <strong>(1)</strong> расположено перед сохранением <code>p</code> <strong>(2)</strong> и сохранение <code>p</code> помечено признаком <code>memory_order_release</code>, но загрузка <code>p</code> <strong>(3)</strong> помечена признаком <code>memory_order_consume</code>. Это означает, что сохранение <code>p</code> происходит-раньше только тех выражений, которые зависят от значения, загруженного из <code>p</code>. Поэтому утверждения о членах-данных структуры <code>x</code> <strong>(4)</strong>, <strong>(5)</strong> гарантированно не сработают, так как загрузка <code>p</code> переносит-зависимость-в эти выражения посредством переменной <code>x</code>. С другой стороны, утверждение о значении <code>а</code> <strong>(6)</strong> может как сработать, так и не сработать; эта операция не зависит от значения, загруженного из <code>p</code>, поэтому нет никаких гарантий о прочитанном значении. Это ясно следует из того, что она помечена признаком <code>memory_order_relaxed</code>.</p>
          <p>Иногда нам не нужны издержки, которыми сопровождается перенос зависимости. Мы хотим, чтобы компилятор мог кэшировать значения в регистрах и изменять порядок операций во имя оптимизации кода, а не волновался по поводу зависимостей. В таких случаях можно воспользоваться шаблоном функции <code>std::kill_dependency()</code> для явного разрыва цепочки зависимостей. Эта функция просто копирует переданный ей аргумент в возвращаемое значение, но попутно разрывает цепочку зависимостей. Например, если имеется глобальный массив с доступом только для чтения, и вы используете семантику <code>std::memory_order_consum</code>e при чтении какого-то элемента этого массива из другого потока, то с помощью <code>std::kill_dependency()</code> можно сообщить компилятору, что ему необязательно заново считывать содержимое элемента массива (см. пример ниже).</p>
          <p>
            <code>int global_data[] = { ... };</code>
          </p>
          <p>
            <code>std::atomic&lt;int&gt; index;</code>
          </p>
          <empty-line/>
          <p>
            <code>void f() {</code>
          </p>
          <p>
            <code> int i = index.load(std::memory_order_consume);</code>
          </p>
          <p>
            <code> do_something_with(global_data[std::kill_dependency(i)]);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Разумеется, в таком простом случае вы вряд ли вообще будете пользоваться семантикой <code>std::memory_order_consume</code>, но в аналогичной ситуации функцией <code>std::kill_dependency()</code> можно воспользоваться и в более сложной программе. Только не забывайте, что это оптимизация, поэтому прибегать к ней следует с осторожностью и только тогда, когда профилирование ясно продемонстрировало необходимость.</p>
          <p>Теперь, рассмотрев основы упорядочения доступа к памяти, мы можем перейти к более сложным аспектам отношения синхронизируется-с, которые проявляются в форме <emphasis>последовательностей освобождений</emphasis> (release sequences).</p>
        </section>
        <section>
          <title>
            <p>5.3.4. Последовательности освобождений и отношение синхронизируется-с</p>
          </title>
          <p>В разделе 5.3.1 я упоминал, что можно получить отношение синхронизируется-с между операцией сохранения атомарной переменной и операцией загрузки той же атомарной переменной в другом потоке, даже если между ними выполняется последовательность операций чтения-модификации-записи, — при условии, что все операции помечены надлежащим признаками. Теперь, когда мы знаем обо всех возможных «признаках» упорядочения, я могу подробнее осветить этот вопрос. Если операция сохранения помечена одним из признаков <code>memory_order_release</code>, <code>memory_order_acq_rel</code> или <code>memory_order_seq_cst</code>, а операция загрузки — одним из признаков <code>memory_order_consume</code>, <code>memory_order_acquire</code> или <code>memory_order_seq_cst</code>, и каждая операция в цепочке загружает значение, записанное предыдущей операцией, то такая цепочка операций составляет <emphasis>последовательность освобождений</emphasis>, и первая в ней операция сохранения синхронизируется-с (в случае <code>memory_order_acquire</code> или <code>memory_order_seq_cst</code>) или предшествует-по-зависимости (в случае <code>memory_order_consume</code>) последней операции загрузки. Любая атомарная операция чтения-модификации-записи в цепочке может быть помечена <emphasis>произвольным</emphasis> признаком упорядочения (даже <code>memory_order_relaxed</code>).</p>
          <p>Чтобы попять, что это означает и почему так важно, рассмотрим значение типа <code>atomic&lt;int&gt;</code>, которое используется как счетчик <code>count</code> элементов в разделяемой очереди (см. листинг ниже).</p>
          <empty-line/>
          <p><strong>Листинг 5.11.</strong> Чтение из очереди с применением атомарных операций</p>
          <p>
            <code>#include &lt;atomic&gt;</code>
          </p>
          <p>
            <code>#include &lt;thread&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::vector&lt;int&gt; queue_data; std::atomic&lt;int&gt; count;</code>
          </p>
          <empty-line/>
          <p>
            <code>void populate_queue() {</code>
          </p>
          <p>
            <code> unsigned const number_of_items = 20;</code>
          </p>
          <p>
            <code> queue_data.clear();</code>
          </p>
          <p>
            <code> for (unsigned i = 0; i &lt; number_of_items; ++i) {</code>
          </p>
          <p>
            <code>  queue_data.push_back(i);</code>
          </p>
          <p>
            <code> } &#8592;</code>
            <strong>(1) Начальное сохранение</strong>
          </p>
          <p>
            <code> count.store(number_of_items, std::memory_order_release);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void consume_queue_items() {</code>
          </p>
          <p>
            <code> while (true) { &#8592;</code>
            <strong>(2) Операция ЧМЗ</strong>
          </p>
          <p>
            <code> int item_index;</code>
          </p>
          <p>
            <code> if (</code>
          </p>
          <p>
            <code>  (item_index =</code>
          </p>
          <p>
            <code>   count.fetch_sub(1, std::memory_order_acquire)) &lt;= 0) {</code>
          </p>
          <p>
            <code>   wait_for_more_items();&#8592;&#9488;</code>
            <strong>Ждем дополнительных</strong>
          </p>
          <p>
            <code>   continue;             </code>
            <strong>(3) элементов</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> process(queue_data[item_index-1]);&#8592;&#9488;</code>
            <strong>Чтение из queue_data</strong>
          </p>
          <p>
            <code>}                                  </code>
            <strong>(4) безопасно</strong>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> std::thread a(populate_queue);</code>
          </p>
          <p>
            <code> std::thread b(consume_queue_items);</code>
          </p>
          <p>
            <code> std::thread с(consume_queue_items);</code>
          </p>
          <p>
            <code> a.join();</code>
          </p>
          <p>
            <code> b.join();</code>
          </p>
          <p>
            <code> c.join();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Можно, например, написать программу так, что поток, производящий данные, сохраняет их в разделяемом буфере, а затем вызывает функцию <code>count.store(numbеr_of_items, memory_order_release)</code> <strong>(1)</strong>, чтобы другие потоки узнали о готовности данных. Потоки- потребители, читающие данные из очереди, могли бы затем вызвать <code>count.fetch_sub(1, memory_order_acquire)</code> <strong>(2)</strong>, чтобы проверить, есть ли элементы в очереди перед тем, как фактически читать из разделяемого буфера <strong>(4)</strong>. Если счетчик <code>count</code> стал равен 0, то больше элементов нет, и поток должен ждать <strong>(3)</strong>.</p>
          <p>Если поток-потребитель всего один, то всё хорошо; <code>fetch_sub()</code> — это операция чтения с семантикой <code>memory_order_acquire</code>, а операция сохранения была помечена признаком <code>memory_order_release</code>, поэтому сохранение синхронизируется-с загрузкой, и поток может читать данные из буфера. Но если читают два потока, то второй вызов <code>fetch_sub()</code> увидит значение, записанное при первом вызове, а не то, которое было записано операцией <code>store</code>. Без правила о последовательности освобождений между вторым и первым потоком не было бы отношения происходит-раньше, поэтому было бы небезопасно читать из разделяемого буфера, если только и для первого вызова <code>fetch_sub()</code> тоже не задана семантика <code>memory_order_release</code>; однако, задав ее, мы ввели бы излишнюю синхронизацию между двумя потоками-потребителями. Без правила о последовательности освобождений или задания семантики <code>memory_order_release</code> для всех операций <code>fetch_sub</code> не было бы никакого механизма, гарантирующего, что операции сохранения в queue_data видны второму потребителю, следовательно, мы имели бы гонку за данными. К счастью, первый вызов <code>fetch_sub(</code>) на самом деле <emphasis>участвует</emphasis> в последовательности освобождений, и вызов <code>store()</code> синхронизируется-с вторым вызовом <code>fetch_sub()</code>. Однако отношения синхронизируется-с между двумя потоками-потребителями все еще не существует. Это изображено на рис. 5.7, где пунктирные линии показывают последовательность освобождений, а сплошные — отношения происходит-раньше.</p>
          <image l:href="#img_15_novyjjrazmer.png"/>
          <p><strong>Рис. 5.7.</strong> Последовательность освобождений для операций с очередью из листинга 5.11</p>
          <p>В цепочке может быть сколько угодно звеньев, но при условии, что все они являются операциями чтения-модификации-записи, как <code>fetch_sub()</code>, операция <code>store()</code> синхронизируется-с каждым звеном, помеченным признаком <code>memory_order_acquire</code>. В данном примере все звенья одинаковы и являются операциями захвата, но это вполне могли бы быть разные операции с разной семантикой упорядочения доступа к памяти.</p>
          <p>Хотя большая часть отношений синхронизации проистекает из семантики упорядочения доступа к памяти, применённой к операциям над атомарными переменными, существует возможность задать дополнительные ограничения на упорядочение с помощью <emphasis>барьеров</emphasis> (fence).</p>
        </section>
        <section>
          <title>
            <p>5.3.5. Барьеры</p>
          </title>
          <p>Библиотека атомарных операций была бы неполна без набора барьеров. Это операции, которые налагают ограничения на порядок доступа к памяти без модификации данных. Обычно они используются в сочетании с атомарными операциями, помеченными признаком <code>memory_order_relaxed</code>. Барьеры — это глобальные операции, они влияют на упорядочение других атомарных операций в том потоке, где устанавливается барьер. Своим названием барьеры обязаны тому, что устанавливают в коде границу, которую некоторые операции не могут пересечь. В разделе 5.3.3 мы говорили, что компилятор или сам процессор вправе изменять порядок ослабленных операций над различными переменными. Барьеры ограничивают эту свободу и вводят отношения происходит-раньше и синхронизируется-с, которых до этого не было.</p>
          <p>В следующем листинге демонстрируется добавление барьера между двумя атомарными операциями в каждом потоке из листинга 5.5.</p>
          <empty-line/>
          <p><strong>Листинг 5.12.</strong> Ослабленные операции можно упорядочить с помощью барьеров</p>
          <p>
            <code>#include &lt;atomic&gt;</code>
          </p>
          <p>
            <code>#include &lt;thread&gt;</code>
          </p>
          <p>
            <code>#include &lt;assert.h&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>std::atomic&lt;bool&gt; x, y;</code>
          </p>
          <p>
            <code>std::atomic&lt;int&gt; z;</code>
          </p>
          <empty-line/>
          <p>
            <code>void write_x_then_y() {</code>
          </p>
          <p>
            <code> x.store(true, std::memory_order_relaxed);           &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> std::atomic_thread_fence(std::memory_order_release);&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> y.store(true, std::memory_order_relaxed);           &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void read_y_then_x() {</code>
          </p>
          <p>
            <code> while (!y.load(std::memory_order_relaxed));         &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> std::atomic_thread_fence(std::memory_order_acquire);&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code> if (x.load(std::memory_order_relaxed))              &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  ++z;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> x = false;</code>
          </p>
          <p>
            <code> y = false;</code>
          </p>
          <p>
            <code> z = 0;</code>
          </p>
          <p>
            <code> std::thread a(write_x_then_y);</code>
          </p>
          <p>
            <code> std::thread b(read_y_then_x);</code>
          </p>
          <p>
            <code> a.join();</code>
          </p>
          <p>
            <code> b.join();</code>
          </p>
          <p>
            <code> assert(z.load() != 0); &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Барьер освобождения <strong>(2)</strong> синхронизируется-с барьером захвата <strong>(5)</strong>, потому что операция загрузки <code>y</code> в точке <strong>(4)</strong> читает значение, сохраненное в точке <strong>(3)</strong>. Это означает, что сохранение <code>x</code> <strong>(1)</strong> происходит-раньше загрузки <code>x</code> <strong>(6)</strong>, поэтому прочитанное значение должно быть равно <code>true</code>, и утверждение <strong>(7)</strong> не сработает. Здесь мы наблюдаем разительное отличие от исходного случая без барьеров, когда сохранение и загрузка <code>x</code> не были упорядочены, и утверждение могло сработать. Отметим, что оба барьера обязательны: чтобы получить отношение синхронизируется-с необходимо освобождение в одном потоке и захват в другом.</p>
          <p>В данном случае барьер освобождения <strong>(2)</strong> оказывает такой же эффект, как если бы операция сохранения <code>y</code> <strong>(3)</strong> была помечена признаком <code>memory_order_release</code>, а не <code>memory_order_relaxed</code>. Аналогично эффект от барьера захвата <strong>(5)</strong> такой же, как если бы операция загрузки <code>y</code> <strong>(4)</strong> была помечена признаком <code>memory_order_acquire</code>. Это общее свойство всех барьеров: если операция захвата видит результат сохранения, имевшего место после барьера освобождения, то барьер синхронизируется-с этой операцией захвата. Если же операция загрузки, имевшая место до барьера захвата, видит результат операции освобождения, то операция освобождения синхронизируется-с барьером захвата. Разумеется, можно поставить барьеры по обе стороны, как в примере выше, и в таком случае если загрузка, которая имела место до барьера захвата, видит значение, записанное операцией сохранения, имевшей место после барьера освобождения, то барьер освобождения синхронизируется-с барьером захвата.</p>
          <p>Хотя барьерная синхронизация зависит от значений, прочитанных или записанных операциями до и после барьеров, важно отметить, что точкой синхронизации является сам барьер. Если взять функцию <code>write_x_then_y</code> из листинга 5.12 и перенести запись в <code>x</code> после барьера, как показано ниже, то уже не гарантируется, что условие в утверждение будет истинным, несмотря на то что запись в x предшествует записи в <code>y</code>:</p>
          <p>
            <code>void write_x_then_y() {</code>
          </p>
          <p>
            <code> std::atomic_thread_fence(std::memory_order_release);</code>
          </p>
          <p>
            <code> x.store(true, std::memory_order_relaxed);</code>
          </p>
          <p>
            <code> y.store(true, std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Эти две операции больше не разделены барьером и потому не упорядочены. Барьер обеспечивает упорядочение только тогда, когда находится <emphasis>между</emphasis> сохранением <code>x</code> и сохранением <code>y</code>. Конечно, наличие или отсутствие барьера не влияет на упорядочения, обусловленные отношениями происходит-раньше, которые существуют благодаря другим атомарным операциям.</p>
          <p>Данный пример, как и почти все остальные в этой главе, целиком построен на переменных атомарных типов. Однако реальная польза от применения атомарных операций для навязывания упорядочения проистекает из того, что они могут упорядочивать неатомарные операции и тем самым предотвращать неопределенное поведение из-за гонок за данными, как мы видели в листинге 5.2.</p>
        </section>
        <section>
          <title>
            <p>5.3.6. Упорядочение неатомарных операций с помощью атомарных</p>
          </title>
          <p>Если заменить тип переменной <code>x</code> в листинге 5.12 обычным неатомарным типом <code>bool</code> (как в листинге ниже), то гарантируется точно такое же поведение, как и раньше.</p>
          <empty-line/>
          <p><strong>Листинг 5.13.</strong> Принудительное упорядочение неатомарных операций</p>
          <p>
            <code>#include &lt;atomic&gt;</code>
          </p>
          <p>
            <code>#include &lt;thread&gt;</code>
          </p>
          <p>
            <code>#include &lt;assert.h&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>bool x = false;    &#8592;&#9488;</code>
            <strong>Теперь x — простая</strong>
          </p>
          <p>
            <code>std::atomic&lt;bool&gt; y;&#9474;</code>
            <strong>неатомарная</strong>
          </p>
          <p>
            <code>std::atomic&lt;int&gt; z; &#9474;</code>
            <strong>переменная</strong>
          </p>
          <p>
            <code>void write_x_then_y() {</code>
            <strong>(1) Сохранение x</strong>
          </p>
          <p>
            <code> x = true;            &#8592;&#9496;</code>
            <strong>перед барьером</strong>
          </p>
          <p>
            <code> std::atomic_thread_fence(std::memory_order_release);</code>
          </p>
          <p>
            <code> y.store(true, std::memory_order_relaxed);&#8592;&#9488;</code>
            <strong>Сохранение y</strong>
          </p>
          <p>
            <code>}                                         </code>
            <strong>(2) после барьера</strong>
          </p>
          <empty-line/>
          <p>
            <code>void read_y_then_x()                        </code>
            <strong>(3) Ждем, пока не</strong>
          </p>
          <p>
            <code>{                                            &#9474;</code>
            <strong>увидим значение,</strong>
          </p>
          <p>
            <code> while (!y.load(std::memory_order_relaxed));&#8592;&#9496;</code>
            <strong>записанное в 2</strong>
          </p>
          <p>
            <code> std::atomic_thread_fence(std::memory_order_acquire);</code>
          </p>
          <p>
            <code> if (x) &#8592;&#9488;</code>
            <strong>Здесь будет прочитано</strong>
          </p>
          <p>
            <code>  ++z;   </code>
            <strong>(4) значение, записанное в 1</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> x = false;</code>
          </p>
          <p>
            <code> y = false;</code>
          </p>
          <p>
            <code> z = 0;</code>
          </p>
          <p>
            <code> std::thread a(write_x_then_y);</code>
          </p>
          <p>
            <code> std::thread b(read_y_then_x);</code>
          </p>
          <p>
            <code> a.join();</code>
          </p>
          <p>
            <code> b.join();             </code>
            <strong>(5) Это утверждение</strong>
          </p>
          <p>
            <code> assert(z.load() != 0);&#8592;&#9496;</code>
            <strong>не сработает</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Барьеры по-прежнему обеспечивают упорядочение сохранения <code>x</code> <strong>(1)</strong> и <code>y</code> <strong>(2)</strong> и загрузки <code>y</code> <strong>(3)</strong> и <code>x</code> <strong>(4)</strong>, и, как и раньше, существует отношение происходит-раньше между сохранением <code>x</code> и загрузкой <code>x</code>, поэтому утверждение <strong>(5)</strong> не сработает. Сохранение <code>y</code> <strong>(2)</strong> и загрузка <code>y</code> <strong>(3)</strong> тем не менее должны быть атомарными, иначе возникла бы гонка за <code>y</code>, но барьеры упорядочивают операции над <code>x</code> после того, как поток-читатель увидел сохраненное значение <code>y</code>. Такое принудительное упорядочение означает, что гонки за <code>x</code> нет, хотя ее значение модифицируется в одном потоке, а читается в другом.</p>
          <p>Но не только с помощью барьеров можно упорядочить неатомарные операции. Эффект упорядочения мы наблюдали также в листинге 5.10, где пара <code>memory_order_release</code> / <code>memory_order_consume</code> упорядочивала неатомарные операции доступа к динамически выделенному объекту. Многие примеры из этой главы можно было бы переписать, заменив некоторые операции с семантикой <code>memory_order_relaxed</code> простыми неатомарными операциями.</p>
          <p>Упорядочение неатомарных операций с помощью атомарных — это та область, где особую важность приобретает аспект расположено-перед отношения происходит-раньше. Если неатомарная операция расположено-перед атомарной, и эта атомарная операция происходит-раньше какой-либо операции в другом потоке, то и неатомарная операция также происходит-раньше этой операции в другом потоке. Именно из этого вытекает упорядочение операций над <code>x</code> в листинге 5.13, и именно поэтому работает пример из листинга 5.2. Этот факт также лежит в основе таких высокоуровневых средств синхронизации в стандартной библиотеке С++, как мьютексы и условные переменные. Чтобы понять, как это работает, рассмотрим простой мьютекс-спинлок из листинга 5.1.</p>
          <p>В функции <code>lock()</code> выполняется цикл по <code>flag.test_and_set()</code> с упорядочением <code>std::memory_order_acquire</code>, а функция <code>unlock()</code> вызывает операцию <code>flag.clear()</code> с признаком упорядочения <code>std::memory_order_release</code>. В момент, когда первый поток вызывает <code>lock()</code>, флаг еще сброшен, поэтому первое обращение к <code>test_and_set()</code> установит его и вернет <code>false</code>. Это означает, что поток завладел блокировкой, и цикл завершается. Теперь этот поток вправе модифицировать любые данные, защищенные мьютексом. Всякий другой поток, который вызовет <code>lock()</code> в этот момент, обнаружит, что флаг уже поднят, и потому будет заблокирован в цикле <code>test_and_set()</code>. Когда поток, владеющий блокировкой, закончит модифицировать защищенные данные, он вызовет функцию <code>unlock()</code>, которая вызовет <code>flag.clear()</code> с семантикой <code>std::memory_order_release</code>.</p>
          <p>Это приводит к синхронизации-с (см. раздел 5.3.1) последующим обращением к <code>flag.test_and_set()</code> из функции <code>lock()</code> в другом потоке, потому что в этом обращении задана семантика <code>std::memory_order_acquire</code>. Так как модификация защищенных данных обязательно расположена-перед вызовом <code>unlock()</code>, то эта модификация происходит-раньше вызова <code>unlock()</code> и, следовательно, происходит-раньше последующего обращения к <code>lock()</code> из другого потока (благодаря наличию отношения синхронизируется-с между <code>unlock()</code> и <code>lock()</code>) и происходит-раньше любой операции доступа к данным из второго потока после того, как он захватит блокировку.</p>
          <p>В других реализациях мьютексов используются иные внутренние операции, но принцип остается неизменным: <code>lock()</code> — это операция захвата над некоторой внутренней ячейкой памяти, a <code>unlock()</code> — операция освобождения над той же ячейкой памяти.</p>
        </section>
      </section>
      <section>
        <title>
          <p>5.4. Резюме</p>
        </title>
        <p>В этой главе мы рассмотрели низкоуровневые детали модели памяти в C++11 и атомарные операции, лежащие в основе синхронизации потоков. Были также рассмотрены простые атомарные типы, предоставляемые специализациями шаблона класса <code>std::atomic&lt;&gt;</code>, и обобщенный интерфейс в виде основного шаблона <code>std::atomic&lt;&gt;</code>, операции над этими типами и непростые детали, связанные с различными вариантами упорядочения доступа к памяти.</p>
        <p>Мы также рассмотрели барьеры и их использование в сочетании с операциями над атомарными типами для обеспечения принудительного упорядочения. Наконец, мы вернулись к началу и показали, как можно использовать атомарные операции для упорядочения неатомарных операций, выполняемых в разных потоках.</p>
        <p>В следующей главе мы увидим, как высокоуровневые средства синхронизации вкупе с атомарными операциями применяются для проектирования эффективных контейнеров, допускающих параллельный доступ, а также напишем алгоритмы для параллельной обработки данных.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Глава 6</p>
        <p>Проектирование параллельных структур данных с блокировками</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Что понимается под проектированием структур данных, рассчитанных на параллельный доступ?</p>
        <p>&#9632; Рекомендации по проектированию таких структур.</p>
        <p>&#9632; Примеры реализации параллельных структур данных.</p>
      </annotation>
      <section>
        <p>В предыдущей главе мы рассмотрели низкоуровневые детали атомарных операций и модели памяти. В этой главе мы на время отойдем от низкоуровневых деталей (чтобы вернуться к ним в главе 7) и поразмыслим о структурах данных.</p>
        <p>От выбора структуры данных может в значительной степени зависеть всё решение поставленной задачи, и параллельное программирование — не исключение. Если к структуре данных планируется обращаться из разных потоков, то возможно два варианта: либо структура вообще неизменяемая, и тогда никакой синхронизации не требуется, либо программа спроектирована так, что любые изменения корректно синхронизированы. Одна из возможностей — завести отдельный мьютекс и пользоваться для защиты данных внешней по отношению к структуре блокировкой, применяя технику, рассмотренную в главах 3 и 4. Другая — спроектировать саму структуру данных, так чтобы к ней был возможен параллельный доступ.</p>
        <p>При проектировании структуры данных, допускающей параллельный доступ, мы можем использовать основные строительные блоки многопоточных приложений, описанные в предыдущих главах, например мьютексы и условные переменные. На самом деле, вы уже видели примеры структур, в которых сочетание этих блоков гарантирует безопасный доступ из нескольких потоков.</p>
        <p>Мы начнем эту главу с нескольких общих рекомендаций по проектированию параллельных структур данных. Затем мы еще раз вернемся к использованию блокировок и условных переменных в простых структурах, после чего перейдём к более сложным. В главе 7 я покажу, как с помощью атомарных операций можно строить структуры данных без блокировок.</p>
        <p>Но довольно предисловий — посмотрим, что входит в проектирование структуры данных для параллельного программирования.</p>
      </section>
      <section>
        <title>
          <p>6.1. Что понимается под проектированием структур данных, рассчитанных на параллельный доступ?</p>
        </title>
        <section>
          <p>На простейшем уровне это означает, что нужно спроектировать структуру данных, к которой смогут одновременно обращаться несколько потоков для выполнения одних и тех же или разных операций, причём каждый поток должен видеть согласованное состояние структуры. Данные не должны теряться или искажаться, все инварианты должны быть соблюдены, и никаких проблематичных состояний гонки не должно быть. Такая структура данных называется <emphasis>потокобезопасной</emphasis>. В общем случае структура данных безопасна только относительно определенных типов параллельного доступа. Не исключено, что несколько потоков могут одновременно выполнять какую-то одну операцию над структурой, а для выполнения другой необходим монопольный доступ. Наоборот, бывает, что несколько потоков могут одновременно и безопасно выполнять <emphasis>различные</emphasis> операции, но при выполнении <emphasis>одной и той же</emphasis> операции в разных потоках возникают проблемы.</p>
          <p>Но проектирование с учетом параллелизма этим не исчерпывается: задача заключается в том, чтобы предоставить <emphasis>возможность распараллеливания</emphasis> потокам, обращающимся к структуре данных. По природе своей, мьютекс означает <emphasis>взаимное исключение</emphasis>: в каждый момент времени только один поток может захватить мьютекс. Следовательно, мьютекс защищает структуру данных, явным образом <emphasis>предотвращая</emphasis> истинно параллельный доступ к ней.</p>
          <p>Это называется <emphasis>сериализацией</emphasis>: потоки обращаются к защищенным мьютексом данным по очереди, то есть последовательно, а не параллельно. Чтобы обеспечить истинно параллельный доступ, нужно тщательно продумывать внутреннее устройство структуры данных. Одни структуры данных оставляют больший простор для распараллеливания, чем другие, но идея остается неизменной: чем меньше защищаемая область, тем меньше операций приходится сериализовывать и тем больше потенциал для распараллеливания.</p>
          <p>Прежде чем знакомиться с конкретными структурами данных, приведём несколько простых рекомендаций, полезных при проектировании с учетом параллелизма.</p>
        </section>
        <section>
          <title>
            <p>6.1.1. Рекомендации по проектированию структур данных для параллельного доступа</p>
          </title>
          <p>Как я уже отмечал, при проектировании структур данных для параллельного доступа нужно учитывать два аспекта: обеспечить <emphasis>безопасность</emphasis> доступа и <emphasis>разрешить</emphasis> истинно параллельный доступ. Как сделать структуру потокобезопасной, я уже рассказывал в главе 3.</p>
          <p>• Гарантировать, что ни один поток не может увидеть состояние, в котором инварианты структуры данных нарушены действиями со стороны других потоков.</p>
          <p>• Позаботиться о предотвращении состояний гонки, внутренне присущих структуре данных, предоставив такие функции, которые выполняли бы операции целиком, а не частями.</p>
          <p>• Обращать внимание на том, как ведет себя структура данных при наличии исключений, — не допускать нарушения инвариантов и в этом случае.</p>
          <p>• Минимизировать шансы возникновения взаимоблокировки, ограничивая область действия блокировок и избегая но возможности вложенных блокировок.</p>
          <p>Прежде чем задумываться об этих деталях, важно решить, какие ограничения вы собираетесь наложить на использование структуры данных: если некоторый поток обращается к структуре с помощью некоторой функции, то какие функции можно в этот момент безопасно вызывать из других потоков?</p>
          <p>Это на самом деле весьма важный вопрос. Обычно конструкторы и деструкторы нуждаются в монопольном доступе к структуре данных, но обязанность не обращаться к структуре до завершения конструирования или после начала уничтожения возлагается на пользователя. Если структура поддерживает присваивание, функцию <code>swap()</code> или копирующий конструктор, то проектировщик должен решить, безопасно ли вызывать эти операции одновременно с другими или пользователь должен обеспечить на время их выполнения монопольный доступ, хотя большинство других операций можно без опаски выполнять параллельно из разных потоков.</p>
          <p>Второй аспект, нуждающийся в рассмотрении, — обеспечение истинно параллельного доступа. Тут я не могу предложить конкретных рекомендаций, а вместо этого перечислю несколько вопросов, которые должен задать себе проектировщик структуры данных.</p>
          <p>• Можно ли ограничить область действия блокировок, так чтобы некоторые части операции выполнялись не под защитой блокировки?</p>
          <p>• Можно ли защитить разные части структуры данных разными мьютексами?</p>
          <p>• Все ли операции нуждаются в одинаковом уровне защиты?</p>
          <p>• Можно ли с помощью простого изменения структуры данных расширить возможности распараллеливания, не затрагивая семантику операций?</p>
          <p>В основе всех этих вопросов лежит одна и та же мысль: как свести к минимуму необходимую сериализацию и обеспечить максимально возможную степень истинного параллелизма? Часто бывает так, что структура данных допускает одновременный доступ из нескольких потоков для чтения, но поток, желающий модифицировать данные, должен получать монопольный доступ. Такое требование поддерживает класс <code>boost::shared_mutex</code> и ему подобные. Как мы скоро увидим, встречается и другой случай: поддерживается одновременный доступ из потоков, выполняющих различные операции над структурой, но потоки, выполняющие одну и ту же операцию, сериализуются.</p>
          <p>В простейших потокобезопасных структурах данных обычно для защиты используются мьютексы и блокировки. Хотя, как мы видели в главе 3, им свойственны некоторые проблемы, но гарантировать с их помощью, что в каждый момент времени доступ к данным будет иметь только один поток, сравнительно легко. Мы будем знакомиться с проектированием потокобезопасных структур данных постепенно, и в этой главе рассмотрим только структуры на основе блокировок. А разговор о параллельных структурах данных без блокировок отложим до главы 7.</p>
        </section>
      </section>
      <section>
        <title>
          <p>6.2. Параллельные структуры данных с блокировками</p>
        </title>
        <section>
          <p>Проектирование параллельных структур данных с блокировками сводится к тому, чтобы захватить нужный мьютекс при доступе к данным и удерживать его минимально возможное время. Это довольно сложно, даже когда имеется только один мьютекс, защищающий всю структуру. Как мы видели в главе 3, требуется гарантировать, что к данным невозможно обратиться без защиты со стороны мьютекса и что интерфейс свободен от внутренне присущих состояний гонки. Если для защиты отдельных частей структуры применяются разные мьютексы, то проблема еще усложняется, поскольку в случае, когда некоторые операции требуют захвата нескольких мьютексов, появляется возможность взаимоблокировки. Поэтому к проектированию структуры данных с несколькими мьютексами следует подходить еще более внимательно, чем при наличии единственного мьютекса. В этом разделе мы применим рекомендации из раздела 6.1.1 к проектированию нескольких простых структур данных, защищаемых мьютексами. В каждом случае мы будем искать возможности повысить уровень параллелизма, обеспечивая в то же время потокобезопасность.</p>
          <p>Начнем с реализации стека, приведённой в главе 3; это одна из самых простых структур данных, к тому же в ней используется всего один мьютекс. Но является ли она потокобезопасной? И насколько она хороша с точки зрения достижения истинного распараллеливания?</p>
        </section>
        <section>
          <title>
            <p>6.2.1. Потокобезопасный стек с блокировками</p>
          </title>
          <p>В следующем листинге воспроизведен код потокобезопасного стека из главы 3. Задача состояла в том, чтобы реализовать потокобезопасную структуру данных наподобие <code>std::stack&lt;&gt;</code>, которая поддерживала бы операции заталкивания и выталкивания.</p>
          <empty-line/>
          <p><strong>Листинг 6.1.</strong> Определение класса потокобезопасного стека</p>
          <p>
            <code>#include &lt;exception&gt;</code>
          </p>
          <empty-line/>
          <p>
            <code>struct empty_stack: std::exception {</code>
          </p>
          <p>
            <code> const char* what() const throw();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> std::stack&lt;T&gt; data;</code>
          </p>
          <p>
            <code> mutable std::mutex m;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_stack(){}</code>
          </p>
          <p>
            <code> threadsafe_stack(const threadsafe_stack&amp; other) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(other.m);</code>
          </p>
          <p>
            <code>  data = other.data;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(m);</code>
          </p>
          <p>
            <code>  data.push(std::move(new_value)); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; pop() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(m);</code>
          </p>
          <p>
            <code>  if (data.empty()) throw empty_stack(); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; const res(</code>
          </p>
          <p>
            <code>   std::make_shared&lt;T&gt;(std::move(data.top())));&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  data.pop(); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(m);</code>
          </p>
          <p>
            <code>  if (data.empty()) throw empty_stack();</code>
          </p>
          <p>
            <code>  value = std::move(data.top()); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  data.pop(); &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool empty() const {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(m);</code>
          </p>
          <p>
            <code>  return data.empty();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Посмотрим, как в этом случае применяются сформулированные выше рекомендации. Во-первых, легко видеть, что базовую потокобезопасность обеспечивает защита каждой функции-члена с помощью мьютекса <code>m</code>. Он гарантирует, что в каждый момент времени к данным может обращаться только один поток, поэтому если функции-члены поддерживают какие-то инварианты, то ни один поток не увидит их нарушения.</p>
          <p>Во-вторых, существует потенциальная гонка между <code>empty()</code> и любой из функций <code>pop()</code>, но поскольку мы явно проверяем, что стек пуст, удерживая блокировку в <code>pop()</code>, эта гонка не проблематична. Возвращая извлеченные данные прямо в <code>pop()</code>, мы избегаем потенциальной гонки, которая могла бы случиться, если бы <code>top()</code> и <code>pop()</code> были отдельными функциями-членами, как в <code>std::stack&lt;&gt;</code>.</p>
          <p>Далее, существует несколько возможных источников исключений. Операция захвата мьютекса может возбудить исключение, но, во-первых, это крайне редкий случай (свидетельствующий о проблемах в реализации мьютекса или о нехватке системных ресурсов), а, во-вторых, эта операция всегда выполняется в самом начале любой функции-члена. Поскольку в этот момент никакие данные еще не изменены, опасности нет. Операция освобождения мьютекса не может завершиться ошибкой, она всегда безопасна, а использование <code>std::lock_guard&lt;&gt;</code> гарантирует, что мьютекс не останется захваченным.</p>
          <p>Вызов <code>data.push()</code> <strong>(1)</strong> может возбудить исключение, если его возбуждает копирование или перемещение данных либо если памяти недостаточно для увеличения размера структуры, в которой хранятся сами данные. В любом случае <code>std::stack&lt;&gt;</code> гарантирует безопасность, поэтому здесь проблемы тоже нет.</p>
          <p>В первом перегруженном варианте <code>pop()</code> наш код может возбудить исключение <code>empty_stack</code> <strong>(2)</strong>, но в этот момент еще ничего не изменено, так что мы в безопасности. Создание объекта <code>res</code> (3) может возбудить исключение по двум причинам: при обращении к <code>std::make_shared</code> может не хватить памяти для нового объекта и внутренних данных, необходимых для подсчёта ссылок, или копирующий либо перемещающий конструктор возбуждает исключение при копировании или перемещении данных в только что выделенную область памяти. В обоих случаях исполняющая среда С++ и стандартная библиотека гарантируют отсутствие утечек памяти и корректное уничтожение нового объекта (если он был создан). Поскольку мы все еще не модифицировали данные стека, все хорошо. Вызов <code>data.pop()</code> <strong>(4)</strong> гарантированно не возбуждает исключений, равно как и возврат результата, так что этот вариант <code>pop()</code> безопасен относительно исключений.</p>
          <p>Второй перегруженный вариант <code>pop()</code> аналогичен, только на этот раз исключение может возбудить оператор копирующего или перемещающего присваивания <strong>(5)</strong>, а не конструктор нового объекта или экземпляра <code>std::shared_ptr</code>. Но и теперь мы ничего не изменяли до вызова функции <code>data.pop()</code> <strong>(6)</strong>, которая гарантированно не возбуждает исключений, так что и этот вариант безопасен относительно исключений.</p>
          <p>Наконец, функция <code>empty()</code> вообще не изменяет данные, так что она точно безопасна относительно исключений</p>
          <p>В этом коде есть две возможности для взаимоблокировки из-за того, что пользовательский код вызывается, когда удерживается блокировка: копирующий или перемещающий конструктор <strong>(1)</strong>, <strong>(3)</strong> и копирующий или перемещающий оператор присваивания <strong>(5)</strong> хранимых в стеке данных. И еще — <code>operator new</code>, который также мог бы быть определён пользователем. Если любая из этих функций вызовет функции-члены стека, в который вставляется или из которого удаляется элемент, либо затребует какую-либо блокировку в момент, когда удерживается блокировка, захваченная при вызове функции-члена стека, то может возникнуть взаимоблокировка. Однако было бы разумно возложить ответственность за это на пользователей стека; невозможно представить себе разумную реализацию операций добавления в стек и удаления из стека, которые не копировали бы данные и не выделяли память.</p>
          <p>Поскольку все функции-члены используют для защиты данных класс <code>std::lock_guard&lt;&gt;</code>, их можно безопасно вызывать из любого количества потоков. Единственные небезопасные функции-члены — конструкторы и деструкторы, но эта проблема не особенно серьезна; объект можно сконструировать и уничтожить только один раз. Вызов функций-членов не полностью сконструированного или частично уничтоженного объекта — это всегда плохо, и к одновременности доступа отношения не имеет. Таким образом, пользователь должен гарантировать, что никакой другой поток не может обратиться к стеку, пока он не будет сконструирован полностью, и что любая операция доступа завершается до начала его уничтожения.</p>
          <p>Хотя благодаря блокировке несколько потоков могут одновременно вызывать функции-члены стека, в каждый момент времени с ним реально работает не более одного потока. Такая <emphasis>сериализация</emphasis> потоков может снизить производительность приложения в случае, когда имеется значительная конкуренция за стек, — пока поток ожидает освобождения блокировки, он не выполняет никакой полезной работы. Кроме того, стек не предоставляет средств, позволяющих ожидать добавления элемента. Следовательно, если потоку нужно получить из стека элемент, то он должен периодически опрашивать его с помощью <code>empty()</code> или просто вызывать <code>pop()</code> и обрабатывать исключение <code>empty_stack</code>.</p>
          <p>Поэтому для такого сценария данная реализация стека неудачна, так как ожидающий поток должен либо впустую растрачивать драгоценные ресурсы, ожидая данных, либо пользователь должен писать внешний код ожидания и извещения (например, с помощью условных переменных), который сделает внутренний механизм блокировки избыточным и, стало быть, расточительным. Приведенная в главе 4 реализация очереди демонстрирует, как можно включить такое ожидание в саму структуру данных с помощью условной переменной. Это и станет нашим следующим примером.</p>
        </section>
        <section>
          <title>
            <p>6.2.2. Потокобезопасная очередь с блокировками и условными переменными</p>
          </title>
          <p>В листинге 6.2 воспроизведен код потокобезопасной очереди из главы 4. Если стек построен по образцу <code>std::stack&lt;&gt;</code>, то очередь — по образцу <code>std::queue&lt;&gt;</code>. Но ее интерфейс также отличается от стандартного адаптера контейнера, потому что запись в структуру данных должна быть безопасной относительно одновременного доступа из нескольких потоков.</p>
          <empty-line/>
          <p><strong>Листинг 6.2.</strong> Потокобезопасная очередь с блокировками и условными переменными</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> mutable std::mutex mut;</code>
          </p>
          <p>
            <code> std::queue&lt;T&gt; data_queue;</code>
          </p>
          <p>
            <code> std::condition_variable data_cond;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_queue() {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_queue.push(std::move(data));</code>
          </p>
          <p>
            <code>  data_cond.notify_one(); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void wait_and_pop(T&amp; value) { &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_cond.wait(lk, [this]{return !data_queue.empty();});</code>
          </p>
          <p>
            <code>  value = std::move(data_queue.front());</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; wait_and_pop() &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_cond.wait(lk, [this] {return !data_queue.empty();});&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; res(</code>
          </p>
          <p>
            <code>   std::make_shared&lt;T&gt;(std::move(data_queue.front())));</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool try_pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  if (data_queue.empty())</code>
          </p>
          <p>
            <code>   return false;</code>
          </p>
          <p>
            <code>  value = std::move(data_queue.front());</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  return true;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; try_pop() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  if (data_queue.empty())</code>
          </p>
          <p>
            <code>   return std::shared_ptr&lt;T&gt;(); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; res(</code>
          </p>
          <p>
            <code>   std::make_shared&lt;T&gt;(std::move(data_queue.front())));</code>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool empty() const {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  return data_queue.empty();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Структурно очередь в листинге 6.2 реализована аналогично стеку в листинге 6.1, отличие только в обращениях к функции <code>data_cond.notify_one()</code> в <code>push()</code> <strong>(1)</strong> и в наличии двух вариантов функции <code>wait_and_pop()</code> <strong>(2)</strong>, <strong>(3)</strong>. Оба перегруженных варианта <code>try_pop()</code> почти идентичны функциям <code>pop()</code> в листинге 6.1 с тем отличием, что не возбуждают исключение, если очередь пуста. Вместо этого одна функция возвращает булевское значение, показывающее, были ли извлечены данные, а вторая — возвращающая указатель на данные <strong>(5)</strong> — указатель <code>NULL</code>. Точно так же можно было бы поступить и в случае стека. Таким образом, если оставить в стороне функции <code>wait_and_pop()</code>, то применим тот же анализ, который мы провели для стека.</p>
          <p>Новые функции <code>wait_and_pop()</code> решают проблему ожидания значения в очереди, с которой мы столкнулись при обсуждении стека; вместо того чтобы раз за разом вызывать <code>empty()</code>, ожидающий поток может просто вызвать <code>wait_and_pop()</code>, а структура данных обслужит этот вызов с помощью условной переменной. Обращение к <code>data_cond.wait()</code> не вернет управление, пока во внутренней очереди не появится хотя бы один элемент, так что мы можем не беспокоиться но поводу того, что в этом месте кода возможна пустая очередь. При этом данные по-прежнему защищаются мьютексом. Таким образом, функции <code>wait_and_pop()</code> не вводят новых состояний гонки, не создают возможности взаимоблокировок и не нарушают никаких инвариантов.</p>
          <p>В части безопасности относительно исключений есть мелкая неприятность — если помещения данных в очередь ожидают несколько потоков, то лишь один из них будет разбужен в результате вызова <code>data_cond.notify_one()</code>. Однако если этот поток возбудит исключение в <code>wait_and_pop()</code>, например при конструировании <code>std::shared_ptr&lt;&gt;</code> <strong>(4)</strong>, то ни один из оставшихся потоков разбужен не будет. Если это неприемлемо, то можно заменить <code>notify_one()</code> на <code>data_cond.notify_all()</code>, тогда будут разбужены все потоки, но за это придётся заплатить — большая часть из них сразу же уснет снова, увидев, что очередь по-прежнему пуста. Другой вариант — включить в <code>wait_and_pop()</code> обращение к <code>notify_one()</code> в случае исключения, тогда другой поток сможет попытаться извлечь находящееся в очереди значение. Третий вариант — перенести инициализацию <code>std::shared_ptr&lt;&gt;</code> в <code>push()</code> и сохранять экземпляры <code>std::shared_ptr&lt;&gt;</code>, а не сами значения данных. Тогда при копировании <code>std::shared_ptr&lt;&gt;</code> из внутренней очереди <code>std::queue&lt;&gt;</code> никаких исключений возникнуть не может, и <code>wait_and_pop()</code> становится безопасной. В следующем листинге приведена реализация очереди, переработанная с учетом высказанных соображений.</p>
          <empty-line/>
          <p><strong>Листинг 6.3.</strong> Потокобезопасная очередь, в которой хранятся объекты <code>std::shared_ptr</code></p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> mutable std::mutex mut;</code>
          </p>
          <p>
            <code> std::queue&lt;std::shared_ptr&lt;T&gt; &gt; data_queue;</code>
          </p>
          <p>
            <code> std::condition_variable data_cond;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_queue() {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void wait_and_pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_cond.wait(lk, [this]{return !data_queue.empty();});</code>
          </p>
          <p>
            <code>  value = std::move(*data_queue.front()); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool try_pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  if (data_queue.empty())</code>
          </p>
          <p>
            <code>   return false;</code>
          </p>
          <p>
            <code>  value = std::move(*data_queue.front()); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  return true;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; wait_and_pop() {</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_cond.wait(lk, [this]{return !data_queue.empty();});</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; res = data_queue.front(); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; try_pop() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  if (data_queue.empty())</code>
          </p>
          <p>
            <code>   return std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; res = data_queue.front(); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  data_queue.pop();</code>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data(</code>
          </p>
          <p>
            <code>   std::make_shared&lt;T&gt;(std::move(new_value))); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  data_queue.push(data);</code>
          </p>
          <p>
            <code>  data_cond.notify_one();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool empty() const {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(mut);</code>
          </p>
          <p>
            <code>  return data_queue.empty();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Последствия хранения данных, обернутых в <code>std::shared_ptr&lt;&gt;</code>, понятны: функции pop, которые получают значение из очереди в виде ссылки на переменную, теперь должны разыменовывать указатель <strong>(1)</strong>, <strong>(2)</strong>, а функции <code>pop</code>, которые возвращают <code>std::shared_ptr&lt;&gt;</code>, теперь могут напрямую извлекать его из очереди <strong>(3)</strong>, <strong>(4)</strong> без дальнейших манипуляций.</p>
          <p>У хранения данных в виде <code>std::shared_ptr&lt;&gt;</code> есть и еще одно преимущество: выделение памяти для нового объекта можно производить не под защитой блокировки в <code>push()</code> <strong>(5)</strong>, тогда как в листинге 6.2 это приходилось делать в защищенном участке кода внутри <code>pop()</code>. Поскольку выделение памяти, вообще говоря, дорогая операция, это изменение весьма благотворно скажется на общей производительности очереди, так как уменьшается время удержания мьютекса, а, значит, у остальных потоков остается больше времени на полезную работу.</p>
          <p>Как и в примере стека, применение мьютекса для защиты всей структуры данных ограничивает возможности распараллеливания работы с очередью; хотя ожидать доступа к очереди могут несколько потоков, выполняющих разные функции, в каждый момент лишь один совершает какие-то действия. Однако это ограничение отчасти проистекает из того, что мы пользуемся классом <code>std::queue&lt;&gt;</code>, — стандартный контейнер составляет единый элемент данных, который либо защищен, либо нет. Полностью взяв на себя управление деталями реализации структуры данных, мы сможем обеспечить мелкогранулярные блокировки и повысить уровень параллелизма.</p>
        </section>
        <section>
          <title>
            <p>6.2.3. Потокобезопасная очередь с мелкогранулярными блокировками и условными переменными</p>
          </title>
          <p>В листингах 6.2 и 6.3 имеется только один защищаемый элемент данных (<code>data_queue</code>) и, следовательно, только один мьютекс. Чтобы воспользоваться мелкогранулярными блокировками, мы должны заглянуть внутрь очереди и связать мьютекс с каждым хранящимся в ней элементом данных.</p>
          <p>Проще всего реализовать очередь в виде односвязного списка, как показано на рис. 6.1. Указатель <emphasis>head</emphasis> направлен на первый элемент списка, и каждый элемент указывает на следующий. Когда данные извлекаются из очереди, в <emphasis>head</emphasis> записывается указатель на следующий элемент, после чего возвращается элемент, который до этого был в начале.</p>
          <p>Добавление данных производится с другого конца. Для этого нам необходим указатель <emphasis>tail</emphasis>, направленный на последний элемент списка. Чтобы добавить узел, мы записываем в поле <emphasis>next</emphasis> в последнем элементе указатель на новый узел, после чего изменяем указатель <emphasis>tail</emphasis>, так чтобы он адресовал новый элемент. Если список пуст, то оба указателя <emphasis>head</emphasis> и <emphasis>tail</emphasis> равны <code>NULL</code>.</p>
          <p>В следующем листинге показана простая реализация такой очереди с урезанным по сравнению с листингом 6.2 интерфейсом; мы оставили только функцию <code>try_pop()</code> и убрали функцию <code>wait_and_pop()</code>, потому что эта очередь поддерживает только однопоточную работу.</p>
          <image l:href="#img_16_novyjjrazmer_novyjjrazmer.png"/>
          <p><strong>Рис. 6.1.</strong> Очередь, представленная в виде односвязного списка</p>
          <empty-line/>
          <p><strong>Листинг 6.4.</strong> Простая реализация однопоточной очереди</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  T data;</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; next;</code>
          </p>
          <p>
            <code>  node(T data_):</code>
          </p>
          <p>
            <code>   data(std::move(data_)) {}</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <p>
            <code> std::unique_ptr&lt;node&gt; head;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> node* tail;                &#8592;</code>
            <strong>(2)</strong>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> queue() {}</code>
          </p>
          <p>
            <code> queue(const queue&amp; other) = delete;</code>
          </p>
          <p>
            <code> queue&amp; operator=(const queue&amp; other) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; try_pop() {</code>
          </p>
          <p>
            <code>  if (!head) {</code>
          </p>
          <p>
            <code>   return std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; const res(</code>
          </p>
          <p>
            <code>   std::make_shared&lt;T&gt;(std::move(head-&gt;data)));</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; const old_head = std::move(head);</code>
          </p>
          <p>
            <code>  head = std::move(old_head-&gt;next);&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; p(new node(std::move(new_value)));</code>
          </p>
          <p>
            <code>  node* const new_tail = p.get();</code>
          </p>
          <p>
            <code>  if (tail) {</code>
          </p>
          <p>
            <code>   tail-&gt;next = std::move(p);&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   head = std::move(p);      &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  tail = new_tail;           &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Прежде всего отметим, что в листинге 6.4 для управления узлами используется класс <code>std::unique_ptr&lt;node&gt;</code>, потому что он гарантирует удаление потерявших актуальность узлов (и содержащихся в них данных) без явного использования <code>delete</code>. За передачу владения отвечает <code>head</code>, тогда как <code>tail</code> является простым указателем на последний узел.</p>
          <p>В однопоточном контексте эта реализация прекрасно работает, но при попытке ввести мелкогранулярные блокировки в многопоточном контексте возникают две проблемы. Учитывая наличие двух элементов данных (<code>head</code> <strong>(1)</strong> и <code>tail</code> <strong>(2)</strong>), мы в принципе могли бы использовать два мьютекса — для защиты <code>head</code> и <code>tail</code> соответственно. Но не всё так просто.</p>
          <p>Самая очевидная проблема заключается в том, что <code>push()</code> может изменять как <code>head</code> <strong>(5)</strong>, так и <code>tail</code> <strong>(6)</strong>, поэтому придётся захватывать оба мьютекса. Это не очень хорошо, но не трагедия, потому что захватить два мьютекса, конечно, можно. Настоящая проблема возникает из-за того, что и <code>push()</code>, и <code>pop()</code> обращаются к указателю <code>next</code> в узле: <code>push()</code> обновляет <code>tail-&gt;next</code> <strong>(4)</strong>, a <code>try_pop()</code> читает <code>head-&gt;next</code> <strong>(3)</strong>. Если в очереди всего один элемент, то <code>head==tail</code>, и, значит, <code>head-&gt;next</code> и <code>tail-&gt;next</code> — один и тот же объект, который, следовательно, нуждается в защите. Поскольку нельзя сказать, один это объект или нет, не прочитав и <code>head</code>, и <code>tail</code>, нам приходится захватывать один и тот же мьютекс в <code>push()</code> и в <code>try_pop()</code>, и получается, что мы ничего не выиграли по сравнению с предыдущей реализацией. Есть ли выход из этого тупика?</p>
          <subtitle>Обеспечение параллелизма за счет отделения данных</subtitle>
          <p>Решить проблему можно, заранее выделив фиктивный узел, не содержащий данных, и тем самым гарантировать, что в очереди всегда есть хотя бы один узел, отделяющий голову от хвоста. В случае пустой очереди <code>head</code> и <code>tail</code> теперь указывают на фиктивный узел, а не равны <code>NULL</code>. Это хорошо, потому что <code>try_pop()</code> не обращается к <code>head-&gt;next</code>, если очередь пуста. После добавления в очередь узла (в результате чего в ней находится один реальный узел) <code>head</code> и <code>tail</code> указывают на разные узлы, так что гонки за <code>head-&gt;next</code> и <code>tail-&gt;next</code> не возникает. Недостаток этого решения в том, что нам пришлось добавить лишний уровень косвенности для хранения указателя на данные, чтобы поддержать фиктивный узел. В следующем листинге показано, как теперь выглядит реализация.</p>
          <empty-line/>
          <p><strong>Листинг 6.5.</strong> Простая очередь с фиктивным узлом</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; next;</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::unique_ptr&lt;node&gt; head;</code>
          </p>
          <p>
            <code> node* tail;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> queue():</code>
          </p>
          <p>
            <code><strong> head(new node), tail(head.get())</strong>&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> {}</code>
          </p>
          <empty-line/>
          <p>
            <code> queue(const queue&amp; other) = delete;</code>
          </p>
          <p>
            <code> queue&amp; operator=(const queue&amp; other) = delete;</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; try_pop() {</code>
          </p>
          <p>
            <code><strong>  if (head.get() ==tail)</strong> &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  {</code>
          </p>
          <p>
            <code>   return std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code><strong>  std::shared_ptr&lt;T&gt; const res(head-&gt;data);</strong>&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; old_head = std::move(head);</code>
          </p>
          <p>
            <code>  head = std::move(old_head-&gt;next); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  return res; &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>
              <strong>  std::shared_ptr&lt;T&gt; new_data(</strong>
            </code>
          </p>
          <p>
            <code><strong>   std::make_shared&lt;T&gt;(std::move(new_value)));</strong>&#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code><strong>  std::unique_ptr&lt;node&gt; p(new node);</strong> &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code><strong>  tail-&gt;data = new_data;</strong> &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>  node* const new_tail = p.get();</code>
          </p>
          <p>
            <code>  tail-&gt;next = std::move(p);</code>
          </p>
          <p>
            <code>  tail = new_tail;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Изменения в <code>try_pop()</code> минимальны. Во-первых, мы сравниваем <code>head</code> с <code>tail</code> <strong>(3)</strong>, а не с <code>NULL</code>, потому что благодаря наличию фиктивного узла <code>head</code> никогда не может обратиться в <code>NULL</code>. Поскольку <code>head</code> имеет тип <code>std::unique_ptr&lt;node&gt;</code>, для сравнения необходимо вызывать <code>head.get()</code>. Во-вторых, так как в <code>node</code> теперь хранится указатель на данные <strong>(1)</strong>, то можно извлекать указатель непосредственно <strong>(4)</strong> без конструирования нового экземпляра <code>T</code>. Наиболее серьезные изменения претерпела функция <code>push()</code>: мы должны сначала создать новый экземпляр <code>T</code> в куче и передать владение им <code>std::shared_ptr&lt;&gt;</code> <strong>(7)</strong> (обратите внимание на использование функции <code>std::make_shared</code>, чтобы избежать накладных расходов на второе выделение памяти под счетчик ссылок). Вновь созданный узел станет новым фиктивным узлом, поэтому передавать конструктору значение <code>new_value</code> необязательно <strong>(8)</strong>. Вместо этого мы записываем в старый фиктивный узел значение только что созданной копии — <code>new_value</code> <strong>(9)</strong>. Наконец, первоначальный фиктивный узел следует создать в конструкторе <strong>(2)</strong>.</p>
          <p>Уверен, теперь вы задаетесь вопросом, что мы выиграли от всех этих изменений и как они помогут сделать код потокобезопасным. Разберемся. Функция <code>push()</code> теперь обращается только к <code>tail</code>, но не к <code>head</code>, и это, безусловно, улучшение. <code>try_pop()</code> обращается и к <code>head</code>, и к <code>tail</code>, но <code>tail</code> нужен только для начального сравнения, так что блокировка удерживается очень недолго. Основной выигрыш мы получили за счет того, что из-за наличия фиктивного узла <code>try_pop()</code> и <code>push()</code> никогда не оперируют одним и тем же узлом, так что нам больше не нужен всеохватывающий мьютекс. Стало быть, мы можем завести по одному мьютексу для <code>head</code> и <code>tail</code>. Но где расставить блокировки?</p>
          <p>Мы хотим обеспечить максимум возможностей для распараллеливания, поэтому блокировки должны освобождаться как можно быстрее. С функцией <code>push()</code> всё просто: мьютекс должен быть заблокирован на протяжении всех обращений к <code>tail</code>, а это означает, что мы захватываем его после выделения памяти для нового узла <strong>(8)</strong> и перед тем, как записать данные в текущий последний узел <strong>(9)</strong>. Затем блокировку следует удерживать до конца функции.</p>
          <p>С <code>try_pop()</code> сложнее. Прежде всего, нам нужно захватить мьютекс для <code>head</code> и удерживать его, пока мы не закончим работать с <code>head</code>. По сути дела, этот мьютекс определяет, какой поток производит извлечение из очереди, поэтому захватить его надо в самом начале. После того как значение <code>head</code> изменено <strong>(5)</strong>, мьютекс можно освободить; в момент, когда возвращается результат <strong>(6)</strong>, он уже не нужен. Остается разобраться с защитой доступа к <code>tail</code>. Поскольку мы обращаемся к <code>tail</code> только один раз, то можно захватить мьютекс на время, требуемое для чтения. Проще всего сделать это, поместив операцию доступа в отдельную функцию. На самом деле, поскольку участок кода, в котором мьютекс для <code>head</code> должен быть заблокирован, является частью одной функции-члена, то будет правильнее завести отдельную функцию и для него тоже. Окончательный код приведён в листинге 6.6.</p>
          <empty-line/>
          <p><strong>Листинг 6.6.</strong> Потокобезопасная очередь с мелкогранулярными блокировками</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data;</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; next;</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::mutex head_mutex;</code>
          </p>
          <p>
            <code> std::unique_ptr&lt;node&gt; head;</code>
          </p>
          <p>
            <code> std::mutex tail_mutex;</code>
          </p>
          <p>
            <code> node* tail;</code>
          </p>
          <empty-line/>
          <p>
            <code> node* get_tail() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; tail_lock(tail_mutex);</code>
          </p>
          <p>
            <code>  return tail;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::unique_ptr&lt;node&gt; pop_head() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; head_lock(head_mutex);</code>
          </p>
          <p>
            <code>  if (head.get() == get_tail()) {</code>
          </p>
          <p>
            <code>   return nullptr;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; old_head = std::move(head);</code>
          </p>
          <p>
            <code>  head = std::move(old_head-&gt;next);</code>
          </p>
          <p>
            <code>  return old_head;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_queue():</code>
          </p>
          <p>
            <code>  head(new node), tail(head.get()) {}</code>
          </p>
          <p>
            <code> threadsafe_queue(const threadsafe_queue&amp; other) = delete;</code>
          </p>
          <p>
            <code> threadsafe_queue&amp; operator=(</code>
          </p>
          <p>
            <code>  const threadsafe_queue&amp; other) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; try_pop() {</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; old_head = pop_head();</code>
          </p>
          <p>
            <code>  return old_head ? old_head-&gt;data : std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; new_data(</code>
          </p>
          <p>
            <code>   std::make_shared&lt;T&gt;(std::move(new_value)));</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; p(new node);</code>
          </p>
          <p>
            <code>  node* const new_tail = p.get();</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; tail_lock(tail_mutex);</code>
          </p>
          <p>
            <code>  tail-&gt;data = new_data;</code>
          </p>
          <p>
            <code>  tail-&gt;next = std::move(p);</code>
          </p>
          <p>
            <code>  tail = new_tail;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Давайте взглянем на этот код критически, памятуя о рекомендациях из раздела 6.1.1. Прежде чем искать, где нарушены инварианты, надо бы их точно сформулировать:</p>
          <p>• <code>tail-&gt;next == nullptr</code>.</p>
          <p>• <code>tail-&gt;data == nullptr</code>.</p>
          <p>• <code>head == tail</code> означает, что список пуст.</p>
          <p>• Для списка с одним элементом <code>head-&gt;next==tail</code>.</p>
          <p>• Для каждого узла <code>x</code> списка, для которого <code>x!=tail</code>, <code>x-&gt;data</code> указывает на экземпляр <code>T</code>, a <code>x-&gt;next</code> — на следующий узел списка. Если <code>x-&gt;next==tail</code>, то <code>x</code> — последний узел списка.</p>
          <p>• Если проследовать по указателям <code>next</code>, начиная с головы списка, то рано или поздно мы достигнем его хвоста.</p>
          <p>Сама по себе, функция <code>push()</code> очень проста: все модификации данных защищены мьютексом <code>tail_mutex</code>, и инвариант при этом сохраняется, потому что новый хвостовой узел пуст и правильно установлены указатели <code>data</code> и <code>next</code> для старого хвостового узла, который теперь стал настоящим последним узлом списка.</p>
          <p>Самое интересное происходит в функции <code>try_pop()</code>. Как выясняется, мьютекс <code>tail_mutex</code> нужен не только для защиты чтения самого указателя <code>tail</code>, но и чтобы предотвратить гонку при чтении данных из головного узла. Не будь этого мьютекса, могло бы получиться, что один поток вызывает <code>try_pop()</code>, а другой одновременно вызывает <code>push()</code>, и эти операции никак не упорядочиваются. Хотя каждая функция-член удерживает мьютекс, но это разные <emphasis>мьютексы</emphasis>, а функции могут обращаться к одним и тем же данным — ведь все данные появляются в очереди только благодаря <code>push()</code>. Раз потоки потенциально могут обращаться к одним и тем же данным без какого бы то ни было упорядочения, то возможна гонка за данными и, как следствие (см. главу 5), неопределенное поведение. К счастью, блокировка мьютекса <code>tail_mutex</code> в <code>get_tail()</code> решает все проблемы. Поскольку внутри <code>get_tail()</code> захватывается тот же мьютекс, что в <code>push()</code>, то оба вызова оказываются упорядоченными. Либо обращение к функции <code>get_tail(</code>) происходит раньше обращения к <code>push()</code> — тогда <code>get_tail()</code> увидит старое значение <code>tail</code> — либо после обращения к <code>push()</code> — и тогда она увидит новое значение <code>tail</code> <emphasis>и новые данные, присоединенные к прежнему значению</emphasis> <code><emphasis>tail</emphasis></code>.</p>
          <p>Важно также, что обращение к <code>get_tail()</code> производится под защитой захваченного мьютекса <code>head_mutex</code>. Если бы это было не так, то между вызовом <code>get_tail()</code> и захватом <code>head_mutex</code> мог бы вклиниться вызов <code>pop_head()</code>, потому что другой поток вызвал <code>try_pop()</code> (и, следовательно, <code>pop_head()</code>) и захватил мьютекс первым, не давая первому потоку продолжить исполнение:</p>
          <p>
            <code>                                  &#9474;</code>
            <strong>Эта реализация</strong>
          </p>
          <p>
            <code>std: :unique_ptr&lt;node&gt; pop_head()&#8592;&#9496;</code>
            <strong>некорректна</strong>
          </p>
          <p>
            <code>{                                   </code>
            <strong>(1) Старое значение tail</strong>
          </p>
          <p>
            <code>                                    &#9474;</code>
            <strong>получено не</strong>
          </p>
          <p>
            <code> node* const old_tail = get_tail();&#8592;&#9496;</code>
            <strong>под защитой head_mutex</strong>
          </p>
          <p>
            <code> std::lock_guard&lt;std::mutex&gt; head_lock(head_mutex);</code>
          </p>
          <p>
            <code> if (head.get() == old_tail)      &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  return nullptr;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> std::unique_ptr&lt;node&gt; old_head = std::move(head);</code>
          </p>
          <p>
            <code> head = std::move(old_head-&gt;next);&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> return old_head;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>При такой — <emphasis>некорректной</emphasis> — реализации в случае, когда <code>get_tail()</code> <strong>(1)</strong> вызывается вне области действия блокировки, может оказаться, что и <code>head</code>, и <code>tail</code> изменились к моменту, когда первому потоку удалось захватить <code>head_mutex</code>, и теперь возвращенный хвост мало того что больше не является хвостом, но и вообще не принадлежит списку. Тогда сравнение <code>head</code> с <code>old_tail</code> <strong>(2)</strong> не прошло бы, хотя <code>head</code> в действительности является последним узлом. Следовательно, после обновления <strong>(3)</strong> узел <code>head</code> мог бы оказаться в списке дальше <code>tail</code>, то есть за концом списка, что полностью разрушило бы структуру данных. В <emphasis>корректной</emphasis> реализации, показанной в листинге 6.6, вызов <code>get_tail()</code> производится под защитой <code>head_mutex</code>. Это означает, что больше никакой поток не сможет изменить <code>head</code>, a <code>tail</code> будет только отодвигаться от начала списка (по мере добавления новых узлов с помощью <code>push()</code>) — это вполне безопасно. Указатель <code>head</code> никогда не сможет оказаться дальше значения, возвращенного <code>get_tail()</code>, так что инварианты соблюдаются.</p>
          <p>После того как <code>pop_head()</code> удалит узел из очереди, обновив <code>head</code>, мьютекс освобождается, и <code>try_pop()</code> может извлечь данные и удалить узел, если таковой был (или вернуть <code>NULL</code>-экземпляр класса <code>std::shared_ptr&lt;&gt;</code>, если узла не было), твердо зная, что она работает в единственном потоке, который имеет доступ к этому узлу.</p>
          <p>Далее, внешний интерфейс является подмножеством интерфейса из листинга 6.2, поэтому ранее выполненный анализ остается в силе: в интерфейсе нет внутренне присущих состояний гонки.</p>
          <p>Вопрос об исключениях более интересен. Поскольку мы изменили порядок выделения памяти, исключения могут возникать в других местах. Единственные операции в <code>try_pop()</code>, способные возбудить исключение, — это захваты мьютексов, но пока мьютексы не захвачены, данные не модифицируются. Поэтому <code>try_pop()</code> безопасна относительно исключений. С другой стороны, <code>push()</code> выделяет из кучи память для объектов <code>T</code> и <code>node</code>, и каждая такая операция может возбудить исключение. Однако оба вновь созданных объекта присваиваются интеллектуальным указателям, поэтому в случае исключения память корректно освобождается. После того как мьютекс захвачен, ни одна из последующих операций внутри <code>push()</code> не может возбудить исключение, так что мы снова в безопасности.</p>
          <p>Поскольку мы не изменяли интерфейс, то новых внешних возможностей для взаимоблокировки не возникло. Внутренних возможностей также нет; единственное место, где захватываются два мьютекса, — это функция <code>pop_head()</code>, но она всегда захватывает сначала <code>head_mutex</code>, а потом <code>tail_mutex</code>, так что взаимоблокировки не случится.</p>
          <p>Осталось рассмотреть только один вопрос — в какой мере возможно распараллеливание. Эта структура данных предоставляет куда больше таких возможностей, чем приведенная в листинге 6.2, потому что гранулярность блокировок мельче, и <emphasis>больше работы выполняется не под защитой блокировок</emphasis>. Например, в <code>push()</code> память для нового узла и нового элемента данных выделяется, когда ни одна блокировка не удерживается. Это означает, что несколько потоков могут спокойно выделять новые узлы и элементы данных в одно и то же время. В каждый момент времени только один поток может добавлять новый узел в список, но выполняющий это действие код сводится к нескольким простым присваиваниям указателей, так что блокировка удерживается совсем недолго по сравнению с реализацией на основе <code>std::queue&lt;&gt;</code>, где мьютекс остается захваченным в течение всего времени, пока выполняются операции выделения памяти внутри <code>std::queue&lt;&gt;</code>.</p>
          <p>Кроме того, <code>try_pop()</code> удерживает <code>tail_mutex</code> лишь на очень короткое время, необходимое для защиты чтения <code>tail</code>. Следовательно, почти все действия внутри <code>try_pop()</code> могут производиться одновременно с вызовом <code>push()</code>. Объем операций, выполняемых под защитой мьютекса <code>head_mutex</code> также совсем невелик; дорогостоящая операция <code>delete</code> (в деструкторе указателя на узел) производится вне блокировки. Это увеличивает потенциальное число одновременных обращений к <code>try_pop()</code>; в каждый момент времени только один поток может вызывать <code>pop_head()</code>, зато несколько потоков могут удалять старые узлы и безопасно возвращать данные.</p>
          <subtitle>Ожидание поступления элемента</subtitle>
          <p>Ну хорошо, код в листинге 6.6 дает в наше распоряжение потокобезопасную очередь с мелкогранулярными блокировками, но он поддерживает только функцию <code>try_pop()</code> (и к тому же всего в одном варианте). А как насчет таких удобных функций <code>wait_and_pop()</code>, которые мы написали в листинге 6.2? Сможем ли мы реализовать идентичный интерфейс, сохранив мелкогранулярные блокировки?</p>
          <p>Ответ, разумеется, — да, только вот как это сделать? Модифицировать <code>push()</code> несложно: нужно лишь добавить вызов <code>data_cond.notify_one()</code> в конец функции, как и было в листинге 6.2. Но на самом деле не всё так просто; мы же связались с мелкогранулярными блокировками для того, чтобы увеличить уровень параллелизма. Если оставить мьютекс захваченным на все время вызова <code>notify_one()</code> (как в листинге 6.2), то поток, разбуженный до того, как мьютекс освобожден, должен будет ждать мьютекса. С другой стороны, если освободить мьютекс <emphasis>до</emphasis> обращения к notify_one(), то ожидающий поток сможет захватить его сразу, как проснётся (если, конечно, какой-то другой поток не успеет раньше). Это небольшое улучшение, но в некоторых случаях оно бывает полезно.</p>
          <p>Функция <code>wait_and_pop()</code> сложнее, потому что мы должны решить, где поместить ожидание, какой задать предикат и какой мьютекс захватить. Мы ждем условия «очередь не пуста», оно представляется выражением <code>head != tail</code>. Если записать его в таком виде, то придется захватывать и <code>head_mutex</code>, и <code>tail_mutex</code>, но, разбирая код в листинге 6.6, мы уже поняли, что захватывать <code>tail_mutex</code> нужно только для чтения <code>tail</code>, а не для самого сравнения, та же логика применима и здесь. Если записать предикат в виде <code>head != get_tail()</code>, то нужно будет захватить только <code>head_mutex</code> и использовать уже полученную блокировку для защиты <code>data_cond.wait()</code>. Прочий код такой же, как в <code>try_pop()</code>.</p>
          <p>Второй перегруженный вариант <code>try_pop()</code> и соответствующий ему вариант <code>wait_and_pop()</code> нуждаются в тщательном осмыслении. Если просто заменить возврат указателя <code>std::shared_ptr&lt;&gt;</code>, полученного из <code>old_head</code>, копирующим присваиванием параметру <code>value</code>, то функция перестанет быть безопасной относительно исключений. В этот момент элемент данных уже удален из очереди и мьютекс освобожден, осталось только вернуть данные вызывающей программе. Однако, если копирующее присваивание возбудит исключение (а почему бы и нет?), то элемент данных будет потерян, потому что вернуть его в то же место очереди, где он был, уже невозможно.</p>
          <p>Если фактический тип <code>T</code>, которым конкретизируется шаблон, обладает не возбуждающими исключений оператором перемещающего присваивания или операцией обмена (<code>swap</code>), то так поступить можно, но ведь мы ищем общее решение, применимое к любому типу <code>T</code>. В таком случае следует поместить операции, способные возбудить исключения, в защищенную область перед тем, как удалять узел из списка. Это означает, что нам необходим еще один перегруженный вариант <code>pop_head()</code>, который извлекает сохраненное значение до модификации списка.</p>
          <p>Напротив, модификация функции empty() тривиальна: нужно просто захватить <code>head_mutex</code> и выполнить проверку <code>head == get_tail()</code> (см. листинг 6.10). Окончательный код очереди приведён в листингах 6.7, 6.8, 6.9 и 6.10.</p>
          <empty-line/>
          <p><strong>Листинг 6.7.</strong> Потокобезопасная очередь с блокировкой и ожиданием: внутренние данные и интерфейс</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data;</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; next;</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <p>
            <code> std::mutex head_mutex;</code>
          </p>
          <p>
            <code> std::unique_ptr&lt;node&gt; head;</code>
          </p>
          <p>
            <code> std::mutex tail_mutex;</code>
          </p>
          <p>
            <code> node* tail;</code>
          </p>
          <p>
            <code> std::condition_variable data_cond;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_queue():</code>
          </p>
          <p>
            <code>  head(new node), tail(head.get()) {}</code>
          </p>
          <p>
            <code> threadsafe_queue(const threadsafe_queue&amp; other) = delete;</code>
          </p>
          <p>
            <code> threadsafe_queue&amp; operator=(</code>
          </p>
          <p>
            <code>  const threadsafe_queue&amp; other) = delete;</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; try_pop();</code>
          </p>
          <p>
            <code> bool try_pop(T&amp; value);</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; wait_and_pop();</code>
          </p>
          <p>
            <code> void wait_and_pop(T&amp; value);</code>
          </p>
          <p>
            <code> void push(T new_value);</code>
          </p>
          <p>
            <code> void empty();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Код, помещающий новые узлы в очередь, прост — его реализация (показанная в листинге ниже) близка к той, что мы видели раньше.</p>
          <empty-line/>
          <p><strong>Листинг 6.8.</strong> Потокобезопасная очередь с блокировкой и ожиданием: добавление новых значений</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>void threadsafe_queue&lt;T&gt;::push(T new_value) {</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; new_data(</code>
          </p>
          <p>
            <code>  std::make_shared&lt;T&gt;(std::move(new_value)));</code>
          </p>
          <empty-line/>
          <p>
            <code> std::unique_ptr&lt;node&gt; p(new node);</code>
          </p>
          <p>
            <code> {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; tail_lock(tail_mutex);</code>
          </p>
          <p>
            <code>  tail-&gt;data = new_data;</code>
          </p>
          <p>
            <code>  node* const new_tail = p.get();</code>
          </p>
          <p>
            <code>  tail-&gt;next = std::move(p);</code>
          </p>
          <p>
            <code>  tail = new_tail;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> data_cond.notify_one();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Как уже отмечалось, вся сложность сосредоточена в части <emphasis>pop</emphasis>. В листинге ниже показана реализация функции-члена <code>wait_and_pop()</code> и относящихся к ней вспомогательных функций.</p>
          <empty-line/>
          <p><strong>Листинг 6.9.</strong> Потокобезопасная очередь с блокировкой и ожиданием: <code>wait_and_pop</code></p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> node* get_tail() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; tail_lock(tail_mutex);</code>
          </p>
          <p>
            <code>  return tail;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::unique_ptr&lt;node&gt; pop_head() {&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; old_head = std::move(head);</code>
          </p>
          <p>
            <code>  head = std::move(old_head-&gt;next);</code>
          </p>
          <p>
            <code>  return old_head;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt; wait_for_data() {&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; head_lock(head_mutex);</code>
          </p>
          <p>
            <code>  data_cond.wait(</code>
          </p>
          <p>
            <code>   head_lock, [&amp;]{return head.get() != get_tail();});</code>
          </p>
          <p>
            <code>  return std::move(head_lock);                 &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::unique_ptr&lt;node&gt; wait_pop_head() {</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; head_lock(wait_for_data());&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  return pop_head();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::unique_ptr&lt;node&gt; wait_pop_head(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; head_lock(wait_for_data());&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  value = std::move(*head-&gt;data);</code>
          </p>
          <p>
            <code>  return pop_head();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; wait_and_pop() {</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; const old_head = wait_pop_head();</code>
          </p>
          <p>
            <code>  return old_head-&gt;data;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void wait_and_pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; const old_head = wait_pop_head(value);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В реализации извлечения из очереди используется несколько небольших вспомогательных функций, которые упрощают код и позволяют устранить дублирование, например: <code>pop_head()</code> <strong>(1)</strong> (модификация списка в результате удаления головного элемента) и <code>wait_for_data()</code> <strong>(2)</strong> (ожидание появления данных в очереди). Особенно стоит отметить функцию <code>wait_for_data()</code>, потому что она не только ждет условную переменную, используя лямбда-функцию в качестве предиката, но и возвращает объект блокировки вызывающей программе <strong>(3)</strong>. Тем самым мы гарантируем, что та же самая блокировка удерживается, пока данные модифицируются в соответствующем перегруженном варианте <code>wait_pop_head()</code> <strong>(4)</strong>, <strong>(5)</strong>. Функция <code>pop_head()</code> используется также в функции <code>try_pop()</code>, показанной ниже.</p>
          <empty-line/>
          <p><strong>Листинг 6.10.</strong> Потокобозопасная очередь с блокировкой и ожиданием: <code>try_pop()</code> и <code>empty()</code></p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> std::unique_ptr&lt;node&gt; try_pop_head() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; head_lock(head_mutex);</code>
          </p>
          <p>
            <code>  if (head.get() == get_tail()) {</code>
          </p>
          <p>
            <code>   return std::unique_ptr&lt;node&gt;();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  return pop_head();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::unique_ptr&lt;node&gt; try_pop_head(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; head_lock(head_mutex);</code>
          </p>
          <p>
            <code>  if (head.get() == get_tail()) {</code>
          </p>
          <p>
            <code>   return std::unique_ptr&lt;node&gt;();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  value = std::move(*head-&gt;data);</code>
          </p>
          <p>
            <code>  return pop_head();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; try_pop() {</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; old_head = try_pop_head();</code>
          </p>
          <p>
            <code>  return old_head ? old_head-&gt;data : std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool try_pop(T&amp; value) {</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; const old_head = try_pop_head(value);</code>
          </p>
          <p>
            <code>  return old_head;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void empty() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; head_lock(head_mutex);</code>
          </p>
          <p>
            <code>  return (head.get() == get_tail());</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Эта реализация очереди ляжет в основу очереди без блокировок, которую мы будем рассматривать в главе 7. Данная очередь <emphasis>неограниченная</emphasis>, то есть в нее можно помещать и помещать данные, ничего не удаляя, пока не кончится память. Альтернативой является <emphasis>ограниченная</emphasis> очередь, максимальная длина которой задается при создании. Попытка поместить элемент в заполненную очередь либо завершается ошибкой, либо приводит к приостановке потока до тех пор, пока из очереди не будет удален хотя бы один элемент. Ограниченные очереди бывают полезны для равномерного распределения задач между потоками (см. главу 8). Такая дисциплина не дает потоку (или потокам), заполняющему очередь, намного обогнать потоки, читающие из очереди.</p>
          <p>Показанную реализацию неограниченной очереди легко преобразовать в очередь с ограниченной длиной, введя ожидание условной переменной в функцию <code>push()</code>. Вместо того чтобы ждать, пока в очереди появятся элементы (как <code>pop()</code>), мы должны будем ждать, когда число элементов в ней окажется меньше максимума. Дальнейшее обсуждение ограниченных очередей выходит за рамки этой книги, мы же перейдём от очередей к более сложным структурам данных.</p>
        </section>
      </section>
      <section>
        <title>
          <p>6.3. Проектирование более сложных структур данных с блокировками</p>
        </title>
        <section>
          <p>Стеки и очереди — простые структуры данных, их интерфейс крайне ограничен, и используются они в очень узких целях. Но не все структуры данных так просты, как правило они поддерживают более широкий набор операций. В принципе, это может открыть больше возможностей для распараллеливания, но и проблема защиты данных сильно усложняется, так как приходится учитывать много разных способов доступа. При проектировании структур данных, предназначенных для параллельного доступа, важно принимать во внимание характер выполняемых операций.</p>
          <p>Чтобы понять, какие трудности возникают на этом пути, рассмотрим справочную таблицу (lookup table).</p>
        </section>
        <section>
          <title>
            <p>6.3.1. Разработка потокобезопасной справочной таблицы с блокировками</p>
          </title>
          <p>Справочная таблица, или словарь позволяет ассоциировать значения одного типа (типа ключа) со значениями того же или другого типа (ассоциированного типа). В общем случае задача такой структуры — запрашивать данные, ассоциированные с данным ключом. В стандартной библиотеке С++ для этой цели предназначены ассоциативные контейнеры: <code>std::map&lt;&gt;</code>, <code>std::multimap&lt;&gt;</code>, <code>std::unordered_map&lt;&gt;</code>, и <code>std::unordered_multimap&lt;&gt;</code>.</p>
          <p>Справочная таблица используется иначе, чем стек или очередь. Если большинство операций со стеком и очередью каким-то образом модифицируют структуру данных, то есть либо добавляют, либо удаляют элементы, то справочная таблица изменяется сравнительно редко. Примером может служить простой DNS-кэш из листинга 3.13, предоставляющий интерфейс, сильно урезанный по сравнению с <code>std::map&lt;&gt;</code>. При рассмотрении стека и очереди мы видели, что интерфейсы стандартных контейнеров не годятся для случая, когда к структуре данных одновременно обращаются несколько потоков, так как им внутренне присущи состояния гонки. Поэтому интерфейсы приходится пересматривать и сокращать.</p>
          <p>Самая серьезная с точки зрения распараллеливания проблема в интерфейсе контейнера <code>std::map&lt;&gt;</code> — его итераторы. Можно написать итератор так, что доступ к контейнеру с его помощью для чтения и модификации будет безопасен, но это амбициозная задача. Для корректной работы нужно учесть, что другой поток может удалить элемент, на который итератор сейчас ссылается, а это совсем непросто. Поэтому при первом подходе к проектированию интерфейса потокобезопасной справочной таблицы итераторы мы опустим. Памятуя о том, насколько сильно интерфейс <code>std::map&lt;&gt;</code> (и прочих стандартных ассоциативных контейнеров) зависит от итераторов, пожалуй, будет разумнее сразу отказаться от попыток смоделировать их и вместо этого придумать новый интерфейс с нуля.</p>
          <p>Справочной таблице нужно всего несколько основных операций:</p>
          <p>• добавить новую пару ключ/значение;</p>
          <p>• изменить значение, ассоциированное с данным ключом;</p>
          <p>• удалить ключ и ассоциированное с ним значение;</p>
          <p>• получить значение, ассоциированное с данным ключом, если такой ключ существует.</p>
          <p>Есть также несколько полезных операций, относящихся к контейнеру в целом, например: проверить, пуст ли контейнер, получить полный текущий список ключей или полное множество пар ключ/ значение.</p>
          <p>Если придерживаться базовых рекомендаций, касающихся потокобезопасности, например, не возвращать ссылки и защищать мьютексом все тело каждой функции-члена, то все эти операции будут безопасны. Угроза возникновения гонки возникает прежде всего при добавлении новой пары ключ/значение; если два потока одновременно добавляют новое значение, то лишь один из них будет первым, а второй, следовательно, получит ошибку. Один из способов решить эту проблему состоит в том, чтобы объединить операции добавления и изменения в одной функции-члене, как мы проделали в DNS-кэше в листинге 3.13.</p>
          <p>С точки зрения интерфейса, остается еще лишь один интересный момент: фраза «если такой ключ существует» в описании операции получения ассоциированного значения. Можно, например, предоставить пользователю возможность задать некий результат «по умолчанию», который будет возвращен, если указанного ключа нет.</p>
          <p>
            <code>mapped_type get_value(</code>
          </p>
          <p>
            <code> key_type const&amp; key, mapped_type default_value);</code>
          </p>
          <p>В таком случае можно использовать сконструированный по умолчанию экземпляр типа <code>mapped_type</code>, если <code>default_value</code> не было задано явно. Эту идею можно развить и возвращать не просто экземпляр <code>mapped_type</code>, а объект типа <code>std::pair&lt;mapped_type, bool&gt;</code>, где <code>bool</code> указывает, было ли найдено значение. Другой вариант — использовать интеллектуальный указатель, ссылающийся на значение; если он равен <code>NULL</code>, то значение не было найдено.</p>
          <p>Как уже отмечалось, после определения интерфейса (в предположении, что состояний гонки в нем нет), обеспечить потокобезопасность можно, заведя единственный мьютекс, который дет захватываться в начале каждой функции-члена для защиты внутренней структуры данных. Однако тем самым мы сведем на нет все возможности распараллеливания, которые могли бы открыться в результате наличия отдельных функций для чтения и модификации структуры данных. Отчасти исправить ситуацию можно было бы, воспользовавшись мьютексом, который разрешает нескольким потокам читать данные, но только одному — изменять их, например, классом <code>boost::shared_mutex</code> из листинга 3.13. Это, конечно, несколько улучшило бы общую картину, но при таком решении модифицировать структуру данных по-прежнему может только один поток. В идеале хотелось бы добиться большего.</p>
          <subtitle>Проектирование структуры данных для справочной таблицы с мелкогранулярными блокировками</subtitle>
          <p>Как и в случае очереди (см. раздел 6.2.3), чтобы ввести мелкогранулярные блокировки, нужно внимательно изучить особенности структуры данных, а не пытаться обернуть уже имеющийся контейнер, например <code>std::map&lt;&gt;</code>. Есть три общепринятых подхода к реализации ассоциативного контейнера, каковым является, в частности, справочная таблица:</p>
          <p>• двоичное, например красно-черное, дерево;</p>
          <p>• отсортированный массив;</p>
          <p>• хеш-таблица.</p>
          <p>Двоичное дерево плохо приспособлено для распараллеливания — каждый просмотр или модификация должны начинается с доступа к корневому узлу, который, следовательно, нужно блокировать. Блокировку, конечно, можно освобождать по мере спуска вниз по дереву, но в целом это немногим лучше блокирования всей структуры целиком.</p>
          <p>Отсортированный массив еще хуже, потому что заранее невозможно сказать, в каком месте массива может оказаться требуемое значение, поэтому придется заводить одну блокировку на весь массив. Остается только хеш-таблица. В предположении, что число кластеров фиксировано, вопрос о том, в каком кластере находится ключ, является свойством только лишь самого ключа и хеш-функции. А это значит, что мы сможем завести по одной блокировке на каждый кластер. Если еще и использовать мьютекс, который поддерживает несколько читателей и одного писателя, то коэффициент распараллеливания увеличится в <emphasis>N</emphasis> раз, где <emphasis>N</emphasis> — число кластеров. Недостаток в том, что нужна хорошая хеш-функция для ключа. В стандартной библиотеке С++ имеется шаблон <code>std::hash&lt;&gt;</code>, которым можно воспользоваться для этой цели. Он уже специализирован для таких фундаментальных типов, как <code>int</code>, и некоторых библиотечных типов, например <code>std::string</code>, а пользователь может без труда написать специализации и для других типов ключа. Если, следуя примеру стандартных неупорядоченных контейнеров, указать в качестве параметра шаблона тип объекта-функции, которая выполняет хеширование, то пользователь сможет сам решить, специализировать ли ему шаблон <code>std::hash&lt;&gt;</code> для типа своего ключа или предоставить отдельную хеш-функцию.</p>
          <p>Теперь обратимся собственно к коду. Как могла бы выглядеть реализация потокобезопасной справочной таблицы? Один из вариантов показан ниже.</p>
          <empty-line/>
          <p><strong>Листинг 6.11.</strong> Потокобезопасная справочная таблица</p>
          <p>
            <code>template&lt;typename Key, typename Value,</code>
          </p>
          <p>
            <code>         typename Hash = std::hash&lt;Key&gt; &gt;</code>
          </p>
          <p>
            <code>class threadsafe_lookup_table {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> class bucket_type {</code>
          </p>
          <p>
            <code> private:</code>
          </p>
          <p>
            <code>  typedef std::pair&lt;Key, Value&gt; bucket_value;</code>
          </p>
          <p>
            <code>  typedef std::list&lt;bucket_value&gt; bucket_data;</code>
          </p>
          <p>
            <code>  typedef typename bucket_data::iterator bucket_iterator;</code>
          </p>
          <empty-line/>
          <p>
            <code>  bucket_data data;</code>
          </p>
          <p>
            <code>  mutable boost::shared_mutex mutex;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code>  bucket_iterator find_entry_for(Key const&amp; key) const {&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   return std::find_if(data.begin(), data.end(),</code>
          </p>
          <p>
            <code>                       [&amp;](bucket_value const&amp; item)</code>
          </p>
          <p>
            <code>   { return item.first == key; });</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code> public:</code>
          </p>
          <p>
            <code>  Value value_for(</code>
          </p>
          <p>
            <code>   Key const&amp; key, Value const&amp; default_value) const {</code>
          </p>
          <p>
            <code>   boost::shared_lock&lt;boost::shared_mutex&gt; lock(mutex);&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>   bucket_iterator const found_entry = find_entry_for(key);</code>
          </p>
          <p>
            <code>   return (found_entry==data.end()) ?</code>
          </p>
          <p>
            <code>           default_value : found_entry-&gt;second;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  void add_or_update_mapping(</code>
          </p>
          <p>
            <code>   Key const&amp; key, Value const&amp; value) {</code>
          </p>
          <p>
            <code>   std::unique_lock&lt;boost::shared_mutex&gt; lock(mutex);&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>   bucket_iterator const found_entry = find_entry_for(key);</code>
          </p>
          <p>
            <code>   if (found_entry == data.end()) {</code>
          </p>
          <p>
            <code>    data.push_back(bucket_value(key, value));</code>
          </p>
          <p>
            <code>   } else {</code>
          </p>
          <p>
            <code>    found_entry-&gt;second = value;</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  void remove_mapping(Key const&amp; key) {</code>
          </p>
          <p>
            <code>   std::unique_lock&lt;boost::shared_mutex&gt; lock(mutex);&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>   bucket_iterator const found_entry = find_entry_for(key);</code>
          </p>
          <p>
            <code>   if (found_entry != data.end()) {</code>
          </p>
          <p>
            <code>    data.erase(found_entry);</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::vector&lt;std::unique_ptr&lt;bucket_type&gt;&gt; buckets;&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> Hash hasher;</code>
          </p>
          <empty-line/>
          <p>
            <code> bucket_type&amp; get_bucket(Key const&amp; key) const {&#8592; </code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>  std::size_t const bucket_index = hasher(key)%buckets.size();</code>
          </p>
          <p>
            <code>  return *buckets[bucket_index];</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> typedef Key key_type;</code>
          </p>
          <p>
            <code> typedef Value mapped_type;</code>
          </p>
          <p>
            <code> typedef Hash hash_type;</code>
          </p>
          <empty-line/>
          <p>
            <code> threadsafe_lookup_table(</code>
          </p>
          <p>
            <code>  unsigned num_buckets = 19,</code>
          </p>
          <p>
            <code>  Hash const&amp; hasher_ = Hash()):</code>
          </p>
          <p>
            <code>  buckets(num_buckets), hasher(hasher_) {</code>
          </p>
          <p>
            <code>  for (unsigned i = 0; i &lt; num_buckets; ++i) {</code>
          </p>
          <p>
            <code>   buckets[i].reset(new bucket_type);</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> threadsafe_lookup_table(</code>
          </p>
          <p>
            <code>  threadsafe_lookup_table const&amp; other) = delete;</code>
          </p>
          <p>
            <code> threadsafe_lookup_table&amp; operator=(</code>
          </p>
          <p>
            <code>  threadsafe_lookup_table const&amp; other) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> Value value_for(Key const&amp; key,</code>
          </p>
          <p>
            <code>  Value const&amp; default_value = Value()) const {</code>
          </p>
          <p>
            <code>  return get_bucket(key).value_for(key, default_value);&#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void add_or_update_mapping(Key const&amp; key,Value const&amp; value) {</code>
          </p>
          <p>
            <code>  get_bucket(key).add_or_update_mapping(key, value);&#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void remove_mapping(Key const&amp; key) {</code>
          </p>
          <p>
            <code>  get_bucket(key).remove_mapping(key);&#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В этой реализации для хранения кластеров используется вектор <code>std::vector&lt;std::unique_ptr&lt;bucket_type&gt;&gt;</code> <strong>(6)</strong>, это позволяет задавать число кластеров в конструкторе. По умолчанию оно равно 19 (произвольно выбранное простое число); оптимальные показатели работы хеш-таблиц достигаются, когда имеется простое число кластеров. Каждый кластер защищен мьютексом типа <code>boost::shared_mutex</code> <strong>(1)</strong>, который позволяет нескольким потокам одновременно читать, но только одному обращаться к любой из функций модификации <emphasis>данного кластера</emphasis>.</p>
          <p>Поскольку количество кластеров фиксировано, функцию <code>get_bucket()</code> <strong>(7)</strong> можно вызывать вообще без блокировки <strong>(8)</strong>, <strong>(9)</strong>, <strong>(10)</strong>, а затем захватить мьютекс кластера для совместного (только для чтения) <strong>(3)</strong> или монопольного (чтение/запись) <strong>(4)</strong>, <strong>(5)</strong> владения — в зависимости от вызывающей функции.</p>
          <p>Во всех трех функциях используется функция-член кластера <code>find_entry_for()</code> <strong>(2)</strong>, которая определяет, есть ли в данном кластере указанный ключ. Каждый кластер содержит всего лишь список <code>std::list&lt;&gt;</code> пар ключ/значение, поэтому добавлять и удалять элементы легко.</p>
          <p>Я уже рассматривал это решение с точки зрения распараллеливания, и мы убедились, что все надежно защищено мьютексами. Но как обстоит дело с безопасностью относительно исключений? Функция <code>value_for</code> ничего не изменяет, поэтому с ней проблем нет: если она и возбудит исключение, то на структуру данных это не повлияет.</p>
          <p>Функция <code>remove_mapping</code> модифицирует список, обращаясь к его функции-члену <code>erase</code>, которая гарантированно не возбуждает исключений, так что здесь тоже всё безопасно. Остается функция <code>add_or_update_mapping</code>, которая может возбуждать исключения в обеих ветвях <code>if</code>. Функция <code>push_back</code> безопасна относительно исключений, то есть в случае исключения оставляет список в исходном состоянии, так что с этой ветвью всё хорошо. Единственная проблема — присваивание в случае замены существующего значения; если оператор присваивания возбуждает исключение, то мы полагаемся на то, что он оставляет исходный объект неизмененным. Однако это не влияет на структуру данных в целом и является свойством пользовательского типа, так что пускай пользователь и решает эту проблему.</p>
          <p>В начале этого раздела я упоминал, что было бы хорошо, если бы можно было получить текущее состояние справочной таблицы, например, в виде объекта <code>std::map&lt;&gt;</code>. Чтобы копия состояния была согласована, потребуется заблокировать контейнер целиком, то есть все кластеры сразу. Поскольку для «обычных» операций захватывается мьютекс только одного кластера, то получение копии состояния будет единственной операцией, блокирующей все кластеры. При условии, что мьютексы всегда захватываются в одном и том же порядке, взаимоблокировка не возникнет. Такая реализация приведена в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 6.12.</strong> Получение содержимого таблицы <code>threadsafe_lookup_table</code> в виде <code>std::map&lt;&gt;</code></p>
          <p>
            <code>std::map&lt;Key, Value&gt; threadsafe_lookup_table::get_map() const {</code>
          </p>
          <p>
            <code> std::vector&lt;std::unique_lock&lt;boost::shared_mutex&gt; &gt; locks;</code>
          </p>
          <p>
            <code> for (unsigned i = 0; i &lt; buckets.size(); ++i) {</code>
          </p>
          <p>
            <code>  locks.push_back(</code>
          </p>
          <p>
            <code>   std::unique_lock&lt;boost::shared_mutex&gt;(buckets[i].mutex));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::map&lt;Key, Value&gt; res;</code>
          </p>
          <p>
            <code> for (unsigned i = 0; i &lt; buckets.size(); ++i) {</code>
          </p>
          <p>
            <code>  for (bucket_iterator it = buckets[i].data.begin();</code>
          </p>
          <p>
            <code>  it != buckets[i].data.end(); ++it) {</code>
          </p>
          <p>
            <code>   res.insert(*it);</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> return res;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Реализация справочной таблицы, показанная в листинге 6.11, увеличивает уровень параллелизма таблицы в целом за счет того, что каждый кластер блокируется отдельно, и при этом используется <code>boost::shared_mutex</code>, который позволяет нескольким потокам одновременно читать кластер. Но нельзя ли добиться большего уровня параллелизма, еще уменьшив гранулярность блокировок? В следующем разделе мы покажем, как это сделать, воспользовавшись потокобезопасным списковым контейнером с поддержкой итераторов.</p>
        </section>
        <section>
          <title>
            <p>6.3.2. Потокобезопасный список с блокировками</p>
          </title>
          <p>Список — одна из самых простых структур данных, и, наверное, написать его потокобезопасную версию будет несложно, правда? Все зависит от того, какая вам нужна функциональность и требуется ли поддержка итераторов — та самая, которую я побоялся включать в справочную таблицу на том основании, что это слишком сложно. Основная идея итератора в духе STL состоит в том, что итератор содержит своего рода ссылку на элемент внутренней структуры данных, образующей контейнер. Если контейнер модифицируется из другого потока, то ссылка должна оставаться действительной, а это значит, что итератор должен удерживать блокировку на какую-то часть структуры. Учитывая, что контейнер никак не контролирует время жизни STL-итератора, такой подход абсолютно непродуктивен.</p>
          <p>Альтернатива — включить функции итерирования, например <code>for_each</code>, в сам контейнер. Тогда контейнер сможет полностью управлять своим обходом и блокировкой, но зато перестаёт отвечать рекомендациям но предотвращению взаимоблокировок из главы 3. Чтобы функция <code>for_each</code> делала что-то полезное, она должна вызывать предоставленный пользователем код, удерживая блокировку. Хуже того, она должна передавать ссылку на каждый элемент контейнера пользовательскому коду, чтобы тот мог к этому элементу обратиться. Можно было бы вместо ссылки передавать копию элемента, но это обойдется слишком дорого, если размер элементов велик.</p>
          <p>Таким образом, мы оставим на совести пользователя заботу о предотвращении взаимоблокировок, предупредив его, что в пользовательских функциях не следует ни захватывать блокировки, ни сохранять ссылки, которые могли бы использоваться для доступа к данным вне защиты блокировок и тем самым привести к гонке. В случае внутреннего списка, используемого в реализации справочной таблицы, это абсолютно безопасно, поскольку мы не собираемся делать ничего противозаконного.</p>
          <p>Остается решить, какие операции должен поддерживать список. Вернувшись к листингам 6.11 и 6.12, вы увидите, что именно нам требуется:</p>
          <p>• добавлять элемент в список;</p>
          <p>• удалять элемент из списка, если он удовлетворяет некоторому условию;</p>
          <p>• искать в списке элемент, удовлетворяющий некоторому условию;</p>
          <p>• изменить элемент, удовлетворяющий некоторому условию;</p>
          <p>• скопировать все элементы списка в другой контейнер.</p>
          <p>Чтобы получился приличный списковый контейнер общего назначения, полезно было бы добавить еще кое-какие операции, например вставку в указанную позицию, но для нашей справочной таблицы это излишне, поэтому оставляю реализацию в качестве упражнения для читателя.</p>
          <p>Основная идея связанного списка с мелкогранулярными блокировками — завести по одному мьютексу на каждый узел. Если список длинный, то получится целая куча мьютексов! Достоинство заключается в том, что операции над отдельными частями списка полностью распараллеливаются: каждая операция удерживает только блокировки на узлы, которыми манипулирует, и освобождает блокировку при переходе к следующему узлу. В листинге ниже приведена реализация такого списка.</p>
          <empty-line/>
          <p><strong>Листинг 6.13.</strong> Потокобезопасный список с поддержкой итераторов</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class threadsafe_list {</code>
          </p>
          <p>
            <code> struct node { &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  std::mutex m;</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data;</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; next;</code>
          </p>
          <empty-line/>
          <p>
            <code>  node() : &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   next() {}</code>
          </p>
          <empty-line/>
          <p>
            <code> node(T const&amp; value) : &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  data(std::make_shared&lt;T&gt;(value)) {}</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> node head;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> threadsafe_list() {}</code>
          </p>
          <p>
            <code> ~threadsafe_list() {</code>
          </p>
          <p>
            <code>  remove_if([](node const&amp;){return true;});</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> threadsafe_list(threadsafe_list const&amp; other) = delete;</code>
          </p>
          <p>
            <code> threadsafe_list&amp; operator=(</code>
          </p>
          <p>
            <code>  threadsafe_list const&amp; other) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> void push_front(T const&amp; value) {</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;node&gt; new_node(new node(value));&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(head.m);</code>
          </p>
          <p>
            <code>  new_node-&gt;next = std::move(head.next);          &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  head.next = std::move(new_node);                &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Function&gt;</code>
          </p>
          <p>
            <code> void for_each(Function f) {                     &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>  node* current = &amp;head;</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(head.m);       &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>  while(node* const next = current-&gt;next.get()) {&#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>   std::unique_lock&lt;std::mutex&gt; next_lk(next-&gt;m);&#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>   lk.unlock();            &#8592;</code>
            <strong>(11)</strong>
          </p>
          <p>
            <code>   f(*next-&gt;data);         &#8592;</code>
            <strong>(12)</strong>
          </p>
          <p>
            <code>   current = next;</code>
          </p>
          <p>
            <code>   lk = std::move(next_lk);&#8592;</code>
            <strong>(13)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Predicate&gt;</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; find_first_if(Predicate p) {&#8592;</code>
            <strong>(14)</strong>
          </p>
          <p>
            <code>  node* current = &amp;head;</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(head.m);</code>
          </p>
          <p>
            <code>  while (node* const next=current-&gt;next.get()) {</code>
          </p>
          <p>
            <code>   std::unique_lock&lt;std::mutex&gt; next_lk(next-&gt;m);</code>
          </p>
          <p>
            <code>   lk.unlock();</code>
          </p>
          <p>
            <code>   if (p(*next-&gt;data)) {&#8592;</code>
            <strong>(15)</strong>
          </p>
          <p>
            <code>    return next-&gt;data;  &#8592;</code>
            <strong>(16)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   current = next;</code>
          </p>
          <p>
            <code>   lk = std::move(next_lk);</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  return std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Predicate&gt;             &#8592;</code>
            <strong>(17)</strong>
          </p>
          <p>
            <code> void remove_if(Predicate p) {</code>
          </p>
          <p>
            <code>  node* current = &amp;head;</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt; lk(head.m);</code>
          </p>
          <p>
            <code>  while(node* const next = current-&gt;next.get()) {</code>
          </p>
          <p>
            <code>   std::unique_lock&lt;std::mutex&gt; next_lk(next-&gt;m);</code>
          </p>
          <p>
            <code>   if (p(*next-&gt;data)) {                  &#8592;</code>
            <strong>(18)</strong>
          </p>
          <p>
            <code>    std::unique_ptr&lt;node&gt; old_next = std::move(current-&gt;next);</code>
          </p>
          <p>
            <code>    current-&gt;next = std::move(next-&gt;next);&#8592;</code>
            <strong>(19)</strong>
          </p>
          <p>
            <code>    next_lk.unlock();</code>
          </p>
          <p>
            <code>   }            &#8592;</code>
            <strong>(20)</strong>
          </p>
          <p>
            <code>   else {</code>
          </p>
          <p>
            <code>    lk.unlock();&#8592;</code>
            <strong>(21)</strong>
          </p>
          <p>
            <code>    current = next;</code>
          </p>
          <p>
            <code>    lk = std::move(next_lk);</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Показанный в листинге 6.13 шаблон <code>threadsafe_list&lt;&gt;</code> — это реализация односвязного списка, в котором каждый элемент является структурой типа <code>node</code> <strong>(1)</strong>. В роли головы <code>head</code> списка выступает сконструированный по умолчанию объект <code>node</code>, в котором указатель <code>next</code> равен <code>NULL</code> <strong>(2)</strong>. Новые узлы добавляются в список функцией <code>push_front()</code>; сначала новый узел конструируется <strong>(4)</strong>, при этом для хранимых в нем данных выделяется память из кучи <strong>(3)</strong>, но указатель <code>next</code> остается равным <code>NULL</code>. Затем мы должны захватить мьютекс для узла <code>head</code>, чтобы получить нужное значение указателя next <strong>(5)</strong>, после чего вставить узел в начало списка, записав в <code>head.next</code> указатель на новый узел <strong>(6)</strong>. Пока всё хорошо: для добавления элемента в список необходимо захватить только один мьютекс, поэтому никакого риска взаимоблокировки нет. Кроме того, медленная операция выделения памяти происходит вне блокировки, так что блокировка защищает только обновление двух указателей — действия, которые не могут привести к ошибке. Переходим к функциям итерирования.</p>
          <p>Для начала рассмотрим функцию <code>for_each()</code> <strong>(7)</strong>. Она принимает объект <code>Function</code>, который применяется к каждому элементу списка; следуя примеру большинства библиотечных алгоритмов, этот объект передаётся по значению и может быть как настоящей функцией, так и объектом класса, в котором определена оператор вызова. В данном случае функция должна принимать в качестве единственного параметра значение типа <code>T</code>. Здесь мы производим передачу блокировки. Сначала захватывается мьютекс в головном узле <code>head</code> <strong>(8)</strong>. Теперь можно безопасно получить указатель на следующий узел <code>next</code> (с помощью <code>get()</code>, потому что мы не принимаем на себя владение указателем). Если этот указатель не равен <code>NULL</code> <strong>(9)</strong>, то захватываем мьютекс в соответствующем узле <strong>(10)</strong>, чтобы обработать данные. Получив блокировку для этого узла, мы можем освободить блокировку для предыдущего узла <strong>(11)</strong> и вызвать указанную функцию <strong>(12)</strong>. По выходе из этой функции мы можем обновить указатель <code>current</code> на только что обработанный узел и с помощью <code>move</code> передать владение блокировкой от <code>next_lk</code> в <code>lk</code> <strong>(13)</strong>. Поскольку <code>for_each</code> передаёт каждый элемент данных напрямую пользовательской функции <code>Function</code>, мы можем обновить данные, скопировать их в другой контейнер и вообще сделать всё, что угодно. Если функция не делает того, чего нельзя, то это безопасно, потому что на всем протяжении вызова удерживается мьютекс узла, содержащего элемент данных.</p>
          <p>Функция <code>find_first_if()</code> <strong>(14)</strong> аналогична <code>for_each()</code>; существенное отличие заключается в том, что переданный предикат <code>Predicate</code> должен вернуть <code>true</code>, если нужный элемент найден, и <code>false</code> в противном случае <strong>(15)</strong>. Если элемент найден, то мы сразу возвращаем хранящиеся в нем данные <strong>(16)</strong>, прерывая поиск. Можно было бы добиться того же результата с помощью <code>for_each()</code>, но тогда мы продолжили бы просмотр списка до конца, хотя после обнаружения искомого элемента в этом уже нет необходимости.</p>
          <p>Функция <code>remove_if()</code> <strong>(17)</strong> несколько отличается, потому что она должна изменить список; <code>for_each()</code> для этой цели непригодна. Если предикат <code>Predicate</code> возвращает <code>true</code> <strong>(18)</strong>, то мы удаляем узел из списка, изменяя значение <code>current-&gt;next</code> <strong>(19)</strong>. Покончив с этим, мы можем освободить удерживаемый мьютекс следующего узла. Узел удаляется, когда объект <code>std::unique_ptr&lt;node&gt;</code>, в который мы его переместили, покидает область видимости <strong>(20)</strong>. В данном случае мы не изменяем <code>current</code>, потому что необходимо проверить следующий узел <code>next</code>. Если <code>Predicate</code> возвращает <code>false</code>, то нужно просто продолжить обход списка, как и раньше <strong>(21)</strong>.</p>
          <p>А могут ли при таком обилии мьютексов возникнуть взаимоблокировки или состояния гонки? Ответ — твердое <emphasis>нет</emphasis>, при условии, что полученные от пользователя предикаты и функции ведут себя, как положено. Итерирование всегда производится в одном направлении, начиная с узла <code>head</code>, и следующий мьютекс неизменно блокируется до освобождения текущего, поэтому не может случиться так, что в разных потоках порядок захвата мьютексов будет различен. Единственный потенциальный кандидат на возникновение гонки — удаление исключенного из списка узла в функции <code>remove_if()</code> <strong>(20)</strong>, потому что это делается после освобождения мьютекса (уничтожение захваченного мьютекса приводит к неопределённому поведению). Однако, немного поразмыслив, мы придём к выводу, что это безопасно, так как в этот момент все еще удерживается мьютекс предыдущего узла (<code>current</code>), поэтому ни один другой поток не сможет попытаться захватить мьютекс удаляемого узла.</p>
          <p>Что можно сказать по поводу распараллеливания? Вся эта возня с мелкогранулярными блокировками затевалась для того, чтобы увеличить уровень параллелизма по сравнению с единственным мьютексом. Так достигли мы своей цели или нет? Да, безусловно — теперь разные потоки могут одновременно работать с разными узлами списка, выполняя разные функции: <code>for_each()</code> для обработки каждого узла, <code>find_first_if()</code> для поиска или <code>remove_if()</code> для удаления элементов. Но, поскольку мьютексы узлов захватываются по порядку, потоки не могут обгонять друг друга. Если какой-то поток тратит много времени на обработку конкретного узла, то, дойдя до этого узла, остальные потоки вынуждены будут ждать.</p>
        </section>
      </section>
      <section>
        <title>
          <p>6.4. Резюме</p>
        </title>
        <p>В начале этой главы мы обсудили, что понимается под проектированием структуры данных, допускающей распараллеливание, и сформулировали несколько рекомендаций. Затем на примере нескольких широко распространенных структур данных (стек, очередь, хеш-таблица и связанный список) мы видели, как эти рекомендации применяются на практике — обеспечивают параллельный доступ с применением блокировок и предотвращают гонки. Теперь вы можете проанализировать дизайн своих структур данных и подумать, где в нем есть возможности для распараллеливания, а где возможны состояния гонки.</p>
        <p>В главе 7 мы узнаем, как можно, не отходя от сформулированных рекомендаций, вообще обойтись без блокировок, применяя для обеспечения необходимых ограничений на упорядочение низкоуровневые атомарные операции.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Глава 7</p>
        <p>Проектирование параллельных структур данных без блокировок</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Реализация параллельных структур данных без использования блокировок.</p>
        <p>&#9632; Техника управления памятью в структурах данных без блокировок.</p>
        <p>&#9632; Простые рекомендации по написанию структур данных без блокировок.</p>
      </annotation>
      <section>
        <p>В предыдущей главе мы рассмотрели общие аспекты проектирования параллельных структур данных и сформулировали общие рекомендации, как удостовериться в том, что спроектированная структура безопасна. Затем мы изучили несколько распространенных структур данных и показали, как можно их реализовать с применением мьютексов и блокировок для защиты разделяемых данных. В первых двух примерах мы использовали один мьютекс для защиты всей структуры данных, а в последующих — несколько мьютексов, защищающих более мелкие части структуры, что обеспечило более высокий уровень параллелизма при доступе к данным.</p>
        <p>Мьютексы — это мощный механизм, позволяющий нескольким потокам безопасно обращаться к структуре данных, не нарушая инвариантов и не порождая гонок. Рассуждать о поведении кода, в котором используются мьютексы, сравнительно просто: код либо захватывает защищающий данные мьютекс, либо нет. Но не всё коту масленица — в главе 3 мы видели, что некорректное использование мьютексов может стать причиной взаимоблокировок, а при рассмотрении очереди и справочной таблицы показали, как гранулярность блокировок может влиять на истинно параллельное выполнение программы. Если бы удалось разработать структуры данных, с которыми можно было бы безопасно работать, не прибегая к блокировкам, то эти проблемы вообще не возникали бы. Такие структуры называются структурами данных <emphasis>без блокировок</emphasis>, или <emphasis>свободными от блокировок</emphasis>.</p>
        <p>В этой главе мы рассмотрим, как можно использовать свойства упорядочения доступа к памяти, присущие атомарным операциям (см. главу 5), для настроения структур данных без блокировок. При проектировании таких структур надо проявлять крайнюю осторожность, потому что реализовать их правильно трудно, а условия, при которых проявляются ошибки, могут возникать очень редко. Начнем с ответа на вопрос, что понимается под структурой данных без блокировок. Затем остановимся на причинах, но которым такие структуры полезны, и, наконец, проработаем ряд примеров и дадим некоторые общие рекомендации.</p>
      </section>
      <section>
        <title>
          <p>7.1. Определения и следствия из них</p>
        </title>
        <section>
          <p>Алгоритмы и структуры данных, в которых для синхронизации доступа используются мьютексы, условные переменные и будущие результаты, называются <emphasis>блокирующими</emphasis>. Приложение вызывает библиотечные функции, которые приостанавливают выполнение потока до тех пор, пока другой поток не завершит некоторое действие. Такие библиотечные функции называются <emphasis>блокирующими</emphasis>, потому что поток не может продвинуться дальше некоторой точки, пока не будет снят блокировка. Обычно ОС полностью приостанавливает заблокированный поток (и отдает его временные кванты другому потоку) до тех пор, пока он не будет <emphasis>разблокирован</emphasis> в результате выполнения некоторого действия в другом потоке, будь то освобождение мьютекса, сигнал условной переменной или перевод будущего результата в состояние <emphasis>готов</emphasis>.</p>
          <p>Структуры данных и алгоритмы, в которые блокирующие библиотечные функции не используются, называются <emphasis>неблокирующими</emphasis>. Но не все такие структуры данных <emphasis>свободны от блокировок</emphasis>, поэтому давайте сначала рассмотрим различные типы неблокирующих структур.</p>
        </section>
        <section>
          <title>
            <p>7.1.1. Типы неблокирующих структур данных</p>
          </title>
          <p>В главе 5 мы реализовали простой мьютекс-спинлок с помощью <code>std::atomic_flag</code>. Этот код воспроизведён в листинге ниже.</p>
          <empty-line/>
          <p><strong>Листинг 7.1.</strong> Реализация мьютекса-спинлока с помощью <code>std::atomic_flag</code></p>
          <p>
            <code>class spinlock_mutex {</code>
          </p>
          <p>
            <code> std::atomic_flag flag;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> spinlock_mutex():</code>
          </p>
          <p>
            <code>  flag(ATOMIC_FLAG_INIT) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void lock() {</code>
          </p>
          <p>
            <code>  while (flag.test_and_set(std::memory_order_acquire));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void unlock() {</code>
          </p>
          <p>
            <code>  flag.clear(std::memory_order_release);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Здесь не вызываются никакие блокирующие функции; <code>lock()</code> просто «крутится» в цикле, пока <code>test_and_set()</code> не вернет <code>false</code>. Отсюда и название <emphasis>спинлок</emphasis> (spin lock) — слово spin означает «крутиться». Как бы то ни было, блокирующих вызовов нет, и, значит, любая программа, в которой для защиты разделяемых данных используется такой мьютекс, будет <emphasis>неблокирующей</emphasis>. Однако она не <emphasis>свободна от блокировок</emphasis>. Это по-прежнему мьютекс, который в каждый момент времени может захватить только один поток. Теперь сформулируем определение <emphasis>свободы от блокировок</emphasis> и посмотрим, какие структуры данных под него подпадают.</p>
        </section>
        <section>
          <title>
            <p>7.1.2. Структуры данных, свободные от блокировок</p>
          </title>
          <p>Чтобы структура данных считалась свободной от блокировок, она должна быть открыта для одновременного доступа со стороны сразу нескольких потоков. Не требуется, чтобы потоки могли выполнять одну и ту же операцию; свободная от блокировок очередь может позволять одного потоку помещать, а другому — извлекать данные, но запрещать одновременное добавление данных со стороны двух потоков. Более того, если один из потоков, обращающихся к структуре данных, будет приостановлен планировщиком в середине операции, то остальные должны иметь возможность завершить операцию, не дожидаясь возобновления приостановленного потока.</p>
          <p>Алгоритмы, в которых применяются операции сравнения с обменом, часто содержат циклы. Зачем вообще используются такие операции? Затем, что другой поток может в промежутке модифицировать данные, и тогда программа должна будет повторить часть операции, прежде чем попытается еще раз выполнить сравнение с обменом. Такой код может оставаться свободным от блокировок при условии, что сравнение с обменом в конце концов завершится успешно, если другие потоки будут приостановлены. Если это не так, то мы по существу получаем спинлок, то есть алгоритм неблокирующий, но не свободный от блокировок.</p>
          <p>Свободные от блокировок алгоритмы с такими циклами могут приводить к <emphasis>застреванию</emphasis> (starvation) потоков, когда один поток, выполняющий операции с «неудачным» хронометражем, продвигается вперёд, а другой вынужден постоянно повторять одну и ту же операцию. Структуры данных, в которых такой проблемы не возникает, называются свободными от блокировок и ожидания.</p>
        </section>
        <section>
          <title>
            <p>7.1.3. Структуры данных, свободные от ожидания</p>
          </title>
          <p>Свободная от блокировок структура данных называется свободной от ожидания, если обладает дополнительным свойством: каждый обращающийся к ней поток может завершить свою работу за ограниченное количество шагов вне зависимости от поведения остальных потоков. Алгоритмы, в которых количество шагов может быть неограничено из-за конфликтов с другими потоками, не свободны от ожидания.</p>
          <p>Корректно реализовать свободные от ожидания структуры данных чрезвычайно трудно. Чтобы гарантировать, что каждый поток сможет завершить свою работу за ограниченное количество шагов, необходимо убедиться, что каждая операция может быть выполнена за один проход и что шаги, выполняемые одним потоком, не приводят к ошибке в операциях, выполняемых другими потоками. В результате алгоритмы выполнения различных операций могут значительно усложниться. Учитывая, насколько трудно правильно реализовать структуру данных, свободную от блокировок и ожидания, нужно иметь весьма веские причины для того, чтобы взяться за это дело; требуется тщательно соотносить затраты с ожидаемым выигрышем. Поэтому обсудим, какие факторы влияют на это соотношение.</p>
        </section>
        <section>
          <title>
            <p>7.1.4. Плюсы и минусы структур данных, свободных от блокировок</p>
          </title>
          <p>Основная причина для использования структур данных, свободных от блокировок, — достижение максимального уровня параллелизма. В контейнерах с блокировками всегда есть возможность, что один поток будет приостановлен на время, пока другой не завершит операцию, — в конце концов, основное назначение мьютекса в том и состоит, чтобы предотвратить одновременный доступ за счет взаимного исключения. В случае структуры данных, свободной от блокировок, <emphasis>какой-то</emphasis> поток продвигается вперёд на каждом шаге. Если же структура еще и свободна от ожидания, то вперёд продвигаются все потоки, вне зависимости от того, что в это время делают другие, — необходимости ждать не возникает. Это свойство весьма желательно, но труднодостижимо. На этом пути очень легко скатиться к спинлоку.</p>
          <p>Вторая причина для использования структур данных, свободных от блокировок, — надежность. Если поток завершается, не освободив блокировку, то вся структура данных безвозвратно испорчена. Но если такое происходит с потоком во время операции над структурой данных, свободной от блокировок, то не теряется ничего, кроме данных самого потока; остальные потоки продолжают нормально работать.</p>
          <p>Но у этой медали есть и оборотная сторона: если вы не можете запретить потокам одновременный доступ к структуре, то должны внимательно следить за соблюдением инвариантов или выбирать альтернативные инварианты, соблюдение которых можно гарантировать. Кроме того, следует обращать внимание на ограничения упорядочения, налагаемые на операции. Чтобы избежать неопределённого поведения вследствие гонки за данными, следует использовать для всех модификаций атомарные операции. Но и этого недостаточно — необходимо гарантировать, что изменения становятся видны другим потокам в правильном порядке. Все это означает, что написание потокобезопасных структур данных без использования блокировок гораздо сложнее, чем с блокировками.</p>
          <p>Ввиду отсутствия блокировок невозможны и взаимоблокировки, однако вместо них появляется угроза активных блокировок. <emphasis>Активная блокировка</emphasis> (live lock) возникает, когда два потока одновременно пытаются изменить структуру данных, но каждый из них должен начинать свою операцию сначала из-за изменений, произведенных другим потоком. Таким образом, каждый поток беспрестанно повторяет попытки в цикле. Представьте себе двух людей, пытающихся разойтись в узком проходе. Войдя в него одновременно, они сталкиваются лбами, поэтому оба отступают назад и пробуют еще раз. И так будет повторяться до тех пор, пока кто-то не проскочит первым (по взаимному согласию, потому что оказался быстрее или просто благодаря удаче). Как и в этом простом примере, активные блокировки обычно существуют недолго, потому что зависят от случайных временных соотношений при планировании потоков. Поэтому они скорее «подъедают» производительность, чем вызывают долгосрочные проблемы, но остерегаться их все равно стоит. По определению программа, свободная от блокировок, не страдает от активных блокировок, потому что существует ограничение сверху на количество шагов, необходимых для выполнения операции. Зато и алгоритм, скорее всего, окажется сложнее альтернативного и может потребовать большего числа шагов даже в случае, когда никакой другой поток одновременно не обращается к структуре данных.</p>
          <p>Это подводит нас к еще одному недостатку кода, свободного от блокировок и ожидания: хотя он позволяет лучше распараллелить операции над структурой данных и сократить время ожидания в каждом конкретном потоке, общая производительность программы вполне может <emphasis>упасть</emphasis>. Во-первых, атомарные операции, используемые в свободном от блокировок коде, часто выполняются гораздо медленнее, чем неатомарные, а в структуре данных без блокировок их, скорее всего, будет гораздо больше, чем в аналогичной структуре с блокировками на основе мьютексов. К тому же, оборудование должно как-то синхронизировать данные между потоками, которые обращаются к одним и тем же атомарным переменным. В главе 8 мы увидим, что эффект перебрасывания кэша, возникающий из-за того, что несколько потоков обращаются к одним и тем же атомарным переменным, может привести к существенному падению производительности. Как обычно, необходимо тщательно анализировать аспекты, связанные с производительностью (время ожидания в худшем случае, среднее время ожидания, полное время выполнения и т.д.), для обоих решений — с блокировками и без, — прежде чем остановиться на каком-то одном.</p>
          <p>А теперь перейдём к примерам.</p>
        </section>
      </section>
      <section>
        <title>
          <p>7.2. Примеры структур данных, свободных от блокировок</p>
        </title>
        <section>
          <p>Для демонстрации некоторых приёмов проектирования структур данных, свободных от блокировок, мы рассмотрим реализации ряда простых структур.</p>
          <p>Как уже отмечалось, структуры данных, свободные от блокировок, опираются на использование атомарных операций и связанные с ними гарантии упорядочения доступа к памяти, благодаря которым можно быть уверенным, что изменения данных становятся видны потокам в правильном порядке. Сначала мы будем использовать во всех атомарных операциях принимаемое по умолчанию упорядочение <code>memory_order_seq_cst</code>, потому что оно проще всего для понимания (напомним, что семантика <code>memory_order_seq_cst</code> устанавливает полное упорядочение всех операций). Но позже мы посмотрим, как ослабить некоторые ограничения с помощью семантик <code>memory_order_acquire</code>, <code>memory_order_release</code> и даже <code>memory_order_relaxed</code>. Хотя ни в одном примере мьютексы не используются напрямую, не стоит забывать, что отсутствие блокировок гарантируется только для типа <code>std::atomic_flag</code>. На некоторых платформах в казалось бы свободном от блокировок коде могут использоваться внутренние блокировки, скрытые в реализации стандартной библиотеки С++ (детали см. в главе 5). В этом случае простая структура данных с блокировками может оказаться предпочтительнее, но дело не только в этом; прежде чем выбирать ту или иную реализацию, нужно четко сформулировать требования, а затем подвергнуть профилированию различные решения, удовлетворяющие этим требованиям.</p>
          <p>Итак, снова начнем с простейшей структуры данных — стека.</p>
        </section>
        <section>
          <title>
            <p>7.2.1. Потокобезопасный стек без блокировок</p>
          </title>
          <p>Основное свойство стека понятно: элементы извлекаются в порядке, обратном тому, в котором помещались — последним пришёл, первым ушел (LIFO). Поэтому важно убедиться, что после добавления значения в стек оно может быть сразу же безопасно извлечено другим потоком и что только один поток получает данное значение. Простейшая реализация стека основана на связанном списке; указатель <code>head</code> направлен на первый узел (который будет извлечен следующим), и каждый узел указывает на следующий в списке. При такой схеме добавление узла реализуется просто.</p>
          <p>1. Создать новый узел.</p>
          <p>2. Записать в его указатель <code>next</code> текущее значение <code>head</code>.</p>
          <p>3. Записать в <code>head</code> указатель на новый узел.</p>
          <p>Все это прекрасно работает в однопоточной программе, но, когда стек могут модифицировать сразу несколько потоков, этого недостаточно. Существенно, что если узлы добавляют два потока, то между шагами 2 и 3 возможна гонка: второй поток может модифицировать значение <code>head</code> после того, как первый прочитает его на шаге 2, но до изменения на шаге 3. В таком случае изменения, произведенные вторым потоком, будут отброшены или случится еще что-нибудь похуже. Прежде чем решать эту проблему, следует отметить, что после того, как указатель <code>head</code> будет изменен и станет указывать на новый узел, этот узел может быть прочитан другим потоком. Поэтому крайне важно, чтобы новый узел был аккуратно подготовлен <emphasis>до того</emphasis>, как на него начнет указывать <code>head</code>; потом изменять узел уже нельзя.</p>
          <p>Ну хорошо, а как все-таки быть с этим неприятным состоянием гонки? Ответ таков — использовать атомарную операцию сравнить-и-обменять на шаге 3, гарантирующую, что <code>head</code> не был модифицирован с момента чтения на шаге 2. Если был, то следует вернуться в начало цикла и повторить. В листинге ниже показано, как можно реализовать потокобезопасную функцию <code>push()</code> без блокировок.</p>
          <empty-line/>
          <p><strong>Листинг 7.2.</strong> Реализация функции <code>push()</code> без блокировок</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  T data;</code>
          </p>
          <p>
            <code>  node* next;</code>
          </p>
          <p>
            <code>  node(T const&amp; data_) : &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>   data(data_) {}</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::atomic&lt;node*&gt; head;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void push(T const&amp; data) {</code>
          </p>
          <p>
            <code>  node* const new_node = new node(data);&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  new_node-&gt;next = head.load();         &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  while (!head.compare_exchange_weak(</code>
          </p>
          <p>
            <code>          new_node-&gt;next, new_node));   &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В этом коде дотошно реализованы все три пункта изложенного выше плана: создать новый узел <strong>(2)</strong>, записать в его поле <code>next</code> текущее значение <code>head</code> <strong>(3)</strong> и записать в <code>head</code> указатель на новый узел <strong>(4)</strong>. Заполнив данные самой структуры <code>node</code> в конструкторе <strong>(1)</strong>, мы гарантируем, что узел готов к использованию сразу после конструирования, так что легкая проблема решена. Затем мы вызываем функцию <code>compare_exchange_weak()</code>, которая проверяет, что указатель <code>head</code> по-прежнему содержит то значение, которое было сохранено в <code>new_node-&gt;next</code> <strong>(3)</strong>, и, если это так, то записывает его в <code>new_node</code>. В этой части программы используется также полезное свойство сравнения с обменом: если функция возвращает <code>false</code>, означающее, что сравнение не прошло (например, потому что значение <code>head</code> было изменено другим потоком), то в переменную, которая передана в первом параметре (<code>new_node-&gt;next</code>) записывается текущее значение <code>head</code>. Поэтому нам не нужно перезагружать <code>head</code> на каждой итерации цикла — это сделает за нас компилятор. Кроме того, поскольку мы сразу переходим в начало цикла в случае неудачного сравнения, можно использовать функцию <code>compare_exchange_weak</code>, которая в некоторых архитектурах дает более оптимальный код, чем <code>compare_exchange_strong</code> (см. главу 5).</p>
          <p>Итак, операции <code>pop()</code> у нас пока еще нет, но уже можно сверить реализацию <code>push()</code> с рекомендациями. Единственное место, где возможны исключения, — конструирование нового узла <strong>(1)</strong>, но здесь все будет подчищено автоматически, и, поскольку список еще не модифицирован, то опасности нет. Поскольку мы сами строим данные, сохраняемые в узле <code>node</code>, и используем <code>compare_exchange_weak()</code> для обновления указателя <code>head</code>, то проблематичных состояний гонки здесь нет. Если операция сравнения с обменом завершилась успешно, то узел находится в списке, и его можно извлекать. Так как нет никаких блокировок, то нет и возможности взаимоблокировки, и, стало быть, функция <code>push()</code> успешно сдала экзамен.</p>
          <p>Теперь, когда у нас есть средства для добавления данных в стек, надо научиться их извлекать обратно. На первый взгляд, тут всё просто.</p>
          <p>1. Прочитать текущее значение <code>head</code>.</p>
          <p>2. Прочитать <code>head-&gt;next</code>.</p>
          <p>3. Записать в <code>head</code> значение <code>head-&gt;next</code>.</p>
          <p>4. Вернуть поле <code>data</code>, хранящееся в извлеченном узле <code>node</code>.</p>
          <p>5. Удалить извлеченный узел.</p>
          <p>Однако наличие нескольких потоков осложняет дело. Если два потока пытаются удалить элементы из стека, то оба могут прочитать одно и то же значение <code>head</code> на шаге 1. Если затем один поток успеет выполнить все операции вплоть до шага 5, прежде чем другой доберется до шага 2, то второй поток попробует разыменовать висячий указатель. Это одна из самых серьезных проблем при написании кода, свободного от блокировок, поэтому пока мы просто опустим шаг 5, смирившись с утечкой узлов.</p>
          <p>Однако на этом трудности не кончаются. Есть еще одна проблема: если два потока прочитают одно и то же значение <code>head</code>, то они вернут один и тот же узел. Это вступает в противоречие с самой идеей стека, поэтому должно быть предотвращено любой ценой. Решить проблему можно так же, как мы устранили гонку в <code>push()</code>: использовать для обновления <code>head</code> операцию сравнения с обменом. Если она завершается с ошибкой, значит, либо в промежутке был добавлен новый узел, либо другой поток только что извлек узел, который собирались извлечь мы. В любом случае нужно вернуться на шаг 1 (хотя операция сравнения с обменом автоматически перечитывает <code>head</code>).</p>
          <p>Если сравнение с обменом завершилось успешно, то мы точно знаем, что больше ни один поток не пытался удалить данный узел из стека, поэтому можем без опаски выполнить шаг 4. Вот первая попытка написать код <code>pop()</code>:</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_stack {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void pop(T&amp; result) {</code>
          </p>
          <p>
            <code>  node* old_head = head.load();</code>
          </p>
          <p>
            <code>  while (!head.compare_exchange_weak(old_head, old_head-&gt;next));</code>
          </p>
          <p>
            <code>  result = old_head-&gt;data;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Вроде бы всё красиво и лаконично, но, помимо утечки узлов, осталось еще две проблемы. Во-первых, этот код не работает для пустого списка: если указатель <code>head</code> нулевой, то при попытке прочитать <code>next</code> мы получим неопределённое поведение. Это легко исправить, сравнивая в цикле <code>while</code> значение <code>head</code> с <code>nullptr</code>: если стек оказался пуст, мы можем либо возбудить исключение, либо вернуть булевский индикатор успеха или ошибки.</p>
          <p>Вторая проблема касается безопасности относительно исключений. Впервые подступаясь к потокобезопасному стеку в главе 3, мы видели, что простой возврат объекта по значению небезопасен относительно исключений: если исключение возникает во время копирования возвращаемого значения, то значение будет потеряно. Тогда передача ссылки на результат оказалась приемлемым решением, которое гарантировало неизменность стека в случае исключения. К сожалению, сейчас мы лишены такой роскоши; безопасно скопировать данные можно только тогда, когда мы точно знаем, что больше никакой поток не пытается вернуть данный узел, а <emphasis>это означает, что узел уже удален из стека</emphasis>. Следовательно, передача возвращаемого значения по ссылке больше не является преимуществом, с тем же успехом можно было бы вернуть его и по значению. Чтобы безопасно вернуть значение, придется воспользоваться другим вариантом, описанным в главе 3: возвращать интеллектуальный указатель на данные.</p>
          <p>Возврат <code>nullptr</code> в качестве значения интеллектуального указателя будет означать, что данных в стеке нет, но беда в том, что теперь приходится выделять память из кучи. Если делать это в <code>pop()</code>, то получится, что мы ровным счетом ничего не выиграли, потому что выделение памяти может возбудить исключение. Вместо этого мы будем выделять память в <code>push()</code>, при помещении данных в стек — память-то для структуры <code>node</code> выделять приходится в любом случае. Возврат <code>std::shared_ptr&lt;&gt;</code> не возбуждает исключений, поэтому <code>pop()</code> теперь безопасна. Собрав все вместе, мы получим код, показанный в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 7.3.</strong> Свободный от блокировок стек с утечкой узлов</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node              </code>
            <strong>(1) Теперь данные</strong>
          </p>
          <p>
            <code> {                         &#9474;</code>
            <strong>удерживаются</strong>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data;&#8592;&#9496;</code>
            <strong>указателем</strong>
          </p>
          <p>
            <code>  node* next;</code>
          </p>
          <empty-line/>
          <p>
            <code>  node(T const&amp; data_) :          </code>
            <strong>(2) Создаем std::shared_ptr</strong>
          </p>
          <p>
            <code>   data(std::make_shared&lt;T&gt;(data))&#8592;&#9508;</code>
            <strong>Для только что выде-</strong>
          </p>
          <p>
            <code>   {}                              &#9474;</code>
            <strong>ленного T</strong>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::atomic&lt;node*&gt; head;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void push(T const&amp; data) {</code>
          </p>
          <p>
            <code>  node* const new_node = new node(data);</code>
          </p>
          <p>
            <code>  new_node-&gt;next = head.load();</code>
          </p>
          <p>
            <code>  while (!head.compare_exchange_weak(new_node-&gt;next, new_node));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; pop()</code>
          </p>
          <p><code> {</code>                                                        <strong>(3) Перед разыменованием</strong></p>
          <p><code>  node* old_head = head.load();&#9474;</code><strong>проверяем, что old_head</strong> —</p>
          <p>
            <code>  while (old_head &amp;&amp;          &#8592;&#9496;</code>
            <strong>ненулевой указатель</strong>
          </p>
          <p>
            <code>   !head.compare_exchange_weak(old_head, old_head-&gt;next));</code>
          </p>
          <p>
            <code>  return old_head ? old_head-&gt;data : std::shared_ptr&lt;T&gt;();&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Теперь данные удерживаются указателем <strong>(1)</strong>, поэтому мы должны выделять память для них из кучи в конструкторе узле <strong>(2)</strong>. Кроме того, перед тем как разыменовывать <code>old_head</code> в цикле <code>compare_exchange_weak()</code> <strong>(3)</strong>, следует проверять указатель на нуль. Наконец, мы либо возвращаем ассоциированные с узлом данные, если узел имеется, либо нулевой указатель, если его нет <strong>(4)</strong>. Отметим, что этот алгоритм <emphasis>свободен от блокировок</emphasis>, но не <emphasis>свободен от ожидания</emphasis>, потому что цикл <code>while</code> в <code>push()</code> и <code>pop()</code> теоретически может выполняться бесконечно, если <code>compare_exchange_weak()</code> будет каждый раз возвращать <code>false</code>.</p>
          <p>Если бы у нас был сборщик мусора (как в управляемых языках типа С# или Java), то на этом можно было бы ставить точку — старый узел был бы убран и повторно использован после того, как все потоки перестанут к нему обращаться. Но сегодня мало найдётся компиляторов С++ с встроенным сборщиком мусора, поэтому прибираться за собой нужно самостоятельно.</p>
        </section>
        <section>
          <title>
            <p>7.2.2. Устранение утечек: управление памятью в структурах данных без блокировок</p>
          </title>
          <p>При первом подходе к <code>pop()</code> мы решили смириться с утечкой узлов, чтобы избежать гонки в случае, когда один поток удаляет узел, а другой в это время хранит указатель на него, который собирается разыменовать. Однако в корректной программе на С++ утечка памяти, конечно, недопустима, так что с этим надо что-то делать. Сейчас мы покажем, как эта проблема решается.</p>
          <p>Основная трудность состоит в том, что мы хотим освободить занятую узлом память, но не можем сделать это, пока нет уверенности, что никакой другой поток не хранит указателей на нее. Если бы в каждый момент времени только один поток вызывал <code>pop()</code> для данного экземпляра стека, то все было бы прекрасно. Функция <code>push()</code> не обращается к уже добавленному в стек узлу, так что кроме потока, вызвавшего <code>pop()</code>, этот узел больше никого не интересует, и его можно безопасно удалить.</p>
          <p>С другой стороны, если мы все-таки хотим, чтобы несколько потоков могли одновременно вызывать <code>pop()</code>, то нужно каким-то образом отслеживать момент, когда удаление узла становится безопасным. По сути дела, это означает, что необходимо написать специализированный сборщик мусора для узлов <code>node</code>. Звучит пугающе, и эта задача действительно не самая простая, но на практике все не так плохо: мы проверяем только указатели на <code>node</code> и только те узлы, к которым обращается <code>pop()</code>. Нас не интересуют узлы внутри <code>push()</code>, потому что они доступны только одному потоку, пока не окажутся в стеке. А вот внутри <code>pop()</code> к одному и тому же узлу могут одновременно иметь доступ несколько потоков.</p>
          <p>Если потоков, вызывающих <code>pop()</code>, нет вообще, то можно без опаски удалить все узлы, ожидающие удаления. Поэтому, если после извлечения данных помещать узлы в список «подлежат удалению», то их можно будет удалить одним махом в момент, когда не будет потоков, вызывающих <code>pop()</code>. Но как узнать, что потоков, вызывающих <code>pop()</code>, действительно нет? Очень просто — подсчитывать их. Если увеличивать счетчик при входе и уменьшать при выходе, то удалять узлы из списка «подлежащих удалению» можно будет, когда счетчик становится равным нулю. Разумеется, сам счетчик должен быть атомарным, чтобы к нему можно было безопасно обращаться из нескольких потоков. В листинге 7.4 показала исправленная функция <code>pop()</code>, а в листинге 7.5 — вспомогательные функции, используемые в ее реализации.</p>
          <empty-line/>
          <p><strong>Листинг 7.4.</strong> Освобождение занятой узлами памяти в момент, когда нет потоков, вызывающих <code>pop()</code></p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> std::atomic&lt;unsigned&gt; threads_in_pop;&#8592;&#9488;</code>
            <strong>Атомарная</strong>
          </p>
          <p>
            <code> void try_reclaim(node* old_head);    </code>
            <strong>(1) переменная</strong>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; pop()</code>
          </p>
          <p>
            <code> {                            </code>
            <strong>(2) Увеличить счетчик</strong>
          </p>
          <p>
            <code>  ++threads_in_pop;           &#8592;&#9508;</code>
            <strong>перед тем, как что-то</strong>
          </p>
          <p>
            <code>  node* old_head = head.load();&#9474;</code>
            <strong>делать</strong>
          </p>
          <p>
            <code>  while (old_head &amp;&amp;</code>
          </p>
          <p>
            <code>   !head.compare_exchange_weak(old_head, old_head-&gt;next));</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; res;</code>
          </p>
          <p>
            <code>  if (old_head)</code>
          </p>
          <p>
            <code>  {                         </code>
            <strong>(3) He копировать</strong>
          </p>
          <p>
            <code>   res.swap(old_head-&gt;data);&#8592;&#9508;</code>
            <strong>указатель, а извлечь</strong>
          </p>
          <p>
            <code>  }                          &#9474;</code>
            <strong>данные из узла</strong>
          </p>
          <p>
            <code>  try_reclaim(old_head);&#8592;&#9488;</code>
            <strong>Освободить удаленные</strong>
          </p>
          <p>
            <code>  return res;           </code>
            <strong>(4) узлы, если получится</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Атомарная переменная <code>threads_in_pop</code> <strong>(1)</strong> нужна для подсчета потоков, которые в данный момент пытаются извлечь элемент из стека. Она увеличивается на единицу в начале <code>pop()</code> <strong>(2)</strong> и уменьшается на единицу внутри функции <code>try_reclaim()</code>, которая вызывается после изъятия узла из списка <strong>(4)</strong>. Поскольку мы откладываем удаление самого узла, то можно с помощью <code>swap()</code> переместить из него данные <strong>(3)</strong>, а не просто скопировать указатель; тогда данные будут автоматически удалены, когда в них отпадает необходимость, вместо того, чтобы занимать память только потому, что на них ссылается еще не удаленный узел. В следующем листинге показан код функции <code>try_reclaim()</code>.</p>
          <empty-line/>
          <p><strong>Листинг 7.5.</strong> Механизм освобождения памяти на основе подсчёта ссылок</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> std::atomic&lt;node*&gt; to_be_deleted;</code>
          </p>
          <empty-line/>
          <p>
            <code> static void delete_nodes(node* nodes) {</code>
          </p>
          <p>
            <code>  while (nodes) {</code>
          </p>
          <p>
            <code>   node* next = nodes-&gt;next;</code>
          </p>
          <p>
            <code>   delete nodes;</code>
          </p>
          <p>
            <code>   nodes = next;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void try_reclaim(node* old_head) {</code>
          </p>
          <empty-line/>
          <p>
            <code>  if (threads_in_pop == 1) &#8592;</code>
            <strong>(1) </strong>
          </p>
          <p>
            <code>  {         </code>
            <strong>Заявляем права на список подлежащих удалению узлов (2)</strong>
          </p>
          <p>
            <code>   node* nodes_to_delete = to_be_deleted.exchange(nullptr);&#8592;&#9496;</code>
          </p>
          <p>
            <code>   if (!--threads_in_pop)&#8592;&#9488;</code>
            <strong>Я — единственный</strong>
          </p>
          <p>
            <code>   {                      </code>
            <strong>(3) поток в pop()?</strong>
          </p>
          <p>
            <code>    delete_nodes(nodes_to_delete);       &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>   } else if(nodes_to_delete) {          &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>    chain_pending_nodes(nodes_to_delete);&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   delete old_head; &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   chain_pending_node(old_head); &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>   --threads_in_pop;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void chain_pending_nodes(node* nodes) {</code>
          </p>
          <p>
            <code>  node* last = nodes;</code>
          </p>
          <p>
            <code>  while (node* const next =</code>
          </p>
          <p>
            <code>         last-&gt;next) {&#8592;&#9488;  </code>
            <strong>По указателям</strong>
          </p>
          <p>
            <code>                       &#9500;</code>
            <strong>(9) next доходим до</strong>
          </p>
          <p>
            <code>   last = next;        &#9474;  </code>
            <strong>конца списка</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  chain_pending_nodes(nodes, last);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void chain_pending_nodes(node* first, node* last) {</code>
          </p>
          <p>
            <code>  last-&gt;next = to_be_deleted;&#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>  while (</code>
          </p>
          <p>
            <code>   !to_be_deleted.compare_exchange_weak(&#8592;&#9488;   </code>
            <strong>цикл гарантиру-</strong>
          </p>
          <p>
            <code>   last-&gt;next, first));                  &#9500;</code>
            <strong>(11)ет, что last-&gt;next</strong>
          </p>
          <p>
            <code>  }                                      &#9474;   </code>
            <strong>корректно</strong>
          </p>
          <empty-line/>
          <p>
            <code> void chain_pending_node(node* n) {</code>
          </p>
          <p>
            <code>  chain_pending_nodes(n, n);&#8592;</code>
            <strong>(12)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Если при попытке освободить занятую узлом <strong>(1)</strong> память счетчик <code>threads_in_pop</code> оказывается равен 1, то данный поток — единственный в <code>pop()</code>, и, значит, можно безопасно удалять только что исключенный из списка узел <strong>(7)</strong> и, <emphasis>быть может</emphasis>, также узлы, ожидающие удаления. Если счетчик <emphasis>не</emphasis> равен 1, то никакие узлы удалять нельзя, поэтому мы просто добавляем узел в список ожидающих <strong>(8)</strong>.</p>
          <p>Предположим, что <code>threads_in_pop</code> равно 1. Тогда нам нужно освободить ожидающие узлы, потому что если этого не сделать, то они так и будут ожидать удаления до момента уничтожения стека. Для этого мы запрашиваем монопольные права на список с помощью атомарной операции <code>exchange</code> <strong>(2)</strong>, после чего уменьшаем на единицу счетчик <code>threads_in_pop</code> <strong>(3)</strong>. Если в результате счетчик оказался равным нулю, значит, больше ни один поток не работает со списком ожидающих удаления узлов. По ходу дела могли появиться новые ожидающие узлы, но сейчас — когда можно безопасно очистить список — нам это безразлично. Мы просто вызываем функцию <code>delete_nodes</code>, которая обходит список и удаляет узлы <strong>(4)</strong>.</p>
          <p>Если счетчик после уменьшения <emphasis>не</emphasis> равен нулю, то освобождать узлы небезопасно, поэтому если такие узлы есть <strong>(5)</strong>, то нужно поместить их в начало списка ожидающих <strong>(6)</strong>. Такое может случиться, если к структуре данных одновременно обращаются несколько потоков. Другие потоки могли вызвать <code>pop()</code> в промежутке между первой проверкой <code>threads_in_pop</code> <strong>(1)</strong> и «заявлением прав» на список <strong>(2)</strong> и добавить в список узлы, к которым все еще обращается один или несколько потоков. На рис. 7.1 поток С добавляет узел Y в список <code>to_be_deleted</code>, несмотря на то, что поток В все еще ссылается на него по указателю <code>old_head</code> и, значит, будет пробовать читать его указатель <code>next</code>. Поэтому поток А не может удалить узлы без риска вызвать неопределенное поведение в потоке В.</p>
          <image l:href="#img_17_novyjjrazmer.png"/>
          <p><strong>Рис. 7.1.</strong> На примере трех потоков, вызывающих <code>pop()</code>, видно, почему необходимо проверять <code>threads_in_pop</code> после заявления прав на список узлов, ожидающих удаления, в <code>try_reclaim()</code></p>
          <p>Чтобы поместить узлы, ожидающие удаления, в список ожидающих, мы используем уже имеющийся указатель <code>next</code> для связывания. Для того чтобы добавить цепочку в список, мы проходим до конца цепочки <strong>(9)</strong>, записываем в указатель <code>next</code> в последнем узле текущее значение <code>to_be_deleted</code> <strong>(10)</strong> и сохраняем указатель на первый узел цепочки как новый указатель <code>to_be_deleted</code> <strong>(11)</strong>. Здесь необходимо вызывать <code>compare_exchange_weak</code> в цикле, чтобы не допустить утечки узлов, добавленных другим потоком. В результате в <code>next</code> записывается указатель на последний узел цепочки, если он изменился. Добавление единственного узла в список — это особый случай, когда первый узел в добавляемой цепочке совпадает с последним <strong>(12)</strong>.</p>
          <p>Этот алгоритм работает вполне приемлемо, если нагрузка невелика, то есть существуют моменты <emphasis>затишья</emphasis>, когда в <code>pop()</code> нет ни одного потока. Но эта ситуация кратковременна; именно поэтому мы должны проверять, что счетчик <code>threads_in_pop</code> после уменьшения обратился в нуль <strong>(3)</strong>, прежде чем освобождать память, и по той же причине проверка стоит <emphasis>до</emphasis> удаления только что изъятого из стека узла <strong>(7)</strong>. Удаление узла может занять относительно много времени, а мы хотим, чтобы окно, в котором другие потоки могут модифицировать список, было как можно короче. Чем больше времени проходит между моментом, когда поток впервые обнаружил, что <code>threads_in_pop</code> равно 1, и попыткой удалить узлы, тем больше шансов, что какой-то другой поток вызовет <code>pop()</code>, после чего <code>threads_in_pop</code> перестанет быть равно 1 и, стало быть, удалять узлы станет нельзя.</p>
          <p>Если нагрузка высока, то затишье может не наступить <emphasis>никогда</emphasis>, поскольку новые потоки входят в <code>pop()</code> до того, как пребывавшие там успевают выйти. В таком случае список <code>to_be_deleted</code> будет расти неограниченно, и мы снова сталкиваемся с утечкой памяти. Если периодов затишья не ожидается, то необходим другой механизм освобождения узлов. Главное здесь — определить, когда ни один поток больше не обращается к конкретному узлу, который, следовательно, можно освободить. Из всех возможных механизмов такого рода для понимания проще всего тот, в котором используются <emphasis>указатели опасности</emphasis> (hazard pointers).</p>
        </section>
        <section>
          <title>
            <p>7.2.3. Обнаружение узлов, не подлежащих освобождению, с помощью указателей опасности</p>
          </title>
          <p>Термин <emphasis>указатели опасности</emphasis> откосится к технике, предложенной Магедом Майклом (Maged Michael)<a l:href="#n12" type="note">[12]</a>. Они называются так потому, что удаление узла, на который все еще могут ссылаться другие потоки, — опасное предприятие. Если действительно существует поток, ссылающийся на данный узел, и этот поток попытается обратиться к нему по ссылке, то мы получим неопределенное поведение. Основная идея заключается в том, что поток, собирающийся получить доступ к объекту, который другой поток может захотеть удалить, сначала устанавливает указатель опасности, ссылающийся на этот объект, информируя тем самым другой поток, что удалять этот объект действительно опасно. После того как объект перестает быть нужным, указатель опасности очищается. Если вам доводилось наблюдать гребную регату между командами Оксфорда и Кембриджа, то вы могли видеть аналогичный механизм, применяемый в начале заезда: рулевой в лодке может поднять руку, сообщая, что экипаж еще не готов. Пока хотя бы один рулевой держит руку поднятой, судья не может дать старт заезду. После того как оба рулевых опустят руки, судья может давать старт, однако рулевой вправе снова поднять руку, если заезд еще не начался, а ситуация, на его взгляд, изменилась.</p>
          <p>Собираясь удалить объект, поток должен сначала проверить указатели опасности в других имеющихся в системе потоках. Если ни один из указателей опасности не ссылается на данный объект, то его можно спокойно удалять. В противном случае удаление следует отложить. Периодически поток просматривает список отложенных объектов в поисках тех, которые уже можно удалить.</p>
          <p>Высокоуровневое описание выглядит достаточно простым, но как это сделать на С++?</p>
          <p>Прежде всего, необходимо место для хранения указателя на интересующий нас объект — сам <emphasis>указатель опасности</emphasis>. Это место должно быть видно из всех потоков, причем указатель опасности должен существовать в каждом потоке, который может получить доступ к структуре данных. Корректное и эффективное выделение такого места — непростая задача, поэтому отложим ее на потом, а пока предположим, что существует функция <code>get_hazard_pointer_for_current_thread()</code>, которая возвращает ссылку на указатель опасности. Затем нужно установить указатель опасности перед чтением указателя, который мы намерены разыменовать, — в данном случае указателя <code>head</code> на начало списка:</p>
          <p>
            <code>std::shared_ptr&lt;T&gt; pop() {</code>
          </p>
          <p>
            <code> std::atomic&lt;void*&gt;&amp; hp =</code>
          </p>
          <p>
            <code>  get_hazard_pointer_for_current_thread();</code>
          </p>
          <p>
            <code> node* old_head = head.load();&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> node* temp;</code>
          </p>
          <p>
            <code> do {</code>
          </p>
          <p>
            <code>  temp = old_head;</code>
          </p>
          <p>
            <code>  hp.store(old_head);         &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  old_head = head.load();</code>
          </p>
          <p>
            <code> } while (old_head != temp);  &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> // ...</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Это необходимо делать в цикле <code>while</code>, чтобы узел <code>node</code> случайно не был удалён между чтением старого указателя <code>head</code> <strong>(1)</strong> и установкой указателя опасности <strong>(2)</strong>. В течение этого промежутка времени ни один поток не знает, что мы собираемся обратиться к этому узлу. К счастью, если кто-то собирается удалить старый узел <code>head</code>, то сам указатель <code>head</code> должен был быть изменен, так что мы можем это проверить и не выходить из цикла, пока не будем твердо уверены, что указатель <code>head</code> по-прежнему имеет то же значение, которое было записано в указатель опасности <strong>(3)</strong>. Такое использование указателей опасности опирается на тот факт, что можно безопасно использовать значение указателя даже после того, как объект, на который он указывает, уже удалён. Технически для стандартных реализаций <code>new</code> и <code>delete</code> это считается неопределенным поведением, поэтому либо убедитесь, что ваша реализация стандартной библиотеки допускает такое использование, либо реализуйте собственный распределитель.</p>
          <p>Установив указатель опасности, мы можем продолжить выполнение <code>pop()</code>, будучи уверены, что ни один другой поток не попытается «вытащить» из-под нас узлы. Ну почти уверены: при каждом перечитывании <code>old_head</code> необходимо обновлять указатель опасности перед тем, как разыменовывать вновь прочитанное значение указателя. После того как узел извлечён из списка, мы можем очистить наш собственный указатель опасности. Если на наш узел не ссылаются другие указатели опасности, то его можно удалять; в противном случае его следует поместить в список узлов, ожидающих удаления. В листинге ниже приведен полный код функции <code>pop()</code>, реализованной по такой схеме.</p>
          <empty-line/>
          <p><strong>Листинг 7.6.</strong> Реализация функции <code>pop()</code> с помощью указателей опасности</p>
          <p>
            <code>std::shared_ptr&lt;T&gt; pop() {</code>
          </p>
          <p>
            <code> std::atomic&lt;void*&gt;&amp; hp =</code>
          </p>
          <p>
            <code>  get_hazard_pointer_for_current_thread();</code>
          </p>
          <p>
            <code> node* old_head = head.load();</code>
          </p>
          <p>
            <code> do {</code>
          </p>
          <p>
            <code>  node* temp;</code>
            <strong>(1) Цикл, пока указатель</strong>
          </p>
          <p>
            <code>  do         &#8592;&#9508;</code>
            <strong>опасности не установлен</strong>
          </p>
          <p>
            <code>  {           &#9474;</code>
            <strong>на head</strong>
          </p>
          <p>
            <code>   temp = old_head;</code>
          </p>
          <p>
            <code>   hp.store(old_head);</code>
          </p>
          <p>
            <code>   old_head = head.load();</code>
          </p>
          <p>
            <code>  } while (old_head != temp);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> while (old_head &amp;&amp;</code>
          </p>
          <p>
            <code>  !head.compare_exchange_strong(old_head, old_head-&gt;next))</code>
          </p>
          <p>
            <code>  hp.store(nullptr);&#8592;</code>
            <strong>(2) Закончив, очищаем указатель опасности</strong>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; res;</code>
          </p>
          <p>
            <code> if (old_head) {</code>
          </p>
          <p>
            <code>  res.swap(old_head-&gt;data);</code>
          </p>
          <p>
            <code>  if (outstanding_hazard_pointers_for(old_head))&#8592;&#9488;</code>
            <strong>Прежде чем</strong>
          </p>
          <p>
            <code>  {                                              &#9500;</code>
            <strong>(3) удалять узел,</strong>
          </p>
          <p>
            <code>   reclaim_later(old_head);                      &#9474;</code>
            <strong>проверяем,</strong>
            <code>&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  }                                              &#9474;</code>
            <strong>нет ли ссы-</strong>
          </p>
          <p>
            <code>  else                                           &#9474;</code>
            <strong>лающихся на</strong>
          </p>
          <p>
            <code>  {                                              &#9474;</code>
            <strong>него указате-</strong>
          </p>
          <p>
            <code>                                                 &#9474;</code>
            <strong>лей опасности</strong>
          </p>
          <p>
            <code>   delete old_head; &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  delete_nodes_with_no_hazards();&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> return res;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Начнём с того, что мы перенесли цикл, в котором устанавливается указатель опасности, во внешний цикл, где перечитывается <code>old_head</code>, если операция сравнения с обменом завершается неудачно <strong>(1)</strong>. Здесь мы используем функцию <code>compare_exchange_strong()</code>, потому что фактическая работа делается внутри цикла <code>while</code>: ложный отказ в <code>compare_exchange_weak()</code> привел бы к ненужному сбросу указателя опасности. Таким образом, гарантируется, что указатель опасности установлен перед разыменованием <code>old_head</code>. Заявив свои права на узел, мы можем очистить указатель опасности <strong>(2)</strong>. Получив узел в свое распоряжение, мы должны проверить, не ссылаются ли на него указатели опасности, принадлежащие другим потокам <strong>(3)</strong>. Если это так, то удалять узел пока нельзя, а нужно поместить его в список ожидающих <strong>(4)</strong>; в противном случае узел можно удалять немедленно <strong>(5)</strong>. Наконец, мы добавили вызов функции, в которой проверяется, существуют ли узлы, для которых мы ранее вызывали <code>reclaim_later()</code>. Если не осталось указателей опасности, ссылающихся на эти узлы, то мы можем спокойно удалить их <strong>(6)</strong>. Те же узлы, на которые еще ссылается хотя бы один указатель опасности, остаются в списке и будут проверены следующим потоком, вызвавшим <code>pop()</code>.</p>
          <p>Разумеется, в новых функциях — <code>get_hazard_pointer_for_current_thread()</code>, <code>reclaim_later()</code>, <code>outstanding_hazard_pointers_for()</code> и <code>delete_nodes_with_no_hazards()</code> — скрыта масса деталей, поэтому отдёрнем занавес и посмотрим, как они работают.</p>
          <p>Как именно в функции <code>get_hazard_pointer_for_current_thread()</code> выделяется память для принадлежащих потокам указателей опасности, несущественно для логики программы (хотя, как будет показано ниже, может влиять на эффективность). Поэтому пока ограничимся простой структурой: массивом фиксированного размера, в котором хранятся пары (идентификатор потока, указатель). Функция <code>get_hazard_pointer_for_current_thread()</code> ищет в этом массиве первую свободную позицию и записывает в поле ID идентификатор текущего потока. Когда поток завершается, эта позиция освобождается — в поле ID заносится сконструированное по умолчанию значение <code>std::thread::id()</code>. Этот алгоритм показан в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 7.7.</strong> Простая реализация функции <code>get_hazard_pointer_for_current_thread</code></p>
          <p>
            <code>unsigned const max_hazard_pointers = 100;</code>
          </p>
          <p>
            <code>struct hazard_pointer {</code>
          </p>
          <p>
            <code> std::atomic&lt;std::thread::id&gt; id;</code>
          </p>
          <p>
            <code> std::atomic&lt;void*&gt; pointer;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>hazard_pointer hazard_pointers[max_hazard_pointers];</code>
          </p>
          <empty-line/>
          <p>
            <code>class hp_owner {</code>
          </p>
          <p>
            <code> hazard_pointer* hp;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> hp_owner(hp_owner const&amp;) = delete;</code>
          </p>
          <p>
            <code> hp_owner operator=(hp_owner const&amp;) = delete;</code>
          </p>
          <p>
            <code> hp_owner() :</code>
          </p>
          <p>
            <code>  hp(nullptr) {</code>
          </p>
          <p>
            <code>  for (unsigned i = 0; i &lt; max_hazard_pointers; ++i) {</code>
          </p>
          <p>
            <code>   std::thread::id old_id;</code>
          </p>
          <p>
            <code>   if (</code>
          </p>
          <p>
            <code>    hazard_pointers[i].</code>
          </p>
          <p>
            <code>    id.compare_exchange_strong(         &#8592;&#9488;</code>
          </p>
          <p>
            <code>     old_id, std::this_thread::get_id()))&#9474;</code>
            <strong>Пытаемся заявить</strong>
          </p>
          <p>
            <code>   {                                     &#9474;</code>
            <strong>права на владе-</strong>
          </p>
          <p>
            <code>    hp = &amp;hazard_pointers[i];            &#9474;</code>
            <strong>ние указателем</strong>
          </p>
          <p>
            <code>    break;                               &#9474;</code>
            <strong>опасности</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  if (!hp) {&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>   throw std::runtime_error("No hazard pointers available");</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::atomic&lt;void*&gt;&amp; get_pointer() {</code>
          </p>
          <p>
            <code>  return hp-&gt;pointer;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> ~hp_owner() {&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  hp-&gt;pointer.store(nullptr);</code>
          </p>
          <p>
            <code>  hp-&gt;id.store(std::thread::id());</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>std::atomic&lt;void*&gt;&amp; get_hazard_pointer_for_current_thread()&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>{                                    </code>
            <strong>(4) У каждого потока</strong>
          </p>
          <p>
            <code> thread_local static hp_owner hazard;&#8592;&#9496;</code>
            <strong>свой указатель опасности</strong>
          </p>
          <p>
            <code> return hazard.get_pointer();&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Реализация самой функции <code>get_hazard_pointer_for_current_thread()</code> обманчиво проста <strong>(3)</strong>: в ней объявлена переменная типа <code>hp_owner</code> в поточно-локальной памяти <strong>(4)</strong>, в которой хранится принадлежащий данному потоку указатель опасности. Затем она просто возвращает полученный от этого объекта указатель <strong>(5)</strong>. Работает это следующим образом: в первый раз, когда <emphasis>каждый поток</emphasis> вызывает эту функцию, создается новый экземпляр <code>hp_owner</code>. Его конструктор <strong>(1)</strong> ищет в таблице пар (владелец, указатель) незанятую запись (такую, у которой нет владельца). На каждой итерации цикла он с помощью <code>compare_exchange_strong()</code> атомарно выполняет два действия: проверяет, что у текущей записи нет владельца, и делает владельцем себя <strong>(2)</strong>. Если <code>compare_exchange_strong()</code> возвращает <code>false</code>, значит, записью владеет другой поток, поэтому мы идем дальше. Если же функция вернула <code>true</code>, то мы успешно зарезервировали запись для текущего потока, поэтому можем сохранить ее адрес и прекратить поиск <strong>(3)</strong>. Если мы дошли до конца списка и не обнаружили свободной записи <strong>(4)</strong>, значит, потоков, использующих указатель опасности, слишком много, так что приходится возбуждать исключение.</p>
          <p>После того как экземпляр <code>hp_owner</code> для данного потока создан, последующие обращения происходят гораздо быстрее, потому что указатель запомнен и просматривать таблицу снова нет нужды.</p>
          <p>Когда завершается поток, для которого был создан объект <code>hp_owner</code>, этот объект уничтожается. Прежде чем сохранить в идентификаторе владельца значение <code>std::thread::id()</code>, деструктор записывает в сам указатель значение <code>nullptr</code>, чтобы другие потоки могли повторно использовать эту запись. При такой реализации <code>get_hazard_pointer_for_current_thread()</code> реализация функции <code>outstanding_hazard_pointers_for()</code> совсем проста: требуется только найти переданное значение в таблице указателей опасности:</p>
          <p>
            <code>bool outstanding_hazard_pointers_for(void* p) {</code>
          </p>
          <p>
            <code> for (unsigned i = 0; i &lt; max_hazard_pointers; ++i) {</code>
          </p>
          <p>
            <code>  if (hazard_pointers[i].pointer.load() == p) {</code>
          </p>
          <p>
            <code>   return true;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> return false;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>He нужно даже проверять, есть ли у записи владелец, так как в бесхозных записях все равно хранятся нулевые указатели, поэтому сравнение заведомо вернёт <code>false</code>; это еще упрощает код. Теперь функции <code>reclaim_later()</code> и <code>delete_nodes_with_no_hazards()</code> могут работать с простым связанным списком; <code>reclaim_later()</code> добавляет в него узлы, a <code>delete_nodes_with_no_hazards()</code> удаляет узлы, на которые не ссылаются указатели опасности. Реализация обеих функций приведена в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 7.8.</strong> Простая реализация функций освобождения узлов</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>void do_delete(void* p) {</code>
          </p>
          <p>
            <code> delete static_cast&lt;T*&gt;(p);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>struct data_to_reclaim {</code>
          </p>
          <p>
            <code> void* data;</code>
          </p>
          <p>
            <code> std::function&lt;void(void*)&gt; deleter;</code>
          </p>
          <p>
            <code> data_to_reclaim* next;</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename T&gt;</code>
          </p>
          <p>
            <code> data_to_reclaim(T* p) : &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  data(p),</code>
          </p>
          <p>
            <code>  deleter(&amp;do_delete&lt;T&gt;), next(0) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> ~data_to_reclaim() {</code>
          </p>
          <p>
            <code>  deleter(data); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>std::atomic&lt;data_to_reclaim*&gt; nodes_to_reclaim;</code>
          </p>
          <empty-line/>
          <p>
            <code>void add_to_reclaim_list(data_to_reclaim* node) {&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> node-&gt;next = nodes_to_reclaim.load();</code>
          </p>
          <p>
            <code> while (</code>
          </p>
          <p>
            <code>  !nodes_to_reclaim.compare_exchange_weak(node-&gt;next, node));</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>void reclaim_later(T* data) {                   &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> add_to_reclaim_list(new data_to_reclaim(data));&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void delete_nodes_with_no_hazards() {</code>
          </p>
          <p>
            <code> data_to_reclaim* current =</code>
          </p>
          <p>
            <code>  nodes_to_reclaim.exchange(nullptr);                   &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> while(current) {</code>
          </p>
          <p>
            <code>  data_to_reclaim* const next = current-&gt;next;</code>
          </p>
          <p>
            <code>  if (!outstanding_hazard_pointers_for(current-&gt;data)) {&#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>   delete current;                                      &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   add_to_reclaim_list(current);                        &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  current = next;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Полагаю, вы обратили внимание, что <code>reclaim_later()</code> — шаблон функции, а не обычная функция <strong>(4)</strong>. Объясняется это тем, что указатели опасности — это универсальный механизм, поэтому не стоит ограничивать его только узлами стека. Ранее для хранения указателей мы использовали тип <code>std::atomic&lt;void*&gt;</code>. Поэтому мы должны обрабатывать произвольный указательный тип, но просто указать <code>void*</code> нельзя, так как мы собираемся удалять данные по указателю, а оператору <code>delete</code> нужно знать реальный тип указателя. Как мы скоро увидим, конструктор <code>data_to_reclaim</code> прекрасно справляется с этой проблемой: <code>reclaim_later()</code> просто создает новый экземпляр <code>data_to_reclaim</code> для переданного указателя и добавляет его в список отложенного освобождения <strong>(5)</strong>. Сама функция <code>add_to_reclaim_list()</code> <strong>(3)</strong> — не более чем простой цикл по <code>compare_exchange_weak()</code> для головного элемента списка; мы уже встречались с такой конструкцией раньше.</p>
          <p>Но вернёмся к конструктору <code>data_to_reclaim</code> <strong>(1)</strong>, который также является шаблоном. Он сохраняет подлежащие удалению данные в виде указателя <code>void*</code> в члене <code>data</code>, после чего запоминает указатель на подходящую конкретизацию <code>do_delete()</code> — простую функцию, которая приводит тип <code>void*</code> к типу параметризованного указателя, а затем удаляет объект, на который он указывает. Шаблон <code>std::function&lt;&gt;</code> безопасно обертывает этот указатель на функцию, так что впоследствии деструктору <code>data_to_reclaim</code> для удаления данных нужно всего лишь вызвать запомненную функцию <strong>(2)</strong>.</p>
          <p>Деструктор <code>data_to_reclaim</code> не вызывается, когда мы добавляем узлы в список; он вызывается только, когда на узел не ссылается ни один указатель опасности. За это отвечает функция <code>delete_nodes_with_no_hazards()</code>.</p>
          <p>Эта функция сначала заявляет права на владение всем списком подлежащих освобождению узлов, вызывая <code>exchange()</code> <strong>(6)</strong>. Это простое, но крайне важное действие гарантирует, что данный конкретный набор узлов будет освобождать только один поток. Другие потоки вправе добавлять в список новые узлы и даже пытаться освободить их, никак не затрагивая работу этого потока.</p>
          <p>Далее мы по очереди просматриваем все узлы списка, проверяя, ссылаются ли на них не сброшенные указатели опасности <strong>(7)</strong>. Если нет, то запись можно удалить (очистив хранящиеся в ней данные) <strong>(8)</strong>. В противном случае мы возвращаем элемент в список, чтобы освободить его позже <strong>(9)</strong>.</p>
          <p>Хотя эта простая реализация справляется с задачей безопасного освобождения удаленных узлов, она заметно увеличивает накладные расходы. Для просмотра массива указателей опасности требуется проверить <code>max_hazard_pointers</code> атомарных переменных, и это делается при каждом вызове <code>pop()</code>. Атомарные операции по необходимости работают медленно — зачастую в 100 раз медленнее эквивалентных обычных операций на настольном ПК, — поэтому <code>pop()</code> оказывается дорогостоящей операцией. Мало того что приходится просматривать список указателей опасности для исключаемого из списка узла, так еще надо просмотреть его для каждого узла в списке ожидающих освобождения. Понятно, что это не слишком удачная идея. В списке может храниться <code>max_hazard_pointers</code> узлов, и каждый из них нужно сравнить с <code>max_hazard_pointers</code> хранимых указателей опасности. Черт! Должно существовать решение получше.</p>
          <subtitle>Более быстрые стратегии освобождения с применением указателей опасности</subtitle>
          <p>И оно, конечно же, существует. Показанное выше решение — это простая и наивная реализация указателей опасности, которую я привел, только чтобы объяснить идею. Первое, что можно сделать, — пожертвовать памятью ради быстродействия. Вместо того чтобы проверять каждый узел в списке освобождения при каждом обращении к <code>pop()</code>, мы вообще не будем пытаться освобождать узлы, пока их число в списке не превысит <code>max_hazard_pointers</code>. Тогда мы гарантированно сможем освободить хотя бы один узел. Но если просто ждать, пока в списке накопится <code>max_hazard_pointers+1</code> узлов, то выиграем мы немного. После того как число узлов достигает <code>max_hazard_pointers</code>, мы будем пытаться освобождать их почти при каждом вызове <code>pop()</code>, так что проблема лишь немного отодвинулась во времени. Но если дождаться, пока в списке наберётся <code>2*max_hazard_pointers</code> узлов, то мы гарантированно сможем освободить по крайней мере <code>max_hazard_pointers</code> узлов, и тогда следующую попытку нужно будет делать не раньше, чем через <code>max_hazard_pointers</code> обращений к <code>pop()</code>. Это уже гораздо лучше. Вместо того чтобы просматривать <code>max_hazard_pointers</code> узлов при каждом вызове <code>pop()</code> (и, возможно, ничего не освободить), мы проверяем <code>2*max_hazard_pointers</code> через каждые <code>max_hazard_pointers</code> вызовов <code>pop()</code> и освобождаем не менее <code>max_hazard_pointers</code>. Получается, что в среднем мы проверяем два узла при каждом вызове <code>pop()</code>, и один из них точно освобождается.</p>
          <p>Но и у этого решения есть недостаток (помимо увеличенного расхода памяти): теперь мы должны подсчитывать узлы в списке освобождения, то есть использовать атомарный счетчик, а, кроме того, за доступ к самому списку конкурируют несколько потоков. Если память позволяет, то можно предложить еще более эффективную схему освобождения: каждый поток хранит собственный список освобождения в поточно-локальной памяти. Тогда ни для счетчика, ни для доступа к списку не понадобятся атомарные переменные. Но в обмен придется выделить память для <code>max_hazard_pointers * max_hazard_pointers</code> узлов. Если поток завершается прежде, чем освобождены все его узлы, то оставшиеся можно перенести в глобальный список, как и раньше, а затем добавить в локальный список следующего потока, пожелавшего выполнить процедуру освобождения.</p>
          <p>Еще один недостаток указателей опасности состоит в том, что они защищены патент пой заявкой, поданной IBM<a l:href="#n13" type="note">[13]</a>. Если вы пишете программное обеспечение, которое будет применяться в стране, где эти патенты признаются, то придется получить соответствующую лицензию. Это проблема, общая для многих методов освобождения памяти без блокировок; поскольку в этой области ведутся активные исследования, крупные компании берут патенты всюду, где могут. Возможно, вы задаетесь вопросом, зачем я посвятил так много страниц описанию техники, которой многие не смогут воспользоваться. Что ж, вопрос не праздный. Во-первых, в некоторых случаях ей можно воспользоваться, не платя лицензионных отчислений. Например, если вы разрабатываете бесплатную программу на условиях лицензии GPL<a l:href="#n14" type="note">[14]</a>, то она может подпадать под заявление IBM об отказе от патентных притязаний<a l:href="#n15" type="note">[15]</a>. Во-вторых — и это более существенно — объяснение техники помогает высветить вещи, о которых надо помнить при написании кода, свободного от блокировок, например, о плате за атомарные операции.</p>
          <p>А существуют ли непатентованные методы освобождения памяти, применимые в программах без блокировок? К счастью, да. Один из них — подсчет ссылок.</p>
        </section>
        <section>
          <title>
            <p>7.2.4. Нахождение используемых узлов с помощью подсчета ссылок</p>
          </title>
          <p>В разделе 7.2.2 мы видели, что проблема удаления узлов сводится к задаче нахождения узлов, к которым еще обращаются потоки-читатели. Если бы можно было точно узнать, на какие узлы есть ссылки и когда количество ссылок обращается в нуль, то узлы можно было бы удалить. Указатели опасности решают эту проблему путем хранения списка используемых узлов, а механизм подсчета ссылок — путем хранения числа потоков, обращающихся к каждому узлу.</p>
          <p>Выглядит просто и элегантно, но реализовать на практике очень трудно. Сразу приходит в голову мысль, что для такой задачи подошло бы что-то вроде <code>std::shared_ptr&lt;&gt;</code> — ведь это и есть указатель с подсчетом ссылок. Увы, хотя некоторые операции над <code>std::shared_ptr&lt;&gt;</code> атомарны, не гарантируется, что они свободны от блокировок. Сам по себе класс <code>std::shared_ptr&lt;&gt;</code> ничем не хуже прочих с точки зрения операций над атомарными типами, но он рассчитан на применение в самых разных контекстах, и попытка сделать атомарные операции над ним свободными от блокировок, скорее всего, привела бы к увеличению накладных расходов при любом его использовании. Если на вашей платформе функция <code>std::atomic_is_lock_free(&amp;some_shared_ptr)</code> возвращает <code>true</code>, то проблему освобождения памяти можно считать полностью решенной. Достаточно хранить в списке объекты <code>std::shared_ptr&lt;node&gt;</code>, как показано в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 7.9.</strong> Свободный от блокировок стек на основе свободной от блокировок реализации <code>std::shared_ptr&lt;&gt;</code></p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data;</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;node&gt; next;</code>
          </p>
          <p>
            <code>  node(T const&amp; data_) :</code>
          </p>
          <p>
            <code>   data(std::make_shared&lt;T&gt;(data_)) {}</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;node&gt; head;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void push(T const&amp; data) {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;node&gt; const new_node =</code>
          </p>
          <p>
            <code>   std::make_shared&lt;node&gt;(data);</code>
          </p>
          <p>
            <code>  new_node-&gt;next = head.load();</code>
          </p>
          <p>
            <code>  while (!std::atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code>   &amp;head, &amp;new_node-&gt;next, new_node));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; pop() {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;node&gt; old_head = std::atomic_load(&amp;head);</code>
          </p>
          <p>
            <code>  while(old_head &amp;&amp; !std::atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code>   &amp;head, &amp;old_head, old_head-&gt;next));</code>
          </p>
          <p>
            <code>  return old_head ? old_head-&gt;data : std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В том весьма вероятном случае, когда реализация <code>std::shared_ptr&lt;&gt;</code> не свободна от блокировок, управлять подсчетом ссылок придется самостоятельно.</p>
          <p>В одном из возможных способов используется не один, а два счетчика ссылок — внутренний и внешний. Их сумма равна общему количеству ссылок на узел. Внешний счетчик хранится вместе с указателем на узел и увеличивается при каждом чтении этого указателя. Когда читатель закапчивает работу с узлом, он уменьшает его <emphasis>внутренний</emphasis> счетчик. Таким образом, по завершении простой операции чтения указателя внешний счетчик увеличится на единицу, а внутренний уменьшится на единицу.</p>
          <p>Когда необходимость в связи между внешним счетчиком и указателем отпадает (то есть узел невозможно получить из области памяти, доступной другим потокам), внутренний счетчик увеличивается на величину внешнего минус 1, а внешний отбрасывается. Если внутренний счетчик обратился в нуль, значит, никаких ссылок на узел извне не осталось и его можно удалять. Для обновления разделяемых данных по-прежнему необходимо применять атомарные операции. Теперь рассмотрим реализацию свободного от блокировок стека, в которой эта техника используется для гарантии того, что узлы освобождаются, только когда это безопасно.</p>
          <p>В листинге ниже показала внутренняя структура данных и реализация функции <code>push()</code> — простая и элегантная.</p>
          <empty-line/>
          <p><strong>Листинг 7.10.</strong> Помещение узла в свободный от блокировок стек с разделённым счётчиком ссылок</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node;</code>
          </p>
          <empty-line/>
          <p>
            <code> struct counted_node_ptr {&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  int external_count;</code>
          </p>
          <p>
            <code>  node* ptr;</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data;&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  std::atomic&lt;int&gt; internal_count;</code>
          </p>
          <p>
            <code>  counted_node_ptr next;  &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  node(T const&amp; data_) :</code>
          </p>
          <p>
            <code>   data(std::make_shared&lt;T&gt;(data_)), internal_count(0) {}</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::atomic&lt;counted_node_ptr&gt; head;&#8592;</code>
            <strong>(4)</strong>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> ~lock_free_stack() {</code>
          </p>
          <p>
            <code>  while(pop());</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T const&amp; data) {&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  counted_node_ptr new_node;</code>
          </p>
          <p>
            <code>  new_node.ptr = new node(data);</code>
          </p>
          <p>
            <code>  new_node.external_count = 1;</code>
          </p>
          <p>
            <code>  new_node.ptr-&gt;next = head.load();</code>
          </p>
          <p>
            <code>  while(</code>
          </p>
          <p>
            <code>   !head.compare_exchange_weak(new_node.ptr-&gt;next, new_node));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Обратите внимание, что внешний счетчик хранится вместе с указателем на узел в структуре <code>counted_node_ptr</code> <strong>(1)</strong>. Эта структура затем используется для представления указателя <code>next</code> в структуре <code>node</code> <strong>(3)</strong>, где хранится также внешний счетчик <strong>(2)</strong>. Поскольку <code>counted_node_ptr</code> определена как <code>struct</code>, то ее можно использовать в шаблоне <code>std::atomic&lt;&gt;</code> для представления головы списка <code>head</code> <strong>(4)</strong>.</p>
          <p>На платформах, где поддерживается операция сравнения и обмена двойного слова, размер этой структуры достаточно мал для того, чтобы тип данных <code>std::atomic&lt;counted_node_ptr&gt;</code> был свободен от блокировок. Если вы работаете на другой платформе, то лучше пользоваться вариантом <code>std::shared_ptr&lt;&gt;</code>, приведенным в листинге 7.9, потому что в <code>std::atomic&lt;&gt;</code> для гарантирования атомарности используется мьютекс, когда тип слишком велик и с помощью машинных команд обеспечить атомарность невозможно (а, следовательно, ваш алгоритм, якобы «свободный от блокировок», на самом теле таковым не является). Можно поступить и по-другому — если вы готовы ограничить размер счетчика и знаете, что на данной платформе в указателе есть неиспользуемые биты (например, потому что адресное пространство представлено 48 битами, а под указатель отводится 64 бита), то счетчик можно хранить в незанятых битах указателя, и тогда оба поля поместятся в одно машинное слово. Но для таких трюков нужно хорошо знать особенности платформы, так что в этой книге мы их обсуждать не будем.</p>
          <p>Функция <code>push()</code> относительно проста <strong>(5)</strong>. Мы конструируем объект <code>counted_node_ptr</code>, ссылающийся на только что выделенный узел <code>node</code> с ассоциированными данными, и в поле <code>next</code> узла <code>node</code> записываем текущее значение <code>head</code>. Затем с помощью <code>compare_exchange_weak()</code> устанавливаем новое значение <code>head</code>, как и раньше. Внутренний счетчик <code>internal_count</code> инициализируется нулем, а внешний <code>external_count</code> — единицей. Поскольку узел новый, на него пока существует только одна внешняя ссылка (из самого указателя <code>head</code>).</p>
          <p>Как обычно, все сложности сосредоточены в реализации <code>pop()</code>, показанной в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 7.11.</strong> Выталкивание узла из свободного от блокировок стека с разделённым счётчиком ссылок</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> void increase_head_count(counted_node_ptr&amp; old_counter) {</code>
          </p>
          <p>
            <code>  counted_node_ptr new_counter;</code>
          </p>
          <p>
            <code>  do {</code>
          </p>
          <p>
            <code>   new_counter = old_counter;</code>
          </p>
          <p>
            <code>   ++new_counter.external_count;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  while (</code>
          </p>
          <p>
            <code>   !head.compare_exchange_strong(old_counter, new_counter));&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  old_counter.external_count = new_counter.external_count;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> std::shared_ptr&lt;T&gt; pop() {</code>
          </p>
          <p>
            <code>  counted_node_ptr old_head = head.load();</code>
          </p>
          <p>
            <code>  for (;;) {</code>
          </p>
          <p>
            <code>   increase_head_count(old_head);</code>
          </p>
          <p>
            <code>   node* const ptr = old_head.ptr;&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   if (!ptr) {</code>
          </p>
          <p>
            <code>    return std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   if (head.compare_exchange_strong(old_head, ptr-&gt;next)) {&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>    std::shared_ptr&lt;T&gt; res;</code>
          </p>
          <p>
            <code>    res.swap(ptr-&gt;data);                                   &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>    int const count_increase = old_head.external_count - 2;&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>    if (ptr-&gt;internal_count.fetch_add(count_increase) ==</code>
          </p>
          <p>
            <code>        -count_increase) {                                 &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>     delete ptr;</code>
          </p>
          <p>
            <code>    }</code>
          </p>
          <p>
            <code>    return res; &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>   } else if (ptr-&gt;internal_count.fetch_sub(1) == 1) {</code>
          </p>
          <p>
            <code>    delete ptr; &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Теперь, загрузив значение <code>head</code>, мы должны сначала увеличить счетчик внешних ссылок на узел <code>head</code>, показав, что ссылаемся на него, — только тогда его можно безопасно будет разыменовывать. Если попытаться разыменовать указатель <emphasis>до</emphasis> увеличения счетчика ссылок, то вполне может случиться так, что другой поток освободит узел раньше, чем мы успеем обратиться к нему, и, стало быть, оставит нам висячий указатель. <emphasis>Именно в этом главная причина использования разделенного счетчика ссылок</emphasis>: увеличивая внешний счетчик ссылок, мы гарантируем, что указатель останется действительным в течение всего времени работы с ним. Увеличение производится в цикле по <code>compare_exchange_strong()</code> <strong>(1)</strong>, где устанавливаются все поля структуры, чтобы быть уверенным, что другой поток не изменил в промежутке указатель.</p>
          <p>Увеличив счетчик, мы можем без опаски разыменовать поле <code>ptr</code> объекта, загруженного из <code>head</code>, и получить тем самым доступ к адресуемому узлу <strong>(2)</strong>. Если оказалось, что указатель нулевой, то мы находимся в конце списка — больше записей нет. В противном случае мы можем попытаться исключить узел из списка, выполнив <code>compare_exchange_strong()</code> с головным узлом <code>head</code> <strong>(3)</strong>.</p>
          <p>Если <code>compare_exchange_strong()</code> возвращает <code>true</code>, то мы приняли на себя владение узлом и можем с помощью функции <code>swap()</code> вытащить из него данные, которые впоследствии вернём <strong>(4)</strong>. Тем самым гарантируется, что данные случайно не изменятся, если вдруг другие обращающиеся к стеку другие потоки удерживают указатели на этот узел. Затем можно прибавить внешний счетчик к внутреннему с помощью атомарной операции <code>fetch_add</code> <strong>(6)</strong>. Если теперь счетчик ссылок стал равен нулю, то <emphasis>предыдущее</emphasis> значение (то, которое возвращает <code>fetch_add</code>) было противоположно только что прибавленному, и тогда узел можно удалять. Важно отметить, что прибавленное значение на самом деле <emphasis>на 2 меньше</emphasis> внешнего счетчика <strong>(5)</strong>; мы исключили узел из списка, вследствие чего значение счетчика уменьшилось на 1, и больше не обращаемся к узлу из данного потока, что дает уменьшение еще на 1. Неважно, удаляется узел или нет, наша работа закончена, и мы можем вернуть данные <strong>(7)</strong>.</p>
          <p>Если сравнение с обменом <strong>(3)</strong> <emphasis>не проходит</emphasis>, значит, другой поток сумел удалить узел раньше нас, либо другой поток добавил в стек новый узел. В любом случае нужно начать с начала — с новым значением <code>head</code>, которое вернула функция <code>compare_exchange_strong()</code>. Но прежде необходимо уменьшить счетчик ссылок на узел, который мы пытались исключить раньше. Этот поток больше не будет к нему обращаться. Если наш поток — последний, удерживавший ссылку на этот узел (потому что другой поток вытолкнул его из стека), то внутренний счетчик ссылок равен 1, так что после вычитания 1 он обратится в нуль. В таком случае мы можем удалить узел прямо здесь, не дожидаясь перехода к следующей итерации цикла <strong>(8)</strong>.</p>
          <p>До сих мы задавали для всех атомарных операций упорядочение доступа к памяти <code>std::memory_order_seq_cst</code>. В большинстве систем это самый неэффективный режим с точки зрения времени выполнения и накладных расходов на синхронизацию, причем в ряде случаев разница весьма ощутима. Но теперь, определившись с логикой структуры данных, можно подумать и о том, чтобы ослабить некоторые требования к упорядочению, — все-таки не хотелось бы, чтобы пользователи стека несли лишние расходы. Итак, перед тем как расстаться со стеком и перейти к проектированию свободной от блокировок очереди, еще раз присмотримся к операциям стека и спросим себя, нельзя ли где-нибудь использовать более слабое упорядочение доступа, сохранив тот же уровень безопасности?</p>
        </section>
        <section>
          <title>
            <p>7.2.5. Применение модели памяти к свободному от блокировок стеку</p>
          </title>
          <p>Прежде чем менять схему упорядочения, нужно исследовать все операции и определить, какие между ними должны быть отношения. Затем можно будет вернуться и найти минимальное упорядочение, которое эти отношения обеспечивает. Чтобы это сделать, потребуется взглянуть на ситуацию с точки зрения потоков в нескольких разных сценариях. Простейший сценарий возникает, когда один поток помещает элемент данных в стек, а другой через некоторое время извлекает его оттуда, с него и начнем.</p>
          <p>В этом сценарии есть три существенных участника. Во-первых, структура <code>counted_node_ptr</code>, используемая для передачи данных — узла <code>head</code>. Во-вторых, структура <code>node</code>, на которую <code>head</code> ссылается. И, в-третьих, сами данные, на которые указывает узел.</p>
          <p>Поток, выполняющий <code>push()</code>, сначала конструирует элемент данных и объект <code>node</code>, затем устанавливает <code>head</code>. Поток, выполняющий <code>pop()</code>, сначала загружает значение <code>head</code>, затем в цикле сравнения с обменом увеличивает хранящийся в нем счетчик ссылок, после чего читает структуру <code>node</code>, чтобы извлечь из нее значение <code>next</code>. Из этой последовательности можно вывести требуемое отношение; значение <code>next</code> — простой неатомарный объект, поэтому для его безопасного чтения должно существовать отношение происходит-раньше между операциями сохранения (в заталкивающем потоке) и загрузки (в выталкивающем потоке). Поскольку в <code>push()</code> имеется единственная атомарная операция — <code>compare_exchange_weak()</code>, а для существования отношения происходит-раньше между потоками нам нужна операция <emphasis>освобождения</emphasis> (release), то для функции <code>compare_exchange_weak()</code> необходимо задать упорядочение <code>std::memory_order_release</code> или более сильное. Если <code>compare_exchange_weak()</code> вернула <code>false</code>, то ничего не было изменено, и мы можем продолжить цикл, следовательно в этом случае нужна только семантика <code>std::memory_order_relaxed</code>:</p>
          <p>
            <code>void push(T const&amp; data) {</code>
          </p>
          <p>
            <code> counted_node_ptr new_node;</code>
          </p>
          <p>
            <code> new_node.ptr = new node(data);</code>
          </p>
          <p>
            <code> new_node.external_count = 1;</code>
          </p>
          <p>
            <code> new_node.ptr-&gt;next = head.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code> while (!head.compare_exchange_weak(</code>
          </p>
          <p>
            <code>  new_node.ptr-&gt;next, new_node,</code>
          </p>
          <p>
            <code>  std::memory_order_release, std::memory_order_relaxed));</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>А что можно сказать о коде <code>pop()</code>? Чтобы получить желаемое отношение происходит-раньше, перед доступом к <code>next</code> необходима операция с семантикой <code>std::memory_order_acquire</code> или более сильной. Указатель, который разыменовывается для доступа к полю <code>next</code>, — это прежнее значение, прочитанное операцией <code>compare_exchange_strong()</code> в <code>increase_head_count()</code>, поэтому указанная семантика нужна в случае успеха. Как и в <code>push()</code>, если обмен закончился неудачно, мы просто повторяем цикл, поэтому для отказа можно задать ослабленное упорядочение:</p>
          <p>
            <code>void increase_head_count(counted_node_ptr&amp; old_counter) {</code>
          </p>
          <p>
            <code> counted_node_ptr new_counter;</code>
          </p>
          <p>
            <code> do {</code>
          </p>
          <p>
            <code>  new_counter = old_counter;</code>
          </p>
          <p>
            <code>  ++new_counter.external_count;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> while (!head.compare_exchange_strong(</code>
          </p>
          <p>
            <code>  old_counter, new_counter,</code>
          </p>
          <p>
            <code>  std::memory_order_acquire, std::memory_order_relaxed));</code>
          </p>
          <p>
            <code> old_counter.external_count = new_counter.external_count;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Если вызов <code>compare_exchange_strong()</code> завершается успешно, то мы знаем, что раньше в поле <code>ptr</code> прочитанного значения находилось то, что теперь хранится в переменной <code>old_counter</code>. Поскольку сохранение в <code>push()</code> было операцией освобождения, а данный вызов <code>compare_exchange_strong()</code> — операция захвата, то сохранение синхронизируется-с загрузкой, и мы имеем отношение происходит-раньше. Следовательно, сохранение в поле <code>ptr</code> в <code>push()</code> происходит-раньше доступа к <code>ptr-&gt;next</code> в <code>pop()</code>, и мы в безопасности.</p>
          <p>Отметим, что для этого анализа порядок доступа к памяти в начальном вызове <code>head.load()</code> не имел значения, поэтому в нем безопасно задать семантику <code>std::memory_order_relaxed</code>.</p>
          <p>Далее на очереди операция <code>compare_exchange_strong()</code>, которая записывает в <code>head</code> значение <code>old_head.ptr-&gt;next</code>. Нужно ли наложить на нее какие-нибудь ограничения, чтобы гарантировать целостность данных в этом потоке? Если обмен завершается успешно, то мы обращаемся к <code>ptr-&gt;data</code>, поэтому должны быть уверены, что сохранение <code>ptr-&gt;data</code> в потоке, выполняющем <code>push()</code>, происходит-раньше загрузки. Но такая уверенность уже есть: операция захвата в <code>increase_head_count()</code> гарантирует, что существует отношение синхронизируется-с между сохранением в потоке, выполняющем <code>push()</code>, и операцией сравнения с обменом. Поскольку сохранение данных в потоке, выполняющем <code>push()</code>, расположено перед сохранением <code>head</code>, а вызов <code>increase_head_count()</code> расположен перед загрузкой <code>ptr-&gt;data</code>, то отношение происходит-раньше имеет место, и всё будет хорошо, даже если для операции сравнения с обменом в <code>pop()</code> задана семантика <code>std::memory_order_relaxed</code>. Есть еще всего одно место, где изменяется <code>ptr-&gt;data</code> — тот самый вызов <code>swap()</code>, на который вы сейчас смотрите, и ни один другой поток не может оперировать тем же узлом — в этом и заключается смысл сравнения с обменом.</p>
          <p>Если <code>compare_exchange_strong()</code> завершается неудачно, то к новому значению <code>old_head</code> не будет обращений до следующей итерации цикла, и, поскольку мы уже решили, что семантики <code>std::memory_order_acquire</code> хватало в <code>increase_head_count()</code>, то здесь будет достаточно <code>std::memory_order_relaxed</code>.</p>
          <p>Что можно сказать насчёт других потоков? Нужны ли более сильные ограничения, чтобы и другие потоки работали безопасно? Нет, не нужны, потому что <code>head</code> модифицируется только операциями сравнения с обменом. Будучи операциями чтения-модификации-записи, они составляют часть последовательности освобождений, начатой операцией сравнения с обменом в <code>push()</code>. Поэтому <code>compare_exchange_weak()</code> в <code>push()</code> синхронизируется-с операцией <code>compare_exchange_strong()</code> в <code>increase_head_count()</code>, которая прочитает сохраненное значение, даже если в промежутке другие потоки изменят <code>head</code>.</p>
          <p>Мы почти закончили, осталось только рассмотреть функции, в которых используются операции <code>fetch_add()</code>, изменяющие счетчик ссылок. Поток, который добрался до возврата данных из узла, может продолжать в твердой уверенности, что никакой другой поток не сможет модифицировать хранящиеся в узле данные. Однако любой поток, который потерпел <emphasis>неудачу</emphasis> при извлечении данных, знает, что какой-то другой поток данные в узле <emphasis>модифицировал</emphasis>; он использовал функцию <code>swap()</code> для извлечения данных. Следовательно, чтобы предотвратить гонку за данными мы должны гарантировать, что <code>swap()</code> происходит-раньше <code>delete</code>. Чтобы добиться этого, проще всего задать семантику <code>std::memory_order_release</code> при вызове <code>fetch_add()</code> в ветви, где мы возвращаем данные, и семантику <code>std::memory_order_acquire</code> — в ветви, где мы возвращаемся в начало цикла. Однако даже это перебор — лишь один поток выполняет <code>delete</code> (тот, что сбросил счетчик в нуль), поэтому только этому потоку нужно выполнить операцию захвата. К счастью, поскольку <code>fetch_add()</code> — операция чтения-модификации-записи, то она составляет часть последовательности освобождений, поэтому для достижения цели нам достаточно дополнительной операции <code>load()</code>. Если в ветви, где происходит возврат в начало цикла, счетчик ссылок уменьшается до нуля, то здесь же можно перезагрузить счетчик ссылок с семантикой <code>std::memory_order_acquire</code>, чтобы обеспечить требуемое отношение синхронизируется-с, а в самой операции <code>fetch_add()</code> достаточно задать <code>std::memory_order_relaxed</code>. Окончательная реализация стека с новой версией <code>pop()</code> приведена ниже.</p>
          <empty-line/>
          <p><strong>Листинг 7.12.</strong> Свободный от блокировок стек с подсчётом ссылок и ослабленными атомарными операциями</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_stack {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node;</code>
          </p>
          <empty-line/>
          <p>
            <code> struct counted_node_ptr {</code>
          </p>
          <p>
            <code>  int external_count;</code>
          </p>
          <p>
            <code>  node* ptr;</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data;</code>
          </p>
          <p>
            <code>  std::atomic&lt;int&gt; internal_count;</code>
          </p>
          <p>
            <code>  counted_node_ptr next;</code>
          </p>
          <p>
            <code>  node(T const&amp; data_):</code>
          </p>
          <p>
            <code>  data(std::make_shared&lt;T&gt;(data_)), internal_count(0) {}</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::atomic&lt;counted_node_ptr&gt; head;</code>
          </p>
          <empty-line/>
          <p>
            <code> void increase_head_count(counted_node_ptr&amp; old_counter) {</code>
          </p>
          <p>
            <code>  counted_node_ptr new_counter;</code>
          </p>
          <empty-line/>
          <p>
            <code>  do {</code>
          </p>
          <p>
            <code>   new_counter = old_counter;</code>
          </p>
          <p>
            <code>   ++new_counter.external_count;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  while (!head.compare_exchange_strong(old_counter, new_counter,</code>
          </p>
          <p>
            <code>         std::memory_order_acquire,</code>
          </p>
          <p>
            <code>         std::memory_order_relaxed));</code>
          </p>
          <empty-line/>
          <p>
            <code>  old_counter.external_count = new_counter.external_count;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> ~lock_free_stack() {</code>
          </p>
          <p>
            <code>  while(pop());</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T const&amp; data) {</code>
          </p>
          <p>
            <code>  counted_node_ptr new_node;</code>
          </p>
          <p>
            <code>  new_node.ptr = new node(data);</code>
          </p>
          <p>
            <code>  new_node.external_count = 1;</code>
          </p>
          <p>
            <code>  new_node.ptr-&gt;next = head.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  while (!head.compare_exchange_weak(</code>
          </p>
          <p>
            <code>           new_node.ptr-&gt;next, new_node,</code>
          </p>
          <p>
            <code>           std::memory_order_release,</code>
          </p>
          <p>
            <code>           std::memory_order_relaxed));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; pop() {</code>
          </p>
          <p>
            <code>  counted_node_ptr old_head =</code>
          </p>
          <p>
            <code>   head.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  for (;;) {</code>
          </p>
          <p>
            <code>   increase_head_count(old_head);</code>
          </p>
          <p>
            <code>   node* const ptr = old_head.ptr;</code>
          </p>
          <p>
            <code>   if (!ptr) {</code>
          </p>
          <p>
            <code>    return std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   if (head.compare_exchange_strong(old_head, ptr-&gt;next,</code>
          </p>
          <p>
            <code>       std::memory_order_relaxed)) {</code>
          </p>
          <p>
            <code>    std::shared_ptr&lt;T&gt; res;</code>
          </p>
          <p>
            <code>    res.swap(ptr-&gt;data);</code>
          </p>
          <p>
            <code>    int const count_increase = old_head.external_count — 2;</code>
          </p>
          <p>
            <code>    if (ptr-&gt;internal_count.fetch_add(count_increase,</code>
          </p>
          <p>
            <code>        std::memory_order_release) == -count_increase) {</code>
          </p>
          <p>
            <code>     delete ptr;</code>
          </p>
          <p>
            <code>    }</code>
          </p>
          <p>
            <code>    return res;</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   else if (ptr-&gt;internal_count.fetch_add(-1,</code>
          </p>
          <p>
            <code>            std::memory_order_relaxed) == 1) {</code>
          </p>
          <p>
            <code>    ptr-&gt;internal_count.load(std::memory_order_acquire);</code>
          </p>
          <p>
            <code>    delete ptr;</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Мы немало потрудились, но наконец-то дошли до конца, и стек теперь стал куда лучше. За счет тщательно продуманного применения ослабленных операций нам удалось повысить производительность, не жертвуя корректностью. Как видите, реализация <code>pop()</code> теперь насчитывает 37 строк вместо 8 в эквивалентной реализации <code>pop()</code> для стека с блокировками (листинг 7.1) и 7 строк для простого свободного от блокировок стека без управления памятью (листинг 7.2). При рассмотрении свободной от блокировок очереди мы встретимся с аналогичной ситуацией: сложность кода в значительной степени обусловлена именно управлением памятью.</p>
        </section>
        <section>
          <title>
            <p>7.2.6. Потокобезопасная очередь без блокировок</p>
          </title>
          <p>Очередь отличается от стека прежде всего тем, что операции <code>push()</code> и <code>pop()</code> обращаются к разным частям структуры данных, тогда как в стеке та и другая работают с головным узлом списка. Следовательно, и проблемы синхронизации тоже другие. Требуется сделать так, чтобы изменения, произведенные на одном конце, были видны при доступе с другого конца. Однако структура функции <code>try_pop()</code> в листинге 6.6 не так уж сильно отличается от структуры <code>pop()</code> в простом свободном от блокировок стеке в листинге 7.2, поэтому можно с достаточными основаниями предположить, что и весь свободный от блокировок код будет схожим. Посмотрим, так ли это.</p>
          <p>Если взять листинг 6.6 за основу, то нам понадобятся два указателя на <code>node</code>: один для головы списка (<code>head</code>), второй — для хвоста (<code>tail</code>). Поскольку мы собираемся обращаться к ним из нескольких потоков, то надо бы сделать эти указатели атомарными и расстаться с соответствующими мьютексами. Начнём с этого небольшого изменения и посмотрим, куда оно нас приведет. Результат показан в листинге ниже.</p>
          <empty-line/>
          <p><strong>Листинг 7.13.</strong> Свободная от блокировок очередь с одним производителем и одним потребителем</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; data;</code>
          </p>
          <p>
            <code>  node* next;</code>
          </p>
          <p>
            <code>  node():</code>
          </p>
          <p>
            <code>   next(nullptr) {}</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::atomic&lt;node*&gt; head;</code>
          </p>
          <p>
            <code> std::atomic&lt;node*&gt; tail;</code>
          </p>
          <p>
            <code> node* pop_head() {</code>
          </p>
          <p>
            <code>  node* const old_head = head.load();</code>
          </p>
          <p>
            <code>  if (old_head == tail.load()) {&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>   return nullptr;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  head.store(old_head-&gt;next);</code>
          </p>
          <p>
            <code>  return old_head;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> lock_free_queue():</code>
          </p>
          <p>
            <code>  head(new node), tail(head.load()) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> lock_free_queue(const lock_free_queue&amp; other) = delete;</code>
          </p>
          <p>
            <code> lock_free_queue&amp; operator=(</code>
          </p>
          <p>
            <code>  const lock_free_queue&amp; other) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> ~lock_free_queue() {</code>
          </p>
          <p>
            <code>  while(node* const old_head = head.load()) {</code>
          </p>
          <p>
            <code>   head.store(old_head-&gt;next);</code>
          </p>
          <p>
            <code>   delete old_head;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::shared_ptr&lt;T&gt; pop() {</code>
          </p>
          <p>
            <code>  node* old_head = pop_head();</code>
          </p>
          <p>
            <code>  if (!old_head) {</code>
          </p>
          <p>
            <code>   return std::shared_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  std::shared_ptr&lt;T&gt; const res(old_head-&gt;data);&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  delete old_head;</code>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::shared_ptr&lt;T&gt; new_data(std::make_shared&lt;T&gt;(new_value));</code>
          </p>
          <p>
            <code>  node* p = new node;                 &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  node* const old_tail = tail.load(); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  old_tail-&gt;data.swap(new_data);      &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  old_tail-&gt;next = p;                 &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  tail.store(p);                      &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>На первый взгляд, неплохо, и если в каждый момент времени существует только один поток, вызывающий <code>push()</code>, и только один поток, вызывающий <code>pop()</code>, то вообще всё прекрасно. Важно отметить, что в этом случае существует отношение происходит-раньше между <code>push()</code> и <code>pop()</code>, благодаря которому извлечение данных безопасно. Сохранение <code>tail</code> <strong>(7)</strong> синхронизируется-с загрузкой <code>tail</code> <strong>(1)</strong>, сохранение указателя на <code>data</code> в предыдущем узле <strong>(5)</strong> расположено перед сохранением <code>tail</code>, а загрузка <code>tail</code> расположена перед загрузкой указателя на <code>data</code> <strong>(2)</strong>, поэтому сохранение <code>data</code> происходит раньше его загрузки, и всё замечательно. Таким образом, мы получили корректно обслуживаемую очередь с <emphasis>одним производителем и одним потребителем</emphasis>.</p>
          <p>Проблемы начинаются, когда несколько потоков вызывают <code>push()</code> или <code>pop()</code> одновременно. Сначала рассмотрим <code>push()</code>. Если два потока одновременно вызывают <code>push()</code>, то оба выделяют память для нового фиктивного узла <strong>(3)</strong>, оба читают <emphasis>одно и то же</emphasis> значение <code>tail</code> <strong>(4)</strong> и, следовательно, оба изменяют данные-члены <code>data</code> и <code>next</code> одного и того же узла <strong>(5)</strong>, <strong>(6)</strong>. А это уже гонка за данными!</p>
          <p>Аналогичные проблемы возникают в <code>pop_head()</code>. Если два потока вызывают эту функцию одновременно, то оба читают одно и то же значение <code>head</code>, и оба перезаписывают старое значение одним и тем же указателем <code>next</code>. Оба потока теперь думают, что получили один и тот же узел, — прямой путь к катастрофе. Мы должны не только сделать так, чтобы лишь один поток извлекал данный элемент, но и позаботиться о том, чтобы другие потоки могли безопасно обращаться к члену <code>next</code> узла, который прочитали из <code>head</code>. Это точно та же проблема, с которой мы сталкивались при написании <code>pop()</code> для свободного от блокировок стека, поэтому и любое из предложенных тогда решений можно применить здесь.</p>
          <p>Итак, проблему <code>pop()</code> можно считать решенной, но как быть с <code>push()</code>? Здесь трудность заключается в том, что для получения требуемого отношения происходит-раньше между <code>push()</code> и <code>pop()</code> мы должны заполнить поля фиктивного узла до обновления <code>tail</code>. Но это означает, что одновременные вызовы <code>push()</code> конкурируют за те же самые данные, так как был прочитал один и тот же указатель <code>tail</code>.</p>
          <subtitle>Решение проблемы нескольких потоков в <code>push()</code></subtitle>
          <p>Один из способов — добавить фиктивный узел между реальными. Тогда единственной частью текущего узла <code>tail</code>, нуждающейся в обновлении, будет указатель <code>next</code>, который, следовательно, можно было бы сделать атомарным. Если потоку удалось записать в <code>next</code> указатель на свой новый узел вместо <code>nullptr</code>, то он успешно добавил узел; в противном случае ему придется начать сначала и снова прочитать <code>tail</code>. Это потребует небольшого изменения в <code>pop()</code> — нужно будет игнорировать узлы с нулевым указателем на данные и возвращаться в начало цикла. Недостаток этого решения в том, что при каждом вызове <code>pop()</code> придется как правило исключать из списка два узла и производить в два раза больше операций выделения памяти.</p>
          <p>Второй способ — сделать указатель <code>data</code> атомарным и устанавливать его с помощью операции сравнения с обменом. Если она завершится успешно, то мы получили свой хвостовой узел и можем безопасно записать в <code>next</code> указатель на наш новый узел, а затем обновить <code>tail</code>. Если же сравнение с обменом завершается неудачно, потому что другой поток успел сохранить данные, мы возвращаемся в начало цикла, заново читаем <code>tail</code> и пробуем снова. Если атомарные операции над s<code>td::shared_ptr&lt;&gt;</code> свободны от блокировок, то дело сделано. Если нет, нужна альтернатива. Можно, например, заставить <code>pop()</code> возвращать <code>std::unique_ptr&lt;&gt;</code> (в конце концов, это ведь единственная ссылка на объект) и сохранять данные в очереди в виде простого указателя. Тогда его можно было бы хранить как <code>std::atomic&lt;T*&gt;</code> и впоследствии обновлять с помощью <code>compare_exchange_strong()</code>. Если воспользоваться для поддержки нескольких потоков в <code>pop()</code> схемой подсчета ссылок из листинга 7.11, то <code>push()</code> будет выглядеть следующим образом.</p>
          <empty-line/>
          <p><strong>Листинг 7.14.</strong> Первая (неудачная) попытка переработки <code>push()</code></p>
          <p>
            <code>void push(T new_value) {</code>
          </p>
          <p>
            <code> std::unique_ptr&lt;T&gt; new_data(new T(new_value));</code>
          </p>
          <p>
            <code> counted_node_ptr new_next;</code>
          </p>
          <p>
            <code> new_next.ptr = new node;</code>
          </p>
          <p>
            <code> new_next.external_count = 1;</code>
          </p>
          <p>
            <code> for (;;) {</code>
          </p>
          <p>
            <code>  node* const old_tail = tail.load();&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  T* old_data = nullptr;</code>
          </p>
          <p>
            <code>  if (old_tail-&gt;data.compare_exchange_strong(</code>
          </p>
          <p>
            <code>   old_data, new_data.get())) {      &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   old_tail-&gt;next = new_next;</code>
          </p>
          <p>
            <code>   tail.store(new_next.ptr);         &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>   new_data.release();</code>
          </p>
          <p>
            <code>   break;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Применение схемы подсчета ссылок устраняет эту конкретную гонку, но в <code>push()</code> имеются и другие гонки. Взглянув на переработанную версию <code>push()</code> в листинге 7.14, вы обнаружите ту же ситуацию, что уже встречалась нам в стеке: загрузка атомарного указателя <strong>(1)</strong> и разыменование этого указателя <strong>(2)</strong>. В промежутке между этими двумя операциями другой поток может изменить указатель <strong>(3)</strong>, что в конечном итоге приведет к освобождению памяти, запятой узлом (в <code>pop()</code>). Если это произойдет раньше, чем мы разыменовываем указатель, то получится неопределенное поведение. Ой! Возникает искушение добавить в <code>tail</code> внешний счетчик, как мы уже поступили для <code>head</code>, однако на каждый узел уже имеется внешний счетчик в указателе <code>next</code> в предыдущем узле очереди. Если хранить два внешних счетчика для одного узла, то потребуется модифицировать схему подсчета ссылок, чтобы не удалить узел преждевременно. Проблему можно решить, подсчитывая число внешних счетчиков в структуре <code>node</code> и уменьшая это число при уничтожении внешнего счетчика (одновременно с прибавлением значения внешнего счетчика к значению внутреннего). Если внутренний счетчик равен нулю, а внешних не осталось, то узел можно удалять. Эту технику я впервые встретил в проекте Джо Сейга (Joe Seigh) Atomic Ptr Plus<a l:href="#n16" type="note">[16]</a>. В следующем листинге показано, как выглядит <code>push()</code> при использовании такой схемы.</p>
          <empty-line/>
          <p><strong>Листинг 7.15.</strong> Реализация <code>push()</code> для очереди без блокировок с подсчётом ссылок на <code>tail</code></p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node;</code>
          </p>
          <empty-line/>
          <p>
            <code> struct counted_node_ptr {</code>
          </p>
          <p>
            <code>  int external_count;</code>
          </p>
          <p>
            <code>  node* ptr;</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::atomic&lt;counted_node_ptr&gt; head;</code>
          </p>
          <p>
            <code> std::atomic&lt;counted_node_ptr&gt; tail;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code> struct node_counter {</code>
          </p>
          <p>
            <code>  unsigned internal_count:30;</code>
          </p>
          <p>
            <code>  unsigned external_counters:2;&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  std::atomic&lt;T*&gt; data;</code>
          </p>
          <p>
            <code>  std::atomic&lt;node_counter&gt; count;&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  counted_node_ptr next;</code>
          </p>
          <p>
            <code>  node() {</code>
          </p>
          <p>
            <code>   node_counter new_count;</code>
          </p>
          <p>
            <code>   new_count.internal_count = 0;</code>
          </p>
          <p>
            <code>   new_count.external_counters = 2;&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>   count.store(new_count);</code>
          </p>
          <p>
            <code>   next.ptr = nullptr;</code>
          </p>
          <p>
            <code>   next.external_count = 0;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;T&gt; new_data(new T(new_value));</code>
          </p>
          <p>
            <code>  counted_node_ptr new_next;</code>
          </p>
          <p>
            <code>  new_next.ptr = new node;</code>
          </p>
          <p>
            <code>  new_next.external_count = 1;</code>
          </p>
          <p>
            <code>  counted_node_ptr old_tail = tail.load();</code>
          </p>
          <empty-line/>
          <p>
            <code>  for (;;) {</code>
          </p>
          <p>
            <code>   increase_external_count(tail, old_tail);       &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>   T* old_data = nullptr;</code>
          </p>
          <p>
            <code>   if (old_tail.ptr-&gt;data.compare_exchange_strong(&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>       old_data, new_data.get())) {</code>
          </p>
          <p>
            <code>    old_tail.ptr-&gt;next = new_next;</code>
          </p>
          <p>
            <code>    old_tail = tail.exchange(new_next);</code>
          </p>
          <p>
            <code>    free_external_counter(old_tail);              &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>    new_data.release();</code>
          </p>
          <p>
            <code>    break;</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   old_tail.ptr-&gt;release_ref();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В листинге 7.15 <code>tail</code> теперь имеет такой же тип <code>atomic&lt;counted_node_ptr&gt;</code>, как и <code>head</code> <strong>(1)</strong>, а в структуру <code>node</code> добавлен член <code>count</code> вместо прежнего <code>internal_count</code> <strong>(3)</strong>. Член <code>count</code> сам представляет собой структуру с двумя полями: <code>internal_count</code> и <code>external_counters</code> <strong>(2)</strong>. Под поле <code>external_counters</code> отведено только 2 бита, потому что внешних счетчиков может быть не более двух. Воспользовавшись битовыми полями и отведя под <code>internal_count</code> 30 бит, мы ограничили длину поля счетчика 32 битами. В результате мы убиваем сразу двух зайцев: и значение внутреннего счетчика может быть достаточно велико, и вся структура помещается в машинное слово на 32- и 64-разрядных машинах. Очень важно изменять счетчики как единое целое, чтобы избежать гонки. Как это делается, мы покажем чуть ниже. На многих платформах хранение структуры в одном машинном слове повышает шансы на то, что атомарные операции окажутся свободными от блокировок.</p>
          <p>При инициализации структуры <code>node</code> в поле <code>internal_count</code> записывается 0, а в поле <code>external_counters</code> — 2 <strong>(4)</strong>, потому что сразу после добавления нового узла в очередь на него есть две ссылки: из <code>tail</code> и из указателя <code>next</code> в предыдущем узле. Код самой функции <code>push()</code> похож на приведенный в листинге 7.14 с тем отличием, что перед тем как разыменовывать загруженное из <code>tail</code> значение, чтобы вызвать <code>compare_exchange_strong()</code> для члена узла <code>data</code> <strong>(6)</strong>, мы вызываем новую функцию <code>increase_external_count()</code> которая увеличивает счетчик <strong>(5)</strong>, а затем функцию <code>free_external_counter()</code> для старого хвоста <code>old_tail</code> <strong>(7)</strong>.</p>
          <p>Разобравшись с <code>push()</code>, обратим наши взоры на <code>pop()</code>. В ее коде (см. листинг 7.16) логика подсчета ссылок из реализации <code>pop()</code> в листинге 7.11 комбинируется с логикой извлечения из очереди в листинге 7.13.</p>
          <empty-line/>
          <p><strong>Листинг 7.16.</strong> Извлечение узла из очереди без блокировок с подсчётом ссылок на <code>tail</code></p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code> void release_ref();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> std::unique_ptr&lt;T&gt; pop() {</code>
          </p>
          <p>
            <code>  counted_node_ptr old_head =</code>
          </p>
          <p>
            <code>   head.load(std::memory_order_relaxed);   &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  for (;;) {</code>
          </p>
          <p>
            <code>   increase_external_count(head, old_head);&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   node* const ptr = old_head.ptr;</code>
          </p>
          <p>
            <code>   if (ptr == tail.load().ptr) {</code>
          </p>
          <p>
            <code>    ptr-&gt;release_ref();&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>    return std::unique_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   if (head.compare_exchange_strong(old_head, ptr-&gt;next)) {&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>    T* const res = ptr-&gt;data.exchange(nullptr);</code>
          </p>
          <p>
            <code>    free_external_counter(old_head);&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>    return std::unique_ptr&lt;T&gt;(res);</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   ptr-&gt;release_ref();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Все начинается с загрузки значения <code>old_head</code> перед входом в цикл <strong>(1)</strong> и до увеличения внешнего счетчика в загруженном значении <strong>(2)</strong>. Если узел <code>head</code> совпадает с <code>tail</code>, то можно освободить ссылку <strong>(3)</strong> и вернуть нулевой указатель, потому что очередь пуста. Если же в очереди есть данные, то мы пытаемся заявить на них свои права с помощью <code>compare_exchange_strong()</code> (4). Как и в случае стека в листинге 7.11, мы при этом сравниваем внешний счетчик и указатель как единое целое; если хотя бы один из них изменился, то мы должны вернуться в начало цикла, освободив предварительно ссылку 6. Если обмен завершился удачно, то мы получили в свое распоряжение данные в узле, поэтому можем вернуть их вызывающей программе, освободив предварительно внешний счетчик ссылок на извлеченный узел <strong>(5)</strong>. После того как оба внешних счетчика освобождены, а внутренний счетчик обратился в нуль, сам узел можно удалять. Вспомогательные функции подсчета ссылок приведены в листингах 7.17, 7.18 и 7.19.</p>
          <empty-line/>
          <p><strong>Листинг 7.17.</strong> Освобождение ссылки на узел в очереди без блокировок</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  void release_ref() {</code>
          </p>
          <p>
            <code>   node_counter old_counter =</code>
          </p>
          <p>
            <code>    count.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>   node_counter new_counter;</code>
          </p>
          <p>
            <code>   do {</code>
          </p>
          <p>
            <code>    new_counter = old_counter;</code>
          </p>
          <p>
            <code>    --new_counter.internal_count;        &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   while (!count.compare_exchange_strong(&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>          old_counter, new_counter,</code>
          </p>
          <p>
            <code>          std::memory_order_acquire, std::memory_order_relaxed));</code>
          </p>
          <empty-line/>
          <p>
            <code>   if (</code>
          </p>
          <p>
            <code>    !new_counter.internal_count &amp;&amp;</code>
          </p>
          <p>
            <code>    !new_counter.external_counters) {</code>
          </p>
          <p>
            <code>    delete this; &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Реализация <code>node::release_ref()</code> лишь немногим отличается от аналогичного кода в <code>lock_free_stack::pop()</code> (см. листинг 7.11). Там мы работали с единственным внешним счетчиком, поэтому достаточно было вызвать <code>fetch_sub</code>. Здесь же необходимо атомарно обновить всю структуру <code>count</code>, хотя в действительности мы хотим модифицировать только поле <code>internal_count</code> <strong>(1)</strong>. Поэтому никуда не деться от цикла сравнения с обменом <strong>(2)</strong>. Если после уменьшения <code>internal_count</code> оказалось, что и внутренний, и внешний счетчик равны нулю, то это была последняя ссылка, и мы можем удалять узел <strong>(3)</strong>.</p>
          <empty-line/>
          <p><strong>Листинг 7.18.</strong> Получение новой ссылки на узел в очереди без блокировок</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> static void increase_external_count(</code>
          </p>
          <p>
            <code>  std::atomic&lt;counted_node_ptr&gt;&amp; counter,</code>
          </p>
          <p>
            <code>  counted_node_ptr&amp; old_counter) {</code>
          </p>
          <p>
            <code>  counted_node_ptr new_counter;</code>
          </p>
          <p>
            <code>  do {</code>
          </p>
          <p>
            <code>   new_counter = old_counter;</code>
          </p>
          <p>
            <code>   ++new_counter.external_count;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  while (!counter.compare_exchange_strong(</code>
          </p>
          <p>
            <code>   old_counter, new_counter,</code>
          </p>
          <p>
            <code>   std::memory_order_acquire, std::memory_order_relaxed));</code>
          </p>
          <empty-line/>
          <p>
            <code>  old_counter.external_count = new_counter.external_count;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Листинг 7.18 завершает картину. На этот раз мы не освобождаем ссылку, а получаем новую и увеличиваем внешний счетчик. Функция <code>increase_external_count()</code> аналогична <code>increase_head_count()</code> из листинга 7.12, отличаясь от нее тем, что преобразована в статическую функцию-член, которая принимает подлежащий обновлению внешний счетчик извне, а не оперирует внутренним членом класса.</p>
          <empty-line/>
          <p><strong>Листинг 7.19.</strong> Освобождение счётчика внешних ссылок на узел в очереди без блокировок</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> static void free_external_counter(</code>
          </p>
          <p>
            <code>  counted_node_ptr &amp;old_node_ptr) {</code>
          </p>
          <p>
            <code>  node* const ptr = old_node_ptr.ptr;</code>
          </p>
          <p>
            <code>  int const count_increase = old_node_ptr.external_count — 2;</code>
          </p>
          <p>
            <code>  node_counter old_counter =</code>
          </p>
          <p>
            <code>   ptr-&gt;count.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  node_counter new_counter;</code>
          </p>
          <p>
            <code>  do {</code>
          </p>
          <p>
            <code>   new_counter = old_counter;</code>
          </p>
          <p>
            <code>   --new_counter.external_counters;             &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>   new_counter.internal_count += count_increase;&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  while (!ptr-&gt;count.compare_exchange_strong(   &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>   old_counter, new_counter,</code>
          </p>
          <p>
            <code>   std::memory_order_acquire, std::memory_order_relaxed));</code>
          </p>
          <empty-line/>
          <p>
            <code>  if (!new_counter.internal_count &amp;&amp;</code>
          </p>
          <p>
            <code>      !new_counter.external_counters) {</code>
          </p>
          <p>
            <code>   delete ptr;&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Функция <code>free_external_counter()</code> дополняет <code>increase_external_count()</code>. Она аналогична эквивалентной функции из реализации <code>lock_free_stack::pop()</code> в листинге 7.11, но модифицировала с учетом появления поля <code>external_counters</code>. Она обновляет оба счетчика в одном вызове <code>compare_exchange_strong()</code> для всей структуры <code>count</code> <strong>(3)</strong> — точно так же мы поступали при уменьшении <code>internal_count</code> в <code>release_ref()</code>. Значение <code>internal_count</code> обновляется, как в листинге 7.11 <strong>(2)</strong>, a <code>external_counters</code> уменьшается на единицу <strong>(1)</strong>. Если теперь <emphasis>оба</emphasis> значения равны нулю, значит, ссылок на узел не осталось, поэтому его можно удалять <strong>(4)</strong>. Оба обновления необходимо выполнять в одном действии (потому и нужен цикл сравнения с обменом), чтобы избежать гонки. Если бы счетчики обновлялись порознь, то два разных потока могли бы решить, что владеют последней ссылкой на узел, и удалить его, что привело бы к неопределенному поведению.</p>
          <p>Хотя теперь функция работает и свободна от блокировок, осталась еще одна проблема, касающаяся производительности. После того как один поток начал операцию <code>push()</code>, успешно выполнив <code>compare_exchange_strong()</code> от имени <code>old_tail.ptr-&gt;data</code> (точка <strong>(5)</strong> в листинге 7.15), никакой другой войти в <code>push()</code> не может. Попытавшись это сделать, поток увидит новое значение, отличное от <code>nullptr</code>, в результате чего вызов <code>compare_exchange_strong()</code> вернет <code>false</code>, и потоку придется начать цикл заново. Это активное ожидание, которое только потребляет время процессора, не продвигаясь вперед ни на йоту. По сути дела, это блокировка. Первый удачный вызов <code>push()</code> блокирует все остальные потоки, пока не завершится, так что <emphasis>этот код более не свободен от блокировок</emphasis>. Хуже того — обычно операционная система может отдать приоритет потоку, удерживающему мьютекс, если существуют заблокированные потоки, но только не в данном случае, поэтому остальные потоки так и будут пожирать процессорное время, пока первый не закончит. И тут мы вытащим на свет очередной припасенный для освобождения от блокировок трюк: ожидающий поток может помочь потоку, который выполняет <code>push()</code>.</p>
          <subtitle>Освобождение от блокировок одного потока с помощью другого</subtitle>
          <p>Чтобы вновь сделать код свободным от блокировок, нам нужно придумать, как ожидающий поток может продвигаться вперед, даже если поток, находящийся в <code>push()</code>, застрял. Один из способов — помочь застрявшему потоку, выполнив за него часть работы.</p>
          <p>В данном случае мы точно знаем, что нужно сделать: указатель <code>next</code> в хвостовом узле требуется установить на новый фиктивный узел, и тогда сам указатель <code>tail</code> можно будет обновить. Все фиктивные узлы эквивалентны, поэтому не имеет значения, какой из них использовать — созданный потоком, который успешно поместил в очередь данные, или потоком, ожидающим входа в <code>push()</code>. Если сделать указатель <code>next</code> в узле атомарным, то для его установки можно будет применить <code>compare_exchange_strong()</code>. После того как указатель <code>next</code> установлен, в цикле по <code>compare_exchange_weak()</code> можно будет установить <code>tail</code>, проверяя при этом, указывает ли он по-прежнему на тот же самый исходный узел. Если это не так, значит, узел обновил какой-то другой поток, так что можно прекратить попытки и перейти в начало цикла. Реализация этой идеи потребует также небольшого изменения <code>pop()</code>, где нужно будет загрузить указатель <code>next</code>; эта модификация показана в листинге ниже.</p>
          <empty-line/>
          <p><strong>Листинг 7.20.</strong> Модификация <code>pop()</code> с целью помочь при выполнении <code>push()</code></p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> struct node {</code>
          </p>
          <p>
            <code>  std::atomic&lt;T*&gt; data;</code>
          </p>
          <p>
            <code>  std::atomic&lt;node_counter&gt; count;</code>
          </p>
          <p>
            <code>  std::atomic&lt;counted_node_ptr&gt; next;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> std::unique_ptr&lt;T&gt; pop() {</code>
          </p>
          <p>
            <code>  counted_node_ptr old_head =</code>
          </p>
          <p>
            <code>   head.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  for (;;) {</code>
          </p>
          <p>
            <code>   increase_external_count(head, old_head);</code>
          </p>
          <p>
            <code>   node* const ptr = old_head.ptr;</code>
          </p>
          <p>
            <code>   if (ptr == tail.load().ptr) {</code>
          </p>
          <p>
            <code>    return std::unique_ptr&lt;T&gt;();</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   counted_node_ptr next = ptr-&gt;next.load();&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   if (head.compare_exchange_strong(old_head, next)) {</code>
          </p>
          <p>
            <code>    T* const res = ptr-&gt;data.exchange(nullptr);</code>
          </p>
          <p>
            <code>    free_external_counter(old_head);</code>
          </p>
          <p>
            <code>    return std::unique_ptr&lt;T&gt;(res);</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   ptr-&gt;release_ref();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Как я и говорил, изменения тривиальны: указатель <code>next</code> теперь атомарный <strong>(1)</strong>, поэтому операция <code>load</code> в точке <strong>(2)</strong> атомарна. В данном примере мы используем упорядочение по умолчанию <code>memory_order_seq_cst</code>, поэтому явное обращение к <code>load()</code> можно было бы опустить, полагаясь на операцию загрузки в операторе неявного преобразования к типу <code>counted_node_ptr</code>, но явное обращение будет напоминать нам, куда впоследствии добавить явное задание порядка обращения к памяти.</p>
          <empty-line/>
          <p><strong>Листинг 7.21.</strong> Пример реализации функции <code>push()</code>, освобождаемой от блокировок благодаря помощи извне</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>class lock_free_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> void set_new_tail(counted_node_ptr &amp;old_tail, &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>                   counted_node_ptr const &amp;new_tail) {</code>
          </p>
          <p>
            <code>  node* const current_tail_ptr = old_tail.ptr;</code>
          </p>
          <p>
            <code>  while (!tail.compare_exchange_weak(old_tail, new_tail) &amp;&amp;&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>         old_tail.ptr == current_tail_ptr);</code>
          </p>
          <p>
            <code>  if (old_tail.ptr == current_tail_ptr)&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>   free_external_counter(old_tail);    &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  else</code>
          </p>
          <p>
            <code>   current_tail_ptr-&gt;release_ref();    &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void push(T new_value) {</code>
          </p>
          <p>
            <code>  std::unique_ptr&lt;T&gt; new_data(new T(new_value));</code>
          </p>
          <p>
            <code>  counted_node_ptr new_next;</code>
          </p>
          <p>
            <code>  new_next.ptr = new node;</code>
          </p>
          <p>
            <code>  new_next.external_count = 1;</code>
          </p>
          <p>
            <code>  counted_node_ptr old_tail = tail.load();</code>
          </p>
          <empty-line/>
          <p>
            <code>  for (;;) {</code>
          </p>
          <p>
            <code>   increase_external_count(tail, old_tail);</code>
          </p>
          <p>
            <code>   T* old_data = nullptr;</code>
          </p>
          <p>
            <code>   if (old_tail.ptr-&gt;data.compare_exchange_strong(  &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>    old_data, new_data.get())) {</code>
          </p>
          <p>
            <code>    counted_node_ptr old_next = {0};</code>
          </p>
          <p>
            <code>    if (!old_tail.ptr-&gt;next.compare_exchange_strong(&#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>        old_next, new_next)) {</code>
          </p>
          <p>
            <code>     delete new_next.ptr;&#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>     new_next = old_next;&#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>    }</code>
          </p>
          <p>
            <code>    set_new_tail(old_tail, new_next);</code>
          </p>
          <p>
            <code>    new_data.release();</code>
          </p>
          <p>
            <code>    break;</code>
          </p>
          <p>
            <code>   } else {              &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>    counted_node_ptr old_next = {0};</code>
          </p>
          <p>
            <code>    if (old_tail.ptr-&gt;next.compare_exchange_strong(&#8592;</code>
            <strong>(11)</strong>
          </p>
          <p>
            <code>        old_next, new_next)) {</code>
          </p>
          <p>
            <code>     old_next = new_next;    &#8592;</code>
            <strong>(12)</strong>
          </p>
          <p>
            <code>     new_next.ptr = new node;&#8592;</code>
            <strong>(13)</strong>
          </p>
          <p>
            <code>    }</code>
          </p>
          <p>
            <code>    set_new_tail(old_tail, old_next);&#8592;</code>
            <strong>(14)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В целом похоже на исходную версию <code>push()</code> из листинга 7.15, но есть и несколько принципиальных отличий. Если указатель <code>data</code> <emphasis>действительно</emphasis> установлен <strong>(6)</strong>, то нужно обработать случай, когда нам помог другой поток, и кроме того появилась ветвь <code>else</code>, в которой один поток оказывает помощь другому <strong>(10)</strong>.</p>
          <p>Установив указатель <code>data</code> в узле <strong>(6)</strong>, новая версия <code>push()</code> изменяет указатель <code>next</code>, вызывая <code>compare_exchange_strong()</code> <strong>(7)</strong>. Мы используем <code>compare_exchange_strong()</code>, чтобы избежать цикла. Если обмен завершился неудачно, значит, другой поток уже установил указатель <code>next</code>, поэтому нам ни к чему узел, выделенный в начале, и его можно удалить <strong>(8)</strong>. Мы также хотим использовать значение <code>next</code>, установленное другим потоком, для обновления <code>tail</code> <strong>(9)</strong>.</p>
          <p>Собственно обновление указателя <code>tail</code> вынесено в отдельную функцию <code>set_new_tail()</code> <strong>(1)</strong>. В ней мы используем цикл по <code>compare_exchange_weak()</code> <strong>(2)</strong>, потому что если другие потоки пытаются поместить в очередь новый узел с помощью <code>push()</code>, то значение <code>external_count</code> может измениться, а нам не хотелось бы его потерять. Однако нужно позаботиться и о том, чтобы не затереть значение, которое другой поток уже успешно изменил, в противном случае в очереди могут возникнуть циклы, а это уже совершенно лишнее. Следовательно, нужно гарантировать, что часть <code>ptr</code> загруженного значения осталась той же самой, если сравнение с обменом не прошло. Если <code>ptr</code> не изменился после выхода из цикла <strong>(3)</strong>, то мы успешно установили <code>tail</code>, поэтому старый внешний счетчик нужно освободить <strong>(4)</strong>. Если значение <code>ptr</code> изменилось, то счетчик уже освобождён другим потоком, поэтому нам нужно только освободить ссылку, которую удерживает наш поток <strong>(5)</strong>.</p>
          <p>Если поток, вызвавший <code>push()</code>, не сумел установить указатель <code>data</code> на этой итерации цикла, то он может помочь более удачливому потоку завершить обновление. Сначала мы пытаемся записать в next указатель на новый узел, выделенный в этом потоке <strong>(11)</strong>. Если это получилось, то выделенный нами узел будет использоваться как новый узел <code>tail</code> <strong>(12)</strong>, а нам следует выделить еще один узел, поскольку поместить свои данные в очередь еще только предстоит <strong>(13)</strong>. После этого мы можем попытаться установить узел <code>tail</code>, вызвав <code>set_new_tail</code> до перехода к очередной итерации <strong>(14)</strong>.</p>
          <p>Вероятно, вы обратили внимание на чрезмерно большое для такого крохотного фрагмента количество <code>new</code> и <code>delete</code>. Вызвало это тем, что новые узлы создаются в <code>push()</code>, а уничтожаются в <code>pop()</code>. Поэтому быстродействие этого кода существенно зависит от того, насколько эффективно работает распределитель памяти; плохой распределитель может полностью свести на нет свойства масштабируемости, присущие свободному от блокировок контейнеру. Вопрос о выборе и реализации подобных распределителей выходит за рамки данной книги, но имейте в виду, что единственный способ узнать, какой распределитель лучше, — испытывать и замерять производительность. К числу стандартных приемов оптимизации выделения памяти можно отнести создание отдельного распределителя в каждом потоке и использование списка свободных узлов — освободившиеся узлы помещаются в этот список, а не возвращаются распределителю.</p>
          <p>Ну и, пожалуй, хватит примеров. Давайте теперь на основе вышеизложенного сформулируем ряд рекомендаций по написанию структур данных, свободных от блокировок.</p>
        </section>
      </section>
      <section>
        <title>
          <p>7.3. Рекомендации по написанию структур данных без блокировок</p>
        </title>
        <section>
          <p>Если вы тщательно прорабатывали все приведенные в этой главе примеры, то, наверное, оцепили, как трудно правильно написать код без блокировок. Если вы собираетесь проектировать собственные структуры данных, то не лишне будет иметь под рукой рекомендации, на которые можно опираться. Общие советы, относящиеся к параллельным структурам данных, приведенные в начале главы 6, остаются в силе, но этого мало. Из анализа примеров я извлек несколько полезных рекомендаций, к которым вы можете обращаться при проектировании структур данных, свободных от блокировок.</p>
        </section>
        <section>
          <title>
            <p>7.3.1. Используйте <code>std::memory_order_seq_cst</code> для создания прототипа</p>
          </title>
          <p>Порядок доступа к памяти <code>std::memory_order_seq_cst</code> гораздо проще для понимания и анализа, чем любой другой, потому что операции с такой семантикой полностью упорядочены. Во всех примерах из этой главы мы начинали с упорядочения <code>std::memory_order_seq_cst</code> и только потом ослабляли ограничения. В этом смысле использование других способов упорядочения можно считать <emphasis>оптимизацией</emphasis>, которой не следует заниматься преждевременно. В общем случае, для того чтоб определить, какие операции можно ослабить, нужно иметь перед глазами полный код, правильно работающий со структурой данных. Любая попытка пойти другим путем только осложнит вам жизнь. Проблема еще и в том, что тестирование кода может не выявить ошибок, но это еще не гарантирует их отсутствия. Если нет верификатора алгоритма, способного систематически тестировать все возможные сочетания видимости в разных потоках, которые совместимы с гарантиями, предоставляемыми заданными режимами упорядочения доступа к памяти (а такие программы существуют), то одного лишь прогона кода недостаточно.</p>
        </section>
        <section>
          <title>
            <p>7.3.2. Используйте подходящую схему освобождения памяти</p>
          </title>
          <p>Одна из самых сложных сторон написания свободного от блокировок кода — управление памятью. С одной стороны, требуется любой ценой предотвратить удаление объектов, на которые могут ссылаться другие потоки, а, с другой, удалять объекты как можно раньше, чтобы избежать чрезмерного расхода памяти. В этой главе мы познакомились с тремя методами, обеспечивающими безопасное освобождение памяти.</p>
          <p>• Дождаться, когда к структуре данных не будет обращаться ни один поток, и удалить разом все объекты, ожидающие удаления.</p>
          <p>• Использовать указатели опасности для выявления потока, обращающегося к конкретному объекту.</p>
          <p>• Подсчитывать ссылки на объекты и не удалять их, пока ссылки существуют.</p>
          <p>В любом случае идея заключается в том, чтобы каким-то образом отслеживать, сколько потоков обращается к объекту, и удалять его лишь в том случае, когда на него не осталось ни одной ссылки. Существует много методов освобождения памяти в структурах данных, свободных от блокировок. В частности, это идеальная ситуация для применения сборщика мусора. Придумывать алгоритмы гораздо проще, если знаешь, что сборщик мусора удалит узлы, когда они больше не используются, но не раньше.</p>
          <p>Другой способ — использовать узлы повторно и полностью освобождать их только тогда, когда уничтожается вся структура данных. Раз узлы используются повторно, то память никогда не становится недействительной, поэтому некоторые проблемы, сопряженные с неопределенным поведением, вообще не возникают. Недостаток же в том, что взамен появляется так называемая <emphasis>проблема ABA</emphasis>.</p>
        </section>
        <section>
          <title>
            <p>7.3.3. Помните о проблеме ABA</p>
          </title>
          <p>Проблема ABA свойственна любому алгоритму, основанному на сравнении с обменом. Проявляется она следующим образом.</p>
          <p>1. Поток 1 читает атомарную переменную <code>x</code> и обнаруживает, что она имеет значение <code>А</code>.</p>
          <p>2. Поток 1 выполняет некоторую операцию, исходя из этого значения, например разыменовывает его (если это указатель), выполняет поиск или делает еще что-то.</p>
          <p>3. Операционная система приостанавливает поток 1.</p>
          <p>4. Другой поток выполняет некоторые операции с <code>x</code>, в результате которых ее значение изменяется и становится равным <code>B</code>.</p>
          <p>5. Затем этот поток изменяет данные, ассоциированные со значением <code>A</code>, после чего значение, хранящееся в потоке 1, оказывается недействительным. Это может быть нечто кардинальное, например освобождение памяти, адресуемой указателем, или просто изменение какого-то ассоциированного значения.</p>
          <p>6. Далее поток снова изменяет значение <code>x</code> на <code>A</code>, но уже с новыми данными. В случае указателя это может быть новый объект, который но случайному стечению обстоятельства имеет тот же адрес, что прежний.</p>
          <p>7. Поток 1 возобновляется и выполняет сравнение с обменом для переменной <code>x</code>, сравнивая ее значение с <code>A</code>. Операция завершается успешно (потому что значение действительно равно <code>A</code>), но <emphasis>это уже не то</emphasis> <code><emphasis>А</emphasis></code>. Данные, ранее прочитанные потоком на шаге 2, более не действительны, но поток 1 ничего об этом не знает и повреждает структуру данных.</p>
          <p>Ни один из представленных в этой главе алгоритмов не страдает от этой проблемы, но совсем нетрудно написать свободный от блокировок алгоритм, в котором она проявится. Самый распространенный способ избежать ее — хранить вместе с переменной <code>x</code> счетчик ABA. Операция сравнения с обменом тогда производится над комбинацией <code>x</code> и счетчика, как над единым целым. Всякий раз, как значение заменяется, счетчик увеличивается, поэтому даже если окончательное значение <code>x</code> не изменилось, сравнение с обменом не пройдёт, если другой поток в промежутке изменял <code>x</code>.</p>
          <p>Проблема ABA особенно часто встречается в алгоритмах, в которых используются списки свободных узлов или иные способы повторного использования узлов вместо возврата их распределителю.</p>
        </section>
        <section>
          <title>
            <p>7.3.4. Выявляйте циклы активного ожидания и помогайте другим потокам</p>
          </title>
          <p>В последнем примере очереди мы видели, что поток, выполняющий операцию <code>push()</code>, должен дождаться, пока другой поток, выполняющий ту же операцию, завершит свои действия. Если ничего не предпринимать, то этот поток будет крутиться в цикле активного ожидания, впустую расходуя процессорное время и не продвигаясь ни на шаг. Наличие цикла ожидания в действительности эквивалентно блокирующей операции, а тогда с равным успехом можно было бы воспользоваться мьютексами. Модифицировав алгоритм таким образом, что ожидающий поток выполняет неполные шаги, если планировщик выделил ему время до завершения работы в исходном потоке, мы сможем устранить активное ожидание и сделать операцию неблокирующей. В примере очереди нам для этого потребовалось сделать одну переменную-член атомарной и использовать для ее установки операции сравнения с обменом, но в более сложных структурах данных могут понадобиться более обширные изменения.</p>
          <p>Отталкиваясь от структур данных с блокировками, описанных в главе 6, мы в этой главе продемонстрировали простые реализации структур данных без блокировок на примере все тех же стека и очереди. Мы видели, как внимательно нужно подходить к упорядочению доступа к памяти в атомарных операциях, чтобы избежать гонок и гарантировать, что каждый поток видит непротиворечивое представление структуры данных. Мы также поняли, что управление памятью в структурах данных без блокировок оказывается значительно сложнее, чем в структурах с блокировками, и изучили несколько подходов к решению этой проблемы. Еще мы узнали, как предотвращать циклы активного ожидания, помогая завершить работу потоку, которого мы ждем.</p>
          <p>Проектирование свободных от блокировок структур данных — сложная задача, при решении которой легко допустить ошибки, зато такие структуры обладают свойствами масштабируемости, незаменимыми в некоторых ситуациях. Надеюсь, что, проработав приведенные в этой главе примеры и ознакомившись с рекомендациями, вы будете лучше подготовлены к разработке собственных структур данных без блокировок, реализации алгоритмов, описанных в научных статьях, или к поиску ошибок, допущенных бывшим сотрудником компании.</p>
          <p>Во всех случаях, когда некоторые данные разделяются между потоками, нужно задумываться о применяемых структурах данных и о синхронизации. Проектируя структуры данных с учетом параллелизма, вы сможете инкапсулировать ответственность в самой структуре, позволив основной программе сосредоточиться на решаемой задаче, а не на синхронизации доступа к данным. Этот подход будет продемонстрирован в главе 8, где мы перейдём от параллельных структур данных к написанию параллельных программ. В параллельных алгоритмах для повышения производительности используется несколько потоков, и выбор подходящей параллельной структуры данных приобретает решающее значение.</p>
        </section>
      </section>
    </section>
    <section>
      <title>
        <p>Глава 8.</p>
        <p>Проектирование параллельных программ</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Методы распределения данных между потоками.</p>
        <p>&#9632; Факторы, влияющие на производительность параллельного кода.</p>
        <p>&#9632; Как от этих факторов зависит дизайн параллельных структур данных.</p>
        <p>&#9632; Безопасность многопоточного кода относительно исключений.</p>
        <p>&#9632; Масштабируемость.</p>
        <p>&#9632; Примеры реализации параллельных алгоритмов.</p>
      </annotation>
      <section>
        <p>В предыдущих главах мы в основном занимались появившимися в новом стандарте C++11 средствами для написания параллельных программ. В главах 6 и 7 мы видели, как эти средства применяются для проектирования простых структур данных, безопасных относительно доступа из нескольких потоков. Но как столяру недостаточно знать, как устроена петля или шарнир, чтобы смастерить шкаф или стол, так и для проектирования параллельных программ недостаточно знакомства с устройством и применением простых структур данных. Теперь мы будем рассматривать проблему в более широком контексте и научимся строить более крупные узлы, способные выполнять полезную работу В качестве примеров я возьму многопоточные реализации некоторых алгоритмов из стандартной библиотеки С++, но те же самые принципы остаются в силе при разработке всех уровней приложения.</p>
        <p>Как и в любом программном проекте, тщательное продумывание структуры параллельного кода имеет первостепенное значение. Однако в параллельной программе приходится учитывать еще больше факторов, чем в последовательной. Нужно принимать во внимание не только инкапсуляцию, связанность и сцепленность (эти вопросы подробно рассматриваются во многих книгах по проектированию программного обеспечения), но и то, какие данные разделять, как организовывать доступ к ним, каким потокам придётся ждать других потоков для завершения операции и т.д.</p>
        <p>Именно этим мы и будем заниматься в этой главе, начав с высокоуровневых (но фундаментальных) вопросов о том, сколько создавать потоков, какой код выполнять в каждом потоке и как многопоточность влияет на понятность программы, и закончив низкоуровневыми деталями того, как организовать разделяемые данные для достижения оптимальной производительности.</p>
        <p>Начнем с методов распределения работы между потоками.</p>
      </section>
      <section>
        <title>
          <p>8.1. Методы распределения работы между потоками</p>
        </title>
        <section>
          <p>Представьте, что вам поручили построить дом. Для этого предстоит вырыть котлован под фундамент, возвести стены, провести водопровод и электропроводку и т.д. Теоретически, имея достаточную подготовку, все это можно сделать и в одиночку, по времени уйдет много и придётся постоянно переключаться с одного занятия на другое. Можно вместо этого нанять несколько помощников. Тогда нужно решить, сколько людей нанимать и каких специальностей. К примеру, пригласить двух универсалов и всё делать совместно. По-прежнему нужно будет переходить от одной работы к другой, но в итоге строительство удастся завершить быстрее, так как теперь в нем принимает участие больше народу</p>
          <p>Есть и другой путь — нанять бригаду узких специалистов: каменщика, плотника, электрика, водопроводчика и других. Специалисты делают то, что лучше всего умеют, так что если прокладывать трубы не надо, то водопроводчик попивает чаёк. Работа все равно продвигается быстрее, так как занято больше людей, — водопроводчик может заниматься туалетом, пока электрик делает проводку на кухне, но зато когда для конкретного специалиста работы нет, он простаивает. Впрочем, несмотря на простои, специалисты, скорее всего, справятся быстрее, чем бригада мастеров на все руки. Им не нужно менять инструменты, да и свое дело они по идее должны делать быстрее, чем универсалы. Так ли это на самом деле, зависит от разных обстоятельств — нет другого пути, как взять и попробовать.</p>
          <p>Но и специалистов можно нанять много или мало. Наверное, имеет смысл нанимать больше каменщиков, чем электриков. Кроме того, состав бригады и ее общая эффективность могут измениться, если предстоит построить несколько домов. Если в одном доме у водопроводчика мало работы, то на строительстве нескольких его можно занять полностью. Наконец, если вы не обязаны платить специалистам за простой, то можно позволить себе нанять больше людей, пусть даже в каждый момент времени работать будет столько же, сколько раньше.</p>
          <p>Но хватит уже о строительстве, какое отношение всё это имеет к потокам? Да просто к ним применимы те же соображения. Нужно решить, сколько использовать потоков и какие задачи поручить каждому Должны ли потоки быть «универсалами», берущимися за любую подвернувшуюся работу или «специалистами», которые умеют хорошо делать одно дело? Или, быть может, нужно сочетание того и другого? Эти решения необходимо принимать вне зависимости от причин распараллеливания программы и от того, насколько они будут удачны, существенно зависит производительность и ясность кода. Поэтому так важно понимать, какие имеются варианты; тогда решения о структуре приложения будут опираться на знания, а не браться с потолка. В этом разделе мы рассмотрим несколько методов распределения задач и начнем с распределения данных между потоками.</p>
        </section>
        <section>
          <title>
            <p>8.1.1. Распределение данных между потоками до начала обработки</p>
          </title>
          <p>Легче всего распараллеливаются такие простые алгоритмы, как <code>std::for_each</code>, которые производят некоторую операцию над каждым элементом набора данных. Чтобы распараллелить такой алгоритм, можно назначить каждому элементу один из обрабатывающих потоков. Каким образом распределить элементы для достижения оптимальной производительности, зависит от деталей структуры данных, как мы убедимся ниже в этой главе.</p>
          <p>Простейший способ распределения данных заключается в том, чтобы назначить первые <emphasis>N</emphasis> элементов одному потоку, следующие <emphasis>N</emphasis> — другому и так далее, как показано на рис. 8.1, хотя это и не единственное решение. Как бы ни были распределены данные, каждый поток обрабатывает только назначенные ему элементы, никак не взаимодействуя с другими потоками до тех пор, пока не завершит обработку.</p>
          <image l:href="#img_18.png"/>
          <p><strong>Рис. 8.1.</strong> Распределение последовательных блоков данных между потоками</p>
          <p>Такая организация программы знакома каждому, кто программировал в системах Message Passing Interface (МРI)<a l:href="#n17" type="note">[17]</a> или OpenMP<a l:href="#n18" type="note">[18]</a>: задача разбивается на множество параллельных подзадач, рабочие потоки выполняют их параллельно, а затем результаты объединяются на стадии <emphasis>редукции</emphasis>. Этот подход применён в примере функции <code>accumulate</code> из раздела 2.4; в данном случае и параллельные задачи, и финальный шаг редукции представляют собой аккумулирование. Для простого алгоритма <code>for_each</code> финальный шаг отсутствует, так как нечего редуцировать.</p>
          <p>Понимание того, что последний шаг является редукцией, важно; в наивной реализации, представленной в листинге 2.8, финальная редукция выполняется как последовательная операция. Однако часто и ее можно распараллелить; операция <code>accumulate</code> по сути дела <emphasis>сама</emphasis> является редукцией, поэтому функцию из листинга 2.8 можно модифицировать таким образом, чтобы она вызывала себя рекурсивно, если, например, число потоков больше минимального количества элементов, обрабатываемых одним потоком. Или запрограммировать рабочие потоки так, чтобы по завершении задачи они выполняли некоторые шаги редукции, а не запускать каждый раз новые потоки.</p>
          <p>Хотя это действенная техника, применима она не в любой ситуации. Иногда данные не удается заранее распределить равномерно, а как это сделать, становится понятно только в процессе обработки. Особенно наглядно это проявляется в таких рекурсивных алгоритмах, как Quicksort; здесь нужен другой подход.</p>
        </section>
        <section>
          <title>
            <p>8.1.2. Рекурсивное распределение данных</p>
          </title>
          <p>Алгоритм Quicksort состоит из двух шагов: разбиение данных на две части — до и после опорного элемента в смысле требуемого упорядочения, и рекурсивная сортировка обеих «половин». Невозможно распараллелить этот алгоритм, разбив данные заранее, потому что состав каждой «половины» становится известен только в процессе обработки элементов. Поэтому распараллеливание по необходимости должно быть рекурсивным. На каждом уровне рекурсии производится <emphasis>больше</emphasis> вызовов функции <code>quick_sort</code>, потому что предстоит отсортировать элементы, меньшие опорного, и большие опорного. Эти рекурсивные вызовы не зависят друг от друга, так как обращаются к разным элементам, поэтому являются идеальными кандидатами для параллельного выполнения. На рис. 8.2 изображено такое рекурсивное разбиение.</p>
          <image l:href="#img_19.png"/>
          <p><strong>Рис. 8.2.</strong> Рекурсивное разбиение данных</p>
          <p>В главе 4 была приведена подобная реализация. Вместо того чтобы просто вызывать функцию рекурсивно для большей и меньшей «половины», мы с помощью <code>std::async()</code> на каждом шаге запускали асинхронную задачу для меньшей половины. Вызывая <code>std::async()</code>, мы просим стандартную библиотеку С++ самостоятельно решить, имеет ли смысл действительно выполнять задачу в новом потоке или лучше сделать это синхронно.</p>
          <p>Это существенно: при сортировке большого набора данных запуск нового потока для каждого рекурсивного вызова быстро приводит к образованию чрезмерного количества потоков. Как мы увидим ниже, когда потоков слишком много, производительность может не возрасти, а наоборот <emphasis>упасть</emphasis>. Кроме того, если набор данных очень велик, то потоков может просто не хватить. Сама идея рекурсивного разбиения на задачи хороша, нужно только строже контролировать число запущенных потоков. В простых случаях с этим справляется <code>std::async()</code>, но есть и другие варианты.</p>
          <p>Один из них — воспользоваться функцией <code>std::thread::hardware_concurrency()</code> для выбора нужного числа потоков, как мы делали в параллельной версии <code>accumulate()</code> из листинга 2.8. Тогда вместо того чтобы запускать новый поток для каждого рекурсивного вызова, мы можем просто поместить подлежащий сортировке блок данных в потокобезопасный стек типа того, что был описан в главах 6 и 7. Если потоку больше нечего делать — потому что он закончил обработку всех своих блоков или потому что ждет, когда необходимый ему блок будет отсортирован, то он может взять блок из стека и заняться его сортировкой.</p>
          <p>В следующем листинге показана реализация этой идеи.</p>
          <empty-line/>
          <p><strong>Листинг 8.1.</strong> Параллельный алгоритм Quicksort с применением стека блоков, ожидающих сортировки</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>struct sorter { &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> struct chunk_to_sort {</code>
          </p>
          <p>
            <code>  std::list&lt;T&gt; data;</code>
          </p>
          <p>
            <code>  std::promise&lt;std::list&lt;T&gt; &gt; promise;</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> thread_safe_stack&lt;chunk_to_sort&gt; chunks; &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads;        &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> unsigned const max_thread_count;</code>
          </p>
          <p>
            <code> std::atomic&lt;bool&gt; end_of_data;</code>
          </p>
          <empty-line/>
          <p>
            <code> sorter():</code>
          </p>
          <p>
            <code>  max_thread_count(std::thread::hardware_concurrency() - 1),</code>
          </p>
          <p>
            <code>  end_of_data(false) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> ~sorter() {          &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  end_of_data = true; &#8592;</code>
            <strong>(5)</strong>
          </p>
          <empty-line/>
          <p>
            <code>  for (unsigned i = 0; i &lt; threads.size(); ++i) {</code>
          </p>
          <p>
            <code>   threads[i].join(); &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void try_sort_chunk() {</code>
          </p>
          <p>
            <code>  boost::shared_ptr&lt;chunk_to_sort&gt; chunk = chunks.pop();&#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>  if (chunk) {</code>
          </p>
          <p>
            <code>   sort_chunk(chunk); &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> std::list&lt;T&gt; do_sort(std::list&lt;T&gt;&amp; chunk_data) { &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>  if (chunk_data.empty()) {</code>
          </p>
          <p>
            <code>   return chunk_data;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  std::list&lt;T&gt; result;</code>
          </p>
          <p>
            <code>  result.splice(result.begin(), chunk_data, chunk_data.begin());</code>
          </p>
          <p>
            <code>  T const&amp; partition_val = *result.begin();</code>
          </p>
          <empty-line/>
          <p>
            <code>  typename std::list&lt;T&gt;::iterator divide_point = &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>   std::partition(chunk_data.begin(), chunk_data.end(),</code>
          </p>
          <p>
            <code>    [&amp;](T const&amp; val) {return val &lt; partition_val; });</code>
          </p>
          <p>
            <code>  chunk_to_sort new_lower_chunk;</code>
          </p>
          <p>
            <code>  new_lower_chunk.data.splice(new_lower_chunk.data.end(),</code>
          </p>
          <p>
            <code>   chunk_data, chunk_data.begin(),</code>
          </p>
          <p>
            <code>   divide_point);</code>
          </p>
          <p>
            <code>  std::future&lt;std::list&lt;T&gt; &gt; new_lower =</code>
          </p>
          <p>
            <code>   new_lower_chunk.promise.get_future();</code>
          </p>
          <p>
            <code>  chunks.push(std::move(new_lower_chunk)); &#8592;</code>
            <strong>(11)</strong>
          </p>
          <p>
            <code>  if (threads.size() &lt; max_thread_count) { &#8592;</code>
            <strong>(12)</strong>
          </p>
          <p>
            <code>   threads.push_back(std::thread(&amp;sorter&lt;T&gt;::sort_thread, this));</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  std::list&lt;T&gt; new_higher(do_sort(chunk_data));</code>
          </p>
          <empty-line/>
          <p>
            <code>  result.splice(result.end(), new_higher);</code>
          </p>
          <p>
            <code>  while (new_lower.wait_for(std::chrono::seconds(0)) !=</code>
          </p>
          <p>
            <code>   std::future_status::ready) { &#8592;</code>
            <strong>(13)</strong>
          </p>
          <p>
            <code>   try_sort_chunk();            &#8592;</code>
            <strong>(14)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  result.splice(result.begin(), new_lower.get());</code>
          </p>
          <p>
            <code>  return result;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void sort_chunk(boost::shared_ptr&lt;chunk_to_sort&gt; const&amp; chunk) {</code>
          </p>
          <p>
            <code>  chunk-&gt;promise.set_value(do_sort(chunk-&gt;data));&#8592;</code>
            <strong>(15)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void sort_thread() {</code>
          </p>
          <p>
            <code>  while (!end_of_data) {     &#8592;</code>
            <strong>(16)</strong>
          </p>
          <p>
            <code>   try_sort_chunk();         &#8592;</code>
            <strong>(17)</strong>
          </p>
          <p>
            <code>   std::this_thread::yield();&#8592;</code>
            <strong>(18)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>std::list&lt;T&gt; parallel_quick_sort(std::list&lt;T&gt; input) { &#8592;</code>
            <strong>(19)</strong>
          </p>
          <p>
            <code> if (input.empty()) {</code>
          </p>
          <p>
            <code>  return input;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> sorter&lt;T&gt; s;</code>
          </p>
          <empty-line/>
          <p>
            <code> return s.do_sort(input); &#8592;</code>
            <strong>(20)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Здесь функция <code>parallel_quick_sort</code> <strong>(19)</strong> делегирует большую часть работы классу <code>sorter</code> <strong>(1)</strong>, который объединяет стек неотсортированных блоков <strong>(2)</strong> с множеством потоков <strong>(3)</strong>. Основные действия производятся в функции-члене <code>do_sort</code> <strong>(9)</strong>, которая занимается обычным разбиением данных на две части <strong>(10)</strong>. Но на этот раз она не запускает новый поток для каждого блока, а помещает его в стек <strong>(11)</strong> и запускает новый поток, только если еще есть незанятые процессоры <strong>(12)</strong>. Поскольку меньший блок, возможно, обрабатывается другим потоком, нам необходимо дождаться его готовности <strong>(13)</strong>. Чтобы не простаивать зря (в том случае, когда данный поток единственный или все остальные уже заняты), мы пытаемся обработать блок, находящийся в стеке <strong>(14)</strong>. Функция <code>try_sort_chunk</code> извлекает поток из стека <strong>(7)</strong>, сортирует его <strong>(8)</strong> и сохраняет результаты в обещании <code>promise</code>, так чтобы их смог получить поток, который поместил в стек данный блок <strong>(15)</strong>.</p>
          <p>Запущенные потоки крутятся в цикле, пытаясь отсортировать блоки, находящиеся в стеке <strong>(17)</strong>, ожидая, пока будет установлен флаг <code>end_of_data</code> <strong>(16)</strong>. В промежутке между проверками они уступают процессор другим потокам <strong>(18)</strong>, чтобы у тех был шанс поместить в стек новые блоки. Эта программа полагается на то, что деструктор класса <code>sorter</code> <strong>(4)</strong> разберется с запущенными потоками. Когда все данные будут отсортированы, <code>do_sort</code> вернет управление (хотя рабочие потоки все еще выполняются), так что главный поток вернется из <code>parallel_quick_sort</code> <strong>(20)</strong> и, стало быть, уничтожит объект <code>sorter</code>. В этот момент деструктор поднимет флаг <code>end_of_data</code> <strong>(5)</strong> и дождется завершения рабочих потоков <strong>(6)</strong>. Поднятый флаг является для функции потока указанием выйти из цикла <strong>(16)</strong>.</p>
          <p>При таком подходе не возникает проблемы неограниченного количества потоков, с которой мы сталкивались, когда <code>spawn_task</code> каждый раз запускает новый поток. С другой стороны, мы не полагаемся на то, что стандартная библиотека С++ выберет количество рабочих потоков за нас, как то происходит при использовании <code>std::async()</code>. Мы сами ограничиваем число потоков значением <code>std::thread::hardware_concurrency()</code>, чтобы избежать чрезмерно большого количества контекстных переключений. Однако же взамен нас поджидает другая потенциальная проблема: управление потоками и взаимодействие между ними сильно усложняют код. Кроме того, хотя потоки и обрабатывают разные элементы данных, все они обращаются к стеку для добавления новых блоков и извлечения блоков для сортировки. Из-за этой острой конкуренции производительность может снизиться, пусть даже мы используем свободный от блокировок (и, значит, неблокирующий) стек. Почему так происходит, мы увидим чуть ниже.</p>
          <p>Этот подход представляет собой специализированную версию <emphasis>пула потоков</emphasis> — существует набор потоков, которые получают задачи из списка ожидающих работ, выполняют их, а затем снова обращаются к списку. Некоторые потенциальные проблемы, свойственные пулам потоков (в том числе конкуренция за список работ), и способы их решения рассматриваются в главе 9. Задача масштабирования приложения на несколько процессоров более детально обсуждается в этой главе ниже (см. раздел 8.2.1).</p>
          <p>Как при предварительном, так и при рекурсивном распределении данных мы предполагаем, что сами данные фиксированы заранее, а нам нужно лишь найти удачный способ их разбиения. Но так бывает не всегда; если данные порождаются динамически или поступают из внешнего источника, то такой подход не годится. В этом случае имеет смысл распределять работу по типам задач, а не по данным.</p>
        </section>
        <section>
          <title>
            <p>8.1.3. Распределение работы по типам задач</p>
          </title>
          <p>Распределение работы между потоками путем назначения каждому потоку блока данных (заранее или рекурсивно во время обработки) все же опирается на предположение о том, что все потоки производят одни те же действия с данными. Альтернативный подход — заводить специализированные потоки, каждый из которых решает отдельную задачу — как водопроводчики и электрики на стройке. Потоки могут даже работать с одними и теми же данными, но обрабатывать их по-разному.</p>
          <p>Такой способ распределения работы — следствие распараллеливания ради разделения обязанностей; у каждого потока есть своя задача, которую он решает независимо от остальных. Время от времени другие потоки могут поставлять нашему потоку данные или генерировать события, на которые он должен отреагировать, но в общем случае каждый поток занимается тем, для чего предназначен. В принципе, это хороший дизайн — у каждой части кода есть своя зона ответственности.</p>
          <subtitle>Распределение работы по типам задач с целью разделения обязанностей</subtitle>
          <p>Однопоточное приложение должно как-то разрешать противоречия с принципом единственной обязанности, если существует несколько задач, которые непрерывно выполняются в течение длительного промежутка времени, или если приложение должно обрабатывать поступающие события (например, нажатия на клавиши или входящие сетевые пакеты) своевременно, несмотря на наличие других задач. Для решения этой проблемы мы обычную вручную пишем код, который выполняет кусочек задачи А, потом кусочек задачи В, потом проверяет, не нажата ли клавиша и не пришёл ли сетевой пакет, а потом возвращается в начало цикла, чтобы выполнить следующий кусочек задачи А. В результате код задачи А оказывается усложнен из-за необходимости сохранять состояние и периодически возвращать управление главному циклу. Если выполнять в этом цикле чрезмерно много задач, то скорость работы упадёт, а пользователю придётся слишком долго ждать реакции на нажатие клавиши. Уверен, все вы встречались с крайними проявлениями этого феномена не в одном так в другом приложении: вы просите программу выполнить какое-то действие, после чего интерфейс вообще перестаёт реагировать, пока оно не завершится.</p>
          <p>Тут-то и приходят на выручку потоки. Если выполнять каждую задачу в отдельном потоке, то всю эту работу возьмет на себя операционная система. В коде для решения задачи А вы можете сосредоточить внимание только на этой задаче и не думать о сохранении состояния, возврате в главный цикл и о том, сколько вам понадобится времени. Операционная система автоматически сохранит состояние и в подходящий момент переключится на задачу В или С, а если система оснащена несколькими процессорами или ядрами, то задачи А и В могут даже выполняться действительно параллельно. Код обработки клавиш или сетевых пакетов теперь будет работать без задержек, и все остаются в выигрыше: пользователь своевременно получает отклик от программы, а разработчик может писать более простой код, так как каждый поток занимается только тем, что входит в его непосредственные обязанности, не отвлекаясь на управление порядком выполнения или на взаимодействие с пользователем.</p>
          <p>Звучит, как голубая мечта. Да возможно ли такое? Как всегда, дьявол кроется в деталях. Если всё действительно независимо и потокам не нужно общаться между собой, то это и вправду легко. Увы, мир редко бывает таким идеальным. Эти замечательные фоновые потоки часто выполняют какие-то запросы пользователя и должны уведомлять пользователя о завершении, обновляя графический интерфейс. А то еще пользователь вздумает отменить задачу, и тогда интерфейс должен каким-то образом послать потоку сообщение с требованием остановиться. В обоих случаях необходимо все тщательно продумать и правильно синхронизировать, хотя обязанности таки разделены. Поток пользовательского интерфейса занимается только интерфейсом, но должен обновлять его но требованию других потоков. Аналогично поток, занятый фоновой задачей, выполняет только операции, свойственные данной задаче, но не исключено, что одна из этих обязанностей заключается в том, чтобы остановиться по просьбе другого потока. Потоку все равно, откуда поступил запрос, важно лишь, что он адресован ему и относится к его компетенции.</p>
          <p>На пути разделения обязанностей между потоками нас подстерегают две серьезные опасности. Во-первых, мы можем <emphasis>неправильно</emphasis> разделить обязанности. Признаками такой ошибки является большой объем разделяемых данных или положение, при котором потоки должны ждать друг друга; то и другое означает, что взаимодействие между потоками избыточно интенсивно. Когда такое происходит, нужно понять, чем вызвана необходимость взаимодействия. Если все сводится к какой-то одной причине, то, быть может, соответствующую обязанность следует поручить отдельному потоку, освободив от нее всех остальных. Наоборот, если два потока много взаимодействуют друг с другом и мало — с остальными, то, возможно, имеет смысл объединить их в один.</p>
          <p>Распределяя задачи по типам, не обязательно полностью изолировать их друг от друга. Если к нескольким наборам входных данных требуется применять одну <emphasis>последовательность</emphasis> операций, то работу можно разделить так, что каждый поток будет выполнять какой-то один этап этой последовательности.</p>
          <subtitle>Распределение последовательности задач между потоками</subtitle>
          <p>Если задача заключается в применении одной последовательности операций ко многим независимым элементам данных, то можно организовать распараллеленный <emphasis>конвейер.</emphasis> Здесь можно провести аналогию с физическим конвейером: данные поступают с одного конца, подвергаются ряду операций и выходят с другого конца.</p>
          <p>Чтобы распределить работу таким образом, следует создать отдельный поток для каждого участка конвейера, то есть для каждой операции. По завершении операции элемент данных помещается в очередь, откуда его забирает следующий поток. В результате поток, выполняющий первую операцию, сможет приступить к обработке следующего элемента, пока второй поток трудится над первым элементом.</p>
          <p>Такая альтернатива стратегии распределения данных между потоками, которая была описана в разделе 8.1.1, хорошо приспособлена для случаев, когда входные данные вообще неизвестны до начала операции. Например, данные могут поступать по сети или первой в последовательности операцией может быть просмотр файловой системы на предмет нахождения подлежащих обработке файлов.</p>
          <p>Конвейеры хороши также тогда, когда каждая операция занимает много времени; распределяя между потоками задачи, а не данные, мы изменяем качественные показатели производительности. Предположим, что нужно обработать 20 элементов данных на машине с четырьмя ядрами, и обработка каждого элемента состоит из четырех шагов, по 3 секунды каждый. Если распределить данные между потоками, то каждому потоку нужно будет обработать 5 элементов. В предположении, что нет никаких других операций, которые могли бы повлиять на хронометраж, по истечении 12 секунд будет обработано четыре элемента, по истечении 24 секунд — 8 элементов и т.д. На обработку всех 20 элементов уйдет 1 минута. Если организовать конвейер, ситуация изменится. Четыре шага можно распределить между четырьмя ядрами. Теперь первый элемент будет обрабатываться каждым из четырех ядер, и в целом на это уйдет 12 секунд — как и раньше. На самом деле, по истечении 12 секунд в нас обработан всего один элемент, что хуже, чем при распределении данных. Однако после того как конвейер <emphasis>запущен</emphasis>, работа идет немного по-другому; первое ядро, обработав первый элемент, переходит ко второму. Поэтому, когда последнее ядро закончит обработку первого элемента, второй уже будет наготове. В результате каждые три секунды на выходе получается очередной обработанный элемент, тогда как раньше элементы выходили пачками по четыре каждые 12 секунд.</p>
          <p>Суммарное время обработки всего пакета может увеличиться, потому что придётся подождать 9 секунд, пока первый элемент доберется до последнего ядра. Но более плавная обработка в некоторых случаях предпочтительнее. Возьмем, к примеру, систему воспроизведения цифрового видео высокой четкости. Чтобы фильм можно было смотреть без напряжения, частота кадров должна быть не менее 25 в секунду, а лучше — больше. Кроме того, временные промежутки между кадрами должны быть одинаковы для создания иллюзии непрерывного движения. Приложение, способное декодировать 100 кадров секунду, никому не нужно, если оно секунду ждет, потом «выплевывает» сразу 100 кадров, потом еще секунду ждет и снова выдает 100 кадров. С другой стороны, зритель не будет возражать против двухсекундной задержки <emphasis>перед началом</emphasis> просмотра. В такой ситуации распараллеливание с помощью конвейера, позволяющее выводить кадры с постоянной скоростью, безусловно, предпочтительнее.</p>
          <p>Познакомившись с различными способами распределения работы между потоками, посмотрим теперь, какие факторы влияют на производительность многопоточной системы и как от них зависит выбор решения.</p>
        </section>
      </section>
      <section>
        <title>
          <p>8.2. Факторы, влияющие на производительность параллельного кода</p>
        </title>
        <section>
          <p>Если вы распараллеливаете программу, чтобы повысить ее быстродействие в системе с несколькими процессорами, то должны знать о том, какие факторы вообще влияют на производительность. Но и в том случае, когда потоки применяются просто для разделения обязанностей, нужно позаботиться о том, чтобы многопоточность не привела к снижению быстродействия. Пользователи не скажут спасибо, если приложение будет работать на новенькой 16-ядерной машине <emphasis>медленнее</emphasis>, чем на старой одноядерной.</p>
          <p>Как мы скоро увидим, на производительность многопоточного кода оказывают влияние многие факторы и даже решение о том, <emphasis>какой</emphasis> элемент данных в каком потоке обрабатывать (при прочих равных условиях) может кардинально изменить скорость работы программы. А теперь без долгих слов приступим к изучению этих факторов и начнем с самого очевидного: сколько процессоров имеется в системе?</p>
        </section>
        <section>
          <title>
            <p>8.2.1. Сколько процессоров?</p>
          </title>
          <p>Количество (и конфигурация) процессоров — первый из существенных факторов, влияющих на производительность многопоточного приложения. Иногда вы точно знаете о том, на каком оборудовании будет работать программа и можете учесть это при проектировании, произведя реальные измерения на целевой системе или ее точной копии. Если так, то вам крупно повезло; как правило, разработчик лишен такой роскоши. Быть может, программа пишется на <emphasis>похожей</emphasis> системе, но различия могут оказаться весьма значимыми. Например, вы разрабатывали на двух- или четырехъядерной машине, а у заказчика один многоядерный процессор (с произвольным числом ядер), или несколько одноядерных или даже несколько многоядерных процессоров. Поведение и характеристики производительности программы могут существенно зависеть от таких деталей, поэтому нужно заранее продумывать возможные последствия и тестировать в максимально разнообразных конфигурациях.</p>
          <p>В первом приближении один 16-ядерный процессор эквивалентен четырем 4-ядерным или 16 одноядерным, во всех случаях одновременно могут выполняться 16 потоков. Чтобы в полной мере задействовать имеющийся параллелизм, в программе должно быть не менее 16 потоков. Если их меньше, то вычислительная мощность используется не полностью (пока оставляем за скобками тот факт, что могут работать и другие приложения). С другой стороны, если готовых к работе (не заблокированных в ожидании чего-то) потоков больше 16, то приложение будет попусту растрачивать процессорное время на контекстное переключение, о чем мы уже говорили в главе 1. Такая ситуация называется <emphasis>превышением лимита</emphasis> (oversubscription).</p>
          <p>Чтобы приложение могло согласовать количество потоков с возможностями оборудования, в стандартной библиотеке Thread Library имеется функция <code>std::thread::hardware_concurrency()</code>. Мы уже видели, как ее можно использовать для определения подходящего количества потоков.</p>
          <p>Использовать <code>std::thread::hardware_concurrency()</code> напрямую следует с осторожностью; ваш код не знает, какие еще потоки работают в программе, если только вы не сделали эту информацию разделяемой. В худшем случае, когда несколько потоков одновременно вызывают функцию, которая принимает решение о масштабировании с помощью <code>std::thread::hardware_concurrency()</code>, превышение лимита получится очень большим. Функция <code>std::async()</code> решает эту проблему, потому что библиотека знает обо всех обращениях к ней и может планировать потоки с учетом этой информации. Избежать этой трудности помогают также пулы потоков, если пользоваться ими с умом.</p>
          <p>Однако даже если вы учитываете все потоки в своем приложении, остаются еще другие запущенные в системе программы. Вообще-то в однопользовательских системах редко запускают одновременно несколько счетных задач, но бывают области применения, где это обычное дело. Если система проектировалась специально под такие условия, то обычно в ней есть механизмы, позволяющие каждому приложению заказать подходящее количество потоков, хотя они и выходят за рамки стандарта С++. Один из вариантов — аналог <code>std::async()</code>, который при выборе количества потоков учитывает общее число асинхронных задач, выполняемых всеми приложениями. Другой — ограничение числа процессорных ядер, доступных данному приложению. Лично я ожидал бы, что это ограничение будет отражено в значении, которое возвращает функция <code>std::thread::hardware_concurrency()</code> на таких платформах, однако это не гарантируется. Если вас интересует подобный сценарий, обратитесь в документации.</p>
          <p>Положение осложняется еще и тем, что идеальный алгоритм для решения конкретной задачи может зависеть от размерности задачи в сравнении с количеством процессорных устройств. Если имеется <emphasis>массивно параллельная</emphasis> система, где процессоров очень много, то алгоритм с большим числом операций может завершиться быстрее алгоритма с меньшим числом операций, потому что каждый процессор выполняет лишь малую толику общего числа операций.</p>
          <p>По мере роста числа процессоров возникает и еще одна проблема, влияющая на производительность: обращение к общим данным со стороны нескольких процессоров.</p>
        </section>
        <section>
          <title>
            <p>8.2.2. Конкуренция за данные и перебрасывание кэша</p>
          </title>
          <p>Если два потока, одновременно выполняющиеся на разных процессорах, <emphasis>читают</emphasis> одни и те же данные, то обычно проблемы не возникает — данные просто копируются в кэши каждого процессора. Но если один поток <emphasis>модифицирует</emphasis> данные, то изменение должно попасть в кэш другого процессора, а на это требуется время. В зависимости от характера операций в двух потоках и от упорядочения доступа к памяти, модификация может привести к тому, что один процессор должен будет остановиться и подождать, пока аппаратура распространит изменение. С точки зрения процессора, это <emphasis>феноменально</emphasis> медленная операция, эквивалентная многим сотням машинных команд, хотя точное время зависит в основном от физической конструкции оборудования.</p>
          <p>Рассмотрим следующий простой фрагмент кода:</p>
          <p>
            <code>std::atomic&lt;unsigned long&gt; counter(0);</code>
          </p>
          <p>
            <code>void processing_loop() {</code>
          </p>
          <p>
            <code> while(counter.fetch_add(</code>
          </p>
          <p>
            <code>  1, std::memory_order_relaxed) &lt; 100000000) {</code>
          </p>
          <p>
            <code>  do_something();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Переменная <code>counter</code> глобальная, поэтому любой поток, вызывающий <code>processing_loop()</code>, изменяет одну и ту же переменную. Следовательно, после каждого инкремента процессор должен загрузить в свой кэш актуальную копию <code>counter</code>, модифицировать ее значение и сделать его доступным другим процессорам. И хотя мы задали упорядочение <code>std::memory_order_relaxed</code>, чтобы процессору не нужно было синхронизироваться с другими данными, <code>fetch_add</code> — это операция чтения-модификации-записи и, значит, должна получить самое последнее значение переменной. Если другой поток на другом процессоре выполняет этот же код, то значение <code>counter</code> придётся передавать из кэша одного процессора в кэш другого, чтобы при каждом инкременте процессор видел актуальное значение <code>counter</code>. Если функция <code>do_something()</code> достаточно короткая или этот код исполняет много процессоров, то дело кончится тем, что они будут <emphasis>ожидать</emphasis> друг друга; один процессор готов обновить значение, но в это время другой уже обновляет, поэтому придётся дождаться завершения операции и распространения изменения. Такая ситуация называется <emphasis>высокой конкуренцией.</emphasis> Если процессорам редко приходится ждать друг друга, то говорят о <emphasis>низкой конкуренции</emphasis>.</p>
          <p>Подобный цикл приводит к тому, что значение counter многократно передается из одного кэша в другой. Это явление называют <emphasis>перебрасыванием кэша</emphasis> (cache ping-pong), оно может серьезно сказаться на производительности приложения. Когда процессор простаивает в ожидании передачи в кэш, он не может делать <emphasis>вообще</emphasis> ничего, даже если имеются другие потоки, которые могли бы заняться полезной работой. Так что ничего хорошего в этом случае приложению не светит.</p>
          <p>Быть может, вы думаете, что к вам это не относится — ведь в вашей-то программе таких циклов нет. Да так ли? А как насчет блокировок мьютексов? Когда программа захватывает мьютекс в цикле, она выполняет очень похожий код — с точки зрения доступа к данным. Чтобы захватить мьютекс, поток должен доставить составляющие мьютекс данные своему процессору и модифицировать их. Затем он снова модифицирует мьютекс, чтобы освободить его, а данные мьютекса необходимо передать следующему потоку, желающему его захватить. Время передачи <emphasis>добавляется</emphasis> к времени, в течение которого второй поток должен ждать, пока первый освободит мьютекс:</p>
          <p>
            <code>std::mutex m;</code>
          </p>
          <p>
            <code>my_data data;</code>
          </p>
          <p>
            <code>void processing_loop_with_mutex() {</code>
          </p>
          <p>
            <code> while (true) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(m);</code>
          </p>
          <p>
            <code>  if (done_processing(data)) break;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>А теперь самое печальное: если к данным и мьютексу обращаются сразу несколько потоков, то при увеличении числа ядер и процессоров ситуация только <emphasis>ухудшается</emphasis>, то есть возрастает вероятность получить высокую конкуренцию из-за того, что процессоры ждут друг друга. Если вы запускаете несколько потоков для ускорения обработки одних и тех же данных, то потоки начинают конкурировать за данные и, следовательно, за один и тот же мьютекс. Чем потоков больше, чем вероятнее, что они будут пытаться одновременно захватить мьютекс или получить доступ к атомарной переменной или еще что-нибудь в этом роде.</p>
          <p>Последствия конкуренции за мьютексы и за атомарные переменные обычно разнятся по той простой причине, что мьютекс сериализует потоки на уровне операционной системы, а не процессора. Если количество готовых к выполнению потоков достаточно, то операционная система может запланировать один поток, пока другой ожидает мьютекса. Напротив, застывший процессор прекращает выполнение работающего на нем потока. Тем не менее, он оказывает влияние на производительность потоков, <emphasis>конкурирующих</emphasis> за мьютекс, — в конце концов, по определению в каждый момент времени может выполняться только один из них.</p>
          <p>В главе 3 мы видели, что редко обновляемую структуру данных можно защитить мьютексом типа «несколько читателей — один писатель» (см. раздел 3.3.2). Эффект перебрасывания кэша может свести на нет преимущества такого мьютекса при неподходящей рабочей нагрузке, потому что все потоки, обращающиеся к данным (пусть даже только для чтения) все равно должны модифицировать сам мьютекс. По мере увеличения числа процессоров, обращающихся к данным, конкуренция за мьютекс возрастает, и строку кэша, в которой находится мьютекс, приходится передавать между ядрами, что увеличивает время захвата и освобождения мьютекса до неприемлемого уровня. Существуют приёмы, позволяющие сгладить остроту этой проблемы; суть их сводится к распределению мьютекса между несколькими строками кэша, но если вы не готовы реализовать такой мьютекс самостоятельно, то должны будете мириться с тем, что дает система.</p>
          <p>Если перебрасывание кэша — это так плохо, то можно ли его избежать? Ниже в этой главе мы увидим, что ответ лежит в русле общих рекомендаций но улучшению условий для распараллеливания: делать все возможное для того, чтобы сократить конкуренцию потоков за общие ячейки памяти.</p>
          <p>Но это не так-то просто — впрочем, просто никогда не бывает. Даже если к некоторой ячейке памяти в каждый момент времени обращается только один поток, перебрасывание кэша все равно возможно из-за явления, которое называется <emphasis>ложным разделением</emphasis> (false sharing).</p>
        </section>
        <section>
          <title>
            <p>8.2.3. Ложное разделение</p>
          </title>
          <p>Процессорные кэши имеют дело не с отдельными ячейками памяти, а с блоками ячеек, которые называются <emphasis>строками кэша.</emphasis> Обычно размер такого блока составляет 32 или 64 байта, в зависимости от конкретного процессора. Поскольку аппаратный кэш оперирует блоками памяти, небольшие элементы данных, находящиеся в смежных ячейках, часто оказываются в одной строке кэша. Иногда это хорошо: с точки зрения производительности лучше, когда данные, к которым обращается поток, находятся в одной, а не в нескольких строках кэша. Однако, если данные, оказавшиеся в одной строке кэша, логически не связаны между собой и к ним обращаются разные потоки, то возможно возникновение неприятной проблемы.</p>
          <p>Допустим, что имеется массив значений типа <code>int</code> и множество потоков, каждый из которых обращается к своему элементу массива, в том числе для обновления, причём делает это часто. Поскольку размер <code>int</code> обычно меньше строки кэша, то в одной строке окажется несколько значений. Следовательно, хотя каждый поток обращается только к своему элементу, перебрасывание кэша <emphasis>все равно</emphasis> имеет место. Всякий раз, как поток хочет обновить значение в позиции 0, вся строка кэша должна быть передана процессору, на котором этот поток исполняется. И для чего? Только для того, чтобы потом быть переданной процессору, на котором исполняется поток, желающий обновить элемент в позиции 1. Строка кэша разделяется, хотя каждый элемент данных принадлежит только одному потоку. Отсюда и название <emphasis>ложное разделение</emphasis>. Решение заключается в том, чтобы структурировать данные таким образом, чтобы элементы, к которым обращается один поток, находились в памяти рядом (и, следовательно, с большей вероятностью попали в одну строку кэша), а элементы, к которым обращаются разные потоки, отстояли далеко друг от друга и попадали в разные строки кэша. Как это влияет на проектирование кода и данных, вы узнаете ниже.</p>
          <p>Если обращение из разных потоков к данным, находящимся в одной строке кэша, — зло, то как влияет на общую картину расположение в памяти данных, к которым обращается один поток?</p>
        </section>
        <section>
          <title>
            <p>8.2.4. Насколько близки ваши данные?</p>
          </title>
          <p>Ложное разделение вызвано тем, что данные, нужные одному потоку, расположены в памяти слишком близко к данным другого потока. Но есть и еще одна связанная с размещением данных в памяти проблема, которая влияет на производительность одного потока безотносительно к прочим. Эта локальность данных — если данные, к которым обращается поток, разбросаны по памяти, то велика вероятность, что они находятся в разных строках кэша. И наоборот, если данные потока расположены близко друг к другу, то они с большей вероятностью принадлежат одной строке кэша. Следовательно, когда данные разбросаны, из памяти в кэш процессора приходится загружать больше строк кэша, что увеличивает задержку памяти и снижает общую производительность.</p>
          <p>Кроме того, если данные разбросаны, то возрастают шансы на то, что строка кэша, содержащая данные текущего потока, содержит также данные <emphasis>других</emphasis> потоков. В худшем случае может оказаться, что кэш содержит больше ненужных вам данных, чем нужных. Таким образом, впустую растрачивается драгоценная кэш-память и, значит, количество безрезультатных обращений к кэшу увеличивается, и процессору приходится загружать данные из основной памяти, хотя они уже когда-то находились в кэше, но были вытеснены.</p>
          <p>Да, но ведь это относится к однопоточным программам, я-то тут при чем? — спросите вы. А все дело в <emphasis>контекстном переключении.</emphasis> Если количество потоков в системе превышает количество ядер, то каждое ядро будет исполнять несколько потоков. Это увеличивает давление на кэш, поскольку мы пытаемся сделать так, чтобы разные потоки обращались к разным строкам кэша — во избежание ложного разделения. Следовательно, при переключении потоков процессором вероятность перезагрузки строк кэша возрастает, если данные каждого потока находятся в разных строках кэша. Если потоков больше, чем ядер или процессоров, то операционная система может назначить потоку один процессор в течение одного кванта времени и другой — в следующем кванте. В результате строки кэша, содержащие данные этого потока, придётся передавать из одного кэша в другой. Чем больше таких передач, тем больше на них уходит времени. Конечно, операционные системы стараются избежать такого развития событий, но иногда это все же происходит и приводит к падению производительности.</p>
          <p>Проблемы, связанные с контекстным переключением, возникают особенно часто, когда количество <emphasis>готовых к выполнению</emphasis> потоков намного превышает количество <emphasis>ожидающих</emphasis>. Мы уже говорили об этом феномене, который называется превышением лимита.</p>
        </section>
        <section>
          <title>
            <p>8.2.5. Превышение лимита и чрезмерное контекстное переключение</p>
          </title>
          <p>В многопоточных программах количество потоков нередко превышает количество процессоров, если только не используется <emphasis>массивно параллельное</emphasis> оборудование. Однако потоки часто тратят время на ожидание внешнего ввода/вывода, освобождения мьютекса, сигнала условной переменной и т.д., поэтому серьезных проблем не возникает. Наличие избыточных потоков позволяет приложению выполнять полезную работу, а не простаивать, пока потоки чего-то ждут.</p>
          <p>Но не всегда это хорошо. Если избыточных потоков <emphasis>слишком много</emphasis>, то даже <emphasis>готовых к выполнению</emphasis> потоков будет больше, чем процессоров, и операционная система будет вынуждена интенсивно переключать потоки, чтобы никого не обделить временными квантами. В главе 1 мы видели, что это приводит к возрастанию накладных расходов на контекстное переключение, а также к проблемам с кэш-памятью из-за локальности. Превышение лимита может возникать, когда задача порождает новые потоки без ограничений, как, например, в алгоритме рекурсивной сортировки из главы 4, или когда количество потоков, естественно возникающих при распределении работы но типам задач, превышает количество процессоров, а рабочая нагрузка носит счетный характер и мало связана с вводом/выводом.</p>
          <p>Количество потоков, запускаемых из-за особенностей алгоритма распределения данных, можно ограничить, как показано в разделе 8.1.2. Если же превышение лимита обусловлено естественным распределением работы, то тут ничего не поделаешь, остается разве что выбрать другой способ распределения. Но в таком случае для выбора подходящего распределения может потребоваться больше информации о целевой платформе, чем вы располагаете, поэтому заниматься этим следует лишь тогда, когда производительность неприемлема и можно убедительно продемонстрировать, что изменение способа распределения действительно повышает быстродействие.</p>
          <p>Есть и другие факторы, влияющие на производительность многопоточной программы. Например, стоимость перебрасывания кэша может существенно зависеть от того, оснащена ли система двумя одноядерными процессорами или одним двухъдерным, даже если тип и тактовая частота процессоров одинаковы. Однако все основные факторы, эффект которых проявляется наиболее наглядно, были перечислены выше. Теперь рассмотрим, как от них зависит проектирование кода и структур данных.</p>
        </section>
      </section>
      <section>
        <title>
          <p>8.3. Проектирование структур данных для повышения производительности многопоточной программы</p>
        </title>
        <section>
          <p>В разделе 8.1 мы видели различные способы распределения работы между потоками, а в разделе 8.2 — факторы, от которых может зависеть производительность программы. Как воспользоваться этой информацией при проектировании структур данных для многопоточного кода? Этот вопрос отличается от рассмотренных в главах 6 и 7, где основное внимание было уделено проектированию структур данных, безопасных относительно одновременного доступа. В разделе 2 было показано, что размещение в памяти данных, используемых одним потоком, тоже может иметь значение, даже если эти данные ни с какими другими потоками не разделяются.</p>
          <p>Основное, о чем нужно помнить при проектировании структур данных для многопоточной программы, — это <emphasis>конкуренция, ложное разделение</emphasis> и <emphasis>локальность данных</emphasis>. Все три фактора могут оказать большое влияние на производительность, так что нередко добиться улучшения удается, просто изменив размещение данных в памяти или распределение данных между потоками. Начнем с низко висящего плода: распределения элементов массива между потоками.</p>
        </section>
        <section>
          <title>
            <p>8.3.1. Распределение элементов массива для сложных операций</p>
          </title>
          <p>Допустим, что программа, выполняющая сложные математические расчеты, должна перемножить две больших квадратных матрицы. Элемент в левом верхнем углу результирующей матрицы получается следующим образом: каждый элемент первой <emphasis>строки</emphasis> левой матрицы умножается на соответственный элемент первого <emphasis>столбца</emphasis> правой матрицы и полученные произведения складываются. Чтобы получить элемент результирующей матрицы, расположенный на пересечении второй строки и первого столбца, эта операция повторяется для второй строки левой матрицы и первого столбца правой матрицы. И так далее. На рис. 8.3 показано, что элемент результирующей матрицы на пересечении второй строки и третьего столбца получается суммированием попарных произведений элементов второй строки левой матрицы и третьего столбца правой.</p>
          <image l:href="#img_20_novyjjrazmer.png"/>
          <p><strong>Рис. 8.3.</strong> Умножение матриц</p>
          <p>Теперь предположим, что матрицы содержат по несколько тысяч строк и столбцов, иначе заводить несколько потоков для оптимизации умножения не имеет смысла. Обычно, если матрица не разрежена, то она представляется большим массивом в памяти, в котором сначала идут все элементы первой строки, потом все элементы второй строки и так далее. Следовательно, для перемножения матриц нам понадобятся три огромных массива. Чтобы добиться оптимальной производительности, мы должны внимательно следить за порядком доступа к данным, а особенно за операциями записи в третий массив.</p>
          <p>Существует много способов распределить эту работу между потоками. В предположении, что строк и столбцов больше, чем имеется процессоров, можно поручить каждому потоку вычисление нескольких столбцов или строк результирующей матрицы или даже вычисление какой-то ее прямоугольной части.</p>
          <p>В разделах 8.2.3 и 8.2.4 мы видели, что для улучшения использования кэша и предотвращения ложного разделения лучше, когда поток обращается к данным, находящимся в соседних ячейках, а не разбросанным но всей памяти. Если поток вычисляет множество столбцов, то читать ему придётся все значения из первой матрицы и соответственных столбцов второй матрицы, но писать только в назначенные ему столбцы результирующей матрицы. При том, что матрицы хранятся но строкам, это означает, что мы будем обращаться к <emphasis>N</emphasis> элементам первой строки результирующей матрицы, <emphasis>N</emphasis> элементам второй строки и т.д. (<emphasis>N</emphasis> — количество обрабатываемых столбцов). Другие потоки будут обращаться к другим элементам строк, поэтому, чтобы минимизировать вероятность ложного разделения, столбцы, вычисляемые каждым потоком, должны быть соседними, тогда будут соседними и <emphasis>N</emphasis> записываемых элементов в каждой строке. Разумеется, если эти <emphasis>N</emphasis> элементов занимают в точности целое число строк кэша, то ложного разделения вообще не будет, потому что каждый поток работает со своим набором строк кэша.</p>
          <p>С другой стороны, если каждый поток вычисляет множество <emphasis>строк</emphasis>, то он должен будет прочитать все значения <emphasis>правой</emphasis> матрицы и значения из соответственных строк <emphasis>левой</emphasis> матрицы, но в результирующую матрицу записывать будет только строки. Поскольку матрицы хранятся но строкам, то поток будет обращаться ко <emphasis>всем</emphasis> элементам <emphasis>N</emphasis> строк. Если поручить потоку вычисление соседних строк, то он окажется <emphasis>единственным</emphasis> потоком, который пишет в эти строки, то есть будет владельцем непрерывного участка памяти, к которому больше никакие потоки не обращаются. Вероятно, это лучше, чем вычисление множества столбцов, потому что ложное разделение, если и может возникнуть, то только для нескольких последних элементов предыдущего и нескольких первых элементов следующего участка. Однако это предположение нуждается в подтверждении путем прямых измерений на целевой платформе.</p>
          <p>А как насчет третьего варианта — вычисления прямоугольных блоков матрицы? Можно рассматривать его как комбинацию распределения но столбцам и по строкам. Поэтому шансы на ложное разделение такие же, как при распределении но столбцам. Если выбрать число столбцов так, чтобы минимизировать эту вероятность, то у распределения по блокам будет преимущество в части <emphasis>чтения</emphasis> — исходную матрицу придётся читать не целиком, а только те столбцы и строки, которые соответствуют назначенному потоку прямоугольному блоку. Рассмотрим конкретный пример умножения двух матриц размерностью 1000&#215;1000. Всего в каждой матрице миллион элементов. При наличии 100 процессоров каждый из них сможет вычислить 10 строк, то есть 10 000 элементов. Однако для их вычисления процессору придётся прочитать всю правую матрицу (миллион элементов) плюс 10 000 элементов из соответственных строк левой матрицы, итого — 1 010 000 элементов. С другой стороны, если каждый процессор вычисляет блок 100&#215;100 (те же 10 000 элементов), то нужно будет прочитать значения из 100 строк левой матрицы (100&#215;1000 = 100 000 элементов) и 100 столбцов правой матрицы (еще 100 000). В итоге мы получаем только 200 000 прочитанных элементов, то есть в пять раз меньше по сравнению с первым случаем. Если читается меньше элементов, то сокращается вероятность отсутствия нужного значения в кэше, а, значит, производительность потенциально возрастает.</p>
          <p>Поэтому лучше разбить результирующую матрицу на небольшие квадратные или почти квадратные блоки, а не вычислять строки целиком. Конечно, размер блока можно определять на этапе выполнения в зависимости от размерности матриц и числа имеющихся процессоров. Как обычно, если производительность существенна, то важно профилировать разные варианты решения на целевой архитектуре.</p>
          <p>Но если вы не занимаетесь умножением матриц, то какую пользу можете извлечь из этого обсуждения? Да просто те же принципы применимы в любой ситуации, где нужно назначать потокам вычисление больших блоков данных. Тщательно изучите все аспекты доступа к данным и выявите потенциальные причины снижения производительности. Не исключено, что ваша задача обладает схожими характеристиками, позволяющими улучшить быстродействие всего лишь за счет изменения способа распределения работы без модификации основного алгоритма.</p>
          <p>Итак, мы посмотрели, как порядок доступа к элементам массива может отразиться на производительности. А что можно сказать о других структурах данных?</p>
        </section>
        <section>
          <title>
            <p>8.3.2. Порядок доступа к другим структурам данных</p>
          </title>
          <p>По существу, к оптимизации доступа к другим структурам данных применимы те же принципы, что и для массивов.</p>
          <p>• Попытайтесь выбрать распределение данных между потоками, так чтобы данные, расположенные по соседству, обрабатывались одним потоком.</p>
          <p>• Попытайтесь минимизировать объем данных, к которым обращается каждый поток.</p>
          <p>• Попытайтесь сделать так, чтобы данные, к которым обращаются разные потоки, находились достаточно далеко друг от друга, чтобы избежать ложного разделения.</p>
          <p>Разумеется, к другим структурам данных применить эти принципы не так просто. Например, в двоичном дереве очень трудно выделить части, которые сами не являлись бы деревьями, а полезно это или нет, зависит от того, насколько дерево сбалансировано и на сколько частей его нужно разбить. К тому же, память для узлов деревьев по необходимости выделяется динамически, так что оказывается в разных частях кучи.</p>
          <p>Само по себе то, что данные находятся в разных частях кучи, не страшно, но означает, что процессору придётся держать в кэше ячейки из разных участков памяти. На самом деле, это может быть даже хорошо. Если несколько потоков обходят дерево, то всем им нужно получать доступ к узлам. Однако если узлы содержат только <emphasis>указатели</emphasis> на реальные данные, то процессор должен будет загружать данные только по мере необходимости. Если данные модифицируются потоками, то за счет этого, возможно, удастся предотвратить падение производительности из-за ложного разделения между данными самого узла и данными, образующими структуру дерева.</p>
          <p>Схожая проблема возникает для данных, защищенных мьютексом. Предположим, что имеется простой класс, содержащий какие-то элементы данных и защищающий их мьютекс. Для потока, захватывающего мьютекс, было бы идеально, чтобы мьютекс и данные были размещены в памяти рядом. Тогда необходимые ему данные уже находятся в кэше процессора, потому что были загружены вместе с мьютексом, когда поток модифицировал его для захвата. Но есть и оборотная сторона медали: другие потоки, пытающиеся захватить мьютекс, удерживаемый первым потоком, должны будут обратиться к той же памяти. Захват мьютекса обычно реализуется в виде атомарной операции чтения-модификации-записи ячейки памяти, принадлежащей мьютексу, с последующим вызовом ядра ОС, если мьютекс уже захвачен. Операция чтения-модификации-записи вполне может сделать недействительными хранящиеся в кэше данные. С точки зрения мьютекса, это несущественно, так как первый поток все равно не стал бы его трогать, пока не подойдёт время освобождения. Но если мьютекс находится в той же строке кэша, что и данные, которыми оперирует захвативший его поток, то получится, что производительность потока, владеющего мьютексом, надает только <emphasis>потому, что другой поток попытался захватить тот же мьютекс</emphasis>.</p>
          <p>Один из способов проверить, приводит ли такого рода ложное разделение к проблемам, — добавить большие разделительные блоки фиктивных данных между данными, к которым одновременно обращаются разные потоки. Например, следующая структура:</p>
          <p>
            <code>struct protected_data {&#9474;</code>
            <strong>65536 на несколько</strong>
          </p>
          <p>
            <code> std::mutex m;         &#9474;</code>
            <strong>порядков больше, чем</strong>
          </p>
          <p>
            <code> char padding[65536]; &#8592;&#9496;</code>
            <strong>длина строки кэша</strong>
          </p>
          <p>
            <code> my_data data_to_protect;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>удобна для проверки конкуренции за мьютекс, а структура</p>
          <p>
            <code>struct my_data {</code>
          </p>
          <p>
            <code> data_item1 d1;</code>
          </p>
          <p>
            <code> data_item2 d2;</code>
          </p>
          <p>
            <code> char padding[65536];</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>my_data some_array[256];</code>
          </p>
          <p>— для проверки ложного разделения данных массива. Если в результате производительность повысится, значит, ложное разделение составляет проблему, и тогда можно либо оставить заполнитель, либо устранить ложное разделение, по-другому организовав доступ к данным.</p>
          <p>Разумеется, порядок доступа к данным — не единственное, что нужно принимать во внимание при проектировании параллельных программ. Рассмотрим некоторые другие аспекты.</p>
        </section>
      </section>
      <section>
        <title>
          <p>8.4. Дополнительные соображения при проектировании параллельных программ</p>
        </title>
        <section>
          <p>До сих пор мы в этой главе рассматривали различные способы распределения работы между потоками, факторы, влияющие на производительность, и то, как от них зависит выбор порядка доступа к данным и самой структуры данных. Но этим проблематика проектирования параллельных программ не исчерпывается. Необходимо еще принимать во внимание такие вещи, как безопасность относительно исключений и масштабируемость. Говорят, что программа масштабируется, если ее производительность (в терминах повышения быстродействия или увеличения пропускной способности) возрастает при добавлении новых процессорных ядер. В идеале производительность должна расти линейно, то есть система с 100 процессорами должна работать в 100 раз быстрее системы с одним процессором.</p>
          <p>Даже немасштабируемая программа может быть работоспособной — в конце концов, однопоточные приложения в этом смысле, безусловно, не масштабируемы — но вот безопасность относительно исключений — вопрос, напрямую связанный с корректностью. Если программа не безопасна относительно исключений, то может наблюдаться нарушение инвариантов, состояния гонки и даже аварийное завершение. Вот этим вопросом мы сейчас и займемся.</p>
        </section>
        <section>
          <title>
            <p>8.4.1. Безопасность относительно исключений в параллельных алгоритмах</p>
          </title>
          <p>Безопасность относительно исключений — необходимая составная часть любой приличной программы на С++, и параллельные программы — не исключение. На самом деле, при разработке параллельных алгоритмов часто требуется уделять исключениям даже больше внимания. Если какая-то операция в последовательном алгоритме возбуждает исключение, то алгоритм должен лишь позаботиться о предотвращении утечек памяти и нарушения собственных инвариантов, а потом может передать исключение вызывающей программе для обработки. В параллельных же алгоритмах многие операции выполняются в разных потоках. В этом случае исключение невозможно распространить вверх по стеку вызовов, потому что у каждого потока свой стек. Если выход из функции потока производится в результате исключения, то приложение завершается.</p>
          <p>В качестве конкретного примера рассмотрим еще раз функцию <code>parallel_accumulate</code> из листинга 2.8, который воспроизведен ниже.</p>
          <empty-line/>
          <p><strong>Листинг 8.2.</strong> Наивная параллельная организация <code>std::accumulate</code> (из листинга 2.8)</p>
          <p>
            <code>template&lt;typename Iterator, typename T&gt;</code>
          </p>
          <p>
            <code>struct accumulate_block {</code>
          </p>
          <p>
            <code> void operator()(Iterator first, Iterator last, T&amp; result) {</code>
          </p>
          <p>
            <code>  result = std::accumulate(first, last, result); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Iterator, typename T&gt;</code>
          </p>
          <p>
            <code>T parallel_accumulate(Iterator first, Iterator last, T init) {</code>
          </p>
          <p>
            <code> unsigned long const length = std::distance(first, last);&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> if (!length)</code>
          </p>
          <p>
            <code>  return init;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const min_per_thread = 25;</code>
          </p>
          <p>
            <code> unsigned long const max_threads =</code>
          </p>
          <p>
            <code>  (length + min_per_thread - 1) / min_per_thread;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const hardware_threads =</code>
          </p>
          <p>
            <code>  std::thread::hardware_concurrency();</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const num_threads =</code>
          </p>
          <p>
            <code>  std::min(</code>
          </p>
          <p>
            <code>   hardware_threads != 0 ? hardware_threads : 2, max_threads);</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const block_size = length / num_threads;</code>
          </p>
          <empty-line/>
          <p>
            <code> std: :vector&lt;T&gt; results (num_threads); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads(num_threads - 1); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <empty-line/>
          <p>
            <code> Iterator block_start = first; &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  Iterator block_end = block_start; &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  std::advance(block_end, block_size);</code>
          </p>
          <p>
            <code>  threads[i] = std::thread( &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>   accumulate_block&lt;Iterator, T&gt;(),</code>
          </p>
          <p>
            <code>   block_start, block_end, std::ref(results[i]));</code>
          </p>
          <p>
            <code>  block_start = block_end; &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> accumulate_block()(</code>
          </p>
          <p>
            <code>  block_start, last, results[num_threads - 1]);&#8592;</code>
            <strong>(9)</strong>
          </p>
          <empty-line/>
          <p>
            <code> std::for_each(threads.begin(), threads.end(),</code>
          </p>
          <p>
            <code> std::mem_fn(&amp;std::thread::join));</code>
          </p>
          <p>
            <code> return</code>
          </p>
          <p>
            <code>  std::accumulate(results.begin(), results.end(), init); &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Посмотрим, где могут возникнуть исключения. Вообще говоря, это вызовы библиотечных функций, которые могут возбуждать исключения, а также операции, определенные в пользовательском типе.</p>
          <p>Итак, начнем. В точке <strong>(2)</strong> мы обращаемся к функции <code>distance</code>, которая выполняет операции над пользовательским типом итератора. Поскольку мы еще не начали работу, и обращение к этой функции произведено из вызывающего потока, то тут всё нормально. Далее мы выделяем память для векторов <code>results</code> <strong>(3)</strong> и <code>threads</code> <strong>(4)</strong>. И эти обращения произведены из вызывающего потока до начала работы и до создания новых потоков, так что и здесь всё хорошо. Разумеется, если конструктор <code>threads</code> возбудит исключение, то нужно будет освободить память, выделенную для <code>results</code>, но об этом позаботится деструктор.</p>
          <p>С инициализацией объекта <code>block_start</code> <strong>(5)</strong> всё чисто по тем же причинам, так что перейдём к операциям в цикле запуска потоков <strong>(6)</strong>, <strong>(7)</strong>, <strong>(8)</strong>. Если после создания первого же потока <strong>(7)</strong> возникнет исключение, и мы его не перехватим, появится проблема; деструкторы объектов <code>std::thread</code> вызывают <code>std::terminate</code>, что приводит к аварийному завершению программы. Нехорошо.</p>
          <p>Обращение к <code>accumulate_block</code> в точке <strong>(9)</strong> может возбуждать исключения — с точно такими же последствиями: объекты потоков будут уничтожены, а их деструкторы вызовут <code>std::terminate</code>. С другой стороны, исключение, возбуждаемое в последнем обращении к <code>std::accumulate</code> <strong>(10)</strong>, не так опасно, потому что к этому моменту все потоки уже присоединились к вызывающему.</p>
          <p>Таким образом, обращения к <code>accumulate_block</code> из новых потоков могут возбуждать исключения в точке <strong>(1)</strong>. Так как блоки <code>catch</code> отсутствуют, то исключение останется необработанным и приведёт к вызову <code>std::terminate()</code> и завершению программы.</p>
          <p>Если это еще не очевидно, скажем прямо: <emphasis>этот код не безопасен относительно исключений</emphasis>.</p>
          <subtitle>Делаем код безопасным относительно исключений</subtitle>
          <p>Итак, мы выявили все возможные точки возбуждения исключений и поняли, к каким печальным последствиям это приведёт. Что с этим можно сделать? Начнем с вопроса об исключениях, возбуждаемых в созданных нами потоках.</p>
          <p>В главе 4 мы уже познакомились с подходящим для решения проблемы средством. Для чего нам вообще нужны новые потоки? Для того чтобы вычислить результат и при этом учесть возможность возникновения исключений. Но это <emphasis>именно то</emphasis>, для чего предназначено сочетание <code>std::packaged_task</code> и <code>std::future</code>. В листинге 8.3 показан код, переписанный с использованием <code>std::packaged_task</code>.</p>
          <empty-line/>
          <p><strong>Листинг 8.3.</strong> Параллельная версия <code>std::accumulate</code> с применением <code>std::packaged_task</code></p>
          <p>
            <code>template&lt;typename Iterator, typename T&gt;</code>
          </p>
          <p>
            <code>struct accumulate_block {</code>
          </p>
          <p>
            <code> T operator()(Iterator first, Iterator last) {&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  return std::accumulate(first, last, T());   &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Iterator, typename T&gt;</code>
          </p>
          <p>
            <code>T parallel_accumulate(Iterator first, Iterator last, T init) {</code>
          </p>
          <p>
            <code> unsigned long const length = std::distance(first, last);</code>
          </p>
          <empty-line/>
          <p>
            <code> if (!length)</code>
          </p>
          <p>
            <code>  return init;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const min_per_thread = 25;</code>
          </p>
          <p>
            <code> unsigned long const max_threads =</code>
          </p>
          <p>
            <code>  (length + min_per_thread — 1) / min_per_thread;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const hardware_threads =</code>
          </p>
          <p>
            <code>  std::thread::hardware_concurrency();</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const num_threads =</code>
          </p>
          <p>
            <code>  std::min(</code>
          </p>
          <p>
            <code>   hardware_threads i = 0 ? hardware_threads : 2, max_threads);</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const block_size = length / num_threads;</code>
          </p>
          <empty-line/>
          <p>
            <code> std::vector&lt;std::future&lt;T&gt; &gt; futures(num_threads-1);&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads(num_threads — 1);</code>
          </p>
          <empty-line/>
          <p>
            <code> Iterator block_start = first;</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  Iterator block_end = block_start;</code>
          </p>
          <p>
            <code>  std::advance(block_end, block_size);</code>
          </p>
          <p>
            <code>  std::packaged_task&lt;T(Iterator, Iterator)&gt; task( &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>   accumulate_block&lt;Iterator, T&gt;());</code>
          </p>
          <p>
            <code>  futures[i] = task.get_future(); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  threads[i] =</code>
          </p>
          <p>
            <code>   std::thread(std::move(task), block_start, block_end);&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  block_start = block_end;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> T last_result = accumulate_block()(block_start, last); &#8592;</code>
            <strong>(7)</strong>
          </p>
          <empty-line/>
          <p>
            <code> std::for_each(threads.begin(), threads.end(),</code>
          </p>
          <p>
            <code>  std::mem_fn(&amp;std::thread::join));</code>
          </p>
          <empty-line/>
          <p>
            <code> T result = init; &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  result += futures[i].get(); &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> result += last_result; &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code> return result;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Первое изменение заключается в том, что оператор вызова в <code>accumulate_block</code> теперь возвращает результат по значению, а не принимает ссылку на место, где его требуется сохранить <strong>(1)</strong>. Для обеспечения безопасности относительно исключений мы используем <code>std::packaged_task</code> и <code>std::future</code>, поэтому можем воспользоваться этим и для передачи результата. Правда, для этого требуется при вызове <code>std::accumulate</code> <strong>(2)</strong> явно передавать сконструированный по умолчанию экземпляр <code>T</code>, а не использовать повторно предоставленное значение <code>result</code>, но это не слишком существенное изменение.</p>
          <p>Далее, вместо того заводить вектор результатов, мы создаем вектор <code>futures</code> <strong>(3)</strong>, в котором храним объекты <code>std::future&lt;T&gt;</code> для каждого запущенного потока. В цикле запуска потоков мы сначала создаем задачу для <code>accumulate_block</code> <strong>(4)</strong>. В классе <code>std::packaged_task&lt;T(Iterator, Iterator)&gt;</code> объявлена задача, которая принимает два объекта <code>Iterator</code> и возвращает <code>T</code>, а это именно то, что делает наша функция. Затем мы получаем будущий результат для этой задачи <strong>(5)</strong> и исполняем ее в новом потоке, передавая начало и конец обрабатываемого блока <strong>(6)</strong>. Результат работы задачи, равно как и исключение, если оно возникнет, запоминается в объекте <code>future</code>.</p>
          <p>Поскольку используются будущие результаты, массива <code>results</code> больше нет, поэтому мы должны сохранить результат обработки последнего блока в переменной <strong>(7)</strong>, а не в элементе массива. Кроме того, поскольку мы получаем значения из будущих результатов, проще не вызывать <code>std::accumulate</code>, а написать простой цикл <code>for</code>, в котором к переданному начальному значению <strong>(8)</strong> будут прибавляться значения, полученные из каждого будущего результата <strong>(9)</strong>. Если какая-то задача возбудит исключение, то оно будет запомнено в будущем результате и повторно возбуждено при обращении к <code>get()</code>. Наконец, перед тем как возвращать окончательный результат вызывающей программе, мы прибавляем результат обработки последнего блока <strong>(10)</strong>.</p>
          <p>Таким образом, мы устранили одну из потенциальных проблем: исключения, возбужденные в рабочих потоках, повторно возбуждаются в главном. Если исключения возникнут в нескольких рабочих потоках, то вверх распространится только одно, но это не очень страшно. Если вы считаете, что это все-таки важно, то можете воспользоваться чем-то вроде класса <code>std::nested_exception</code>, чтобы собрать все такие исключения и передать их главному потоку.</p>
          <p>Осталось решить проблему утечки потоков в случае, когда исключение возникает между моментом запуска первого потока и присоединением всех запущенных. Для этого проще всего перехватить любое исключение, дождаться присоединения потоков, которые все еще находятся в состоянии <code>joinable()</code>, а потом возбудить исключение повторно:</p>
          <p>
            <code>try {</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  // ... как и раньше</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> T last_result = accumulate_block()(block_start, last);</code>
          </p>
          <p>
            <code> std::for_each(threads.begin(), threads.end(),</code>
          </p>
          <p>
            <code> std::mem_fn(&amp;std::thread::join));</code>
          </p>
          <p>
            <code>} catch (...) {</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_thread - 1); ++i) {</code>
          </p>
          <p>
            <code> if (threads[i].joinable())</code>
          </p>
          <p>
            <code>  thread[i].join();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> throw;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Теперь все работает. Все потоки будут присоединены вне зависимости от того, как завершилась обработка блока. Однако блоки <code>try-catch</code> выглядят некрасиво, и часть кода дублируется. Мы присоединяем потоки как в «нормальной» ветке, так и в блоке <code>catch</code>. Дублирование кода — вещь почти всегда нежелательная, потому что изменения придётся вносить в несколько мест. Давайте лучше перенесём этот код в деструктор — ведь именно такова идиома очистки ресурсов в С++. Вот как выглядит этот класс:</p>
          <p>
            <code>class join_threads {</code>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt;&amp; threads;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> explicit join_threads(std::vector&lt;std::thread&gt;&amp; threads_):</code>
          </p>
          <p>
            <code>  threads(threads_) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> ~join_threads() {</code>
          </p>
          <p>
            <code>  for (unsigned long i = 0; i &lt; threads.size(); ++i) {</code>
          </p>
          <p>
            <code>   if (threads[i].joinable())</code>
          </p>
          <p>
            <code>    threads[i].join();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Это похоже на класс <code>thread_guard</code> из листинга 2.3, только на этот раз мы «охраняем» целый вектор потоков. Теперь наш код упрощается.</p>
          <empty-line/>
          <p><strong>Листинг 8.4.</strong> Безопасная относительно исключений версия <code>std::accumulate</code></p>
          <p>
            <code>template&lt;typename Iterator, typename T&gt;</code>
          </p>
          <p>
            <code>T parallel_accumulate(Iterator first, Iterator last, T init) {</code>
          </p>
          <p>
            <code> unsigned long const length = std::distance(first, last);</code>
          </p>
          <empty-line/>
          <p>
            <code> if (!length)</code>
          </p>
          <p>
            <code>  return init;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const min_per_thread = 25;</code>
          </p>
          <p>
            <code> unsigned long const max_threads =</code>
          </p>
          <p>
            <code>  (length + min_per_thread - 1) / min_per_thread;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const hardware_threads =</code>
          </p>
          <p>
            <code>  std::thread::hardware_concurrency();</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const num_threads =</code>
          </p>
          <p>
            <code>  std::min(</code>
          </p>
          <p>
            <code>   hardware_threads i = 0 ? hardware_threads : 2, max_threads);</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const block_size = length / num_threads;</code>
          </p>
          <empty-line/>
          <p>
            <code> std::vector&lt;std::future&lt;T&gt; &gt; futures(num_threads — 1);</code>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads(num_threads - 1);</code>
          </p>
          <p>
            <code> join_threads joiner(threads); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code> Iterator block_start = first;</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  Iterator block_end = block_start;</code>
          </p>
          <p>
            <code>  std::advance(block_end, block_size);</code>
          </p>
          <p>
            <code>  std::packaged_task&lt;T(Iterator, Iterator)&gt; task(</code>
          </p>
          <p>
            <code>   accumulate_block&lt;Iterator, T&gt;());</code>
          </p>
          <p>
            <code>  futures[i] = task.get_future();</code>
          </p>
          <p>
            <code>  threads[i] =</code>
          </p>
          <p>
            <code>   std::thread(std:move(task), block_start, block_end);</code>
          </p>
          <p>
            <code>  block_start = block_end;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> T last_result = accumulate_block()(block_start, last);</code>
          </p>
          <empty-line/>
          <p>
            <code> T result = init;</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  result + = futures[i].get(); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> result += last_result;</code>
          </p>
          <p>
            <code> return result;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Создав контейнер потоков, мы создаем объект написанного выше класса <strong>(1)</strong>, который присоединяет все завершившиеся потоки. Теперь явный цикл присоединения можно удалить, точно зная, что при выходе из функции потоки будут присоединены. Отметим, что вызовы <code>futures[i].get()</code> <strong>(2)</strong> приостанавливают выполнение программы до готовности результатов, поэтому в этой точке явно присоединять потоки не нужно. Этим данный код отличается от первоначальной версии в листинге 8.2, где присоединять потоки было необходимо для нрав ильного заполнения вектора <code>results</code>. Мало того что мы получили безопасный относительно исключений код, так еще и функция стала короче, потому что код присоединения вынесен в новый класс (который, кстати, можно использовать и в других программах).</p>
          <subtitle>Обеспечение безопасности относительно исключений при работе с <code>std::async()</code></subtitle>
          <p>Теперь, когда мы знаем, что необходимо для обеспечения безопасности относительно исключений в программе, которая явно управляет потоками, посмотрим, как добиться того же результата при использовании <code>std::async()</code>. Мы уже видели, что в этом случае управление потоками берет на себя библиотека, а запущенный ей поток завершается, когда будущий результат <emphasis>готов</emphasis>. В плане безопасности относительно исключений важно то, что если уничтожить будущий результат, не дождавшись его, то деструктор будет ждать завершения потока. Тем самым мы элегантно решаем проблему утечки потоков, которые еще исполняются и хранят ссылки на данные. В следующем листинге показана безопасная относительно исключений реализация с применением <code>std::async()</code>.</p>
          <empty-line/>
          <p><strong>Листинг 8.5.</strong> Безопасная относительно исключений версия <code>std::accumulate</code> с применением <code>std::async</code></p>
          <p>
            <code>template&lt;typename Iterator, typename T&gt;</code>
          </p>
          <p>
            <code>T parallel_accumulate(Iterator first, Iterator last, T init) {</code>
          </p>
          <p>
            <code> unsigned long const length = std::distance(first, last);&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> unsigned long const max_chunk_size = 25;</code>
          </p>
          <p>
            <code> if (length &lt;= max_chunk_size) {</code>
          </p>
          <p>
            <code>  return std::accumulate(first, last, init); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> } else {</code>
          </p>
          <p>
            <code>  Iterator mid_point = first;</code>
          </p>
          <p>
            <code>  std::advance(mid_point, length / 2); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  std::future&lt;T&gt; first_half_result =</code>
          </p>
          <p>
            <code>   std::async(parallel_accumulate&lt;Iterator, T&gt;, &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>   first, mid_point, init);</code>
          </p>
          <p>
            <code>  T second_half_result =</code>
          </p>
          <p>
            <code>   parallel_accumulate(mid_point, last, T());         &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  return first_half_result.get() + second_half_result;&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В этой версии мы распределяем данные рекурсивно, а не вычисляем распределение по блокам заранее, но в целом код намного проще предыдущей версии и при этом <emphasis>безопасен относительно исключений</emphasis>. Как и раньше, сначала мы вычисляем длину последовательности <strong>(1)</strong>, и, если она меньше максимального размера блока, то вызываем <code>std::accumulate</code> напрямую <strong>(2)</strong>. В противном случае находим среднюю точку последовательности <strong>(3)</strong> и запускаем асинхронную задачу, которая будет обрабатывать левую половину <strong>(4)</strong>. Для обработки правой половины мы вызываем себя рекурсивно <strong>(5)</strong>, а затем складываем результаты обработки обеих половин <strong>(6)</strong>. Библиотека гарантирует, что <code>std::async</code> задействует имеющийся аппаратный параллелизм, не создавая слишком большого количества потоков. Некоторые «асинхронные» вызовы на самом деле будут исполняться синхронно при обращении к <code>get()</code> <strong>(6)</strong>.</p>
          <p>Изящество этого решения не только в том, что задействуется аппаратный параллелизм, но и в том, что безопасность относительно исключений обеспечивается тривиальным образом. Если рекурсивный вызов <strong>(5)</strong> возбудит исключение, то будущий результат, созданный при обращении к <code>std::async</code> <strong>(4)</strong>, будет уничтожен при распространении исключения вверх по стеку. Это в свою очередь приведёт к ожиданию завершения асинхронного потока, так что «висячий поток» не образуется. С другой стороны, если исключение возбуждает асинхронный вызов, то оно будет запомнено в будущем результате и повторно возбуждено при обращении к <code>get()</code> <strong>(6)</strong>.</p>
          <p>Какие еще соображения следует принимать во внимание при проектировании параллельного кода? Давайте поговорим о <emphasis>масштабируемости</emphasis>. Насколько увеличится производительность программы, если запустить ее на машине с большим количеством процессоров?</p>
        </section>
        <section>
          <title>
            <p>8.4.2. Масштабируемость и закон Амдала</p>
          </title>
          <p>Под <emphasis>масштабируемостью</emphasis> понимается свойство программы использовать дополнительные имеющиеся в системе процессоры. На одном полюсе находятся однопоточные приложения, которые вообще не масштабируемы, — даже если система оснащена 100 процессорами, быстродействие такой программы не возрастет. На другом полюсе мы встречаем проект SETI@Home<a l:href="#n19" type="note">[19]</a>, который рассчитан на использование тысяч процессоров (в виде отдельных компьютеров, добровольно подключаемых к сети пользователями).</p>
          <p>В многопоточной программе количество потоков, выполняющих полезную работу, может изменяться в процессе исполнения. Даже если каждый поток на всем протяжении своего существования делает что-то полезное, первоначально в приложении имеется всего один поток, который должен запустить все остальные. Но такой сценарий крайне маловероятен. Потоки часто не работают, а ожидают друг друга или завершения операций ввода/вывода.</p>
          <p>Всякий раз, как один поток чего-то ждет (неважно, чего именно), а никакого другого потока, готового занять вместо него процессор, нет, процессор, который мог бы выполнять полезную работу, простаивает.</p>
          <p>Упрощенно можно представлять, что программа состоит из «последовательных» участков, в которых полезные действия выполняет только один поток, и «параллельных», где задействованы все имеющиеся процессоры. Если программа исполняется на машине с большим числом процессоров, то теоретически «параллельные» участки могли бы завершаться быстрее, а «последовательные» такими бы и остались. Приняв такие упрощающие предположения, можно оценить потенциальное повышение производительности при увеличении количества процессоров: если доля «последовательных» участков равна <emphasis>f</emphasis><sub><emphasis>s</emphasis></sub>, то коэффициент повышения производительности <emphasis>P</emphasis> при числе процессоров <emphasis>N</emphasis> составляет</p>
          <image l:href="#img_21.png_0"/>
          <empty-line/>
          <p>Это <emphasis>закон Амдала</emphasis>, на который часто ссылаются при обсуждении производительности параллельных программ. Если код полностью распараллелен, то есть доля последовательных участков нулевая, то коэффициент ускорения равен <emphasis>N</emphasis>. Если же, к примеру, последовательные участки составляют треть программы, то даже при бесконечном количестве процессоров не удастся добиться ускорения более чем в три раза.</p>
          <p>Конечно, эта картина чересчур упрощённая, потому что редко встречаются бесконечно делимые задачи, без чего это соотношение неверно, и не менее редко вся работа сводится только к процессорным вычислениям, как то предполагается в законе Амдала. Во время исполнения потоки могут ожидать разных событий.</p>
          <p>Но из закона Амдала все же следует, что если целью распараллеливания является повышение производительности, то следует проектировать всё приложение так, чтобы процессорам всегда было чем заняться. За счет уменьшения длины «последовательных» участков или времени ожидания можно повысить выигрыш от добавления новых процессоров. Альтернативный подход — подать на вход системы больше данных и тем самым загрузить параллельные участки работой; при этом можно будет уменьшить долю последовательных участков и повысить коэффициент <emphasis>P</emphasis>.</p>
          <p>По существу, масштабируемость — это возможность либо уменьшить время, затрачиваемое на какое-то действие, либо увеличить объем данных, обрабатываемых в единицу времени, при увеличении количества процессоров. Иногда оба свойства эквивалентны (можно обработать больше данных, если каждый элемент обрабатывается быстрее), но это необязательно. Прежде чем выбирать способ распределения работы между потоками, важно определить, какие аспекты масштабируемости представляют для вас наибольший интерес.</p>
          <p>В начале этого раздела я уже говорил, что у потоков не всегда есть чем заняться. Иногда они вынуждены ждать другие потоки, завершения ввода/вывода или еще чего-то. Если на время этого ожидания загрузить систему какой-нибудь полезной работой, такое простаивание можно «скрыть».</p>
        </section>
        <section>
          <title>
            <p>8.4.3. Сокрытие латентности с помощью нескольких потоков</p>
          </title>
          <p>При обсуждении производительности многопоточного кода мы часто предполагали, что потоки трудятся изо всех сил и, получая в свое распоряжение процессор, всегда имеют полезную работу. Конечно, это не так — потоки часто оказываются блокированы в ожидании какого-то события: завершения ввода/вывода, освобождения мьютекса, завершения операции в каком-то другом потоке, сигнала условной переменной, готовности будущего результата… Наконец, они могут просто спать какое-то время.</p>
          <p>Но какова бы ни была причина ожидания, если потоков столько же, сколько физических процессоров, наличие заблокированных потоков означает, что процессоры работают вхолостую. Процессор, который мог бы исполнять поток, вместо этого не делает ничего. Следовательно, если заранее известно, что какой-то поток будет проводить много времени в ожидании, то имеет смысл задействовать на это время процессор, запустив один или несколько дополнительных потоков.</p>
          <p>Возьмем, к примеру, антивирусный сканер, который для распределения работы использует конвейер. Первый поток просматривает файловую систему и помещает имена файлов в очередь. Второй поток выбирает имена файлов из очереди и сканирует их на предмет наличия вирусов. Мы знаем, что поток просмотра файловой системы определённо будет простаивать в ожидании завершения ввода/вывода, поэтому «лишнее» процессорное время отдаем дополнительному потоку сканирования. Таким образом, у нас будет поток выбора файлов и столько потоков сканирования, сколько имеется процессоров. Поскольку потоку сканирования тоже нужно читать большие куски файлов, то имеет смысл еще увеличить количество таких потоков. Однако в какой-то момент потоков может стать слишком много, и система начнет работать медленнее, потому что вынуждена будет расходовать все больше и больше времени на контекстное переключение (см. раздел 8.2.5).</p>
          <p>Такого рода настройка является оптимизацией, поэтому следует измерять производительность до и после изменения количества потоков; оптимальное их число зависит как от характера работы, так и от доли времени, затрачиваемой потоком на ожидание.</p>
          <p>Иногда удается полезно использовать свободное процессорное время, не запуская дополнительные потоки. Например, если поток блокируется в ожидании завершения ввода/вывода, то имеет смысл воспользоваться асинхронным вводом/выводом, если платформа его поддерживает. Тогда поток сможет заняться полезной работой, пока ввод/вывод выполняется в фоне. С другой стороны, поток, ожидающий завершения операции в другом потоке, может в это время заняться чем-то полезным. Как это делается, мы видели при рассмотрении реализации свободной от блокировок очереди в главе 7. В крайнем случае, когда поток ждет завершения задачи, которая еще не была запущена другим потоком, ожидающий поток может сам выполнить эту задачу целиком или помочь в выполнении какой-то другой задачи. Такой пример мы видели в листинге 8.1, где функция сортировки пыталась отсортировать находящиеся в очереди блоки, пока блоки, которых она ждет, сортируются другими потоками.</p>
          <p>Иногда потоки добавляются не для того, чтобы загрузить имеющиеся процессоры, а чтобы быстрее обрабатывать внешние события, то есть повысить <emphasis>быстроту реакции</emphasis> системы.</p>
        </section>
        <section>
          <title>
            <p>8.4.4. Повышение быстроты реакции за счет распараллеливания</p>
          </title>
          <p>Большинство современных графических интерфейсов пользователя являются <emphasis>событийно-управляемыми</emphasis> — пользователь выполняет в интерфейсе какие-то действия — нажимает клавиши или двигает мышь, в результате чего порождается последовательность событий или сообщений, которые приложение затем обрабатывает. Система может и сама порождать сообщения или события. Чтобы все события и сообщения были корректно обработаны, в приложении обычно присутствует цикл такого вида:</p>
          <p>
            <code>while (true) {</code>
          </p>
          <p>
            <code> event_data event = get_event();</code>
          </p>
          <p>
            <code> if (event.type == quit)</code>
          </p>
          <p>
            <code>  break;</code>
          </p>
          <p>
            <code> process(event);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Детали API, конечно, могут отличаться, но структура всегда одна и та же: дождаться события, обработать его и ждать следующего. В однопоточном приложении такая структура затрудняет программирование длительных задач (см. раздел 8.1.3). Чтобы система оперативно реагировала на действия пользователя, функции <code>get_event()</code> и <code>process()</code> должны вызываться достаточно часто вне зависимости от того, чем занято приложение. Это означает, что задача должна либо периодически приостанавливать себя и возвращать управление циклу обработки событий, либо сама вызывать функции <code>get_event()</code> и <code>process()</code> в подходящих точках. То и другое решение усложняет реализацию задачи.</p>
          <p>Применив распараллеливание для разделения обязанностей, мы сможем вынести длительную задачу в отдельный поток, а выделенному потоку GUI поручить обработку событий. В дальнейшем потоки могут взаимодействовать с помощью простых механизмов, и мешать код обработки событий с кодом задачи не придётся. В листинге ниже приведён набросок такого разделения обязанностей.</p>
          <empty-line/>
          <p><strong>Листинг 8.6.</strong> Отделение потока GUI от потока задачи</p>
          <p>
            <code>std::thread task_thread;</code>
          </p>
          <p>
            <code>std::atomic&lt;bool&gt; task_cancelled(false);</code>
          </p>
          <empty-line/>
          <p>
            <code>void gui_thread() {</code>
          </p>
          <p>
            <code> while (true) {</code>
          </p>
          <p>
            <code>  event_data event = get_event();</code>
          </p>
          <p>
            <code>  if (event.type == quit)</code>
          </p>
          <p>
            <code>   break;</code>
          </p>
          <p>
            <code>  process(event);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void task() {</code>
          </p>
          <p>
            <code> while (!task_complete() &amp;&amp; !task_cancelled) {</code>
          </p>
          <p>
            <code>  do_next_operation();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> if (task_cancelled) {</code>
          </p>
          <p>
            <code>  perform_cleanup();</code>
          </p>
          <p>
            <code> } else {</code>
          </p>
          <p>
            <code>  post_gui_event(task_complete);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void process(event_data const&amp; event) {</code>
          </p>
          <p>
            <code> switch(event.type) {</code>
          </p>
          <p>
            <code> case start_task:</code>
          </p>
          <p>
            <code>  task_cancelled = false;</code>
          </p>
          <p>
            <code>  task_thread = std::thread(task);</code>
          </p>
          <p>
            <code>  break;</code>
          </p>
          <p>
            <code> case stop_task:</code>
          </p>
          <p>
            <code>  task_cancelled = true;</code>
          </p>
          <p>
            <code>  task_thread.join();</code>
          </p>
          <p>
            <code>  break;</code>
          </p>
          <p>
            <code> case task_complete:</code>
          </p>
          <p>
            <code>  task_thread.join();</code>
          </p>
          <p>
            <code>  display_results();</code>
          </p>
          <p>
            <code>  break;</code>
          </p>
          <p>
            <code> default:</code>
          </p>
          <p>
            <code>  //...</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В результате такого разделения обязанностей поток пользовательского интерфейса всегда будет своевременно реагировать на события, даже если задача занимает много времени. <emphasis>Быстрота реакции</emphasis> часто является основной характеристикой приложения с точки зрения пользователя — с приложением, которое полностью зависает на время выполнения некоторой операции (неважно, какой именно), работать неприятно. За счет выделения специального потока для обработки событий пользовательский интерфейс может сам обрабатывать относящиеся к нему сообщения (например, изменение размера или перерисовка окна), не прерывая длительной операции, но передавая адресованные ей сообщения, если таковые поступают.</p>
          <p>До сих пор в этой главе мы говорили о том, что следует учитывать при проектировании параллельного кода. Поначалу количество разных факторов может привести в изумление, но постепенно они войдут в плоть и кровь и станут вашей второй натурой. Если описанные выше соображения внове для вас, то, надеюсь, они станут яснее после того, как мы рассмотрим конкретные примеры многопоточного кода.</p>
        </section>
      </section>
      <section>
        <title>
          <p>8.5. Проектирование параллельного кода на практике</p>
        </title>
        <section>
          <p>В какой мере следует учитывать описанные выше факторы при проектировании, зависит от конкретной задачи. Для демонстрации мы рассмотрим реализацию параллельных версий трех функций из стандартной библиотеки С++. При этом у нас будет знакомая платформа, на которой можно изучать новые вещи. Попутно мы получим работоспособные версии функций, которые можно будет применить при распараллеливании более крупной программы.</p>
          <p>Я ставил себе задачей продемонстрировать определенные приёмы, а не написать самый оптимальный код. Реализации, в которых лучше используется имеющееся оборудование, можно найти в академической литературе по параллельным алгоритмам или в специализированных многопоточных библиотеках типа Intel Threading Building Blocks<a l:href="#n20" type="note">[20]</a>.</p>
          <p>Концептуально простейшим параллельным алгоритмом является параллельная версия <code>std::for_each</code>, с которой я и начну.</p>
        </section>
        <section>
          <title>
            <p>8.5.1. Параллельная реализация <code>std::for_each</code></p>
          </title>
          <p>Идея <code>std::for_each</code> проста — этот алгоритм вызывает предоставленную пользователем функцию для каждого элемента диапазона. Различие между параллельной и последовательной реализацией <code>std::for_each</code> заключается, прежде всего, в порядке вызовов функции. Стандартная версия <code>std::for_each</code> вызывает функцию сначала для первого элемента диапазона, затем для второго и так далее, тогда как параллельная версия не дает гарантий относительно порядка обработки элементов, они даже могут (и хочется надеяться, <emphasis>будут</emphasis>) обрабатываться параллельно.</p>
          <p>Для реализации параллельной версии нужно всего лишь разбить диапазон на участки, которые будут обрабатываться каждым потоком. Количество элементов известно заранее, поэтому такое разбиение можно произвести до начала работы (см. раздел 8.1.1). Мы будем предполагать, что это единственная исполняемая параллельная задача, поэтому вычислить количество требуемых потоков можно с помощью функции <code>std::thread::hardware_concurrency()</code>. Мы также знаем, что элементы можно обрабатывать абсолютно независимо, поэтому для предотвращения ложного разделения (см. раздел 8.2.3) имеет смысл использовать соседние блоки.</p>
          <p>По своей структуре этот алгоритм похож на параллельную версию <code>std::accumulate</code>, описанную в разделе 8.4.1, только вместо вычисления суммы элементов он применяет к ним заданную функцию. На первый взгляд, это должно бы существенно упростить код, потому что не нужно возвращать никакой результат. Но если мы собираемся передавать исключения вызывающей программе, то все равно придется воспользоваться механизмами <code>std::packaged_task</code> и <code>std::future</code>, чтобы передавать исключения из одного потока в другой. Ниже приведен пример реализации.</p>
          <empty-line/>
          <p><strong>Листинг 8.7.</strong> Параллельная реализация <code>std::for_each</code></p>
          <p>
            <code>template&lt;typename Iterator, typename Func&gt;</code>
          </p>
          <p>
            <code>void parallel_for_each(Iterator first, Iterator last, Func f) {</code>
          </p>
          <p>
            <code> unsigned long const length = std::distance(first, last);</code>
          </p>
          <empty-line/>
          <p>
            <code> if (!length)</code>
          </p>
          <p>
            <code>  return;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const min_per_thread = 25;</code>
          </p>
          <p>
            <code> unsigned long const max_threads =</code>
          </p>
          <p>
            <code>  (length + min_per_thread - 1) / min_per_thread;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const hardware_threads =</code>
          </p>
          <p>
            <code>  std::thread::hardware_concurrency();</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const num_threads =</code>
          </p>
          <p>
            <code>  std::min(</code>
          </p>
          <p>
            <code>   hardware_threads != 0 ? hardware_threads : 2, max_threads);</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const block_size = length / num_threads;</code>
          </p>
          <empty-line/>
          <p>
            <code> std::vector&lt;std::future&lt;void&gt; &gt; futures(num_threads - 1); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads(num_threads – 1);</code>
          </p>
          <p>
            <code> join_threads joiner(threads);</code>
          </p>
          <empty-line/>
          <p>
            <code> Iterator block_start = first;</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  Iterator block_end = block_start;</code>
          </p>
          <p>
            <code>  std::advance(block_end, block_size);</code>
          </p>
          <p>
            <code>  std::packaged_task&lt;void(void)&gt; task( &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   [=]() {</code>
          </p>
          <p>
            <code>    std::for_each(block_start, block_end, f);</code>
          </p>
          <p>
            <code>   });</code>
          </p>
          <p>
            <code>  futures[i] = task.get_future();</code>
          </p>
          <p>
            <code>  threads[i] = std::thread(std::move(task)); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  block_start = block_end;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> std::for_each(block_start, last, f);</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  futures[i].get(); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Структурно код ничем не отличается от приведенного в листинге 8.4, что и неудивительно. Основное различие состоит в том, что в векторе futures хранятся объекты <code>std::future&lt;void&gt;</code> <strong>(1)</strong>, потому что рабочие потоки не возвращают значение, а в качестве задачи мы используем простую лямбда-функцию, которая вызывает функцию <code>f</code> для элементов из диапазона от <code>block_start</code> до <code>block_end</code> <strong>(2)</strong>. Это позволяет не передавать конструктору потока <strong>(3)</strong> диапазон. Поскольку рабочие потоки ничего не возвращают, обращения к <code>futures[i].get()</code> <strong>(4)</strong> служат только для получения исключений, возникших в рабочих потоках; если мы не хотим передавать исключения, то эти обращения можно вообще опустить.</p>
          <p>Реализацию <code>parallel_for_each</code> можно упростить, воспользовавшись <code>std::async</code>, — точно так же, как мы делали при распараллеливании <code>std::accumulate</code>.</p>
          <empty-line/>
          <p><strong>Листинг 8.8.</strong> Параллельная реализация <code>std::for_each</code> с применением <code>std::async</code></p>
          <p>
            <code>template&lt;typename Iterator, typename Func&gt;</code>
          </p>
          <p>
            <code>void parallel_for_each(Iterator first, Iterator last, Func f) {</code>
          </p>
          <p>
            <code> unsigned long const length = std::distance(first, last);</code>
          </p>
          <empty-line/>
          <p>
            <code> if (!length)</code>
          </p>
          <p>
            <code>  return;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const min_per_thread = 25;</code>
          </p>
          <empty-line/>
          <p>
            <code> if (length &lt; (2 * min_per_thread)) {</code>
          </p>
          <p>
            <code>  std::for_each(first, last, f); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> } else {</code>
          </p>
          <p>
            <code>  Iterator const mid_point = first + length / 2;</code>
          </p>
          <p>
            <code>  std::future&lt;void&gt; first_half = &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   std::async(&amp;parallel_for_each&lt;Iterator, Func&gt;,</code>
          </p>
          <p>
            <code>   first, mid_point, f);</code>
          </p>
          <p>
            <code>  parallel_for_each(mid_point, last, f); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  first_half.get();                      &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Как и в случае реализации <code>parallel_accumulate</code> с помощью <code>std::async</code> в листинге 8.5, мы разбиваем данные рекурсивно в процессе выполнения, а не заранее, потому что не знаем, сколько потоков задействует библиотека. На каждом шаге данные делятся пополам, пока их не останется слишком мало для дальнейшего деления. При этом одна половина обрабатывается асинхронно <strong>(2)</strong>, а вторая — непосредственно <strong>(3)</strong>. Когда дальнейшее деление становится нецелесообразным, вызывается <code>std::for_each</code> <strong>(1)</strong>. И снова использование <code>std::async</code> и функции-члена <code>get()</code> объекта <code>std::future</code> <strong>(4)</strong> обеспечивает семантику распространения исключения.</p>
          <p>Теперь перейдем от алгоритмов, которые выполняют одну и ту же операцию над каждым элементом (к их числу относятся также <code>std::count</code> и <code>std::replace</code>), к чуть более сложному случаю — <code>std::find</code>.</p>
        </section>
        <section>
          <title>
            <p>8.5.2. Параллельная реализация <code>std::find</code></p>
          </title>
          <p>Далее будет полезно рассмотреть алгоритм <code>std::find</code>, потому что это один из нескольких алгоритмов, которые могут завершаться еще до того, как обработаны все элементы. Например, если уже первый элемент в диапазоне отвечает условию поиска, то рассматривать остальные не имеет смысла. Как мы скоро увидим, это свойство существенно для повышения производительности, и от него напрямую зависит структура параллельной реализации. На этом примере мы продемонстрируем, как порядок доступа к данным может оказать влияние на проектирование программы (см. раздел 8.3.2). К той же категории относятся алгоритмы <code>std::equal</code> и <code>std::any_of</code>.</p>
          <p>Если вы вместе с женой или другом ищете какую-нибудь старую фотографию в сваленных на чердаке альбомах, то вряд ли захотите, чтобы они продолжали перелистывать страницы, когда вы уже нашли то, что нужно. Наверное, вы просто сообщите им, что искомое найдено (быть может, крикнув «Есть!»), чтобы они могли прекратить поиски и заняться чем-нибудь другим. Но многие алгоритмы по природе своей должны обработать каждый элемент и, стало быть, не имеют эквивалента восклицанию «Есть!». Для алгоритмов типа <code>std::find</code> умение «досрочно» прекращать работу — важное свойство, которое нельзя игнорировать. И, следовательно, его нужно учитывать при проектировании кода — закладывать возможность прерывания других задач, когда ответ уже известен, чтобы программа не ждала, пока прочие рабочие потоки обработают оставшиеся элементы.</p>
          <p>Без прерывания других потоков последовательная версия может работать быстрее параллельной, потому что прекратит поиск, как только будет найден нужный элемент. Если, например, система поддерживает четыре параллельных потока, то каждый из них должен будет просмотреть четверть полного диапазона, поэтому при наивном распараллеливании каждый поток потратит на просмотр своих элементов четверть всего времени. Если искомый элемент окажется в первой четверти диапазона, то последовательный алгоритм завершится раньше, так как не должен будет просматривать оставшиеся элементы.</p>
          <p>Один из способов прервать другие потоки — воспользоваться атомарной переменной в качестве флага и проверять его после обработки каждого элемента. Если флаг поднят, то один из потоков уже нашел нужный элемент, поэтому можно прекращать обработку. При таком способе прерывания мы не обязаны обрабатывать все элементы, и, значит, параллельная версия чаще будет обгонять последовательную. Недостаток состоит в том, что загрузка атомарной переменной — медленная операция, которая тормозит работу каждого потока.</p>
          <p>Мы уже знаем о двух способах возврата значений и распространения исключений. Можно использовать массив будущих результатов и объекты <code>std::packaged_task</code> для передачи значений и исключений, после чего обработать частичные результаты в главном потоке. Или с помощью <code>std::promise</code> устанавливать окончательный результат прямо в рабочем потоке. Все зависит от того, как мы хотим обрабатывать исключения, возникающие в рабочих потоках. Если требуется остановиться при первом возникновении исключения (несмотря на то, что обработаны не все элементы), то можно использовать <code>std::promise</code> для передачи значения и исключения. С другой стороны, если мы хотим, чтобы рабочие потоки продолжали поиск, то используем <code>std::packaged_task</code>, сохраняем все исключения, а затем повторно возбуждаем одно из них, если искомый элемент не найден.</p>
          <p>В данном случае я остановился на <code>std::promise</code>, потому что такое поведение больше походит на поведение <code>std::find</code>. Надо только не забыть о случае, когда искомого элемента в указанном диапазоне нет. Поэтому необходимо дождаться завершения всех потоков <emphasis>перед</emphasis> тем, как получать значение из будущего результата. Если просто блокировать исполнение при обращении к <code>get()</code>, то при условии, что искомого элемента нет, мы будем ждать вечно. Получившийся код приведён ниже.</p>
          <empty-line/>
          <p><strong>Листинг 8.9.</strong> Параллельная реализация алгоритма <code>find()</code></p>
          <p>
            <code>template&lt;typename Iterator, typename MatchType&gt;</code>
          </p>
          <p>
            <code>Iterator parallel_find(Iterator first, Iterator last,</code>
          </p>
          <p>
            <code> MatchType match) {</code>
          </p>
          <p>
            <code> struct find_element { &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  void operator()(Iterator begin, Iterator end,</code>
          </p>
          <p>
            <code>   MatchType match,</code>
          </p>
          <p>
            <code>   std::promise&lt;Iterator&gt;* result,</code>
          </p>
          <p>
            <code>   std::atomic&lt;bool&gt;* done_flag) {</code>
          </p>
          <p>
            <code>   try {</code>
          </p>
          <p>
            <code>    for(; (begin != end) &amp;&amp; !done_flag-&gt;load(); ++begin) {&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>     if (*begin == match) {</code>
          </p>
          <p>
            <code>      result-&gt;set_value(begin);&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>      done_flag-&gt;store(true);  &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>      return;</code>
          </p>
          <p>
            <code>     }</code>
          </p>
          <p>
            <code>    }</code>
          </p>
          <p>
            <code>   } catch (...) { &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>    try {</code>
          </p>
          <p>
            <code>     result-&gt;set_exception(std::current_exception());&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>     done_flag-&gt;store(true);</code>
          </p>
          <p>
            <code>    } catch (...) &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>    {}</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const length = std::distance(first, last);</code>
          </p>
          <empty-line/>
          <p>
            <code> if (!length)</code>
          </p>
          <p>
            <code>  return last;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const min_per_thread = 25;</code>
          </p>
          <p>
            <code> unsigned long const max_threads =</code>
          </p>
          <p>
            <code>  (length + min_per_thread — 1) / min_per_thread;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const hardware_threads =</code>
          </p>
          <p>
            <code>  std::thread::hardware_concurrency();</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const num_threads =</code>
          </p>
          <p>
            <code>  std::min(</code>
          </p>
          <p>
            <code>   hardware_threads != 0 ? hardware_threads : 2, max_threads);</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const block_size = length / num_threads;</code>
          </p>
          <empty-line/>
          <p>
            <code> std::promise&lt;Iterator&gt; result;     &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code> std::atomic&lt;bool&gt; done_flag(false);&#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads(num_threads — 1); {&#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>  join_threads joiner(threads);</code>
          </p>
          <empty-line/>
          <p>
            <code> Iterator block_start = first;</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  Iterator block_end = block_start;</code>
          </p>
          <p>
            <code>  std::advance(block_end, block_size);</code>
          </p>
          <p>
            <code>  threads[i] = std::thread(find_element(), &#8592;</code>
            <strong>(11)</strong>
          </p>
          <p>
            <code>   block_start, block_end, match,</code>
          </p>
          <p>
            <code>   &amp;result, &amp;done_flag);</code>
          </p>
          <p>
            <code>  block_start = block_end;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> find_element()(</code>
          </p>
          <p>
            <code>  block_start, last, match, &amp;result, &amp;done_flag);&#8592;</code>
            <strong>(12)</strong>
          </p>
          <p>
            <code> if (!done_flag.load()) { &#8592;</code>
            <strong>(13)</strong>
          </p>
          <p>
            <code>  return last;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> return result.get_future().get() <strong>&#8592;</strong></code>
            <strong>(14)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В основе своей код в листинге 8.9 похож на предыдущие примеры. На этот раз вся работа производится в операторе вызова, определенном в локальном классе <code>find_element</code> <strong>(1)</strong>. Здесь мы в цикле обходим элементы из назначенного потоку блока, проверяя флаг на каждой итерации <strong>(2)</strong>. Если искомый элемент найден, то мы записываем окончательный результат в объект-обещание <strong>(3)</strong> и перед возвратом устанавливаем флаг <code>done_flag</code> <strong>(4)</strong>.</p>
          <p>Если было возбуждено исключение, то его перехватит универсальный обработчик <strong>(5)</strong> и попытается сохранить исключение в обещании <strong>(6)</strong> перед установкой <code>done_flag</code>. Но установка значения объекта-обещания может возбудить исключение, если значение уже установлено, поэтому мы перехватываем и игнорируем любые возникающие здесь исключения <strong>(7)</strong>.</p>
          <p>Это означает, что если поток, вызвавший <code>find_element</code>, найдет искомый элемент или возбудит исключение, то все остальные потоки увидят поднятый флаг <code>done_flag</code> и прекратят работу. Если несколько потоков одновременно найдут искомое или возбудят исключение, то возникнет гонка за установку результата в обещании. Но это безобидная гонка: победивший поток считается «первым», и установленный им результат приемлем.</p>
          <p>В самой функции <code>parallel_find</code> мы определяем обещание <strong>(8)</strong> и флаг прекращения поиска <strong>(9)</strong>, которые передаем новым потокам вместе с диапазоном для просмотра <strong>(11)</strong>. Кроме того, главный поток пользуется классом <code>find_element</code> для поиска среди оставшихся элементов <strong>(12)</strong>. Как уже отмечалось, мы должны дождаться завершения всех потоков перед тем, как проверять результат, потому что искомого элемента может вообще не оказаться. Для этого мы заключаем код запуска и присоединения потоков в блок <strong>(10)</strong>, так что к моменту проверки флага <strong>(13)</strong> все потоки гарантировано присоединены. Если элемент был найден, то, обратившись к функции <code>get()</code> объекта <code>std::future&lt;Iterator&gt;</code>, мы либо получим результат из обещания, либо возбудим сохраненное исключение.</p>
          <p>Как и раньше, в этой реализации предполагается, что мы собираемся использовать все доступные аппаратные потоки или располагаем каким-то механизмом, который позволит заранее определить количество потоков для предварительного разделения между ними работы. И снова мы можем упростить код, воспользовавшись функцией <code>std::async</code> и рекурсивным разбиением данных, если готовы принять автоматический механизм масштабирования, скрытый в стандартной библиотеке С++. Реализация <code>parallel_find</code> с применением <code>std::async</code> приведена в листинге ниже.</p>
          <empty-line/>
          <p><strong>Листинг 8.10.</strong> Параллельная реализация алгоритма <code>find()</code> с применением <code>std::async</code></p>
          <p>
            <code>template&lt;typename Iterator, typename MatchType&gt; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>Iterator parallel_find_impl(Iterator first, Iterator last,</code>
          </p>
          <p>
            <code> MatchType match,</code>
          </p>
          <p>
            <code> std::atomic&lt;bool&gt;&amp; done) {</code>
          </p>
          <p>
            <code> try {</code>
          </p>
          <p>
            <code>  unsigned long const length = std::distance(first, last);</code>
          </p>
          <p>
            <code>  unsigned long const min_per_thread = 25;          &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  if (length &lt; (2 * min_per_thread)) {              &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>   for(; (first != last) &amp;&amp; !done.load(); ++first) {&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>    if (*first == match) {</code>
          </p>
          <p>
            <code>     done = true;                                   &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>     return first;</code>
          </p>
          <p>
            <code>    }</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   return last; &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   Iterator const mid_point = first + (length / 2);    &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>   std::future&lt;Iterator&gt; async_result =</code>
          </p>
          <p>
            <code>    std::async(&amp;parallel_find_impl&lt;Iterator, MatchType&gt;,&#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>   mid_point, last, match, std::ref(done));</code>
          </p>
          <p>
            <code>   Iterator const direct_result =</code>
          </p>
          <p>
            <code>    parallel_find_impl(first, mid_point, match, done);  &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>   return (direct_result == mid_point) ?</code>
          </p>
          <p>
            <code>    async_result.get() : direct_result; &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> } catch (...) {</code>
          </p>
          <p>
            <code>  done = true; &#8592;</code>
            <strong>(11)</strong>
          </p>
          <p>
            <code>  throw;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Iterator, typename MatchType&gt;</code>
          </p>
          <p>
            <code>Iterator parallel_find(</code>
          </p>
          <p>
            <code> Iterator first, Iterator last, MatchType match) {</code>
          </p>
          <p>
            <code> std::atomic&lt;bool&gt; done(false);</code>
          </p>
          <p>
            <code> return parallel_find_impl(first, last, match, done); &#8592;</code>
            <strong>(12)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Желание закончить поиск досрочно при обнаружении совпадения заставило нас ввести флаг, разделяемый между всеми потоками. Этот флаг, следовательно, нужно передавать во все рекурсивные вызовы. Проще всего сделать это, делегировав работу отдельной функции <strong>(1)</strong>, которая принимает дополнительный параметр — ссылку на флаг <code>done</code>, передаваемый из главной точки входа <strong>(12)</strong>.</p>
          <p>Основная же ветвь кода не таит никаких неожиданностей. Как и во многих предыдущих реализациях, мы задаем минимальное количество элементов, обрабатываемых в одном потоке <strong>(2)</strong>; если размер обеих половин диапазона меньше этой величины, то весь диапазон обрабатывается в текущем потоке <strong>(3)</strong>. Собственно алгоритм сводится к простому циклу — он продолжается, пока не будет достигнут конец заданного диапазона или не установлен флаг <code>done</code> <strong>(4)</strong>. При обнаружении совпадения мы устанавливаем флаг <code>done</code> и выходим из функции <strong>(5)</strong>. Если мы дошли до конца списка или вышли из цикла, потому что другой поток установил флаг <code>done</code>, то возвращаем значение <code>last</code>, означающее, что совпадение не найдено <strong>(6)</strong>.</p>
          <p>Если диапазон можно разбивать, то мы сначала находим среднюю точку <strong>(7)</strong>, а потом через <code>std::async</code> запускаем поиск во второй половине диапазона <strong>(8)</strong>, не забыв передать ссылку на флаг <code>done</code> с помощью <code>std::ref</code>. Одновременно мы просматриваем первую половину диапазона, рекурсивно вызывая себя же <strong>(9)</strong>. И асинхронный, и рекурсивный вызов могут разбивать диапазон и дальше, если он достаточно велик.</p>
          <p>Если прямой рекурсивный вызов вернул <code>mid_point</code>, значит, он не нашел совпадения, поэтому нужно получить результат асинхронного поиска. Если и в той половине ничего не было найдено, то мы получим <code>last</code> <strong>(10)</strong>. Если «асинхронный» вызов на самом деле был не асинхронным, а отложенным, то выполняться он начнет именно при обращении к <code>get()</code>; в таком случае поиск во второй половине списке вообще не будет производиться, если поиск в первой оказался успешным. Если же асинхронный поиск действительно выполнялся в другом потоке, то деструктор переменной <code>async_result</code> будет ждать завершения этого потока, поэтому утечки потоков не произойдет.</p>
          <p>Как и раньше, применение <code>std::async</code> гарантирует безопасность относительно исключений и распространения исключений вверх по стеку вызовов. Если прямой рекурсивный вызов возбудит исключение, то деструктор будущего результата позаботится о том, чтобы поток, в котором работал асинхронный поиск, завершился до возврата из функции. Если исключение возбудит асинхронный вызов, то оно распространится вверх при вызове <code>get()</code> <strong>(10)</strong>. Внешний блок <code>try/catch</code> нужен только для того, чтобы установить флаг <code>done</code> и обеспечить тем самым быстрое завершение всех потоков в случае исключения <strong>(11)</strong>. Программа правильно работала бы и без этого, по продолжала бы сравнивать элементы до естественного завершения всех потоков.</p>
          <p>Существенной особенностью обеих реализаций этого алгоритма (характерной и для других рассмотренных выше параллельных алгоритмов) является тот факт, что элементы могут обрабатываться не в том же порядке, что в стандартном алгоритме <code>std::find</code>. Это важный момент при распараллеливании любого алгоритма. Если порядок имеет значение, то обрабатывать элементы параллельно нельзя. В таких алгоритмах, как <code>parallel_for_each</code>, порядок обработки независимых элементов не важен, однако <code>parallel_find</code> может вернуть элемент, найденный где-то в конце диапазона, хотя имеется другой такой же элемент в начале. Это может оказаться неприятной неожиданностью.</p>
          <p>Итак, нам удалось распараллелить <code>std::find</code>. В начале этого раздела я говорил, что существуют и другие алгоритмы, которые могут завершаться раньше, чем будут обработаны все элементы. К ним применима такая же техника. В главе 9 мы еще вернёмся к вопросу о прерывании потоков.</p>
          <p>В последнем из трех примеров мы направимся в другую сторону и рассмотрим алгоритм <code>std::partial_sum</code>. Он не очень широко известен, но интересен с точки зрения распараллеливания, поскольку позволяет проиллюстрировать некоторые дополнительные проектные решения.</p>
        </section>
        <section>
          <title>
            <p>8.5.3. Параллельная реализация <code>std::partial_sum</code></p>
          </title>
          <p>Алгоритм <code>std::partial_sum</code> вычисляет частичные суммы по диапазону, то есть каждый элемент заменяется суммой всех элементов от начала диапазона до него самого включительно. Таким образом, последовательность 1, 2, 3, 4, 5 преобразуется в 1, (1+2)=3, (1+2+3)=6, (1+2+3+4)=10, (1+2+3+4+5)=15. С точки зрения распараллеливания этот алгоритм интересен тем, что невозможно разбить диапазон на части и обрабатывать каждый блок независимо. Действительно, значение первого элемента необходимо складывать с каждым из остальных элементов, так что независимой обработки не получается.</p>
          <p>Один из возможных подходов — вычислить частичные суммы отдельных блоков, а затем прибавить полученное значение последнего элемента в первом блоке ко всем элементам в следующем блоке и так далее. Например, если исходную последовательность 1, 2, 3, 4, 5, 6, 7, 8, 9 разбить на три равных блока, то после первого прохода получатся блоки {1, 3, 6}, {4, 9, 15}, {7, 15, 24}. Если теперь прибавить 6 (значение последнего элемента в первом блоке) ко всем элементам второго блока, то получится {1, 3, 6}, {10, 15, 21}, {7, 15, 24}. Далее прибавляем последний элемент второго блока (21) ко всем элементам третьего блока и получаем окончательный результат: {1, 3, 6}, {10, 15, 21}, {28, 36, 55}.</p>
          <p>Процедуру прибавления частичной суммы предыдущего блока ко всем элементам следующего также можно распараллелить. Если сначала изменить последний элемент блока, то оставшиеся элементы того же блока могут модифицироваться одним потоком, тогда как другой поток одновременно будет модифицировать следующий блок. И так далее. Такое решение хорошо работает, если количество элементов в списке намного превышает количество процессорных ядер, поскольку в этом случае у каждого ядра будет достаточно элементов для обработки на каждом этапе.</p>
          <p>Если же процессорных ядер очень много (столько же, сколько элементов в списке, или больше), то описанный подход оказывается не столь эффективен. Если разбить всю работу между процессорами, то на первом шаге каждый процессор будет работать всего с двумя элементами. Но тогда на этапе распространения результатов большинство процессоров будут ждать, и хорошо бы их чем-то запять. В таком случае можно подойти к задаче по-другому. Вместо того чтобы сначала вычислять частичные суммы всех блоков, а затем распространять их от предыдущего к следующему, мы можем распространять суммы по частям. Сначала, как и раньше, вычисляем суммы соседних элементов. На следующем шаге каждое вычисленное значение прибавляется к элементу, отстоящему от него на расстояние 2. Затем новые значения прибавляются к элементам, отстоящим на расстояние 4, и так далее. Если начать с тех же самых девяти элементов, то после первого шага мы получим последовательность 1, 3, 5, 7, 9, 11, 13, 15, 17, в которой правильно вычислены первые два элемента. После второго шага получается последовательность 1, 3, 6, 10, 14, 18, 22, 26, 30, в которой правильны первые четыре элемента. После третьего мы получим последовательность 1, 3, 6, 10, 15, 21, 28, 36, 44, в которой правильны первые восемь элементов. И после четвертого шага получаем окончательный результат 1, 3, 6, 10, 15, 21, 28, 36, 45. Общее количество шагов здесь больше, чем в первом варианте, зато и возможности для распараллеливания на большое число процессоров шире — на каждом шаге каждый процессор может обновлять одно число.</p>
          <p>Всего во втором варианте требуется выполнить log<sub>2</sub>(<emphasis>N</emphasis>) шагов по <emphasis>N</emphasis> операций на каждом шаге (по одной на процессор), где <emphasis>N</emphasis> — число элементов в списке. В первом же варианте каждый поток производит <emphasis>N</emphasis>/<emphasis>k</emphasis> операций для вычисления частичной суммы своего блока и еще <emphasis>N</emphasis>/<emphasis>k</emphasis> операций для распространения сумм (здесь <emphasis>k</emphasis> — число потоков). Следовательно, вычислительная сложность первого варианта в терминах количества операций составляет <emphasis>O</emphasis>(<emphasis>N</emphasis>), а второго — <emphasis>O</emphasis>(<emphasis>N</emphasis> log(<emphasis>N</emphasis>)). Однако, если процессоров столько же, сколько элементов в списке, то во втором варианте требуется произвести только log(<emphasis>N</emphasis>) операций <emphasis>на каждом процессоре</emphasis>, тогда как в первом при большом <emphasis>k</emphasis> операции из-за распространения частичных сумм вперед фактически сериализуются. Таким образом, если количество процессоров невелико, то первый алгоритм завершится быстрее, тогда как в массивно параллельных системах победителем окажется второй алгоритм. Это крайнее проявление феномена, обсуждавшегося в разделе 8.2.1.</p>
          <p>Но оставим в стороне эффективность и перейдем к коду. В листинге 8.11 приведена реализация первого подхода.</p>
          <empty-line/>
          <p><strong>Листинг 8.11.</strong> Параллельное вычисление частичных сумм путём разбиения задачи на части</p>
          <p>
            <code>template&lt;typename Iterator&gt;</code>
          </p>
          <p>
            <code>void parallel_partial_sum(Iterator first, Iterator last) {</code>
          </p>
          <p>
            <code> typedef typename Iterator::value_type value_type;</code>
          </p>
          <empty-line/>
          <p>
            <code> struct process_chunk { &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  void operator()(Iterator begin, Iterator last,</code>
          </p>
          <p>
            <code>   std::future&lt;value_type&gt;* previous_end_value,</code>
          </p>
          <p>
            <code>   std::promise&lt;value_type&gt;* end_value) {</code>
          </p>
          <p>
            <code>   try {</code>
          </p>
          <p>
            <code>    Iterator end = last;</code>
          </p>
          <p>
            <code>    ++end;</code>
          </p>
          <p>
            <code>    std::partial_sum(begin, end, begin); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>    if (previous_end_value) {            &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>     value_type&amp; addend = previous_end_value-&gt;get();&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>     *last += addend;              &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>     if (end_value) {</code>
          </p>
          <p>
            <code>      end_value-&gt;set_value(*last); &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>     }</code>
          </p>
          <p>
            <code>     std::for_each(begin, last, [addend](value_type&amp; item) {&#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>      item += addend;</code>
          </p>
          <p>
            <code>     });</code>
          </p>
          <p>
            <code>    } else if (end_value) {</code>
          </p>
          <p>
            <code>     end_value-&gt;set_value(*last); &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>    }</code>
          </p>
          <p>
            <code>   } catch (...) { &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>    if (end_value) {</code>
          </p>
          <p>
            <code>     end_value-&gt;set_exception(std::current_exception()); &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>    } else {</code>
          </p>
          <p>
            <code>     throw; &#8592;</code>
            <strong>(11)</strong>
          </p>
          <p>
            <code>    }</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const length = std::distance(first, last);</code>
          </p>
          <empty-line/>
          <p>
            <code> if (!length)</code>
          </p>
          <p>
            <code>  return last;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const min_per_thread = 25; &#8592;</code>
            <strong>(12)</strong>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const max_threads =</code>
          </p>
          <p>
            <code>  (length + min_per_thread - 1) / min_per_thread;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const hardware_threads =</code>
          </p>
          <p>
            <code>  std::thread::hardware_concurrency();</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const num_threads =</code>
          </p>
          <p>
            <code>  std::min(</code>
          </p>
          <p>
            <code>   hardware_threads!= 0 ? hardware_threads : 2, max_threads);</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const block_size = length / num_threads;</code>
          </p>
          <empty-line/>
          <p>
            <code> typedef typename Iterator::value_type value_type;</code>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads(num_threads - 1);&#8592;</code>
            <strong>(13)</strong>
          </p>
          <p>
            <code> std::vector&lt;std::promise&lt;value_type&gt; &gt;</code>
          </p>
          <p>
            <code>  end_values(num_threads - 1);                     &#8592;</code>
            <strong>(14)</strong>
          </p>
          <p>
            <code> std::vector&lt;std::future&lt;value_type&gt; &gt;</code>
          </p>
          <p>
            <code>  previous_end_values;                             &#8592;</code>
            <strong>(15)</strong>
          </p>
          <p>
            <code> previous_end_values.reserve(num_threads - 1);     &#8592;</code>
            <strong>(16)</strong>
          </p>
          <p>
            <code> join_threads joiner(threads);</code>
          </p>
          <p>
            <code> Iterator block_start = first;</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_threads - 1); ++i) {</code>
          </p>
          <p>
            <code>  Iterator block_last = block_start;</code>
          </p>
          <p>
            <code>  std::advance(block_last, block_size – 1); &#8592;</code>
            <strong>(17)</strong>
          </p>
          <p>
            <code>  threads[i] = std::thread(process_chunk(), &#8592;</code>
            <strong>(18)</strong>
          </p>
          <p>
            <code>   block_start, block_last,</code>
          </p>
          <p>
            <code>   (i !=0 ) ? &amp;previous_end_values[i - 1] : 0, &amp;end_values[i]);</code>
          </p>
          <p>
            <code>  block_start = block_last;</code>
          </p>
          <p><code>  ++block_start; &#8592;</code><strong>(19</strong>)</p>
          <p>
            <code>  previous_end_values.push_back(end_values[i].get_future());&#8592;</code>
            <strong>(20)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> Iterator final_element = block_start;</code>
          </p>
          <p>
            <code> std::advance(</code>
          </p>
          <p>
            <code>  final_element, std::distance(block_start, last) - 1);&#8592;</code>
            <strong>(21)</strong>
          </p>
          <p>
            <code>  process_chunk()(block_start, final_element, &#8592;</code>
            <strong>(22)</strong>
          </p>
          <p>
            <code>  (num_threads &gt; 1) ? &amp;previous_end_values.back() : 0, 0);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Общая структура этого кода не отличается от рассмотренных ранее алгоритмов: разбиение задачи на блоки с указанием минимального размера блока, обрабатываемого одним потоком <strong>(12)</strong>. В данном случае, помимо вектора потоков <strong>(13)</strong>, мы завели вектор обещаний <strong>(14)</strong>, в котором будут храниться значения последних элементов в каждом блоке, и вектор будущих результатов <strong>(15)</strong>, используемый для получения последнего значения из предыдущего блока. Так как мы знаем, сколько всего понадобится будущих результатов, то можем заранее зарезервировать для них место в векторе <strong>(16)</strong>, чтобы избежать перераспределения памяти при запуске потоков.</p>
          <p>Главный цикл выглядит так же, как раньше, только на этот раз нам нужен итератор, который указывает на последний элемент в блоке <strong>(17)</strong>, а не на элемент за последним, чтобы можно было распространить последние элементы поддиапазонов. Собственно обработка производится в объекте-функции <code>process_chunk</code>, который мы рассмотрим ниже; в качестве аргументов передаются итераторы, указывающие на начало и конец блока, а также будущий результат, в котором будет храниться последнее значение из предыдущего диапазона (если таковой существует), и объект-обещание для хранения последнего значения в текущем диапазоне <strong>(18)</strong>.</p>
          <p>Запустив поток, мы можем обновить итератор, указывающий на начало блока, не забыв продвинуть его на одну позицию вперед (за последний элемент предыдущего блока) <strong>(19)</strong>, и поместить будущий результат, в котором будет храниться последнее значение в текущем блоке, в вектор будущих результатов, откуда он будет извлечён на следующей итерации цикла <strong>(20)</strong>.</p>
          <p>Перед тем как обрабатывать последний блок, мы должны получить итератор, указывающий на последний элемент <strong>(21)</strong>, который передается в <code>process_chunk</code> <strong>(22)</strong>. Алгоритм <code>std::partial_sum</code> не возвращает значения, поэтому по завершении обработки последнего блока больше ничего делать не надо. Можно считать, что операция закончилась, когда все потоки завершили выполнение.</p>
          <p>Теперь настало время поближе познакомиться с объектом-функцией <code>process_chunk</code>, который собственно и делает всю содержательную работу <strong>(1)</strong>. Сначала вызывается <code>std::partial_sum</code> для всего блока, включая последний элемент <strong>(2)</strong>, но затем нам нужно узнать, первый это блок или нет <strong>(3)</strong>. Если это <emphasis>не</emphasis> первый блок, то должно быть вычислено значение <code>previous_end_value</code> для предыдущего блока, поэтому нам придется его подождать <strong>(4)</strong>. Чтобы добиться максимального распараллеливания, мы затем сразу же обновляем последний элемент <strong>(5)</strong>, так чтобы это значение можно было передать дальше, в следующий блок (если таковой имеется) <strong>(6)</strong>. Сделав это, мы можем с помощью <code>std::for_each</code> и простой лямбда-функции <strong>(7)</strong> обновить остальные элементы диапазона.</p>
          <p>Если <code>previous_end_value</code> <emphasis>не</emphasis> существует, то это первый блок, поэтому достаточно обновить <code>end_value</code> для следующего блока (опять же, если таковой существует, — может случиться, что блок всего один) <strong>(8)</strong>.</p>
          <p>Наконец, если какая-то операция возбуждает исключение, мы перехватываем его <strong>(9)</strong> и сохраняем в объекте-обещании <strong>(10)</strong>, чтобы оно было распространено в следующий блок, когда он попытается получить последнее значение из предыдущего блока <strong>(4)</strong>. В результате все исключения доходят до последнего блока, где и возбуждаются повторно <strong>(11)</strong>, поскольку в этой точке мы гарантированно работаем в главном потоке.</p>
          <p>Из-за необходимости синхронизации между потоками этот код не получится переписать под <code>std::async</code>. Каждая задача ждет результатов, которые становятся доступны по ходу выполнения других задач, поэтому все задачи должны работать параллельно.</p>
          <p>Разобравшись с решением, основанным на распространении результатов обработки предыдущих блоков, посмотрим на второй из описанных алгоритмов вычисления частичных сумм.</p>
          <subtitle>Реализация прогрессивно-попарного алгоритма вычисления частичных сумм</subtitle>
          <p>Второй способ вычисления частичных сумм, основанный на сложении элементов, расположенных на все большем расстоянии друг от друга, работает лучше всего, когда процессоры могут выполнять операции сложения синхронно. В таком случае никакой дополнительной синхронизации не требуется, потому что все промежуточные результаты можно сразу распространить на следующий нуждающийся в них процессор. Но на практике такие системы встречаются редко — разве что в случаях, когда один процессор может выполнять одну и ту же команду над несколькими элементами данных одновременно с помощью так называемых SIMD-команд (Single-Instruction/Multiple-Data — одиночный поток команд, множественный поток данных). Поэтому мы должны проектировать программу в расчете на общий случай и производить явную синхронизацию на каждом шаге.</p>
          <p>Сделать это можно, например, с помощью <emphasis>барьера</emphasis> — механизма синхронизации, который заставляет потоки ждать, пока указанное количество потоков достигнет барьера. Когда все потоки подошли к барьеру, они разблокируются и могут продолжать выполнение. В библиотеке C++11 Thread Library готовая реализация барьера отсутствует, так что нам придется написать свою собственную.</p>
          <p>Представьте себе американские горки в парке аттракционов. Если желающих покататься достаточно, то смотритель не запустит состав, пока не будут заняты все места. Барьер работает точно так же: вы заранее задаете число «мест», и потоки будут ждать, пока все «места» заполнятся. Когда ожидающих потоков собирается достаточно, они все получают возможность продолжить выполнение; барьер при этом сбрасывается и начинает ждать следующую партию потоков. Часто такая конструкция встречается в цикле, где на каждой итерации у барьера собираются одни и те же потоки. Идея в том, чтобы все потоки «шли в ногу» — никто не должен забегать вперед. В рассматриваемом алгоритме такой «поток-торопыга» недопустим, потому что он мог бы модифицировать данные, которые еще используются другими потоками, или, наоборот, сам попытался бы использовать еще не модифицированные должным образом данные.</p>
          <p>В следующем листинге приведена простая реализация барьера.</p>
          <empty-line/>
          <p><strong>Листинг 8.12.</strong> Простой класс барьера</p>
          <p>
            <code>class barrier {</code>
          </p>
          <p>
            <code> unsigned const count;</code>
          </p>
          <p>
            <code> std::atomic&lt;unsigned&gt; spaces;</code>
          </p>
          <p>
            <code> std::atomic&lt;unsigned&gt; generation;</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> explicit barrier (unsigned count_) : &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> count(count_), spaces(count), generation(0) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void wait() {</code>
          </p>
          <p>
            <code>  unsigned const my_generation = generation; &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  if (!--spaces) {&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>   spaces = count;&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>   ++generation;  &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   while (generation == my_generation) &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>   std::this_thread::yield();          &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Здесь при конструировании барьера мы указываем количество «мест» <strong>(1)</strong>, которое сохраняется в переменной count. В начале количество мест у барьера spaces равно <code>count</code>. Когда очередной поток выполняет функцию <code>wait()</code>, значение <code>spaces</code> уменьшается на единицу <strong>(3)</strong>. Как только оно обращается в нуль, количество мест возвращается к исходному значению <code>count</code> <strong>(4)</strong>, а переменная <code>generation</code> увеличивается, что служит для других потоков сигналом к продолжению работы <strong>(5)</strong>. Если число свободных мест больше нуля, то поток должен ждать. В этой реализации используется простой спинлок <strong>(6)</strong>, который сравнивает текущее значение <code>generation</code> с тем, что было запомнено в начале <code>wait()</code> <strong>(2)</strong>. Поскольку <code>generation</code> изменяется только после того, как все потоки подошли к барьеру <strong>(5)</strong>, мы можем во время ожидания уступить процессор с помощью <code>yield()</code> <strong>(7)</strong>, чтобы ожидающий поток не потреблял процессорное время.</p>
          <p>Эта реализация действительно очень простая — в ней для ожидания используется спинлок, поэтому она не идеальна для случая, когда потоки могут ждать долго, и совсем не годится в ситуации, когда в каждый момент времени может существовать более count потоков, выполнивших <code>wait()</code>. Если требуется, чтобы и в этих случаях барьер работал правильно, то следует использовать более надежную (но и более сложную) реализацию. Кроме того, я ограничился последовательно согласованными операциями над атомарными переменными, потому что они проще для понимания, но вы, возможно, захотите ослабить ограничения на порядок доступа к памяти. Такая глобальная синхронизация дорого обходится в массивно параллельных архитектурах, так как строку кэша, содержащую состояние барьера, приходится передавать всем участвующим процессорам (см. обсуждение перебрасывания кэша в разделе 8.2.2). Поэтому нужно тщательно продумать, является ли это решение оптимальным.</p>
          <p>Как бы то ни было, барьер — это именно то, что нам необходимо в данном случае; имеется фиксированное число потоков, которые должны синхронизироваться на каждой итерации цикла. Ну <emphasis>почти</emphasis> фиксированное. Как вы, наверное, помните, элементы, расположенные близко к началу списка, получают окончательные значения всего через пару шагов. Это означает, что либо все потоки должны крутиться в цикле, пока не будет обработан весь диапазон, либо барьер должен поддерживать выпадение потоков, уменьшая значение <code>count</code>. Я предпочитаю второй вариант, чтобы не заставлять потоки выполнять бессмысленную работу в ожидании завершения последнего шага.</p>
          <p>Но тогда нужно сделать <code>count</code> атомарной переменной, чтобы ее можно было изменять из нескольких потоков без внешней синхронизации:</p>
          <p>
            <code>std::atomic&lt;unsigned&gt; count;</code>
          </p>
          <p>Инициализация не меняется, но при переустановке <code>spaces</code> теперь нужно явно загружать <code>spaces</code> с помощью операции <code>load()</code>:</p>
          <p>
            <code>spaces = count.load();</code>
          </p>
          <p>Больше никаких изменений в <code>wait()</code> вносить не надо, но необходима новая функция-член для уменьшения count. Назовем ее <code>done_waiting()</code>, потому что с ее помощью поток заявляет, что больше ждать не будет.</p>
          <p>
            <code>void done_waiting() {</code>
          </p>
          <p>
            <code> --count;               &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> if (!--spaces) {       &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  spaces = count.load();&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  ++generation;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Прежде всего мы уменьшаем <code>count</code> <code>(1)</code>, чтобы при следующей переустановке <code>spaces</code> было отражено новое, меньшее прежнего, количество ожидающих потоков. Затем уменьшаем количество свободных мест <code>spaces</code> <strong>(2)</strong>. Если этого не сделать, то остальные потоки будут ждать вечно, так как при инициализации <code>spaces</code> было задано старое, большее, значение. Если текущий поток является последним в партии, то количество мест нужно переустановить и увеличить <code>generation</code> на единицу <strong>(3)</strong> — так же, как в <code>wait()</code>. Основное отличие от <code>wait()</code> заключается в том, что поток не должен ждать — он же сам объявляет, что больше ждать не будет!</p>
          <p>Теперь мы готовы написать вторую реализацию алгоритма вычисления частичных сумм. На каждом шаге каждый поток вызывает функцию <code>wait()</code> барьера, чтобы все потоки пересекли его вместе, а, закончив работу, поток вызывает функцию <code>done_waiting()</code>, чтобы уменьшить счетчик. Если наряду с исходным диапазоном использовать второй буфер, то барьер обеспечивает необходимую синхронизацию. На каждом шаге потоки либо читают исходный диапазон и записывают новое значение в буфер, либо наоборот — читают буфер и записывают новое значение в исходный диапазон. На следующем шаге исходный диапазон и буфер меняются местами. Тем самым мы гарантируем отсутствие гонки между операциями чтения и записи в разных потоках. Перед выходом из цикла каждый поток должен позаботиться о записи окончательного значения в исходный диапазон. В листинге 8.13 все это собрано воедино.</p>
          <empty-line/>
          <p><strong>Листинг 8.13.</strong> Параллельная реализация <code>partial_sum</code> методом попарных обновлений</p>
          <p>
            <code>struct barrier {</code>
          </p>
          <p>
            <code> std::atomic&lt;unsigned&gt; count;</code>
          </p>
          <p>
            <code> std::atomic&lt;unsigned&gt; spaces;</code>
          </p>
          <p>
            <code> std::atomic&lt;unsigned&gt; generation;</code>
          </p>
          <empty-line/>
          <p>
            <code> barrier(unsigned count_) :</code>
          </p>
          <p>
            <code>  count(count_), spaces(count_), generation(0) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void wait() {</code>
          </p>
          <p>
            <code>  unsigned const gen = generation.load();</code>
          </p>
          <p>
            <code>  if (!--spaces) {</code>
          </p>
          <p>
            <code>   spaces = count.load();</code>
          </p>
          <p>
            <code>   ++generation;</code>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   while (generation.load() == gen) {</code>
          </p>
          <p>
            <code>    std::this_thread::yield();</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void done_waiting() {</code>
          </p>
          <p>
            <code>  --count;</code>
          </p>
          <p>
            <code>  if (!--spaces) {</code>
          </p>
          <p>
            <code>   spaces = count.load();</code>
          </p>
          <p>
            <code>   ++generation;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Iterator&gt;</code>
          </p>
          <p>
            <code>void parallel_partial_sum(Iterator first, Iterator last) {</code>
          </p>
          <p>
            <code> typedef typename Iterator::value_type value_type;</code>
          </p>
          <empty-line/>
          <p>
            <code> struct process_element { &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  void operator()(Iterator first, Iterator last,</code>
          </p>
          <p>
            <code>   std::vector&lt;value_type&gt;&amp; buffer,</code>
          </p>
          <p>
            <code>   unsigned i, barrier&amp; b) {</code>
          </p>
          <p>
            <code>   value_type&amp; ith_element = *(first + i);</code>
          </p>
          <p>
            <code>   bool update_source = false;</code>
          </p>
          <empty-line/>
          <p>
            <code>   for (unsigned step = 0, stride = 1;</code>
          </p>
          <p>
            <code>        stride &lt;= i; ++step, stride *= 2) {</code>
          </p>
          <p>
            <code>    value_type const&amp; source = (step % 2) ? &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>     buffer[i] : ith_element;</code>
          </p>
          <p>
            <code>    value_type&amp; dest = (step % 2) ?</code>
          </p>
          <p>
            <code>     ith_element:buffer[i];</code>
          </p>
          <p>
            <code>    value_type const&amp; addend = (step % 2) ? &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>     buffer[i - stride] : *(first + i – stride);</code>
          </p>
          <empty-line/>
          <p>
            <code>    dest = source + addend; &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>    update_source = !(step % 2);</code>
          </p>
          <p>
            <code>    b.wait(); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   if (update_source) { &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>    ith_element = buffer[i];</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>   b.done_waiting(); &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const length = std::distance(first, last);</code>
          </p>
          <empty-line/>
          <p>
            <code> if (length &lt;= 1)</code>
          </p>
          <p>
            <code>  return;</code>
          </p>
          <empty-line/>
          <p>
            <code> std::vector&lt;value_type&gt; buffer(length);</code>
          </p>
          <p>
            <code> barrier b(length);</code>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads(length - 1); &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code> join_threads joiner(threads);</code>
          </p>
          <empty-line/>
          <p>
            <code> Iterator block_start = first;</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (length - 1); ++i) {</code>
          </p>
          <p>
            <code>  threads[i] = std::thread(process_element(), first, last,&#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>   std::ref(buffer), i, std::ref(b));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> process_element()(first, last, buffer, length - 1, b);   &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Общая структура кода вам, наверное, уже понятна. Имеется класс с оператором вызова (<code>process_element</code>), который выполняет содержательную работу <strong>(1)</strong> и вызывается из нескольких потоков <strong>(9)</strong>, хранящихся в векторе <strong>(8)</strong>, а также из главного потока <strong>(10)</strong>. Важное отличие заключается в том, что теперь число потоков зависит от числа элементов в списке, а не от результата, возвращаемого функцией <code>std::thread::hardware_concurrency</code>. Я уже говорил, что эта идея не слишком удачна, если только вы не работаете на машине с массивно параллельной архитектурой, где потоки обходятся дешево. Но это неотъемлемая часть самой идеи решения. Можно было бы обойтись и меньшим числом потоков, поручив каждому обработку нескольких значений из исходного диапазона, но тогда при относительно небольшом количестве потоков этот алгоритм оказался бы менее эффективен, чем алгоритм с прямым распространением.</p>
          <p>Так или иначе, основная работа выполняется в операторе вызове из класса <code>process_element</code>. На каждом шаге берется либо <emphasis>i</emphasis>-ый элемент из исходного диапазона, либо <emphasis>i</emphasis>-ый элемент из буфера <strong>(2)</strong> и складывается с предшествующим элементом, отстоящим от него на расстояние <code>stride</code> <strong>(3)</strong>; результат сохраняется в буфере, если мы читали из исходного диапазона, и в исходном диапазоне — если мы читали из буфера <strong>(4)</strong>. Перед тем как переходить к следующему шагу, мы ждем у барьера <strong>(5)</strong>. Работа заканчивается, когда элемент, отстоящий на расстояние <code>stride</code>, оказывается слева от начала диапазона. В этом случае мы должно обновить элемент в исходном диапазоне, если сохраняли окончательный результат в буфере <strong>(6)</strong>. Наконец, мы вызываем функцию <code>done_waiting()</code> <strong>(7)</strong>, сообщая барьеру, что больше ждать не будем.</p>
          <p>Отметим, что это решение не безопасно относительно исключений. Если один из рабочих потоков возбудит исключение в <code>process_element</code>, то приложение аварийно завершится. Решить эту проблему можно было бы, воспользовавшись <code>std::promise</code> для запоминания исключения, как в реализации <code>parallel_find</code> из листинга 8.9, или просто с помощью объекта <code>std::exception_ptr</code>, защищенного мьютексом.</p>
          <p>Вот и подошли к концу обещанные три примера. Надеюсь, они помогли уложить в сознании соображения, высказанные в разделе 8.1, 8.2, 8.3 и 8.4, и показали, как описанные приемы воплощаются в реальном коде.</p>
        </section>
      </section>
      <section>
        <title>
          <p>8.6. Резюме</p>
        </title>
        <p>Эта глава оказалась очень насыщенной. Мы начали с описания различных способов распределения работы между потоками, в частности предварительного распределения данных и использования нескольких потоков для формирования конвейера. Затем мы остановились на низкоуровневых аспектах производительности многопоточного кода, обратив внимание на феномен ложного разделения и проблему конкуренции за данные. Далее мы перешли к вопросу о том, как порядок доступа к данным влияет на производительность программы. После этого мы поговорили о дополнительных соображениях при проектировании параллельных программ, в частности о безопасности относительно исключений и о масштабируемости. И закончили главу рядом примеров реализации параллельных алгоритмов, на которых показали, какие проблемы могут возникать при проектировании многопоточного кода.</p>
        <p>В этой главе пару раз всплывала идея пула потоков — предварительно сконфигурированной группы потоков, выполняющих задачи, назначенные пулу. Разработка хорошего пула потоков — далеко не тривиальное дело. В следующей главе мы рассмотрим некоторые возникающие при этом проблемы, а также другие, более сложные, аспекты управления потоками.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Глава 9.</p>
        <p>Продвинутое управление потоками</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Пулы потоков.</p>
        <p>&#9632; Учет зависимостей между задачами, адресованными пулу.</p>
        <p>&#9632; Занимание работ у потоков из пула.</p>
        <p>&#9632; Прерывание потоков.</p>
      </annotation>
      <section>
        <p>В предыдущих главах мы управляли потоками явно — путем создания объектов <code>std::thread</code> для каждого потока. В нескольких местах мы видели, что это не всегда желательно, так как приходится самостоятельно управлять временем жизни этих объектов, определять, сколько потоков создать для решения данной задачи с учетом имеющегося оборудования и т.д. В идеале хотелось бы просто разбить код на максимально мелкие блоки, которые можно выполнить параллельно, а потом передать их компилятору и библиотеке, сказав: «Распараллель и обеспечь оптимальную производительность».</p>
        <p>В ряде примеров нам встречалась еще одна повторяющаяся тема — мы можем использовать несколько потоков для решения задачи, но хотим, чтобы они завершались досрочно, если выполнено некоторое условие, например: результат уже получен, или произошла ошибка, или пользователь потребовал отменить операцию. В любом случае потокам нужно отправить запрос «Прекратить работу», который означает, что они должны прервать выполняемое задание, прибраться за собой и как можно скорее завершиться.</p>
        <p>В этой главе мы рассмотрим различные механизмы управления потоками и задачами и начнем с автоматического выбора числа потоков и распределения задач между ними.</p>
      </section>
      <section>
        <title>
          <p>9.1. Пулы потоков</p>
        </title>
        <section>
          <p>Во многих компаниях сотрудники, которые обычно работают в офисе, время от времени должны выезжать к клиентам или поставщикам, посещать выставки и конференции. Хотя такие поездки могут считаться обязательными, и в любой день в командировке может находиться сразу несколько человек, но для любого конкретного работника промежуток между поездками может составлять месяцы, а то и годы. В таких условиях резервировать машину для каждого работника было бы дорого и непрактично, поэтому компании содержат парк, или <emphasis>пул машин</emphasis>, то есть ограниченное количество машин, предоставляемых в распоряжении всем работникам. Когда работнику нужно съездить в командировку, он заказывает машину на определенное время, а по завершении поездки возвращает ее в общий пул. Если в какой-то день свободных машин в пуле не оказалось, то командировку придется перенести на другой день.</p>
          <p>В основе <emphasis>пула потоков</emphasis> лежит аналогичная идея, только в общее распоряжение предоставляются не машины, а потоки. Во многих системах бессмысленно заводить отдельный поток для каждой задачи, которая потенциально может выполняться одновременно с другими, но тем не менее хотелось бы воспользоваться преимуществами параллелизма там, где это возможно. Именно это и позволяет сделать пул потоков: задачи, которые в принципе могут выполняться параллельно, отправляются в пул, а тот ставит их в очередь ожидающих работ. Затем один из <emphasis>рабочих потоков</emphasis> забирает задачу из очереди, исполняет ее и идет за следующей задачей.</p>
          <p>При разработке пула потоков нужно принять несколько важных проектных решений, например: сколько потоков будет в пуле, как эффективнее всего назначать потоки задачам, можно ли будет ждать завершения задачи. В этом разделе мы рассмотрим несколько реализаций пула потоков, начав с самого простого.</p>
        </section>
        <section>
          <title>
            <p>9.1.1. Простейший пул потоков</p>
          </title>
          <p>В простейшем случае пул состоит из фиксированного числа <emphasis>рабочих потоков</emphasis> (обычно равного значению, которое возвращает функция <code>std::thread::hardware_concurrency()</code>). Когда у программы появляется какая-то работа, она вызывает функцию, которая помещает эту работу в очередь. Рабочий поток забирает работу из очереди, выполняет указанную в ней задачу, после чего проверяет, есть ли в очереди другие работы. В этой реализации никакого механизма ожидания завершения задачи не предусмотрело. Если это необходимо, то вы должны будете управлять синхронизацией самостоятельно.</p>
          <p>В следующем листинге приведена реализация такого пула потоков.</p>
          <empty-line/>
          <p><strong>Листинг 9.1.</strong> Простой пул потоков</p>
          <p>
            <code>class thread_pool {</code>
          </p>
          <p>
            <code> std::atomic_bool done;</code>
          </p>
          <p>
            <code> thread_safe_queue&lt;std::function&lt;void()&gt; &gt; work_queue;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads; &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> join_threads joiner; &#8592;</code>
            <strong>(3)</strong>
          </p>
          <empty-line/>
          <p>
            <code> void worker_thread() {</code>
          </p>
          <p>
            <code>  while (!done) { &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>   std::function&lt;void()&gt; task;</code>
          </p>
          <p>
            <code>   if (work_queue.try_pop(task)) { &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>    task(); &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>   } else {</code>
          </p>
          <p>
            <code>    std::this_thread::yield(); &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> thread_pool():</code>
          </p>
          <p>
            <code>  done(false), joiner(threads) {</code>
          </p>
          <p>
            <code>  unsigned const thread_count =</code>
          </p>
          <p>
            <code>   std::thread::hardware_concurrency();&#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>  try {</code>
          </p>
          <p>
            <code>   for (unsigned i = 0; i &lt; thread_count; ++i) {</code>
          </p>
          <p>
            <code>    threads.push_back(</code>
          </p>
          <p>
            <code>     std::thread(&amp;thread_pool::worker_thread, this)); &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  } catch (...) {</code>
          </p>
          <p>
            <code>   done = true; &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>   throw;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> ~thread_pool() {</code>
          </p>
          <p>
            <code>  done = true; &#8592;</code>
            <strong>(11)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename FunctionType&gt;</code>
          </p>
          <p>
            <code> void submit(FunctionType f) {</code>
          </p>
          <p>
            <code>  work_queue.push(std::function&lt;void()&gt;(f)); &#8592;</code>
            <strong>(12)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Здесь мы определили вектор рабочих потоков <strong>(2)</strong> и используем одну из потокобезопасных очередей из главы 6 <strong>(1)</strong> для хранения очереди работ. В данном случае пользователь не может ждать завершения задачи, а задача не может возвращать значения, поэтому для инкапсуляции задач можно использовать тип <code>std::function&lt;void()&gt;</code>. Функция <code>submit()</code> обертывает переданную функцию или допускающий вызов объект в объект <code>std::function&lt;void()&gt;</code> и помещает его в очередь <strong>(12)</strong>.</p>
          <p>Потоки запускаются в конструкторе; их количество равно значению, возвращаемому функцией <code>std::thread::hardware_concurrency()</code>, то есть мы создаем столько потоков, сколько может поддержать оборудование <strong>(8)</strong>. Все эти потоки исполняют функцию-член нашего класса <code>worker_thread()</code> <strong>(9)</strong>.</p>
          <p>Запуск потока может завершиться исключением, поэтому необходимо позаботиться о том, чтобы уже запущенные к этому моменту потоки корректно завершались. Для этого мы включили блок <code>try-catch</code>, который в случае исключения поднимает флаг <code>done</code> <strong>(10)</strong>. Кроме того, мы воспользовались классом <code>join_threads</code> из главы 8 <strong>(3)</strong>, чтобы обеспечить присоединение всех потоков. То же самое происходит в деструкторе: мы просто поднимаем флаг <code>done</code> <strong>(11)</strong>, а объект <code>join_threads</code> гарантирует, что потоки завершатся до уничтожения пула. Отметим, что порядок объявления членов важен: и флаг <code>done</code> и объект <code>worker_queue</code> должны быть объявлены раньше вектора <code>threads</code>, который, в свою очередь, должен быть объявлен раньше <code>joiner</code>. Только тогда деструкторы членов класса будут вызываться в правильном порядке; в частности, нельзя уничтожать очередь раньше, чем остановлены все потоки.</p>
          <p>Сама функция <code>worker_thread</code> проста до чрезвычайности: в цикле, который продолжается, пока не поднят флаг <code>done</code> <strong>(4)</strong>, она извлекает задачи из очереди <strong>(5)</strong> и выполняет их <strong>(6)</strong>. Если в очереди нет задач, функция вызывает <code>std::this_thread::yield()</code> <strong>(7)</strong>, чтобы немного отдохнуть и дать возможность поработать другим потокам.</p>
          <p>Часто даже такого простого пула потоков достаточно, особенно если задачи независимы, не возвращают значений и не выполняют блокирующих операций. Но бывает и по-другому: во-первых, у программы могут быть более жесткие требования, а, во-вторых, в таком пуле возможны проблемы, в частности, из-за взаимоблокировок. Кроме того, в простых случаях иногда лучше прибегнуть к функции <code>std::async</code>, как неоднократно демонстрировалось в главе 8. В этой главе мы рассмотрим и более изощренные реализации пула потоков с дополнительными возможностями, которые призваны либо удовлетворить особые потребности пользователя, либо уменьшить количество потенциальных ошибок. Для начала разрешим ожидать завершения переданной пулу задачи.</p>
        </section>
        <section>
          <title>
            <p>9.1.2. Ожидание задачи, переданной пулу потоков</p>
          </title>
          <p>В примерах из главы 8, где потоки запускались явно, главный поток после распределения работы между потоками всегда ждал завершения запущенных потоков. Тем самым гарантировалось, что вызывающая программа получит управление только после полного завершения задачи. При использовании пула потоков ждать нужно завершения задачи, переданной пулу, а не самих рабочих потоков. Это похоже на то, как мы ждали будущих результатов при работе с <code>std::async</code> в главе 8. В случае простого пула потоков, показанного в листинге 9.1, организовывать ожидание придется вручную, применяя механизмы, описанные в главе 4: условные переменные и будущие результаты. Это усложняет код; намного удобнее было бы ждать задачу напрямую.</p>
          <p>За счет переноса сложности в сам пул потоков мы <emphasis>сумеем</emphasis> добиться желаемого. Функция <code>submit()</code> могла бы возвращать некий описатель задачи, по которому затем можно было бы ждать ее завершения. Сам описатель должен был бы инкапсулировать условную переменную или будущий результат. Это упростило бы код, пользующийся пулом потоков.</p>
          <p>Частный случай ожидания завершения запущенной задачи возникает, когда главный поток нуждается в вычисленном ей результате. Мы уже встречались с такой ситуацией выше, например, в функции <code>parallel_accumulate()</code> из главы 2. В таком случае путем использования будущих результатов мы можем объединить ожидание с передачей результата. В листинге 9.2 приведен код модифицированного пула потоков, который разрешает ожидать завершения задачи и передает возвращенный ей результат ожидающему потоку. Поскольку экземпляры класса <code>std::packaged_task&lt;&gt;</code> допускают только <emphasis>перемещение</emphasis>, но не <emphasis>копирование</emphasis>, мы больше не можем воспользоваться классом <code>std::function&lt;&gt;</code> для обертывания элементов очереди, потому что <code>std::function&lt;&gt;</code> требует, чтобы в обернутых объектах-функциях был определён копирующий конструктор. Вместо этого мы напишем специальный класс-обертку, умеющий работать с объектами, обладающими только перемещающим конструктором. Это простой маскирующий тип класс (type-erasure class), в котором определён оператор вызова. Нам нужно поддержать функции, которые не принимают параметров и возвращают <code>void</code>, поэтому оператор всего лишь вызывает виртуальный метод <code>call()</code>, который в свою очередь вызывает обернутую функцию.</p>
          <empty-line/>
          <p><strong>Листинг 9.2.</strong> Пул потоков, ожидающий завершения задачи</p>
          <p>
            <code>class function_wrapper {</code>
          </p>
          <p>
            <code> struct impl_base {</code>
          </p>
          <p>
            <code>  virtual void call() = 0;</code>
          </p>
          <p>
            <code>  virtual ~impl_base() {}</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code> std::unique_ptr&lt;impl_base&gt; impl;</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename F&gt;</code>
          </p>
          <p>
            <code> struct impl_type: impl_base {</code>
          </p>
          <p>
            <code>  F f;</code>
          </p>
          <p>
            <code>  impl_type(F&amp;&amp; f_): f(std::move(f_)) {}</code>
          </p>
          <p>
            <code>  void call() { f(); }</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> template&lt;typename F&gt; function_wrapper(F&amp;&amp; f):</code>
          </p>
          <p>
            <code>  impl(new impl_type&lt;F&gt;(std::move(f))) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void operator()() { impl-&gt;call(); }</code>
          </p>
          <empty-line/>
          <p>
            <code> function_wrapper() = default;</code>
          </p>
          <empty-line/>
          <p>
            <code> function_wrapper(function_wrapper&amp;&amp; other):</code>
          </p>
          <p>
            <code>  impl(std::move(other.impl)) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> function_wrapper&amp; operator=(function_wrapper&amp;&amp; other) {</code>
          </p>
          <p>
            <code>  impl = std::move(other.impl);</code>
          </p>
          <p>
            <code>  return *this;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> function_wrapper(const function_wrapper&amp;) = delete;</code>
          </p>
          <p>
            <code> function_wrapper(function_wrapper&amp;) = delete;</code>
          </p>
          <p>
            <code> function_wrapper&amp; operator=(const function_wrapper&amp;) = delete;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>class thread_pool {</code>
          </p>
          <p>
            <code> thread_safe_queue&lt;function_wrapper&gt; work_queue;&#8592;&#9488;</code>
          </p>
          <p>
            <code>                                                 &#9474;</code>
            <strong>Используем</strong>
          </p>
          <p>
            <code> void worker_thread()                            &#9474;</code>
            <strong>function_</strong>
          </p>
          <p>
            <code> {                                               &#9474;</code>
            <strong>wrapper</strong>
          </p>
          <p>
            <code>  while (!done)                                  &#9474;</code>
            <strong>вместо std::</strong>
          </p>
          <p>
            <code>  {                                              &#9474;</code>
            <strong>function</strong>
          </p>
          <p>
            <code>   function_wrapper task;                       &#8592;&#9496;</code>
          </p>
          <p>
            <code>   if (work_queue.try_pop(task))</code>
          </p>
          <p>
            <code>    task();</code>
          </p>
          <p>
            <code>   else</code>
          </p>
          <p>
            <code>    std::this_thread::yield();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> template&lt;typename FunctionType&gt;</code>
          </p>
          <p>
            <code> std::future&lt;typename std::result_of&lt;FunctionType()&gt;::type&gt;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> submit(FunctionType f) {</code>
          </p>
          <p>
            <code>  typedef typename std::result_of&lt;FunctionType()&gt;::type</code>
          </p>
          <p>
            <code>   result_type;                                        &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  std::packaged_task&lt;result_type()&gt; task(std::move(f));&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  std::future&lt;result_type&gt; res(task.get_future());     &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  work_queue.push(std::move(task));                    &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  return res;                                          &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> // остальное, как и раньше</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Прежде всего отметим, что модифицированная функция <code>submit()</code> <strong>(1)</strong> возвращает объект <code>std::future&lt;&gt;</code>, который будет содержать возвращенное задачей значение и позволит вызывающей программе ждать ее завершения. Для этого нам необходимо знать тип значения, возвращаемого переданной функцией <code>f</code>, и здесь на помощь приходит шаблон <code>std::result_of&lt;&gt;</code>: <code>std::result_of&lt;FunctionType()&gt;::type</code> — это тип результата, возвращенного вызовом объекта типа <code>FunctionType</code> (например, <code>f</code>) без аргументов. Выражение <code>std::result_of&lt;&gt;</code> мы используем также в определении псевдонима типа <code>result_type</code> <strong>(2)</strong> внутри функции.</p>
          <p>Затем <code>f</code> обертывается объектом <code>std::packaged_task&lt;result_type()&gt;</code> <strong>(3)</strong>, потому что <code>f</code> — функция или допускающий вызов объект, который не принимает параметров и возвращает результат типа <code>result_type</code>. Теперь мы можем получить будущий результат из <code>std::packaged_task&lt;&gt;</code> <strong>(4)</strong>, перед тем как помещать задачу в очередь <strong>(5)</strong> и возвращать будущий результат <strong>(6)</strong>. Отметим, что при помещении задачи в очередь мы должны использовать функцию <code>std::move()</code>, потому что класс std::packaged_task&lt;&gt; не допускает копирования. Именно поэтому в очереди хранятся объекты <code>function_wrapper</code>, а не объекты типа.</p>
          <p>Этот пул позволяет ожидать завершения задач и получать возвращаемые ими результаты. В листинге ниже показано, как выглядит функция <code>parallel_accumulate</code>, работающая с таким пулом потоков.</p>
          <empty-line/>
          <p><strong>Листинг 9.3.</strong> Функция <code>parallel_accumulate</code>, реализованная с помощью пула потоков, допускающего ожидание задач</p>
          <p>
            <code>template&lt;typename Iterator, typename T&gt;</code>
          </p>
          <p>
            <code>T parallel_accumulate(Iterator first, Iterator last, T init) {</code>
          </p>
          <p>
            <code> unsigned long const length = std::distance(first, last);</code>
          </p>
          <empty-line/>
          <p>
            <code> if (!length)</code>
          </p>
          <p>
            <code>  return init;</code>
          </p>
          <empty-line/>
          <p>
            <code> unsigned long const block_size = 25;</code>
          </p>
          <p>
            <code> unsigned long const num_blocks =</code>
          </p>
          <p>
            <code>  (length + block_size - 1) / block_size; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code> std::vector&lt;std::future&lt;T&gt; &gt; futures(num_blocks-1);</code>
          </p>
          <p>
            <code> thread_pool pool;</code>
          </p>
          <empty-line/>
          <p>
            <code> Iterator block_start = first;</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_blocks - 1); ++i) {</code>
          </p>
          <p>
            <code>  Iterator block_end = block_start;</code>
          </p>
          <p>
            <code>  std::advance(block_end, block_size);</code>
          </p>
          <p>
            <code>  futures[i] = pool.submit(accumulate_block&lt;Iterator, T&gt;());&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  block_start = block_end;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> T last_result =</code>
          </p>
          <p>
            <code>  accumulate_block&lt;Iterator, T&gt;()(block_start, last);</code>
          </p>
          <p>
            <code> T result = init;</code>
          </p>
          <p>
            <code> for (unsigned long i = 0; i &lt; (num_blocks - 1); ++i) {</code>
          </p>
          <p>
            <code>  result += futures[i].get();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> result += last_result;</code>
          </p>
          <p>
            <code> return result;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Сравнивая этот код с листингом 8.4, следует обратить внимание на две вещи. Во-первых, мы работаем с количеством блоков (<code>num_blocks</code> <strong>(1)</strong>), а не потоков. Чтобы в полной мере воспользоваться масштабируемостью пула потоков, мы должны разбить работу на максимально мелкие блоки, с которыми имеет смысл работать параллельно. Если потоков в пуле немного, то каждый поток будет обрабатывать много блоков, но по мере роста числа потоков, поддерживаемых оборудованием, будет расти и количество блоков, обрабатываемых параллельно.</p>
          <p>Но, выбирая «максимально мелкие блоки, с которыми имеет смысл работать параллельно», будьте осторожны. Отправка задачи пулу потоков, выбор ее рабочим потоком из очереди и передача возвращенного значения с помощью <code>std::future&lt;&gt;</code> — всё это операции не бесплатные, и для совсем мелких задач они не окупятся. <emphasis>Если размер задачи слишком мал, то программа, в которой используется пул потоков, может работать медленнее, чем однопоточная.</emphasis></p>
          <p>В предположении, что размер блока выбран разумно, вам не надо заботиться об упаковке задач, получении будущих результатов и хранении объектов <code>std::thread</code>, чтобы впоследствии их можно было присоединить; все это пул берет на себя. Вам остается лишь вызвать функцию <code>submit()</code>, передав ей свою задачу <strong>(2)</strong>.</p>
          <p>Пул потоков обеспечивает также безопасность относительно исключений. Любое возбужденное задачей исключение передается через будущий результат, возвращенный <code>submit()</code>, а, если выход из функции происходит в результате исключения, то деструктор пула потоков снимет еще работающие задачи и дождется завершения потоков, входящих в пул.</p>
          <p>Эта схема работает для простых случаев, когда задачи независимы. Но не годится, когда одни задачи зависят от других, также переданных пулу.</p>
        </section>
        <section>
          <title>
            <p>9.1.3. Задачи, ожидающие других задач</p>
          </title>
          <p>В этой книге я уже неоднократно приводил пример алгоритма Quicksort. Его идея проста — подлежащие сортировке данные разбиваются на две части: до и после опорного элемента (в смысле заданной операции сравнения). Затем обе части рекурсивно сортируются и объединяются для получения полностью отсортированной последовательности. При распараллеливании алгоритма надо позаботиться о том, чтобы рекурсивные вызовы задействовали имеющийся аппаратный параллелизм.</p>
          <p>В главе 4, где этот пример впервые был представлен, мы использовали <code>std::async</code> для выполнения одного из рекурсивных вызовов на каждом шаге и оставляли библиотеке решение о том, запускать ли новый поток или сортировать синхронно при обращении к <code>get()</code>. Этот подход неплохо работает — каждая задача либо выполняется в отдельном потоке, либо в тот момент, когда нужны ее результаты.</p>
          <p>В главе 8 мы переработали эту реализацию, продемонстрировав альтернативный подход, когда количество потоков фиксировано и определяется уровнем аппаратного параллелизма. В данном случае мы воспользовались стеком ожидающих сортировки блоков. Разбивая на части предложенные для сортировки данные, каждый поток помещал один блок в стек, а второй сортировал непосредственно. Бесхитростное ожидание завершения сортировки второго блока могло бы закончиться взаимоблокировкой, потому что число потоков ограничено, и некоторые из них ждут. Очень легко оказаться в ситуации, когда все потоки ждут завершения сортировки блоков, и ни один ничего не делает. Тогда мы решили эту проблему, заставив поток извлекать блоки из стека и сортировать их, пока тот конкретный блок, которого он ждет, еще не отсортирован.</p>
          <p>Точно такая же проблема возникает при использовании одного из рассмотренных выше простых пулов потоков вместо <code>std::async</code>, как в примере из главы 4. Число потоков тоже ограничено, и может случиться так, что все они будут ждать задач, которые еще запланированы, так как нет свободных потоков. И решение должно быть таким же,</p>
          <p>как в главе 8: обрабатывать стоящие в очереди блоки во время ожидания завершения сортировки своего блока. Но если мы применяем пул потоков для управления списком задач и их ассоциациями с потоками — а именно в этом и состоит смысл пула потоков, — то доступа к списку задач у нас нет. Поэтому необходимо модифицировать сам пул, чтобы он делал это автоматически.</p>
          <p>Проще всего будет добавить в класс <code>thread_pool</code> новую функцию, чтобы исполнять задачу из очереди и управлять циклом самостоятельно. Так мы и поступим. Более развитые реализации пула могли бы включить дополнительную логику в функцию ожидания или добавить другие функции ожидания для обработки этого случая, быть может, даже назначая приоритеты ожидаемым задачам. В листинге ниже приведена новая функция <code>run_pending_task()</code>, а модифицированный алгоритм Quicksort, в котором она используется, показан в листинге 9.5.</p>
          <empty-line/>
          <p><strong>Листинг 9.4.</strong> Реализация функции <code>run_pending_task()</code></p>
          <p>
            <code>void thread_pool::run_pending_task() {</code>
          </p>
          <p>
            <code> function_wrapper task;</code>
          </p>
          <p>
            <code> if (work_queue.try_pop(task)) {</code>
          </p>
          <p>
            <code>  task();</code>
          </p>
          <p>
            <code> } else {</code>
          </p>
          <p>
            <code>  std::this_thread::yield();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Код <code>run_pending_task()</code> вынесен из главного цикла внутри функции <code>worker_thread()</code>, которую теперь можно будет изменить, так чтобы она вызывала <code>run_pending_task()</code>. Функция <code>run_pending_task()</code> пытается получить задачу из очереди и в случае успеха выполняет ее; если очередь пуста, то функция уступает управление ОС, чтобы та могла запланировать другой поток. Показанная ниже реализация Quicksort гораздо проще, чем версия в листинге 8.1, потому что вся логика управления потоками перенесена в пул.</p>
          <empty-line/>
          <p><strong>Листинг 9.5.</strong> Реализация Quicksort на основе пула потоков</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>struct sorter {    &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> thread_pool pool; &#8592;</code>
            <strong>(2)</strong>
          </p>
          <empty-line/>
          <p>
            <code> std::list&lt;T&gt; do_sort(std::list&lt;T&gt;&amp; chunk_data) {</code>
          </p>
          <p>
            <code>  if (chunk_data.empty()) {</code>
          </p>
          <p>
            <code>   return chunk_data;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  std::list&lt;T&gt; result;</code>
          </p>
          <p>
            <code>  result.splice(result.begin(), chunk_data, chunk_data.begin());</code>
          </p>
          <p>
            <code>  T const&amp; partition_val = *result.begin();</code>
          </p>
          <empty-line/>
          <p>
            <code>  typename std::list&lt;T&gt;::iterator divide_point =</code>
          </p>
          <p>
            <code>   std::partition(chunk_data.begin(), chunk_data.end(),</code>
          </p>
          <p>
            <code>    [&amp;](T const&amp; val){ return val &lt; partition_val; });</code>
          </p>
          <empty-line/>
          <p>
            <code>  std::list&lt;T&gt; new_lower_chunk;</code>
          </p>
          <p>
            <code>  new_lower_chunk.splice(new_lower_chunk.end(),</code>
          </p>
          <p>
            <code>   chunk_data, chunk_data.begin(),</code>
          </p>
          <p>
            <code>   divide_point);</code>
          </p>
          <empty-line/>
          <p>
            <code>  std::future&lt;std::list&lt;T&gt; &gt; new_lower = &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  pool.submit(std::bind(&amp;sorter::do_sort, this,</code>
          </p>
          <p>
            <code>   std::move(new_lower_chunk)));</code>
          </p>
          <empty-line/>
          <p>
            <code>  std::list&lt;T&gt; new_higher(do_sort(chunk_data));</code>
          </p>
          <p>
            <code>  result.splice(result.end(), new_higher);</code>
          </p>
          <p>
            <code>  while (!new_lower.wait_for(std::chrono::seconds(0)) ==</code>
          </p>
          <p>
            <code>   std::future_status::timeout) {</code>
          </p>
          <p>
            <code>   pool.run_pending_task(); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  result.splice(result.begin(), new_lower.get());</code>
          </p>
          <p>
            <code>  return result;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>std::list&lt;T&gt; parallel_quick_sort(std::list&lt;T&gt; input) {</code>
          </p>
          <p>
            <code> if (input.empty()) {</code>
          </p>
          <p>
            <code>  return input;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> sorter&lt;T&gt; s;</code>
          </p>
          <p>
            <code> return s.do_sort(input);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Как и в листинге 8.1, реальная работа делегируется функции-члену <code>do_sort()</code> шаблона класса <code>sorter</code> <strong>(1)</strong>, хотя в данном случае этот шаблон нужен лишь для обертывания экземпляра <code>thread_pool</code> <strong>(2)</strong>.</p>
          <p>Управление потоками и задачами теперь свелось к отправке задачи пулу <strong>(3)</strong> и исполнению находящихся в очереди задач в цикле ожидания <strong>(4)</strong>. Это гораздо проще, чем в листинге 8.1, где нужно было явно управлять потоками и стеком подлежащих сортировке блоков. При отправке задачи пулу мы используем функцию <code>std::bind()</code>, чтобы связать указатель <code>this</code> с <code>do_sort()</code> и передать подлежащий сортировке блок. В данном случае мы вызываем <code>std::move()</code>, чтобы данные <code>new_lower_chunk</code> перемещались, а не копировались.</p>
          <p>Мы решили проблему взаимоблокировки, возникающую из- за того, что одни потоки ждут других, но этот пул все еще далек от идеала. Отметим хотя бы, что все вызовы <code>submit()</code> и <code>run_pending_task()</code> обращаются к одной и той же очереди. В главе 8 мы видели, что модификация одного набора данных из разных потоков может негативно сказаться на производительности, стало быть, с этим нужно что-то делать.</p>
        </section>
        <section>
          <title>
            <p>9.1.4. Предотвращение конкуренции за очередь работ</p>
          </title>
          <p>Всякий раз, как поток вызывает функцию <code>submit()</code> экземпляра пула потоков, он помещает новый элемент в единственную разделяемую очередь работ. А рабочие потоки постоянно извлекают элементы из той же очереди. Следовательно, по мере увеличения числа процессоров будет возрастать конкуренция за очередь работ. Это может ощутимо отразиться на производительности; даже при использовании свободной от блокировок очереди, в которой нет явного ожидания, драгоценное время может тратиться на перебрасывание кэша.</p>
          <p>Чтобы избежать перебрасывания кэша, мы можем завести по одной очереди работ на каждый поток. Тогда каждый поток будет помещать новые элементы в свою собственную очередь и брать работы из глобальной очереди работ только тогда, когда в его очереди работ нет. В следующем листинге приведена реализация с использованием переменной типа <code>thread_local</code>, благодаря которой каждый поток обладает собственной очередью работ в дополнение к глобальной.</p>
          <empty-line/>
          <p><strong>Листинг 9.6.</strong> Пул с очередями в поточно-локальной памяти</p>
          <p>
            <code>class thread_pool {</code>
          </p>
          <p>
            <code> thread_safe_queue&lt;function_wrapper&gt; pool_work_queue;</code>
          </p>
          <empty-line/>
          <p>
            <code> typedef std::queue&lt;function_wrapper&gt; local_queue_type;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> static thread_local std::unique_ptr&lt;local_queue_type&gt;</code>
          </p>
          <p>
            <code>  local_work_queue; &#8592;</code>
            <strong>(2)</strong>
          </p>
          <empty-line/>
          <p>
            <code> void worker_thread() {</code>
          </p>
          <p>
            <code>  local_work_queue.reset(new local_queue_type);&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  while (!done) {</code>
          </p>
          <p>
            <code>   run_pending_task();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> template&lt;typename FunctionType&gt;</code>
          </p>
          <p>
            <code> std::future&lt;typename std::result_of&lt;FunctionType()&gt;::type&gt;</code>
          </p>
          <p>
            <code> submit(FunctionType f) {</code>
          </p>
          <p>
            <code>  typedef typename std::result_of&lt;FunctionType()&gt;::type</code>
          </p>
          <p>
            <code>   result_type;</code>
          </p>
          <empty-line/>
          <p>
            <code>  std::packaged_task&lt;result_type()&gt; task(f);</code>
          </p>
          <p>
            <code>  std::future&lt;result_type&gt; res(task.get_future());</code>
          </p>
          <p>
            <code>  if (local_work_queue) { &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>   local_work_queue-&gt;push(std::move(task));</code>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   pool_work_queue.push(std::move(task)); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void run_pending_task() {</code>
          </p>
          <p>
            <code>  function_wrapper task;</code>
          </p>
          <p>
            <code>  if (local_work_queue &amp;&amp; !local_work_queue-&gt;empty()) {&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>   task = std::move(local_work_queue-&gt;front());</code>
          </p>
          <p>
            <code>   local_work_queue-&gt;pop();</code>
          </p>
          <p>
            <code>   task();</code>
          </p>
          <p>
            <code>  } else if(pool_work_queue.try_pop(task)) { &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>   task();</code>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   std::this_thread::yield();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> // остальное, как и раньше</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Для хранения очереди работ в поточно-локальной памяти мы воспользовались указателем <code>std::unique_ptr&lt;&gt;</code> <strong>(2)</strong>, потому что не хотим, чтобы у потоков, не входящих в пул, была очередь; этот указатель инициализируется в функции <code>worker_thread()</code> до начала цикла обработки <strong>(3)</strong>. Деструктор <code>std::unique_ptr&lt;&gt;</code> позаботится об уничтожении очереди работ по завершении потока.</p>
          <p>Затем функция <code>submit()</code> проверяет, есть ли у текущего потока очередь работ <strong>(4)</strong>. Если есть, то это поток из пула, и мы можем поместить задачу в локальную очередь. В противном случае задачу следует помещать в очередь пула, как и раньше <strong>(5)</strong>.</p>
          <p>Аналогичная проверка имеется в функции <code>run_pending_task()</code> <strong>(6)</strong>, только на этот раз нужно еще проверить, есть ли что-нибудь в локальной очереди. Если есть, то можно извлечь элемент из начала очереди и обработать его. Обратите внимание, что локальная очередь может быть обычным объектом <code>std::queue&lt;&gt;</code> <strong>(1)</strong>, так как к ней обращается только один поток. Если в локальной очереди задач нет, то мы проверяем очередь пула, как и раньше <strong>(7)</strong>.</p>
          <p>Таким образом мы действительно уменьшаем конкуренцию, но если распределение работ неравномерно, то может случиться, что в очереди одного потока скопится много задач, тогда как остальным будет нечем заняться. Например, в случае Quicksort только самый первый блок попадает в очередь пула, а остальные окажутся в локальной очереди того потока, который этот блок обработал. Это сводит на нет всю идею пула потоков.</p>
          <p>К счастью, у этой проблемы есть решение: позволить потоку <emphasis>занимать</emphasis> (steal) работы из очередей других потоков, если ни в его собственной, ни в глобальной очереди ничего нет.</p>
        </section>
        <section>
          <title>
            <p>9.1.5. Занимание работ</p>
          </title>
          <p>Если мы хотим, чтобы «безработный» поток мог брать работы из очереди другого потока, то эта очередь должна быть доступна занимающему потоку в <code>run_pending_tasks()</code>. Для этого каждый поток должен зарегистрировать свою очередь в пуле или получать очередь от пула. Кроме того, необходимо позаботиться о надлежащей синхронизации и защите очереди работ, чтобы не нарушались инварианты.</p>
          <p>Можно написать свободную от блокировок очередь, которая позволит потоку-владельцу помещать и извлекать элементы с одного конца, а другим потокам — занимать элементы с другого конца, однако реализация такой очереди выходит за рамки данной книги. Чтобы продемонстрировать идею, мы поступим проще — воспользуемся мьютексом для защиты данных очереди. Мы надеемся, что занимание работ — редкое событие, поэтому конкуренция за мьютекс будет невелика, и накладные расходы на такую очередь окажутся минимальны. Ниже приведена простая реализация с блокировками.</p>
          <empty-line/>
          <p><strong>Листинг 9.7.</strong> Очередь с блокировкой, допускающей занимание работ</p>
          <p>
            <code>class work_stealing_queue {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> typedef function_wrapper data_type;</code>
          </p>
          <p>
            <code> std::deque&lt;data_type&gt; the_queue; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> mutable std::mutex the_mutex;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> work_stealing_queue() {}</code>
          </p>
          <p>
            <code> work_stealing_queue(const work_stealing_queue&amp; other)=delete;</code>
          </p>
          <p>
            <code> work_stealing_queue&amp; operator=(</code>
          </p>
          <p>
            <code>  const work_stealing_queue&amp; other)=delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> void push(data_type data) { &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(the_mutex);</code>
          </p>
          <p>
            <code>  the_queue.push_front(std::move(data));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool empty() const {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(the_mutex);</code>
          </p>
          <p>
            <code>  return the_queue.empty();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool try_pop(data_type&amp; res) { &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(the_mutex);</code>
          </p>
          <p>
            <code>  if (the_queue.empty()) {</code>
          </p>
          <p>
            <code>   return false;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  res = std::move(the_queue.front());</code>
          </p>
          <p>
            <code>  the_queue.pop_front();</code>
          </p>
          <p>
            <code>  return true;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool try_steal(data_type&amp; res) { &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lock(the_mutex);</code>
          </p>
          <p>
            <code>  if (the_queue.empty()) {</code>
          </p>
          <p>
            <code>   return false;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  res = std::move(the_queue.back());</code>
          </p>
          <p>
            <code>  the_queue.pop_back();</code>
          </p>
          <p>
            <code>  return true;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Этот класс является простой оберткой вокруг <code>std::deque&lt;function_wrapper&gt;</code> <strong>(1)</strong>, которая защищает все операции доступа к очереди с помощью мьютекса. Функции <code>push()</code> <strong>(2)</strong> и <code>try_ pop()</code> <strong>(3)</strong> работают с началом очереди, а функция <code>try_steal()</code> — с концом <strong>(4)</strong>.</p>
          <p>Получается, что эта «очередь» для потока-владельца на самом деле является стеком, обслуживаемым согласно дисциплине «последним пришёл, первым обслужен», — задача, которая была помещена последней, извлекается первой. С точки зрения кэш-памяти это даже может повысить производительность, так как относящиеся к последней задаче данные с большей вероятностью окажутся в кэше, чем данные, относящиеся к предыдущей задаче. К тому же, такая дисциплина прекрасно подходит для алгоритмов типа Quicksort. В предшествующих реализациях каждое обращение к <code>do_sort()</code> помещает элемент в очередь, а затем ждет его. Обрабатывая последний помещенный в очередь элемент первым, мы гарантируем, что блок, необходимый текущему вызову для завершения работы, будет обработан раньше блоков, нужных другим ветвям, а, значит, уменьшается как количество активных задач, так и занятый размер стека. Функция <code>try_steal()</code> извлекает элементы из противоположного по сравнению с <code>try_pop()</code> конца очереди, чтобы минимизировать конкуренцию; в принципе, можно было бы применить технику, обсуждавшуюся в главах 6 и 7, чтобы поддержать одновременные обращения к <code>try_pop()</code> и <code>try_steal()</code>.</p>
          <p>Итак, теперь у нас есть замечательная очередь работ, допускающая занимание. Но как воспользоваться ей в пуле потоков? Ниже приведена одна из возможных реализаций.</p>
          <empty-line/>
          <p><strong>Листинг 9.8.</strong> Пул потоков с использованием занимания работ</p>
          <p>
            <code>class thread_pool {</code>
          </p>
          <p>
            <code> typedef function_wrapper task_type;</code>
          </p>
          <empty-line/>
          <p>
            <code> std::atomic_bool done;</code>
          </p>
          <p>
            <code> thread_safe_queue&lt;task_type&gt; pool_work_queue;</code>
          </p>
          <p>
            <code> std::vector&lt;std::unique_ptr&lt;work_stealing_queue&gt; &gt; queues;&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> std::vector&lt;std::thread&gt; threads;</code>
          </p>
          <p>
            <code> join_threads joiner;</code>
          </p>
          <empty-line/>
          <p>
            <code> static thread_local work_stealing_queue* local_work_queue;&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> static thread_local unsigned my_index;</code>
          </p>
          <empty-line/>
          <p>
            <code> void worker_thread(unsigned my_index_) {</code>
          </p>
          <p>
            <code>  my_index = my_index_;</code>
          </p>
          <p>
            <code>  local_work_queue = queues[my_index].get(); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  while (!done) {</code>
          </p>
          <p>
            <code>   run_pending_task();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool pop_task_from_local_queue(task_type&amp; task) {</code>
          </p>
          <p>
            <code>  return local_work_queue &amp;&amp; local_work_queue-&gt;try_pop(task);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool pop_task_from_pool_queue(task_type&amp; task) {</code>
          </p>
          <p>
            <code>  return pool_work_queue.try_pop(task);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool pop_task_from_other_thread_queue(task_type&amp; task) { &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  for (unsigned i = 0; i &lt; queues.size(); ++i) {</code>
          </p>
          <p>
            <code>   unsigned const index = (my_index + i + 1) % queues.size();&#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>   if (queues[index]-&gt;try_steal(task)) {</code>
          </p>
          <p>
            <code>    return true;</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <empty-line/>
          <p>
            <code>  return false;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> thread_pool() :</code>
          </p>
          <p>
            <code>  done(false), joiner(threads) {</code>
          </p>
          <p>
            <code>  unsigned const thread_count =</code>
          </p>
          <p>
            <code>   std::thread::hardware_concurrency();</code>
          </p>
          <p>
            <code>  try {</code>
          </p>
          <p>
            <code>   for (unsigned i = 0; i &lt; thread_count; ++i) {</code>
          </p>
          <p>
            <code>    queues.push_back(std::unique_ptr&lt;work_stealing_queue&gt; (&#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>     new work_stealing_queue));</code>
          </p>
          <p>
            <code>    threads.push_back(</code>
          </p>
          <p>
            <code>     std::thread(&amp;thread_pool::worker_thread, this, i));</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  } catch (...) {</code>
          </p>
          <p>
            <code>   done = true;</code>
          </p>
          <p>
            <code>   throw;</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> ~thread_pool() {</code>
          </p>
          <p>
            <code>  done = true;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename FunctionType&gt;</code>
          </p>
          <p>
            <code> std::future&lt;typename std::result_of&lt;FunctionType()&gt;::type&gt; submit(</code>
          </p>
          <p>
            <code>  FunctionType f) {</code>
          </p>
          <p>
            <code>  typedef typename std::result_of&lt;FunctionType()&gt;::type</code>
          </p>
          <p>
            <code>   result_type;</code>
          </p>
          <empty-line/>
          <p>
            <code>  std::packaged_task&lt;result_type()&gt; task(f);</code>
          </p>
          <p>
            <code>  std::future&lt;result_type&gt; res(task.get_future());</code>
          </p>
          <p>
            <code>  if (local_work_queue) {</code>
          </p>
          <p>
            <code>   local_work_queue-&gt;push(std::move(task));</code>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   pool_work_queue.push(std::move(task));</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code>  return res;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void run_pending_task() {</code>
          </p>
          <p>
            <code>  task_type task;</code>
          </p>
          <p>
            <code>  if (pop_task_from_local_queue(task) || &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>      pop_task_from_pool_queue (task) || &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>      pop_task_from_other_thread_queue(task)) { &#8592;</code>
            <strong>(9)</strong>
          </p>
          <p>
            <code>   task();</code>
          </p>
          <p>
            <code>  } else {</code>
          </p>
          <p>
            <code>   std::this_thread::yield();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Этот код очень похож на код из листинга 9.6. Первое отличие состоит в том, что локальная очередь каждого потока — объект класса <code>work_stealing_queue</code>, а не просто <code>std::queue&lt;&gt;</code> <strong>(2)</strong>. Новый поток не выделяет очередь для себя самостоятельно; это делает конструктор пула потоков <strong>(6)</strong>, и он же сохраняет новую очередь в списке очередей для данного пула <strong>(1)</strong>. Индекс очереди в списке передаётся функции потока и используется затем для получения указателя на очередь <strong>(3)</strong>. Это означает, что пул потоков может получить доступ к очереди, когда пытается занять задачу для потока, которому нечего делать. Новая версия <code>run_pending_task()</code> сначала пытается получить задачу из очереди исполняемого потока <strong>(7)</strong>, затем из очереди пула <strong>(8)</strong> и, наконец, из очереди другого потока <strong>(9)</strong>.</p>
          <p>Функция <code>pop_task_from_other_thread_queue()</code> <strong>(4)</strong> обходит очереди, принадлежащие всем потокам пула, пытаясь занять задачу у каждой. Чтобы не случилось так, что все потоки занимают задачи у первого потока в списке, каждый поток начинает просмотр с позиции, равной его собственному индексу <strong>(5)</strong>.</p>
          <p>Теперь у нас имеется пул потоков, пригодный для самых разных целей. Разумеется, есть масса способов улучшить его для работы в конкретной ситуации, но это я оставляю в качестве упражнения для читателя. В частности, мы совсем не исследовали идею динамического изменения размера пула, так чтобы обеспечить оптимальное использование процессоров, даже когда потоки блокированы в ожидании какого-то события, например, завершения ввода/вывода или освобождения мьютекса.</p>
          <p>Следующим в нашем списке «продвинутых» приёмов управления потоками стоит прерывание потоков.</p>
        </section>
      </section>
      <section>
        <title>
          <p>9.2. Прерывание потоков</p>
        </title>
        <section>
          <p>Часто бывает необходимо сообщить долго работающему потоку о том, что пришло время остановиться. Например, потому что это рабочий поток пула, а мы собираемся уничтожить сам пул, или потому что пользователь отменил работу, выполняемую этим потоком. Причин миллион. Но идея в любом случае одна и та же: послать из одного потока другому сигнал с требованием прекратить работу до ее естественного завершения, и сделать это так, чтобы поток завершился корректно, а не просто выбить почву у него из-под ног.</p>
          <p>Можно было бы придумывать такой механизм специально для каждого случая, но это, пожалуй, перебор. Мало того что общий механизм в дальнейшем упростит написание кода, так он еще и позволит писать код, допускающий прерывание, не заботясь о том, где конкретно он используется. Стандарт C++11 такого механизма не предоставляет, но реализовать его самостоятельно не слишком сложно. Я покажу, как это сделать, но сначала взгляну на проблему с точки зрения интерфейса запуска и прерывания потока, а не с точки зрения самого прерываемого потока.</p>
        </section>
        <section>
          <title>
            <p>9.2.1. Запуск и прерывание другого потока</p>
          </title>
          <p>Начнем с рассмотрения внешнего интерфейса. Что нам нужно от допускающего прерывание потока? На самом элементарном уровне интерфейс должен быть таким же, как у <code>std::thread</code>, но с дополнительной функцией <code>interrupt()</code>:</p>
          <p>
            <code>class interruptible_thread {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> template&lt;typename FunctionType&gt;</code>
          </p>
          <p>
            <code> interruptible_thread(FunctionType f);</code>
          </p>
          <p>
            <code> void join();</code>
          </p>
          <p>
            <code> void detach();</code>
          </p>
          <p>
            <code> bool joinable() const;</code>
          </p>
          <p>
            <code> void interrupt();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В реализации можно было бы использовать <code>std::thread</code> для управления потоком и какую-то структуру данных для обработки прерывания. А как это выглядит с точки зрения самого потока? Как минимум, нужна возможность сказать: «Меня можно прерывать здесь», то есть нам требуется <emphasis>точка прерывания</emphasis>. Чтобы не передавать дополнительные данные, соответствующая функция должна вызываться без параметров: <code>interruption_point()</code>. Отсюда следует, что относящаяся к прерываниям структура данных должна быть доступна через переменную типа <code>thread_local</code>, которая устанавливается при запуске потока. Поэтому, когда поток обращается к функции <code>interruption_point()</code>, та проверяет структуру данных для текущего исполняемого потока. С реализацией <code>interruption_point()</code> мы познакомимся ниже.</p>
          <p>Флаг типа <code>thread_local</code> — основная причина, по которой мы не можем использовать для управления потоком просто класс <code>std::thread</code>; память для него нужно выделить таким образом, чтобы к ней имел доступ как экземпляр <code>interruptible_thread</code>, так и вновь запущенный поток. Для этого функцию, переданную конструктору, можно специальным образом обернуть перед тем, как передавать конструктору <code>std::thread</code>. Как это делается, показано в следующем листинге.</p>
          <empty-line/>
          <p><strong>Листинг 9.9.</strong> Простая реализация <code>interruptible_thread</code></p>
          <p>
            <code>class interrupt_flag {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> void set();</code>
          </p>
          <p>
            <code> bool is_set() const;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>thread_local interrupt_flag this_thread_interrupt_flag; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code>class interruptible_thread {</code>
          </p>
          <p>
            <code> std::thread internal_thread;</code>
          </p>
          <p>
            <code> interrupt_flag* flag;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> template&lt;typename FunctionType&gt;</code>
          </p>
          <p>
            <code> interruptible_thread(FunctionType f) {</code>
          </p>
          <p>
            <code>  std::promise&lt;interrupt_flag*&gt; p; &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  internal_thread = std::thread([f,&amp;p] { &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>   p.set_value(&amp;this_thread_interrupt_flag);</code>
          </p>
          <p>
            <code>   f(); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>  });</code>
          </p>
          <p>
            <code>  flag = p.get_future().get(); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void interrupt() {</code>
          </p>
          <p>
            <code>  if (flag) {</code>
          </p>
          <p>
            <code>   flag-&gt;set(); &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Переданная функция <code>f</code> обертывается лямбда-функцией <strong>(3)</strong>, которая хранит копию <code>f</code> и ссылку на локальный объект-обещание <code>p</code> <strong>(2)</strong>. Перед тем как вызывать переданную функцию <strong>(4)</strong>, лямбда-функция устанавливает в качестве значения обещания адрес переменной <code>this_thread_interrupt_flag</code> (объявленной с модификатором <code>thread_local</code> <strong>(1)</strong>) в новом потоке. Затем вызывающий поток дожидается готовности будущего результата, ассоциированного с обещанием, и сохраняет этот результат в переменной-члене <code>flag</code> <strong>(5)</strong>. Отметим, что лямбда-функция исполняется в новом потоке и хранит висячую ссылку на локальную переменную <code>p</code>, но ничего страшного в этом нет, так как конструктор <code>interruptible_thread</code> ждет, пока на <code>p</code> не останется ссылок в новом потоке, и только потом возвращает управление. Еще отметим, что эта реализация не обрабатывает присоединение или отсоединение потока. Мы сами должны позаботиться об очистке переменной <code>flag</code> в случае выхода или отсоединения потока, чтобы избежать появления висячего указателя.</p>
          <p>Теперь написать функцию <code>interrupt()</code> несложно: имея указатель на флаг прерывания, мы знаем, какой поток прерывать, поэтому достаточно просто поднять этот флаг <strong>(6)</strong>. Что делать дальше, решает сам прерываемый поток. О том, как принимается это решение, мы и поговорим ниже.</p>
        </section>
        <section>
          <title>
            <p>9.2.2. Обнаружение факта прерывания потока</p>
          </title>
          <p>Итак, мы умеем устанавливать флаг прерывания, но толку от него чуть, если поток не проверяет, что его хотят прервать. В простейшем случае это можно сделать с помощью функции <code>interruption_point()</code>, которую можно вызывать в точке, где прерывание безопасно. Если флаг прерывания установлен, то эта функция возбуждает исключение <code>thread_interrupted</code>:</p>
          <p>
            <code>void interruption_point() {</code>
          </p>
          <p>
            <code> if (this_thread_interrupt_flag.is_set()) {</code>
          </p>
          <p>
            <code>  throw thread_interrupted();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Обращаться к этой функции можно там, где нам удобно:</p>
          <p>
            <code>void fоо() {</code>
          </p>
          <p>
            <code> while (!done) {</code>
          </p>
          <p>
            <code>  interruption_point();</code>
          </p>
          <p>
            <code>  process_next_item();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Такое решение работает, но оно не идеально. Лучше всего прерывать поток тогда, когда он блокирован в ожидании чего-либо, но именно в этот момент поток как раз и не работает, а, значит, не может вызвать <code>interruption_point()</code>! Нам требуется какой-то механизм прерываемого ожидания.</p>
        </section>
        <section>
          <title>
            <p>9.2.3. Прерывание ожидания условной переменной</p>
          </title>
          <p>Итак, мы можем обнаруживать прерывание в подходящих местах программы с помощью обращений к функции <code>interruption_point()</code>, но это ничем не помогает в случае, когда поток блокирован в ожидании какого-то события, например сигнала условной переменной. Нам необходима еще одна функция, <code>interruptible_wait()</code>, которую можно будет перегрузить для различных ожидаемых событий, и нужно придумать, как вообще прерывать ожидание. Я уже говорил, что среди прочего ожидать можно сигнала условной переменной, поэтому с нее и начнем. Что необходимо для того, чтобы можно было прервать поток, ожидающий условную переменную? Проще всего было бы известить условную переменную в момент установки флага и поставить точку прерывания сразу после ожидания. Но в этом случае придётся разбудить все потоки, ждущие эту условную переменную, хотя заинтересован в этом только прерываемый поток. Впрочем, потоки, ждущие условную переменную, в любом случае должны обрабатывать ложные пробуждения, а отличить посланный нами сигнал от любого другого они не могут, так что ничего страшного не случится. В структуре <code>interrupt_flag</code> нужно будет сохранить указатель на условную переменную, чтобы при вызове <code>set()</code> ей можно было послать сигнал. В следующем листинге показана возможная реализация функции <code>interruptible_wait()</code> для условных переменных.</p>
          <empty-line/>
          <p><strong>Листинг 9.10.</strong> Неправильная реализация <code>interruptible_wait()</code> для <code>std::condition_variable</code></p>
          <p>
            <code>void interruptible_wait(std::condition_variable&amp; cv,</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt;&amp; lk) {</code>
          </p>
          <p>
            <code> interruption_point();&#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> this_thread_interrupt_flag.set_condition_variable(cv);</code>
          </p>
          <p>
            <code> cv.wait(lk);         &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> this_thread_interrupt_flag.clear_condition_variable();&#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> interruption_point();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В предположении, что существуют функции, которые устанавливают и разрывают ассоциацию условной переменной с флагом прерывания, этот код выглядит просто и понятно. Он проверяет, не было ли прерывания, ассоциирует условную переменную с флагом <code>interrupt_flag</code> для текущего потока <strong>(1)</strong>, ждет условную переменную <strong>(2)</strong>, разрывает ассоциацию с условной переменной <strong>(3)</strong> и снова проверяет, не было ли прерывания. Если поток прерывается во время ожидания условной переменной, то прерывающий поток пошлёт этой переменной сигнал, что пробудит нас и даст возможность проверить факт. К сожалению, этот код не работает, в нем есть две проблемы. Первая довольно очевидна: функция <code>std::condition_variable::wait()</code> может возбуждать исключения, поэтому из <code>interruptible_wait()</code> возможен выход без разрыва ассоциации флага прерывания с условной переменной. Это легко исправляется с помощью структуры, которая разрывает ассоциацию в ее деструкторе.</p>
          <p>Вторая, не столь очевидная, проблема связана с гонкой. Если поток прерывается после первого обращения к <code>interruption_point()</code>, но до обращения к <code>wait()</code>, то не имеет значения, ассоциирована условная переменная с флагом прерывания или нет, потому что <emphasis>поток еще ничего не ждет и, следовательно, не может быть разбужен сигналом, посланным условной переменной</emphasis>. Мы должны гарантировать, что потоку не может быть послан сигнал между последней проверкой прерывания и обращением к <code>wait()</code>. Если не залезать в код класса <code>std::condition_variable</code>, то сделать это можно только одним способом: использовать для защиты мьютекс, хранящийся в <code>lk</code>, который, следовательно, нужно передавать функции <code>set_condition_variable()</code>. К сожалению, при этом возникают новые проблемы: мы передаём ссылку на мьютекс, о времени жизни которого ничего не знаем, другому потоку (тому, который выполняет прерывание), чтобы тот его захватил (внутри <code>interrupt()</code>). Но может случиться, что этот поток уже удерживает данный мьютекс, и тогда возникнет взаимоблокировка. К тому же, появляется возможность доступа к уже уничтоженному мьютексу. В общем, это решение не годится. Но если мы не можем <emphasis>надежно</emphasis> прерывать ожидание условной переменной, то нечего было и затевать это дело — почти того же самого можно было бы добиться и без специальной функции <code>interruptible_wait()</code>. Так какие еще есть варианты? Можно, к примеру, задать таймаут ожидания; использовать вместо <code>wait()</code> функцию <code>wait_for()</code> с очень коротким таймаутом (скажем, 1 мс). Это ограничивает сверху время до момента, когда поток обнаружит прерывание (с учетом промежутка между тактами часов). Если поступить так, что ожидающий поток будет видеть больше ложных пробуждений из-за срабатывания таймера, но тут уж ничего не попишешь. Такая реализация показана в листинге ниже вместе с соответствующей реализацией <code>interrupt_flag</code>.</p>
          <empty-line/>
          <p><strong>Листинг 9.11.</strong> Реализация <code>interruptible_wait()</code> для <code>std::condition_variable</code> с таймаутом</p>
          <p>
            <code>class interrupt_flag {</code>
          </p>
          <p>
            <code> std::atomic&lt;bool&gt; flag;</code>
          </p>
          <p>
            <code> std::condition_variable* thread_cond;</code>
          </p>
          <p>
            <code> std::mutex set_clear_mutex;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> interrupt_flag(): thread_cond(0) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void set() {</code>
          </p>
          <p>
            <code>  flag.store(true, std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(set_clear_mutex);</code>
          </p>
          <p>
            <code>  if (thread_cond) {</code>
          </p>
          <p>
            <code>   thread_cond-&gt;notify_all();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> bool is_set() const {</code>
          </p>
          <p>
            <code>  return flag.load(std::memory_order_relaxed);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void set_condition_variable(std::condition_variable&amp; cv) {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(set_clear_mutex);</code>
          </p>
          <p>
            <code>  thread_cond = &amp;cv;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> void clear_condition_variable() {</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(set_clear_mutex);</code>
          </p>
          <p>
            <code>  thread_cond = 0;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> struct clear_cv_on_destruct {</code>
          </p>
          <p>
            <code>  ~clear_cv_on_destruct() {</code>
          </p>
          <p>
            <code>   this_thread_interrupt_flag.clear_condition_variable();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> };</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>void interruptible_wait(std::condition_variable&amp; cv,</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt;&amp; lk) {</code>
          </p>
          <p>
            <code> interruption_point();</code>
          </p>
          <p>
            <code> this_thread_interrupt_flag.set_condition_variable(cv);</code>
          </p>
          <p>
            <code> interrupt_flag::clear_cv_on_destruct guard;</code>
          </p>
          <p>
            <code> interruption_point();</code>
          </p>
          <p>
            <code> cv.wait_for(lk, std::chrono::milliseconds(1));</code>
          </p>
          <p>
            <code> interruption_point();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Если мы ждем какой-то предикат, то таймаут продолжительностью 1 мс можно полностью скрыть внутри цикла проверки предиката:</p>
          <p>
            <code>template&lt;typename Predicate&gt;</code>
          </p>
          <p>
            <code>void interruptible_wait(std::condition_variable&amp; cv,</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt;&amp; lk,</code>
          </p>
          <p>
            <code> Predicate pred) {</code>
          </p>
          <p>
            <code> interruption_point();</code>
          </p>
          <p>
            <code> this_thread_interrupt_flag.set_condition_variable(cv);</code>
          </p>
          <p>
            <code> interrupt_flag::clear_cv_on_destruct guard;</code>
          </p>
          <p>
            <code> while (!this_thread_interrupt_flag.is_set() &amp;&amp; !pred()) {</code>
          </p>
          <p>
            <code>  cv.wait_for(lk, std::chrono::milliseconds(1));</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> interruption_point();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Правда, предикат при этом проверяется чаще, чем необходимо, но зато эту функцию легко использовать вместо простого вызова <code>wait()</code>. Легко реализовать и другие варианты функций с таймаутом, например: ждать в течение указанного времени или 1 мс в зависимости от того, что меньше.</p>
          <p>Ну хорошо, с ожиданием <code>std::condition_variable</code> мы разобрались, а что сказать о <code>std::condition_variable_any</code>? Всё точно так же или можно сделать лучше?</p>
        </section>
        <section>
          <title>
            <p>9.2.4. Прерывание ожидания <code>std::condition_variable_any</code></p>
          </title>
          <p>Класс <code>std::condition_variable_any</code> отличается от <code>std::condition_variable</code> тем, что работает с <emphasis>любым</emphasis> типом блокировки, а не только с <code>std::unique_lock&lt;std::mutex&gt;</code>. Как выясняется, это сильно упрощает дело, так что мы сможем добиться более впечатляющих результатов, чем получилось с <code>std::condition_variable</code>. Раз допустим <emphasis>любой</emphasis> тип блокировки, то можно написать и свой собственный класс, который захватывает (освобождает) как внутренний мьютекс <code>set_clear_mutex</code> в классе <code>interrupt_flag</code>, так и блокировку, переданную при вызове <code>wait()</code>. Соответствующий код приведён в листинге ниже.</p>
          <empty-line/>
          <p><strong>Листинг 9.12.</strong> Реализация <code>interruptible_wait()</code> для <code>std::condition_variable_any</code></p>
          <p>
            <code>class interrupt_flag {</code>
          </p>
          <p>
            <code> std::atomic&lt;bool&gt; flag;</code>
          </p>
          <p>
            <code> std::condition_variable* thread_cond;</code>
          </p>
          <p>
            <code> std::condition_variable_any* thread_cond_any;</code>
          </p>
          <p>
            <code> std::mutex set_clear_mutex;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> interrupt_flag():</code>
          </p>
          <p>
            <code>  thread_cond(0), thread_cond_any(0) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> void set() {</code>
          </p>
          <p>
            <code>  flag.store(true, std::memory_order_relaxed);</code>
          </p>
          <p>
            <code>  std::lock_guard&lt;std::mutex&gt; lk(set_clear_mutex);</code>
          </p>
          <p>
            <code>  if (thread_cond) {</code>
          </p>
          <p>
            <code>   thread_cond-&gt;notify_all();</code>
          </p>
          <p>
            <code>  } else if (thread_cond_any) {</code>
          </p>
          <p>
            <code>   thread_cond_any-&gt;notify_all();</code>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Lockable&gt;</code>
          </p>
          <p>
            <code> void wait(std::condition_variable_any&amp; cv, Lockable&amp; lk) {</code>
          </p>
          <p>
            <code>  struct custom_lock {</code>
          </p>
          <p>
            <code>   interrupt_flag* self;</code>
          </p>
          <p>
            <code>   Lockable&amp; lk;</code>
          </p>
          <empty-line/>
          <p>
            <code>   custom_lock(interrupt_flag* self_,</code>
          </p>
          <p>
            <code>    std::condition_variable_any&amp; cond,</code>
          </p>
          <p>
            <code>    Lockable&amp; lk_): self(self_), lk(lk_) {</code>
          </p>
          <p>
            <code>    self-&gt;set_clear_mutex.lock();  &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>    self-&gt;thread_cond_any = &amp;cond; &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <empty-line/>
          <p>
            <code>   void unlock() { &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>    lk.unlock();</code>
          </p>
          <p>
            <code>    self-&gt;set_clear_mutex.unlock();</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <empty-line/>
          <p>
            <code>   void lock() {</code>
          </p>
          <p>
            <code>    std::lock(self-&gt;set_clear_mutex, lk); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code>   }</code>
          </p>
          <empty-line/>
          <p>
            <code>   ~custom_lock() {</code>
          </p>
          <p>
            <code>    self-&gt;thread_cond_any = 0; &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>    self-&gt;set_clear_mutex.unlock();</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  };</code>
          </p>
          <empty-line/>
          <p>
            <code>  custom_lock cl(this, cv, lk);</code>
          </p>
          <p>
            <code>  interruption_point();</code>
          </p>
          <p>
            <code>  cv.wait(cl);</code>
          </p>
          <p>
            <code>  interruption_point();</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> // остальное, как и раньше</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Lockable&gt;</code>
          </p>
          <p>
            <code>void interruptible_wait(std::condition_variable_any&amp; cv,</code>
          </p>
          <p>
            <code> Lockable&amp; lk) {</code>
          </p>
          <p>
            <code> this_thread_interrupt_flag.wait(cv, lk);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Наш класс блокировки должен захватить внутренний мьютекс <code>set_clear_mutex</code> на этапе конструирования <strong>(1)</strong> и затем записать в переменную <code>thread_cond_any</code> указатель на объект <code>std::condition_variable_any</code>, переданный конструктору <strong>(2)</strong>. Ссылка на объект <code>Lockable</code> сохраняется для последующего использования; он должен быть уже заблокирован. Теперь проверять, был ли поток прерван, можно, не опасаясь гонки. Если в этой точке флаг прерывания установлен, то это было сделано до захвата мьютекса <code>set_clear_mutex</code>. Когда условная переменная вызывает нашу функцию <code>unlock()</code> внутри <code>wait()</code>, мы разблокируем объект <code>Lockable</code> <emphasis>и внутренний мьютекс</emphasis> <code>set_clear_mutex</code> <strong>(3)</strong>. Это позволяет потокам, которые пытаются нас прервать, захватить <code>set_clear_mutex</code> и проверить указатель <code>thread_cond_any</code>, <emphasis>когда мы уже находимся в</emphasis> <code>wait()</code>, но не раньше. Это именно то, чего мы хотели (но не смогли) добиться в случае <code>std::condition_variable</code>. После того как <code>wait()</code> завершит ожидание (из-за получения сигнала или вследствие ложного пробуждения), она вызовет нашу функцию <code>lock()</code>, которая снова захватит внутренний мьютекс <code>set_clear_mutex</code> и заблокирует объект <code>Lockable</code> <strong>(4)</strong>. Теперь можно еще раз проверить, не было ли прерываний, пока мы находились в <code>wait()</code>, и только потом обнулить указатель <code>thread_cond_any</code> в деструкторе <code>custom_lock</code> <strong>(5)</strong>, где также освобождается <code>set_clear_mutex</code>.</p>
        </section>
        <section>
          <title>
            <p>9.2.5. Прерывание других блокирующих вызовов</p>
          </title>
          <p>Теперь с прерыванием ожидания условной переменной всё ясно, но как быть с другими блокирующими операциями ожидания: освобождения мьютекса, готовности будущего результата и т.д.? Вообще говоря, приходится прибегать к тому же трюку с таймаутом, который мы использовали для <code>std::condition_variable</code>, потому что, если не влезать в код мьютекса или будущего результата, то нет никакого другого способа прервать ожидание, кроме как обеспечить выполнение ожидаемого условия. Но в отличие от условных переменных, мы точно знаем, чего ждем, поэтому можем организовать цикл внутри функции <code>interruptible_wait()</code>.</p>
          <p>Вот, например, как выглядит перегрузка <code>interruptible_wait()</code> для <code>std::future&lt;&gt;</code>:</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>void interruptible_wait(std::future&lt;T&gt;&amp; uf) {</code>
          </p>
          <p>
            <code> while (!this_thread_interrupt_flag.is_set()) {</code>
          </p>
          <p>
            <code>  if (uf.wait_for(lk, std::chrono::milliseconds(1) ==</code>
          </p>
          <p>
            <code>   std::future_status::ready)</code>
          </p>
          <p>
            <code>  break;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> interruption_point();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Здесь мы ждем, пока либо будет установлен флаг прерывания, либо готов будущий результат, но блокирующее ожидание будущего результата продолжается в течение 1 мс на каждой итерации цикла. Это означает, что в среднем запрос на прерывание будет обнаружен с задержкой 0,5 мс, в предположении, что разрешение часов достаточно высокое. Функция <code>wait_for</code> обычно ожидает в течение как минимум одного такта, поэтому если такт системных часов составляет 15 мс, то ждать придётся не одну, а 15 мс. Приемлемо это или нет, зависит от конкретных условий. Таймаут при необходимости можно уменьшить (если часы позволяют), но тогда поток будет чаще просыпаться для проверки флага, что увеличит накладные расходы на переключение задач.</p>
          <p>На данный момент мы знаем, как можно обнаружить прерывание с помощью функций <code>interruption_point()</code> и <code>interruptible_wait()</code>, но что с этим потом делать?</p>
        </section>
        <section>
          <title>
            <p>9.2.6. Обработка прерываний</p>
          </title>
          <p>С точки зрения прерываемого потока, прерывание — это просто исключение типа <code>thread_interrupted</code>, которое, следовательно, можно обработать, как любое другое исключение. В частности, его можно перехватить в стандартном блоке <code>catch</code>:</p>
          <p>
            <code>try {</code>
          </p>
          <p>
            <code> do_something();</code>
          </p>
          <p>
            <code>} catch (thread_interrupted&amp;) {</code>
          </p>
          <p>
            <code> handle_interruption();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Таким образом, прерывание можно перехватить, каким-то образом обработать и потом спокойно продолжить работу. Если мы так поступим, а потом другой поток еще раз вызовет <code>interrupt()</code>, то поток будет снова прерван, когда в очередной раз вызовет функцию <code>interruption_point()</code>. Возможно, это и неплохо, если вы выполняете последовательность независимых задач; текущая задача будет прервана, а поток благополучно перейдёт к следующей задаче в списке.</p>
          <p>Поскольку <code>thread_interrupted</code> — исключение, то при вызове кода, который может быть прерван, следует принимать все обычные для исключений меры предосторожности, чтобы не было утечки ресурсов, и структуры данных оставались согласованными. Часто желательно завершать поток в случае прерывания, так чтобы исключение можно было просто передать вызывающей функции. Но если позволить исключению выйти за пределы функции потока, переданной конструктору <code>std::thread</code>, то будет вызвана функция <code>std::terminate()</code>, что приведёт к завершению всей программы. Чтобы не помещать обработчик <code>catch(thread_interrupted)</code> в каждую функцию, которая передаётся <code>interruptible_thread</code>, можно включить блок <code>catch</code> в обертку, служащую для инициализации <code>interrupt_flag</code>. Тогда распространять необработанное исключение будет безопасно, так как завершится лишь отдельный поток. Инициализация потока в конструкторе <code>interruptible_thread</code> при таком подходе выглядит следующим образом:</p>
          <p>
            <code>internal_thread = std::thread([f, &amp;p] {</code>
          </p>
          <p>
            <code> p.set_value(&amp;this_thread_interrupt_flag);</code>
          </p>
          <p>
            <code>
              <strong>  try {</strong>
            </code>
          </p>
          <p>
            <code>  f();</code>
          </p>
          <p>
            <code>
              <strong> } catch(thread_interrupted const&amp;) {}</strong>
            </code>
          </p>
          <p>
            <code>});</code>
          </p>
          <p>А теперь рассмотрим конкретный пример, когда прерывание оказывается полезно.</p>
        </section>
        <section>
          <title>
            <p>9.2.7. Прерывание фоновых потоков при выходе из приложения</p>
          </title>
          <p>Представьте себе приложение для поиска в файловой системе настольного ПК. Оно должно не только взаимодействовать с пользователем, но и следить за состоянием файловой системы, обнаруживать изменения и обновлять свой индекс. Обычно такие операции поручаются фоновому потоку, чтобы пользовательский интерфейс мог реагировать на действия пользователя. Фоновый поток должен работать на протяжении всего времени жизни приложения; он запускается на этапе инициализации и трудится, пока приложение не завершится. Обычно это происходит при останове операционной системы, так как приложение должно постоянно поддерживать индекс в актуальном состоянии. Как бы то ни было, когда приложение завершается, надо аккуратно остановить и фоновые потоки, например, прервав их.</p>
          <p>В следующем листинге показана возможная реализация управления потоками в такой программе.</p>
          <empty-line/>
          <p><strong>Листинг 9.13.</strong> Фоновый мониторинг файловой системы</p>
          <p>
            <code>std::mutex config_mutex;</code>
          </p>
          <p>
            <code>std::vector&lt;interruptible_thread&gt; background_threads;</code>
          </p>
          <empty-line/>
          <p>
            <code>void background_thread(int disk_id) {</code>
          </p>
          <p>
            <code> while (true) {</code>
          </p>
          <p>
            <code>  interruption_point(); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  fs_change fsc = get_fs_changes(disk_id); &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  if (fsc.has_changes()) {</code>
          </p>
          <p>
            <code>   update_index(fsc); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code>  }</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>void start_background_processing() {</code>
          </p>
          <p>
            <code> background_threads.push_back(</code>
          </p>
          <p>
            <code>  interruptible_thread(background_thread, disk_1));</code>
          </p>
          <p>
            <code> background_threads.push_back(</code>
          </p>
          <p>
            <code>  interruptible_thread(background_thread, disk_2));</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> start_background_processing(); &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> process_gui_until_exit(); &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt; lk(config_mutex);</code>
          </p>
          <p>
            <code> for (unsigned i = 0; i &lt; background_threads.size(); ++i) {</code>
          </p>
          <p>
            <code>  background_threads[i].interrupt(); &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code> for (unsigned i = 0; i &lt; background_threads.size(); ++i) {</code>
          </p>
          <p>
            <code>  background_threads[i].join(); &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>В самом начале запускаются фоновые потоки <strong>(4)</strong>. Затем главный поток продолжает обслуживать пользовательский интерфейс <strong>(5)</strong>. Когда пользователь хочет выйти из приложения, фоновые потоки прерываются <strong>(6)</strong>, после чего главный поток ждет их завершения <strong>(7)</strong>, и только потом выходит сам. Каждый фоновый поток исполняет цикл, в котором следит за изменениями на диске <strong>(2)</strong> и обновляет индекс <strong>(3)</strong>. На каждой итерации цикла поток проверяет, не прервали ли его, вызывая функцию <code>interruption_point()</code> <strong>(1)</strong>.</p>
          <p>Почему мы прерываем все потоки до того, как начинать ждать их завершения? Почем нельзя прервать один поток, дождаться его, потом прервать следующий и так далее? Все из-за <emphasis>параллелизма</emphasis>. Поток не завершается сразу после прерывания, так как должен добраться до очередной точки прерывания, а затем, перед выходом, выполнить все деструкторы и код обработки исключений. Если главный поток будет присоединять прерванные потоки сразу после прерывания, то ему придётся ждать, <emphasis>хотя в это время он мог бы делать полезную работу</emphasis> — прерывать другие потоки. Поэтому мы поступаем по-другому — начинаем ждать только тогда, когда больше никакой работы не осталось (все потоки уже прерваны). Заодно это позволяет прерываемым потокам обрабатывать прерывания параллельно, так что общее время завершения, возможно, уменьшится.</p>
          <p>Описанный механизм прерывания легко развить, добавив дополнительные прерываемые вызовы или запретив прерывания на определенном участке кода, но это я оставляю читателю в качестве упражнения.</p>
        </section>
      </section>
      <section>
        <title>
          <p>9.3. Резюме</p>
        </title>
        <p>В этой главе мы рассмотрели «продвинутые» способы управления потоками: пулы и прерывание потоков. Мы видели, как использование локальных очередей работ и занимания работ может снизить накладные расходы на синхронизацию и потенциально увеличить пропускную способность пула потоков. Кроме того, мы поняли, что выполнение других выбранных из очереди задач во время ожидания завершения подзадачи устраняет возможность взаимоблокировки.</p>
        <p>Мы также познакомились с различными способами прерывания одного потока другим, в частности, с точками прерывания и функциями, которые допускают прерывание во время блокирующего ожидания.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Глава 10.</p>
        <p>Тестирование и отладка многопоточных приложений</p>
      </title>
      <annotation>
        <subtitle>В этой главе:</subtitle>
        <p>&#9632; Ошибки, связанные с параллелизмом.</p>
        <p>&#9632; Поиск ошибок путем тестирования и анализа кода коллегами.</p>
        <p>&#9632; Разработка тестов для многопоточных приложений.</p>
        <p>&#9632; Тестирование производительности многопоточных приложений.</p>
      </annotation>
      <section>
        <p>До сих пор мы занимались главным образом написанием параллельного кода — описанием имеющихся средств и порядка пользования ими и изучением общей структуры кода. Но у разработки ПО есть не менее важная сторона, о которой я еще не упоминал: тестирование и отладка. Если вы надеетесь найти в этой главе простой рецепт тестирования параллельного кода, то будете жестоко разочарованы. Тестировать и отлаживать параллельные программы <emphasis>трудно</emphasis>. Но я все же расскажу о некоторых приёмах, облегчающих эту задачу, а также сформулирую вопросы, над которыми стоит задуматься.</p>
        <p>Тестирование и отладка — две стороны одной медали. Вы прогоняете тесты, чтобы найти в программе ошибки, и отлаживаетесь, чтобы эти ошибки устранить. Если повезёт, то придётся устранять только ошибки, найденные вашими собственными тестами, а не конечными пользователями. Но прежде чем приступать непосредственно к вопросам тестирования и отладки, важно понять, какие вообще могут возникать проблемы.</p>
      </section>
      <section>
        <title>
          <p>10.1. Типы ошибок, связанных с параллелизмом</p>
        </title>
        <section>
          <p>В параллельной программе могут быть любые ошибки, в этом отношении она не представляет собой ничего особенного. Однако есть ряд ошибок, непосредственно связанных с параллелизмом, и вот они-то будут нам особенно интересны. Как правило, эти ошибки попадают в одну из двух категорий:</p>
          <p>• нежелательное блокирование;</p>
          <p>• состояния гонки.</p>
          <p>Эти категории очень общие, поэтому давайте немного уточним их. Сначала рассмотрим нежелательное блокирование.</p>
        </section>
        <section>
          <title>
            <p>10.1.1. Нежелательное блокирование</p>
          </title>
          <p>Что я понимаю под нежелательным блокированием? Прежде всего, поток считается <emphasis>заблокированным</emphasis>, если он не может продолжать выполнение, так как чего-то ждет. Это что-то может быть мьютексом, условной переменной, будущим результатом или завершением ввода/вывода. Это естественный, но не всегда приветствуемый аспект многопоточного кода, потому мы и говорим о проблеме нежелательного блокирования. Тогда возникает следующий вопрос: почему блокирование нежелательно? Обычно потому, что какой-то другой поток ждет результатов от заблокированного потока, чтобы выполнить некоторую операцию. И, значит, этот поток также оказывается заблокированным. На эту тему есть различные вариации.</p>
          <p>• <emphasis>Взаимоблокировка</emphasis> — в главе 3 мы видели, что взаимоблокировка возникает, когда один поток ждет другого, а тот, в свою очередь, ждет первого. Если потоки взаимно блокируют друг друга, то порученные им задачи вообще никогда не будут выполнены. Наиболее наглядно это проявляется, когда один из таких потоков отвечает за пользовательский интерфейс; в этом случае интерфейс просто перестаёт реагировать на действия пользователя. В других случаях интерфейс реагирует, но какая-то задача не может завершиться, например, поиск не возвращает результатов или документ не печатается.</p>
          <p>• <emphasis>Активная блокировка</emphasis> — похожа на взаимоблокировку в том смысле, что один поток ждет другого, а тот ждет первого. Но ключевое отличие заключается в том, что здесь мы имеем не блокирующее ожидание, а цикл активной проверки, например спинлок. В серьезных случаях симптомы выглядят так же, как при взаимоблокировке (приложение не может продолжить работу), только программа потребляет много процессорного времени, потому что потоки блокируют друг друга, продолжая работать. В менее серьезных случаях активная блокировка рано или поздно «рассасывается» из-за вероятностной природы планирования, но заблокированная задача испытывает ощутимые задержки, характеризуемые высоким потреблением процессорного времени.</p>
          <p>• <emphasis>Блокировка в ожидании завершения ввода/вывода или поступления данных из внешнего источника</emphasis> — если поток блокируется в ожидании данных из внешнего источника, то он не может продолжать работу, даже если данные так никогда и не поступят. Поэтому крайне нежелательно, когда такая блокировка происходит в потоке, от работы которого зависят другие потоки.</p>
          <p>Вот вкратце описание нежелательного блокирования. А как насчет состояний гонки?</p>
        </section>
        <section>
          <title>
            <p>10.1.2. Состояния гонки</p>
          </title>
          <p>Состояния гонки — одна из самых распространенных причин ошибок в многопоточных программах, часто взаимоблокировки и активные блокировки — лишь проявления гонки. Не все состояния гонки проблематичны — гонка возникает всякий раз, как поведение зависит от порядка планирования операций в различных потоках. Многие состояния гонки совершенно безобидны; например, безразлично, какой поток заберет очередную задачу из очереди. Однако же целый ряд связанных с параллелизмом ошибок обусловлен именно гонкой. В частности, гонки нередко приводят к следующим проблемам.</p>
          <p>• <emphasis>Гонка за данными</emphasis> — это особый тип гонки, который приводит к неопределенному поведению из-за несинхронизированного одновременного доступа к разделяемой ячейке памяти. С этим видом гонок мы познакомились в главе 5 при изучении модели памяти в С++. Обычно гонка за данными возникает вследствие неправильного использования атомарных операций для синхронизации потоков или в результате доступа к разделяемым данным, не защищенного подходящим мьютексом.</p>
          <p>• <emphasis>Нарушение инвариантов</emphasis> — такие гонки могут проявляться в форме висячих указателей (другой поток уже удалил данные, к которым мы пытаемся обратиться), случайного повреждения памяти (из-за того, что поток читает данные, оказавшиеся несогласованными в результате частичного обновления) и двойного освобождения (например, два потока извлекают из очереди одно и то же значение, и потом оба удаляют ассоциированные с ним данные). Нарушение инварианта может быть связано как с несоблюдением временных соотношений, так и с неправильными значениями. Если требуется, чтобы операции в разных потоках выполнялись в определенном порядке, то некорректная синхронизация может стать причиной гонки, из-за которой требуемый порядок иногда нарушается.</p>
          <p><emphasis>• Проблемы со временем жизни</emphasis> — такого рода проблемы можно было бы отнести к нарушению инвариантов, но на самом деле это отдельная категория. Основная проблема в том, что поток живет дольше, чем данные, к которым он обращается, поэтому может попытаться получить доступ к уже удаленным или разрушенным иным способом данным. Не исключено также, что когда-то отведенная под эти данные память уже занята другим объектом. Обычно такие ошибки возникают, когда поток хранит ссылки на локальные переменные, которые вышли из области видимости до завершения функции потока, но это не единственный сценарий. Если время жизни потока и данных, которыми он оперирует, никак не связано, то всегда существует возможность, что данные будут уничтожены до завершения потока, и у функции потока просто «выбьют почву из-под ног». Если вы вручную вызываете <code>join()</code>, чтобы дождаться завершения потока, то следите за тем, чтобы вызов <code>join()</code> не пропускался из-за исключения. Это простейшая мера безопасности относительно исключений, применяемая к потокам.</p>
          <p>Больше всего неприятностей приносят именно проблематичные гонки. Если возникает взаимоблокировка или активная блокировка, то кажется, что приложение зависло — оно либо вообще перестаёт отвечать, либо тратит на выполнение задачи несоразмерно много времени. Зачастую можно подключить к работающему процессу отладчик и понять, какие потоки участвуют в блокировке и какие объекты синхронизации они не поделили. В случае гонок за данными, нарушенных инвариантов или проблем со временем жизни видимые симптомы ошибки (например, произвольные «падения» или неправильный вывод) могут проявляться где угодно — программа может затереть память, используемую в другой части системы, к которой обращений не будет еще очень долго. Таким образом, ошибка проявляется в коде, совершенно не относящемся к месту ее возникновения, и, возможно, гораздо позже в процессе выполнения программы. Это проклятие всех систем с разделяемой памятью — как бы вы ни пытались ограничить количество данных, доступных потоку, какие бы меры ни принимали для правильной синхронизации, любой поток в состоянии затереть данные, используемые любым другим потоком в том же приложении.</p>
          <p>Теперь, когда мы вкратце описали, какие проблемы нас интересуют, посмотрим, как находить проблемные места в коде и исправлять их.</p>
        </section>
      </section>
      <section>
        <title>
          <p>10.2. Методы поиска ошибок, связанных с параллелизмом</p>
        </title>
        <section>
          <p>В предыдущем разделе мы познакомились с типами ошибок, обусловленных параллелизмом, и тем, как они могут проявляться. Памятуя об этом, мы можем изучить подозрительные участки кода и попытаться понять, есть там ошибки или нет.</p>
          <p>Пожалуй, самый прямой и очевидный путь — <emphasis>посмотреть на код «глазками»</emphasis>. Несмотря на кажущуюся очевидность, на практике сделать это тщательно весьма трудно. Читая только что написанный вами же код, очень легко увидеть то, что вы собирались написать, а не то, что написано на самом деле. Аналогично, при анализе кода, написанного другим человеком, возникает соблазн быстренько проглядеть текст, проверить его на предмет соблюдения местных стандартов кодирования и отметить проблемы, бросающиеся в глаза. А надо бы потратить время, пройтись по коду мелким гребнем, задуматься над местами, связанными с параллелизмом — да и не связанными тоже (а почему бы и нет, в конце концов, ошибка — она и в Африке ошибка). Чуть ниже мы поговорим о том, что конкретно должно стать предметом таких размышлений.</p>
          <p>Но даже после тщательного анализа кода какие-то ошибки могут остаться незамеченными, и в любом случае хотелось бы подтвердить, что код действительно работает — хотя бы ради собственного спокойствия. Поэтому от умозрительного анализа мы перейдём к описанию нескольких способов тестирования многопоточной программы.</p>
        </section>
        <section>
          <title>
            <p>10.2.1. Анализ кода на предмет выявления потенциальных ошибок</p>
          </title>
          <p>Я уже упоминал, что анализ многопоточного кода на предмет выявления ошибок, связанных с параллелизмом, надо проводить тщательно, прочёсывая код мелким гребнем. Если возможно, попросите заняться этим кого-нибудь другого. Поскольку этот человек не писал код, то ему придётся думать, как он работает, и это поможет обнаружить скрытые ошибки. Важно, чтобы у рецензента было достаточно времени — нужно не проглядеть код мельком, за пару минут, а тщательно и усидчиво проанализировать. Большинство ошибок, связанных с параллелизмом, поверхностный читатель не увидит — обычно для их проявления нужно редкое сочетание временных соотношений.</p>
          <p>Коллега, если вам удастся упросить его проанализировать ваш код, будет смотреть на него свежим взглядом и под другим углом зрения, чем вы сами. Поэтому он может заметить вещи, ускользнувшие от вашего внимания. Если коллег нет, попросите приятеля, можете даже выложить свой код в Интернет (не оскорбляя чувств юристов компании). Но даже если не найдется никого, кто проанализирует ваш код, или если рецензент ничего не обнаружит, все равно не отчаивайтесь — на этом свет клином не сошелся. Для начала имеет смысл на время отложить код — поработать над другой частью программы, книжку почитать, погулять. Во время перерыва вы будете подсознательно обдумывать задачу, заняв сознание чем-то другим. А когда вернетесь к коду, он будет казаться не таким знакомым, и, возможно, вам самому удастся взглянуть на него другими глазами.</p>
          <p>Вместо того чтобы обращаться за помощью, можете проанализировать свой код самостоятельно. Например, полезно попытаться <emphasis>во всех деталях</emphasis> объяснить кому-нибудь, как он работает. Это даже необязательно должен быть человек — вполне подойдёт плюшевый медвежонок или надувной цыплёнок. Лично мне очень помогает написание подробных заметок. По ходу объяснения думайте над каждой строкой, рассказывайте, что может произойти, к каким данным происходят обращения и т.д. Задавайте себе вопросы о программе и объясняйте свои ответы. Мне кажется, что это очень действенная методика — задавая себе вопросы и тщательно продумывая ответы, зачастую удается выявить проблемы. Причем задавать вопросы полезно при анализе <emphasis>любого</emphasis> кода, а не только своего собственного.</p>
          <subtitle>Над какими вопросами следует задуматься при анализе многопоточного кода</subtitle>
          <p>Я уже говорил, что рецензенту (неважно, является он автором программы или нет) полезно задавать конкретные вопросы по поводу анализируемой программы. Они позволяют сосредоточиться на деталях кода и выявить потенциальные проблемы. Лично я люблю задавать вопросы, перечисленные ниже, хотя это, конечно, далеко не исчерпывающий список. Вам, возможно, помогут лучше сконцентрироваться совсем другие вопросы.</p>
          <p>• Какие данные нужно защищать от одновременного доступа?</p>
          <p>• Как вы обеспечиваете защиту этих данных?</p>
          <p>• В каком участке программы могут в этот момент находиться другие потоки?</p>
          <p>• Какие мьютексы удерживает данный поток?</p>
          <p>• Какие мьютексы могут удерживать другие потоки?</p>
          <p>• Существуют ли ограничения на порядок выполнения операций в этом и каком-либо другом потоке? Как гарантируется соблюдение этих ограничений?</p>
          <p>• Верно ли, что данные, загруженные этим потоком, все еще действительны? Не могло ли случиться, что их изменили другие потоки?</p>
          <p>• Если предположить, что другой поток может изменить данные, то к чему это приведёт и как гарантировать, что этого никогда не случится?</p>
          <p>Последний вопрос — мой любимый, потому что заставляет думать о взаимосвязях между потоками. Допустив, что в некоторой строке имеется ошибка, вы дальше перевоплощаетесь в сыщика, которому нужно раскрыть преступление. Чтобы убедить себя в отсутствии ошибки, требуется рассмотреть все граничные случаи, приняв во внимание любой возможный порядок операций. Это особенно полезно, если данные в разные моменты времени защищаются разными мьютексами, как, например, обстояло дело в потокобезопасной очереди из главы 6, где мы завели разные мьютексы для головы и хвоста очереди. Чтобы гарантировать безопасность доступа в момент, когда захвачен один мьютекс, нужна уверенность в том, что поток, удерживающий <emphasis>другой</emphasis> мьютекс, не будет пытаться получить доступ к тому же элементу. Очевидно, что общедоступные данные, а также данные, на которые программа может получить ссылку или указатель, нужно анализировать особенно пристрастно.</p>
          <p>Предпоследний вопрос из списка также важен, потому что касается очень распространенной ошибки: если вы освобождаете, а затем снова захватываете мьютекс, то должны предполагать, что другие потоки могли изменить разделяемые данные. На первый взгляд, очевидно, но если операции с мьютексами не видны — например, потому что скрыты внутри какого-то объекта, — то вы неосознанно допускаете именно эту ошибку В главе 6 мы видели, как это может привести к гонке и ошибкам, когда функции в потокобезопасной структуре данных слишком детализированы. Если для стека, не безопасного относительно потоков, наличие отдельных операций <code>top()</code> и <code>pop()</code> оправдано, то для стека, к которому могут одновременно обращаться несколько потоков, это уже не так, потому что между этими двумя вызовами внутренний мьютекс не захвачен, и, значит, какой-то другой поток может модифицировать стек. В главе 6 мы видели, что для решения этой проблемы нужно объединить обе операции в одну — выполняемую под защитой одной и той же блокировки мьютекса. Тем самым опасность гонки устраняется.</p>
          <p>Итак, вы проанализировали код (или это сделал кто-то другой). Вы уверены, что в нем нет ошибок. Но критерием истины, как известно, является практика — как можно протестировать код, подтвердив или опровергнув вашу веру в отсутствие ошибок?</p>
        </section>
        <section>
          <title>
            <p>10.2.2. Поиск связанных с параллелизмом ошибок путем тестирования</p>
          </title>
          <p>Тестирование однопоточных приложений — процедура сравнительно простая, хотя, возможно, и длительная. Теоретически можно идентифицировать все возможные наборы входных данных (или, но крайней мере, все интересные случаи) и подать их на вход приложения. Если поведение и выходные данные программы совпадают с ожидаемыми, значит, для соответствующего набора входных данных программа работает корректно. Тестировать такие ситуации, как переполнение диска, сложнее, но идея та же самая — подготовить начальные условия и прогнать приложение.</p>
          <p>Тестирование многопоточного кода на порядок сложнее, потому что точный порядок выполнения потоков не детерминирован и может изменяться от запуска к запуску. Следовательно, если в коде притаилось какое-то состояние гонки, то даже на одном и том же наборе входных данных программа иногда может работать правильно, а иногда давать ошибку. Наличие потенциальной гонки не означает, что программа будет выдавать ошибку <emphasis>всегда</emphasis>, утверждается лишь, что <emphasis>иногда</emphasis> она <emphasis>может</emphasis> сбоить.</p>
          <p>Ввиду трудностей воспроизведения ошибки, внутренне присущих многопоточным программам, вы должны проектировать тесты очень тщательно. Желательно, чтобы каждый тест проверял как можно меньший участок кода, тогда при возникновении ошибки ее будет проще изолировать. Конкретно, проверять правильность работы операций помещения и извлечения элементов в параллельной очереди лучше напрямую, а не путем тестирования всего куска кода, в котором эта очередь используется. Очень помогает еще на этапе проектирования кода думать о том, как он будет тестироваться. См. по этому поводу раздел о тестопригодности ниже в этой главе.</p>
          <p>Имеет также смысл устранять из тестов параллелизм, так как это позволяет убедиться, что проблема не связана с параллельным доступом. Если проблема проявляется даже при однопоточной работе, то это самая обычная ошибка, не имеющая отношения к параллелизму. Это особенно важно, когда вы пытаетесь установить причины ошибки, произошедшей «в поле», а не в тестовом окружении. Если ошибка возникает в многопоточной части программы, то это еще не значит, что она как-то связана с параллелизмом. При использовании пулов потоков обычно имеется конфигурационный параметр, определяющий число рабочих потоков. Если вы управляете потоками вручную, то нужно будет модифицировать код, так чтобы в тесте работал только один поток. Как бы то ни было, если удастся воспроизвести ошибку в однопоточном варианте программы, то параллелизм можно исключить из числа возможных причин. С другой стороны, если проблема исчезает при работе в <emphasis>одноядерной</emphasis> системе (даже при наличии нескольких одновременно работающих потоков), но появляется в <emphasis>многоядерной</emphasis> или <emphasis>многопроцессорной</emphasis>, то имеет место состояние гонки и, возможно, ошибка, связанная с синхронизацией или упорядочением доступа к памяти.</p>
          <p>При тестировании параллельного кода важна не только структура самого кода, но и структура теста и тестовой среды. Все в том же примере параллельной очереди необходимо проверить следующие случаи.</p>
          <p>• Один поток вызывает <code>push()</code> или <code>pop()</code> для проверки работоспособности очереди на самом простом уровне.</p>
          <p>• Один поток вызывает <code>push()</code> для пустой очереди, а второй в это время вызывает <code>pop()</code>.</p>
          <p>• Несколько потоков вызывают <code>push()</code> для пустой очереди.</p>
          <p>• Несколько потоков вызывают <code>push()</code> для заполненной очереди.</p>
          <p>• Несколько потоков вызывают <code>pop()</code> для пустой очереди.</p>
          <p>• Несколько потоков вызывают <code>pop()</code> для заполненной очереди.</p>
          <p>• Несколько потоков вызывают <code>pop()</code> для частично заполненной очереди, в которой недостаточно элементов для удовлетворения всех потоков.</p>
          <p>• Несколько потоков вызывают <code>push()</code>, а один вызывает <code>pop()</code> для пустой очереди.</p>
          <p>• Несколько потоков вызывают <code>push()</code>, а один вызывает <code>pop()</code> для заполненной очереди.</p>
          <p>• Несколько потоков вызывают <code>push()</code> и несколько потоков вызывают <code>pop()</code> для пустой очереди.</p>
          <p>• Несколько потоков вызывают <code>push()</code> и несколько потоков вызывают <code>pop()</code> для заполненной очереди.</p>
          <p>Проверив все эти и другие случаи, вы затем должны учесть дополнительные параметры тестовой среды.</p>
          <p>• Что понимается под «несколькими потоками» в каждом случае (3, 4, 1024)?</p>
          <p>• Достаточно ли в системе процессорных ядер, чтобы каждый поток работал на отдельном ядре?</p>
          <p>• Какова архитектура процессора, на котором будет прогоняться тест?</p>
          <p>• Как обеспечить подходящее планирование для циклов «while» в тестах?</p>
          <p>В зависимости от ситуации может быть необходимо принять во внимание и другие факторы. Из четырех приведённых выше аспектов тестовой среды первый и последний относятся к структуре самого теста (и рассматриваются в разделе 10.2.5), а оставшиеся два — к физической тестовой системе. Сколько потоков использовать, определяется конкретной программой, но способов структурировать тесты для получения нужного планирования потоков существует несколько. Прежде чем рассматривать их, поговорим о том, как следует проектировать код, чтобы его было легко тестировать.</p>
        </section>
        <section>
          <title>
            <p>10.2.3. Проектирование с учетом тестопригодности</p>
          </title>
          <p>Тестировать многопоточный код трудно, поэтому вы должны сделать все возможное, чтобы облегчить эту задачу. И едва ли не самое важное — проектировать код с учетом тестопригодности. Для однопоточных программ на эту тему написано немало, и многие рекомендации применимы и к многопоточному случаю. Вообще говоря, код проще тестировать, если он написан с соблюдением следующих принципов.</p>
          <p>• Обязанности всех функций и классов четко очерчены.</p>
          <p>• Каждая функция короткая и решает ровно одну задачу.</p>
          <p>• Тесты способны полностью контролировать окружение тестируемого кода.</p>
          <p>• Код, выполняющий конкретную тестируемую операцию, находится приблизительно в одном месте, а не разбросан но всей системе.</p>
          <p>• Автор сначала думал о том, как будет тестировать код, а только потом приступал к его написанию.</p>
          <p>Все это остается в силе и для многопоточного кода. Я бы даже сказал, что думать о тестопригодности многопоточной программы даже важнее, чем однопоточной, поскольку тестировать ее гораздо труднее. Очень важен последний пункт: даже если вы не считаете нужным писать тесты раньше кода, все равно стоит заранее подумать о том, как вы будете тестировать — какие входные данные использовать, при каких условиях могут проявиться проблемы, какие способы обращения к коду могут выявить потенциальные проблемы и т.д.</p>
          <p>Один из лучших способов проектирования параллельного кода, пригодного для тестирования, — устранить параллелизм. Если программу удается разбить на части, которые отвечают за взаимодействие потоков, и части, которые оперируют данными внутри одного потока, то проблема сильно упрощается. Части, оперирующие данными, к которым может обращаться только один поток, можно тестировать, применяя хорошо известные методы. А трудный для тестирования параллельный код, который отвечает за взаимодействие потоков и должен гарантировать, что в каждый момент времени только один поток обращается к конкретному блоку данных, теперь оказывается гораздо короче и обозримее.</p>
          <p>Например, приложение, спроектированное в виде многопоточного конечного автомата, можно разбить на несколько частей. Логику управления состояниями в каждом потоке, отвечающую за правильность переходов и операций для любого возможного набора входных событий, можно тестировать независимо, применяя стандартные методы для однопоточного случая. При этом входные событие, которые реально должны были бы поступать от других потоков, будет поставлять тестовая среда. После этого независимо можно протестировать основной код конечного автомата и код маршрутизации сообщений и убедиться, что события доставляются нужному потоку в правильном порядке; при этом специально для тестов будет написана простая логика работы в каждом состоянии.</p>
          <p>Или, если получится разбить программу на несколько блоков вида <emphasis>читать разделяемые данные / преобразовать данные / обновить разделяемые данные</emphasis>, то части <emphasis>преобразовать данные</emphasis> можно будет протестировать с помощью стандартных методов, поскольку это обычный однопоточный код. И трудная задача тестирования многопоточных преобразований будет сведена к тестированию чтения и обновления разделяемых данных, что гораздо проще.</p>
          <p>Нужно обращать особое внимание на библиотечные вызовы, в которых могут использоваться внутренние переменные для хранения состояния, поскольку эти переменные становятся разделяемыми, если к библиотечным функциям обращаются сразу несколько потоков. Проблема в том, что сразу не очевидно, что код обращается к разделяемым данным. Впрочем, со временем вы запоминаете такие функции, потому что они, словно болячка, постоянно напоминают о себе. Тогда можно либо добавить подходящую защиту и синхронизацию, либо пользоваться другими функциями, безопасными для доступа из нескольких потоков.</p>
          <p>Проектирование многопоточного кода с учетом тестопригодности не сводится к структурированию программы с целью уменьшить объем кода, имеющего дело с параллелизмом, и внимательному обращению с библиотечными функциями. Полезно также помнить о вопросах, которые вы задаете себе при анализе кода (см. раздел 10.2.1). Они, правда, не имеют прямого отношения к тестированию и тестопригодности, но, постоянно держа в уме вопросы тестирования, вы будете принимать более правильные проектные решения, которые затем это самое тестирование облегчат.</p>
          <p>Итак, мы поговорили о том, как проектировать код с учетом тестопригодности и но возможности отделять «параллельные» части (например, потокобезопасные контейнеры и логику событий конечного автомата) от «однопоточных» (которые все же могут взаимодействовать с другими потоками при посредстве параллельных частей). А теперь рассмотрим некоторые приёмы тестирования параллельного кода.</p>
        </section>
        <section>
          <title>
            <p>10.2.4. Приемы тестирования многопоточного кода</p>
          </title>
          <p>Вы уже продумали сценарий, который собираетесь тестировать, и написали код, подвергающий тестируемые функции испытаниям. Как обеспечить произвольный потенциально проблематичный порядок планирования, чтобы ошибки вылезли на свет? Есть несколько способов, начиная с тестирования грубой силой, или нагрузочного тестирования.</p>
          <subtitle>Тестирование грубой силой</subtitle>
          <p>Идея тестирования грубой силой заключается в том, чтобы подвергать программу большой нагрузке и наблюдать за появлением ошибок. Обычно это означает, что код прогоняется многократно и, возможно, с большим количеством потоков. Если некоторая ошибка возникает только при определенном порядке планирования потоков, то чем дольше вы будете гонять код, тем больше будет вероятность ее проявления. Если тест прогоняется только один раз и при этом проходит, то появляется некоторая уверенность в его правильности. Если тест проходит десять раз подряд, то эта уверенность возрастает. Ну а если и после миллиарда прогонов ошибок не было, то доверие к коду становится еще сильнее.</p>
          <p>Степень доверия к результатам, конечно, зависит от объема кода, проверяемого каждым тестом. Если тесты очень детальные, как, например, рассмотренные выше для потокобезопасной очереди, то такое тестирование грубой силой порождает высокую степень доверия к программе. С другой стороны, если тестированию подвергаются крупные участки кода, то количество возможных вариантов порядка планирования настолько велико, что и после миллиарда прогонов теста уверенность в правильности кода слабенькая.</p>
          <p><emphasis>Недостаток метода грубой силы в том, что он может вселять ложную уверенность</emphasis>. Если тест написан таким образом, что проблематичные условия просто не могут возникнуть, то прогонять его можно сколь угодно долго, и всякий раз он будет проходить, хотя стоит условиям чуть-чуть измениться, как сразу возникнет ошибка. Наихудший вариант такого развития событий возникает, когда система, на которой производится тестирование, настроена так, что проблематичные условия в принципе невозможны. Это бывает, когда производственная система отличается от тестовой, и конкретное сочетание оборудования и операционной системы не дает материализоваться условиям, при которых возникает ошибка.</p>
          <p>Классический пример — тестирование многопоточного приложения на однопроцессорной машине. Поскольку все потоки исполняются единственным процессором, работа программы автоматически сериализуется, а разнообразные состояния гонки и проблемы перебрасывания кэша, которые могли бы наблюдаться в многопроцессорной системе, вообще невозможны. Но это еще не все — процессоры с разной архитектурой предоставляют различные средства синхронизации и упорядочения доступа к памяти. Например, в процессорах x86 и x86-64 атомарные операции загрузки одинаковы вне зависимости от того, помечены они признаком <code>memory_order_relaxed</code> или <code>memory_order_seq_cst</code> (см. раздел 5.3.3). Это означает, что код, написанный в предположении ослабленного упорядочения, может работать на машинах с архитектурой x86, но откажет на машине с системой команд, допускающей более точное управление порядком доступа к памяти, например, SPARC.</p>
          <p>Если приложение должно быть переносимо на разные архитектуры, то и тестировать его следует на машинах, представляющих каждую возможную архитектуру. Поэтому я и включил архитектуру процессора в список факторов, которые нужно учитывать при тестировании (см. раздел 10.2.2).</p>
          <p>Применяя тестирование грубой силой, важно всеми силами избегать условий, способных породить ложную уверенность. Для этого необходимо тщательно планировать тесты, уделяя внимание не только тому, какие участки кода подвергать тестированию, но также проектированию стенда (test harness) и выбору тестовой среды. Вы должны постараться протестировать как можно больше путей выполнения кода и взаимодействий между потоками. При этом еще необходимо знать, <emphasis>какие именно</emphasis> варианты протестированы, а <emphasis>какие остались не протестированными</emphasis>.</p>
          <p>Хотя метод грубой силы дает некоторую уверенность в правильности кода, гарантировать обнаружение всех ошибок он не может. Однако существует методика, которая <emphasis>гарантированно</emphasis> находит проблемы, если только у вас есть время применить ее к своему коду и подходящее программное обеспечение. Я называю ее <emphasis>комбинаторным имитационным тестированием</emphasis>.</p>
          <subtitle>Комбинаторное имитационное тестирование</subtitle>
          <p>Название не вполне внятное, поэтому объясню, что я имею в виду. Идея в том, чтобы прогонять код под управлением специальной программы, которая <emphasis>имитирует</emphasis> реальную среду. Вам, наверное, доводилось слышать о программах, которые запускают несколько виртуальных машин на одном физическом компьютере, причём характеристики каждой виртуальной машины и оборудования эмулируются программным супервизором. Здесь всё похоже, только вместо эмулирования системы имитационное ПО записывает последовательности операций доступа к данным, захвата блокировок и атомарных операций в каждом потоке. Затем она применяет правила модели памяти, определенные в С++, чтобы повторить прогон при любой допустимой <emphasis>комбинации</emphasis> операций и таким образом выявить гонки и взаимоблокировки.</p>
          <p>Хотя такое исчерпывающее тестирование всех комбинаций гарантированно обнаружит все проблемы, на поиск которых система рассчитана, но для любой программы, кроме самых тривиальных, оно займет чудовищно много времени, потому что количество комбинаций экспоненциально увеличивается с ростом числа потоков и операций, выполняемых в каждом потоке. Лучше применять эту методику к детальным тестам отдельных частей кода, а не ко всему приложению. Очевидный недостаток заключается том, что необходимо специальное имитационное ПО, способное обработать встречающиеся в вашей программе операции.</p>
          <p>Таким образом, мы располагаем методикой, подразумевающей многократный прогон тестов при обычных условиях, которая, однако, может пропускать некоторые ошибки, и методикой, предполагающий запуск в специально созданных условиях, которая найдет ошибки с гораздо большей вероятностью. А есть ли еще какие-нибудь варианты?</p>
          <p>Третий способ — воспользоваться библиотекой, которая сама обнаруживает проблемы, возникающие при прогоне тестов.</p>
          <subtitle>Обнаружение возникающих во время тестирования проблем с помощью специальной библиотеки</subtitle>
          <p>Этот вариант не обеспечивает исчерпывающего покрытия, которое дает комбинаторное имитационное тестирование, но все же позволяет выявить многие проблемы за счет специальных реализаций таких библиотечных примитивов синхронизации, как мьютексы, блокировки и условные переменные. Например, часто требуется, чтобы любой доступ к некоторым разделяемым данным, производился, когда захвачен определенный мьютекс. Если бы была возможность проверить, какие мьютексы захвачены в момент доступа к этим данным, то можно было бы сообщить об ошибке в случае, когда нужный мьютекс не захвачен. Пометив разделяемые данные определенным образом, мы смогли бы сообщить библиотеке, что проверять.</p>
          <p>Такая реализация библиотеки могла бы также записывать последовательность захватов в случае, когда некоторый поток одновременно удерживает более одного мьютекса. Если другой поток попытается захватить те же мьютексы в другом порядке, то будет зарегистрирована <emphasis>потенциальная</emphasis> взаимоблокировка, даже если при реальном прогоне теста она не возникала.</p>
          <p>Для тестирования многопоточного кода могла бы быть полезна и специальная библиотека другого рода, в которой реализации таких примитивов, как мьютексы и условные переменные, позволяют автору теста управлять тем, какой поток захватит блокировку, если ее ожидают несколько потоков, или какой из потоков, ожидающих условную переменную, будет разбужен вызовом <code>notify_one()</code>. Это дало бы возможность настраивать конкретные сценарии и проверять, что код работает в соответствии с ожиданиями.</p>
          <p>Некоторые из описанных средств тестирования следовало бы включать в стандартную библиотеку С++, а другие можно было бы реализовать на основе стандартной библиотеке как часть тестового стенда.</p>
          <p>Обсудив различные способы исполнения тестового кода, посмотрим, как можно структурировать код для достижения желаемого порядка планирования потоков.</p>
        </section>
        <section>
          <title>
            <p>10.2.5. Структурирование многопоточного тестового кода</p>
          </title>
          <p>В разделе 10.2.2 я говорил о том, что нужно придумать, как обеспечить надлежащий порядок планирования для циклов «while» в тестах. Сейчас самое время поговорить о возникающих здесь вопросах.</p>
          <p>Основная проблема — организовать набор потоков таким образом, чтобы каждый исполнял выбранный фрагмент кода в указанный вами момент времени. В простейшем случае потоков всего два, но решение легко обобщается и на большее число. На первом этапе нужно определиться, как устроен каждый тест:</p>
          <p>• код общей настройки, исполняемый в самом начале;</p>
          <p>• потоковый код настройки, исполняемый в каждом потоке;</p>
          <p>• содержательный код, исполняемый в параллельно работающих потоках;</p>
          <p>• код, исполняемый по завершении параллельного исполнения; может включать утверждения о состоянии программы.</p>
          <p>Для определённости рассмотрим пример из списка в разделе 10.2.2: один поток вызывает <code>push()</code> для пустой очереди, а второй в это время вызывает <code>pop()</code>.</p>
          <p>Код <emphasis>общей</emphasis> настройки очевиден: надо создать очередь. В потоке, исполняющем <code>pop()</code>, нет <emphasis>потокового</emphasis> кода настройки. Потоковый код настройки для потока, исполняющего <code>push()</code>, зависит от интерфейса очереди и типа сохраняемого в ней объекта. Если конструировать сохраняемый объект дорого или память для него должна выделяться из кучи, то лучше сделать это в потоковом коде настройки, чтобы не оказывать влияния на сам тест. С другой стороны, если в очереди хранятся всего лишь значения типа <code>int</code>, то мы ничего не выиграем от их конструирования в коде настройки. Собственно тестируемый код тоже прост — вызвать <code>push()</code> в одном потоке и <code>pop()</code> в другом. А вот как быть с кодом, «исполняемым по завершении»?</p>
          <p>В данном случае всё зависит от того, что должна делать функция <code>pop()</code>. Если предполагается, что она блокирует поток до появления данных в очереди, то, очевидно, мы ожидаем, что будут возвращены данные, переданные функции <code>push()</code>, и что очередь в итоге окажется пустой. Если же <code>pop()</code> <emphasis>не</emphasis> блокирует поток и может вернуть управление, даже когда очередь пуста, то требуется проверить два возможных исхода: либо <code>pop()</code> вернула данные, переданные <code>push()</code>, и очередь пуста, либо <code>pop()</code> известила об отсутствии данных и в очереди есть один элемент. Истинно должно быть ровно одно утверждение; чего мы точно не хотим, так это ситуации, когда <code>pop()</code> говорит «нет данных», но очередь пуста, или когда <code>pop()</code> вернула значение, а очередь все равно <emphasis>не</emphasis> пуста. Для упрощения теста предположим, что функция <code>pop()</code> блокирующая. Тогда в завершающем коде должно быть утверждение вида «извлеченное значение совпадает с помещённым и очередь пуста».</p>
          <p>Определившись со структурой кода, мы должны постараться, чтобы все работало в соответствии с планом. Один из путей - воспользоваться набором объектов <code>std::promise</code>, обозначающих, что все готово. Каждый поток устанавливает обещание, сообщая, что он готов, а затем ждет (копии) будущего результата <code>std::shared_future</code>, полученного из третьего объекта s<code>td::promise</code>; главный поток ждет обещаний от всех потоков, а затем запускает потоки, устанавливая <code>go</code>. Тем самым гарантируется, что каждый поток запущен и находится в точке, непосредственно предшествующей коду, который должен выполняться параллельно; весь потоковый код настройки должен завершиться до установки обещания <code>go</code>. Наконец, главный поток ждет завершения других потоков и проверяет получившееся состояние. Мы также должны принять во внимание исключения и гарантировать, что ни один поток не будет ждать сигнала <code>go</code>, который никогда не поступит. В листинге ниже приведён один из возможных способов структурирования этого теста.</p>
          <empty-line/>
          <p><strong>Листинг 10.1.</strong> Пример теста, проверяющего параллельное выполнение функций очереди <code>push()</code> и <code>pop()</code></p>
          <p>
            <code>void test_concurrent_push_and_pop_on_empty_queue() {</code>
          </p>
          <p>
            <code> threadsafe_queue&lt;int&gt; q; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <empty-line/>
          <p>
            <code> std::promise&lt;void&gt; go, push_ready, pop_ready;&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> std::shared_future&lt;void&gt;</code>
          </p>
          <p>
            <code>  ready(go.get_future()); &#8592;</code>
            <strong>(3)</strong>
          </p>
          <empty-line/>
          <p>
            <code> std: :future&lt;void&gt; push_done; &#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> std::future&lt;int&gt; pop_done;</code>
          </p>
          <empty-line/>
          <p>
            <code> try {</code>
          </p>
          <p>
            <code>  push_done = std::async(std::launch::async, &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code>   [&amp;q, ready, &amp;push_ready]() {</code>
          </p>
          <p>
            <code>    push_ready.set_value();</code>
          </p>
          <p>
            <code>    ready.wait();</code>
          </p>
          <p>
            <code>    q.push(42);</code>
          </p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  );</code>
          </p>
          <p>
            <code>  pop_done = std::async(std::launch::async, &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code>   [&amp;q, ready, &amp;pop_ready]() {</code>
          </p>
          <p>
            <code>    pop_ready.set_value();</code>
          </p>
          <p>
            <code>    ready.wait();</code>
          </p>
          <p><code>    return q.pop(); &#8592;</code>(7)</p>
          <p>
            <code>   }</code>
          </p>
          <p>
            <code>  );</code>
          </p>
          <p>
            <code>  push_ready.get_future().wait(); &#8592;</code>
            <strong>(8)</strong>
          </p>
          <p>
            <code>  pop_ready.get_future().wait();</code>
          </p>
          <p>
            <code>  go.set_value(); &#8592;</code>
            <strong>(9)</strong>
          </p>
          <empty-line/>
          <p>
            <code>  push_done.get(); &#8592;</code>
            <strong>(10)</strong>
          </p>
          <p>
            <code>  assert(pop_done.get() == 42); &#8592;</code>
            <strong>(11)</strong>
          </p>
          <p>
            <code>  assert(q.empty());</code>
          </p>
          <p>
            <code> } catch (...) {</code>
          </p>
          <p>
            <code>  go.set_value(); &#8592;</code>
            <strong>(12)</strong>
          </p>
          <p>
            <code>  throw;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Структура кода в точности соответствует описанной выше. Сначала, в коде общей настройки, мы создаем пустую очередь <strong>(1)</strong>. Затем создаем все объекты-обещания для сигналов <code>ready</code> (готово) <strong>(2)</strong> и получаем <code>std::shared_future</code> для сигнала <code>go</code> <strong>(3)</strong>. После этого создаются будущие результаты, означающие, что потоки завершили исполнение <strong>(4)</strong>. Они должны быть созданы вне блока <code>try</code>, чтобы сигнал <code>go</code> можно было установить в случае исключения, не ожидая завершения потоков (что привело бы к взаимоблокировке — вещь, абсолютно недопустимая в тесте).</p>
          <p>Внутри блока <code>try</code> мы затем можем создать потоки <strong>(5)</strong>, <strong>(6)</strong> — использование <code>std::launch::async</code> гарантирует, что каждая задача работает в отдельном потоке. Отметим, что благодаря использованию <code>std::async</code> обеспечить безопасность относительно исключений проще, чем в случае простого <code>std::thread</code>, потому что деструктор будущего результата присоединит поток. В переменных, захваченных лямбда-функцией, хранится ссылка на очередь, соответствующее обещание для подачи сигнала о готовности, а также копия будущего результата <code>ready</code>, полученного из обещания <code>go</code>.</p>
          <p>Как было описано выше, каждая задача устанавливает свой сигнал <code>ready</code>, а затем ждет общего сигнала <code>ready</code>, прежде чем начать исполнение тестируемого кода. Главный поток делает всё наоборот — ждет сигналов от обоих потоков <strong>(8)</strong>, а затем сигнализирует им о том, что можно переходить к исполнению тестируемого кода <strong>(9)</strong>.</p>
          <p>Напоследок главный поток вызывает функцию <code>get()</code> обоих будущих результатов, возвращенных асинхронными вызовами, чтобы дождаться завершения задач <strong>(10)</strong>, <strong>(11)</strong> и проверить получившееся состояние. Отметим, что задача <emphasis>pop</emphasis> возвращает извлеченное из очереди значение в будущем результате <strong>(7)</strong>, чтобы мы могли проверить его в утверждении <strong>(11)</strong>.</p>
          <p>В случае исключения мы устанавливаем сигнал <code>go</code>, чтобы не оказалось висячего потока, и возбуждаем исключение повторно <strong>(12)</strong>. Будущие результаты, соответствующие обеим задачам <strong>(4)</strong>, были объявлены последними, поэтому уничтожаются первыми, и их деструкторы ждут завершения задач, если они еще не завершились.</p>
          <p>Хотя служебного кода многовато для тестирования двух простых вызовов, что-то в этом роде все равно необходимо, чтобы проверить именно то, что мы хотим проверить. Например, запуск потока занимает довольно много времени, поэтому если бы мы не заставили потоки ждать сигнала <code>go</code>, то поток, помещающий данные, вполне мог бы завершиться еще до запуска потока, извлекающего данные, а это шло бы вразрез с целью данного теста. Благодаря использованию будущих результатов мы можем быть уверены, что оба потока запущены и блокированы в ожидании одного и того же будущего. Как только это будущее наступит, оба потока начнут работать. Привыкнув к этой структуре, вы без труда напишете и другие тесты. Продемонстрированный принцип без труда обобщается на случай, когда в каком-то тесте требуется более двух потоков.</p>
          <p>До сих пор мы говорили о <emphasis>корректности</emphasis> многопоточного кода. Это, конечно, самая важная, но не единственная цель тестирования. Существенна также его <emphasis>производительность</emphasis>, и далее мы займемся этим вопросом.</p>
        </section>
        <section>
          <title>
            <p>10.2.6. Тестирование производительности многопоточного кода</p>
          </title>
          <p>Одна из основных причин распараллеливания кода — задействовать многоядерные процессоры для повышения производительности программы. Поэтому проверять, что производительность действительно возросла, так же важно, как при использовании других методов оптимизации.</p>
          <p>Когда распараллеливание применяется ради повышения производительности, особый интерес представляет <emphasis>масштабируемость</emphasis> — мы хотим, чтобы на машине с 24 ядрами код выполнялся примерно в 24 раза быстрее или обрабатывал в 24 раза больше данных, чем на машине с одним ядром, — при прочих равных условиях. Мы не хотим, чтобы на двухъядерной машине код исполнялся в два раза быстрее, а на 24-ядерной — медленнее. В разделе 8.4.2 мы видели, что если значительная часть программы работает в одном потоке, то выигрыш от распараллеливания надает. Поэтому еще до начала тестирования стоит критически проанализировать общую структуру программы, чтобы понять, можно ли рассчитывать на 24-кратное ускорение или вследствие того, что большая часть программы работает последовательно, коэффициент ускорения вряд ли превысит 3.</p>
          <p>В предыдущих главах было показано, что конкуренция между процессорами за доступ к структуре данных может весьма негативно сказаться на производительности. Программа, которая хорошо масштабируется, когда число процессоров мало, может повести себя никуда не годно при увеличении их числа из-за возрастания конкуренции.</p>
          <p>Следовательно, при тестировании производительности многопоточной программы лучше замерять результаты в максимально широком спектре конфигураций, чтобы можно было составить целостное представление о масштабируемости. Как минимум, следует прогнать тесты на однопроцессорной машине и на машине с максимальным числом процессорных ядер, которое вы можете себе позволить.</p>
        </section>
      </section>
      <section>
        <title>
          <p>10.3. Резюме</p>
        </title>
        <p>В этой главе мы рассмотрели различные виды ошибок, связанных с параллелизмом, — от взаимоблокировок и активных блокировок до гонок за данными и других проблематичных состояний гонки. Были описаны различные методы поиска ошибок. Я сформулировал вопросы, над которыми следует поразмыслить, дал рекомендации по написанию тестопригодного кода и рассказал о том, как структурировать тесты для параллельных программ. И, наконец, мы затронули вопрос о некоторых служебных компонентах, которые могут оказать помощь в процессе тестирования.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Приложение А.</p>
        <p>Краткий справочник по некоторым конструкциям языка С++</p>
      </title>
      <section>
        <p>Новый стандарт С++ отнюдь не исчерпывается поддержкой параллелизма; в нем появилось немало других языковых средств и новых библиотек. В этом приложении я вкратце расскажу о тех новых возможностях, которые используются в библиотеке многопоточности и встречаются в этой книге. За исключением модификатора <code>thread_local</code> (рассматриваемого в разделе А.8), все они не имеют прямого отношения к параллелизму, однако важны и (или) полезны для написания многопоточного кода. Я ограничился лишь теми конструкциями, которые либо необходимы (например, ссылки на <emphasis>r</emphasis>-значения), либо делают код проще и яснее. Поначалу разобраться в программе, где применяются эти конструкции, будет трудно, но, познакомившись с ними поближе, вы согласитесь, что, вообще говоря, включающий их код проще, а не сложнее для понимания. По мере распространения С++11 описываемые средства будут встречаться в программах все чаще.</p>
        <p>А теперь, без дальнейших предисловий, начнем с изучения <emphasis>ссылок на r-значения</emphasis> — средства, которое широко используется в библиотеке Thread Library для передачи владения (потоками, блокировками и вообще всем на свете) от одного объекта другому.</p>
      </section>
      <section>
        <title>
          <p>А.1. Ссылки на <emphasis>r</emphasis>-значения</p>
        </title>
        <section>
          <p>Всякий, кто программировал на С++, знаком со ссылками; в С++ ссылки служат для создания альтернативного имени существующего объекта. Любой доступ к объекту по ссылке, в том числе для модификации, приводит к манипуляциям с исходным объектом. Например:</p>
          <p>
            <code>int var = 42;   &#9474;</code>
            <strong>Создаем ссылку</strong>
          </p>
          <p>
            <code>int&amp; ref = var;&#8592;&#9496;</code>
            <strong>на var</strong>
          </p>
          <p>
            <code>ref = 99;           &#9474;</code>
            <strong>В результате присваивания ссылке</strong>
          </p>
          <p>
            <code>assert (var == 99);&#8592;&#9496;</code>
            <strong>изменен оригинал</strong>
          </p>
          <p>Ссылки, к которым мы все давно привыкли, являются <emphasis>ссылками на l-значения.</emphasis> Термин <emphasis>l-значение</emphasis> появился еще в языке С и обозначает любую конструкцию, которая может находиться в левой части выражения присваивания, — именованные объекты, объекты, созданные в стеке или в куче, или члены других объектов, то есть сущности, расположенные по определенному адресу в памяти. Термин <emphasis>r-значение</emphasis> также происходит из С и обозначает конструкции, которые могут находиться только в правой части выражения присваивания, — например, литералы и временные объекты. Ссылки на <emphasis>l</emphasis>-значения можно связать только с <emphasis>l</emphasis>-значениями, но не с <emphasis>r</emphasis>-значениями. Так, невозможно написать</p>
          <p>
            <code>int&amp; i = 42;</code>
          </p>
          <p>потому что 42 — это <emphasis>r</emphasis>-значение. Впрочем, это не совсем верно; всегда разрешалось связывать <emphasis>r</emphasis>-значение с константной ссылкой на <emphasis>l</emphasis>-значение:</p>
          <p>
            <code>int const&amp; i = 42;</code>
          </p>
          <p>Однако в стандарте это исключение сделано сознательно задолго до появления ссылок на <emphasis>r</emphasis>-значения, и смысл его в том, чтобы разрешить передавать временные объекты функциям, принимающим ссылки. Благодаря этому механизму становятся возможны неявные преобразования, например, можно написать:</p>
          <p>
            <code>void print(std::string const&amp; s);</code>
          </p>
          <p>
            <code>print("hello");</code>
          </p>
          <p>Как бы то ни было, в стандарте C++11 официально введены ссылки на <emphasis>r-значения</emphasis>, которые связываются <emphasis>только</emphasis> с <emphasis>r</emphasis>-значениями, но не с <emphasis>l</emphasis>-значениями, и объявляются с помощью двух знаков амперсанда:</p>
          <p>
            <code>int&amp;&amp; i = 42;</code>
          </p>
          <p>
            <code>int j = 42;</code>
          </p>
          <p>
            <code>int&amp;&amp; k = j;</code>
          </p>
          <p>Таким образом, функцию можно перегрузить в зависимости от того, являются параметры <emphasis>l</emphasis>-значениями или <emphasis>r</emphasis>-значениями, — один вариант будет принимать ссылку на <emphasis>l</emphasis>-значение, другой — на <emphasis>r</emphasis>-значение. Эта возможность — краеугольный камень <emphasis>семантики перемещения</emphasis>.</p>
        </section>
        <section>
          <title>
            <p>A.1.1. Семантика перемещения</p>
          </title>
          <p><emphasis>r</emphasis>-значения — это обычно временные объекты, поэтому их можно спокойно модифицировать; если известно, что параметр функции — r-значение, то его можно использовать как временную память, то есть «позаимствовать» его содержимое без ущерба для корректности программы. Это означает, что вместо <emphasis>копирования</emphasis> параметра, являющегося <emphasis>r</emphasis>-значением, мы можем просто <emphasis>переместить</emphasis> его содержимое. В случае больших динамических структур это позволяет сэкономить на выделении памяти и оставляет простор для оптимизации.</p>
          <p>Рассмотрим функцию, которая принимает в качестве параметра <code>std::vector&lt;int&gt;</code> и хочет иметь его внутреннюю копию для модификации, так чтобы не затрагивать оригинал. Раньше мы для этого должны были принимать параметр как <code>const</code>-ссылку на <emphasis>l</emphasis>-значение и делать внутреннюю копию:</p>
          <p>
            <code>void process_copy(std::vector&lt;int&gt; const&amp; vec_) {</code>
          </p>
          <p>
            <code> std::vector&lt;int&gt; vec(vec_);</code>
          </p>
          <p>
            <code> vec.push_back(42);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>При этом функция может принимать как <emphasis>l</emphasis>-значения, так и <emphasis>r</emphasis>-значения, но копирование производится всегда. Однако, если добавить перегруженный вариант, который принимает ссылку на <emphasis>r</emphasis>-значение, то в этом случае можно будет избежать копирования, поскольку нам точно известно, что оригинал разрешается модифицировать:</p>
          <p>
            <code>void process_copy(std::vector&lt;int&gt;&amp;&amp; vec) {</code>
          </p>
          <p>
            <code> vec.push_back(42);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Если функция является конструктором класса, то можно умыкнуть содержимое <emphasis>r</emphasis>-значения и воспользоваться им для создания нового экземпляра. Рассмотрим класс, показанный в листинге ниже. В конструкторе по умолчанию он выделяет большой блок памяти, а в деструкторе освобождает его.</p>
          <empty-line/>
          <p><strong>Листинг А.1.</strong> Класс с перемещающим конструктором</p>
          <p>
            <code>class X {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> int* data;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> X() : data(new int[1000000]) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> ~X() {</code>
          </p>
          <p>
            <code>  delete [] data;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> X(const X&amp; other) : &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  data(new int[1000000]) {</code>
          </p>
          <p>
            <code>  std::copy(other.data, other.data + 1000000, data);</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> X(X&amp;&amp; other) : &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  data(other.data) {</code>
          </p>
          <p>
            <code>  other.data = nullptr;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p><emphasis>Копирующий конструктор</emphasis><strong>(1)</strong> определяется как обычно: выделяем новый блок памяти и копируем в него данные. Но теперь у нас есть еще один конструктор, который принимает ссылку на <emphasis>r</emphasis>-значение <strong>(2)</strong>. Это <emphasis>перемещающий конструктор</emphasis>. В данном случае мы копируем только <emphasis>указатель</emphasis> на данные, а в объекте <code>other</code> остается нулевой указатель. Таким образом, мы обошлись без выделения огромного блока памяти и сэкономили время на копировании данных из <emphasis>r</emphasis>-значения.</p>
          <p>В классе <code>X</code> перемещающий конструктор — всего лишь оптимизация, но в ряде случаев такой конструктор имеет смысл определять, даже когда копирующий конструктор не предоставляется. Например, идея <code>std::unique_ptr&lt;&gt;</code> в том и заключается, что любой ненулевой экземпляр является единственным указателем на свой объект, поэтому копирующий конструктор лишен смысла. Однако же перемещающий конструктор позволяет передавать владение указателем от одного объекта другому, поэтому <code>std::unique_ptr&lt;&gt;</code> можно использовать в качестве возвращаемого функцией значения — указатель перемещается, а не копируется.</p>
          <p>Чтобы явно переместить значение из именованного объекта, который больше заведомо не будет использоваться, мы можем привести его к типу <emphasis>r</emphasis>-значения либо с помощью <code>static_cast&lt;X&amp;&amp;&gt;</code>, либо путем вызова функции <code>std::move()</code>:</p>
          <p>
            <code>X x1;</code>
          </p>
          <p>
            <code>X x2 = std::move(x1);</code>
          </p>
          <p>
            <code>X x3 = static_cast&lt;X&amp;&amp;&gt;(x2);</code>
          </p>
          <p>Это особенно удобно, когда требуется переместить значение параметра в локальную переменную или переменную-член без копирования, потому что хотя параметр, являющийся ссылкой на <emphasis>r</emphasis>-значение, и может связываться с <emphasis>r</emphasis>-значениями, но внутри функции он трактуется как <emphasis>l</emphasis>-значение:</p>
          <p>
            <code>void do_stuff(X&amp;&amp; x_) {</code>
          </p>
          <p>
            <code> X a(x_); &#8592;</code>
            <strong>Копируется</strong>
          </p>
          <p>
            <code> X b(std::move(x_)); &#8592;</code>
            <strong>Перемещается</strong>
          </p>
          <p>
            <code>}              &#9474;</code>
            <strong><emphasis>r</emphasis>-значение связывается</strong>
          </p>
          <p>
            <code>do_stuff(X());&#8592;&#9496;</code>
            <strong>со ссылкой на</strong>
            <emphasis>
              <strong>r</strong>
            </emphasis>
            <strong>-значение</strong>
          </p>
          <p>
            <code>X x;         &#9474;</code>
            <strong>Ошибка,</strong>
            <emphasis>
              <strong>l</strong>
            </emphasis>
            <strong>-значение нельзя связывать</strong>
          </p>
          <p>
            <code>do_stuff(x);&#8592;&#9496;</code>
            <strong>со ссылкой на</strong>
            <emphasis>
              <strong>r</strong>
            </emphasis>
            <strong>-значение</strong>
          </p>
          <p>Семантика перемещения сплошь и рядом используется в библиотеке Thread Library — и в случаях, когда копирование не имеет смысла, но сами ресурсы можно передавать, и как оптимизация, чтобы избежать дорогостоящего копирования, когда исходный объект все равно будет уничтожен. Один пример мы видели в разделе 2.2, где <code>std::move()</code> использовалась для передачи экземпляра <code>std::unique_ptr&lt;&gt;</code> новому потоку, а второй — в разделе 2.3, когда рассматривали передачу владения потоком от одного объекта <code>std::thread</code> другому.</p>
          <p>Ни один из классов <code>std::thread</code>, <code>std::unique_lock&lt;&gt;</code>, <code>std::future&lt;&gt;</code>, <code>std::promise&lt;&gt;</code>, <code>std::packaged_task&lt;&gt;</code> не допускает копирования, но в каждом из них имеется перемещающий конструктор, который позволяет передавать ассоциированный ресурс другому экземпляру и возвращать объекты этих классов из функций. Объекты классов <code>std::string</code> и <code>std::vector&lt;&gt;</code> можно копировать, как и раньше, но дополнительно они обзавелись перемещающими конструкторами и перемещающими операторами присваивания, чтобы избежать копирования данных из <emphasis>r</emphasis>-значений.</p>
          <p>Стандартная библиотека С++ никогда не делает ничего с объектом, который был явно перемещён в другой объект, кроме его уничтожения или присваивания <emphasis>ему</emphasis> значения (путем копирования или, что более вероятно, перемещения). Однако рекомендуется учитывать в инвариантах класса состояние перемещен-из. Например, экземпляр <code>std::thread</code>, содержимое которого перемещено, эквивалентен объекту <code>std::thread</code>, сконструированному по умолчанию, а экземпляр <code>std::string</code>, бывший источником перемещения, все же находится в согласованном состоянии, хотя не дается никаких гарантий относительно того, что это за состояние (в терминах длины строки или содержащихся в ней символов).</p>
        </section>
        <section>
          <title>
            <p>А.1.2. Ссылки на <emphasis>r</emphasis>-значения и шаблоны функций</p>
          </title>
          <p>Еще один нюанс имеет отношение к использованию ссылок на <emphasis>r</emphasis>-значения в качестве параметров шаблона функции: если параметр функции — ссылка на <emphasis>r</emphasis>-значение типа параметра шаблона, механизм автоматического выведения типа аргумента шаблона заключает, что тип — это ссылка на <emphasis>l</emphasis>-значение, если функции передано <emphasis>l</emphasis>-значение, или обычный не-ссылочный тип, если передано <emphasis>r</emphasis>-значение. Фраза получилась довольно запутанной, поэтому приведём пример. Рассмотрим такую функцию:</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>void foo(T&amp;&amp; t) {}</code>
          </p>
          <p>Если при вызове передать ей <emphasis>r</emphasis>-значение, как показано ниже, то в качестве <code>T</code> выводится тип этого значения:</p>
          <p>
            <code>foo(42);</code>
          </p>
          <p>
            <code>foo(3.14159);</code>
          </p>
          <p>
            <code>fоо(std::string());</code>
          </p>
          <p>Но если вызвать <code>foo</code>, передав <emphasis>l-значение</emphasis>, то механизм выведения типа решит, что <code>T</code> — ссылка на <emphasis>l</emphasis>-значение:</p>
          <p>
            <code>int i = 42;</code>
          </p>
          <p>
            <code>foo(i);</code>
          </p>
          <p>Поскольку объявлено, что параметр функции имеет тип <code>T&amp;&amp;</code>, то получается, что это ссылка на ссылку, и такая конструкция трактуется как обычная одинарная ссылка. Таким образом, сигнатура функции <code>foo&lt;int&amp;&gt;()</code> такова:</p>
          <p>
            <code>void foo&lt;int&amp;&gt;(int&amp; t);</code>
          </p>
          <p>Это позволяет одному шаблону функции принимать параметры, являющиеся как <emphasis>l</emphasis>-, так и <emphasis>r</emphasis>-значениями. В частности, это используется в конструкторе <code>std::thread</code> (см. разделы 2.1 и 2.2), чтобы в случае, когда переданный допускающий вызов объект является <emphasis>r</emphasis>-значением, его можно было бы не копировать, а переместить во внутреннюю память.</p>
        </section>
      </section>
      <section>
        <title>
          <p>А.2. Удаленные функции</p>
        </title>
        <p>Иногда операция копирования класса лишена смысла. Типичный пример — <code>std::mutex</code>. Действительно, что должно было бы получиться в результате копирования мьютекса? Другой пример — <code>std::unique_lock&lt;&gt;</code>, экземпляр этого класса является единственным владельцем удерживаемой им блокировки. Честное копирование в этом случае означало бы, что у блокировки два владельца, а это противоречит определению. Передача владения, описанная в разделе А.1.2, имеет смысл, но это не копирование. Уверен, вы назовете и другие примеры.</p>
        <p>Стандартная идиома предотвращения копирования класса хорошо известна — объявить копирующий конструктор и копирующий оператор присваивания закрытыми и не предоставлять их реализации. Если теперь какой-нибудь внешний по отношению к классу код попытается скопировать объект такого класса, то произойдёт ошибка на этапе компиляции, а если то же самое попытается сделать член класса или его друг, — то ошибка на этапе компоновки (так как реализации отсутствуют):</p>
        <p>
          <code>class no_copies {</code>
        </p>
        <p>
          <code>public:</code>
        </p>
        <p>
          <code> no_copies(){}</code>
        </p>
        <empty-line/>
        <p>
          <code>private:</code>
        </p>
        <p>
          <code> no_copies(no_copies const&amp;); &#8592;</code>
          <strong>Реализаций нет</strong>
        </p>
        <p>
          <code> no_copies&amp; operator=(no_copies const&amp;);</code>
        </p>
        <p>
          <code>};</code>
        </p>
        <empty-line/>
        <p>
          <code>no_copies a; &#8592;</code>
          <strong>He компилируется</strong>
        </p>
        <p>
          <code>no_copies b(a);</code>
        </p>
        <p>Комитет, разрабатывавший стандарт C++11, конечно, знал об этой идиоме, но счел ее не совсем честным приёмом. Поэтому было решено предоставить более общий механизм, применимый и к другим случаям: объявить функцию <emphasis>удаленной</emphasis>, включив в ее объявление конструкцию <code>= delete</code>. Тогда класс <code>no_copies</code> можно записать в виде:</p>
        <p>
          <code>class no_copies {</code>
        </p>
        <p>
          <code>public:</code>
        </p>
        <p>
          <code> no_copies() {}</code>
        </p>
        <p>
          <code> no_copies(no_copies const&amp;) = delete;</code>
        </p>
        <p>
          <code> no_copies&amp; operator=(no_copies const&amp;) = delete;</code>
        </p>
        <p>
          <code>};</code>
        </p>
        <p>Это гораздо нагляднее и четко выражает намерения автора. Кроме того, компилятор может в этом случае выдать более понятное сообщение об ошибке, и к тому же при попытке скопировать объект внутри функции-члена класса ошибка произойдёт уже на этапе компиляции, а не компоновки.</p>
        <p>Если, удалив копирующие конструктор и оператор присваивания, вы явно напишете перемещающие конструктор и оператор присваивания, то класс будет допускать только перемещение — как, например, <code>std::thread</code> и <code>std::unique_lock&lt;&gt;</code>. В следующем листинге приведен пример такого класса.</p>
        <empty-line/>
        <p><strong>Листинг А.2.</strong> Простой тип, допускающий только перемещение</p>
        <p>
          <code>class move_only {</code>
        </p>
        <p>
          <code> std::unique_ptr&lt;my_class&gt; data;</code>
        </p>
        <empty-line/>
        <p>
          <code>public:</code>
        </p>
        <p>
          <code> move_only(const move_only&amp;) = delete;</code>
        </p>
        <p>
          <code> move_only(move_only&amp;&amp; other):</code>
        </p>
        <p>
          <code>  data(std::move(other.data)) {}</code>
        </p>
        <p>
          <code> move_only&amp; operator=(const move_only&amp;) = delete;</code>
        </p>
        <p>
          <code> move_only&amp; operator=(move_only&amp;&amp; other) {</code>
        </p>
        <p>
          <code>  data = std::move(other.data);</code>
        </p>
        <p>
          <code>  return *this;</code>
        </p>
        <p>
          <code> }</code>
        </p>
        <p>
          <code>};</code>
        </p>
        <empty-line/>
        <p>
          <code>move_only m1;     &#9474;</code>
          <strong>Ошибка, копирующий конструктор объявлен</strong>
        </p>
        <p>
          <code>move_only m2(m1);&#8592;&#9496;</code>
          <strong>удаленным</strong>
        </p>
        <p>
          <code>move_only m3(std::move(m1));&#8592;&#9488;</code>
          <strong>правильно, имеется переме-</strong>
        </p>
        <p>
          <code>                             &#9474;</code>
          <strong>щающий конструктор</strong>
        </p>
        <p>Объекты, допускающие только перемещение, можно передавать функциям в качестве параметров и возвращать из функций, но если вы захотите переместить содержимое <emphasis>l</emphasis>-значения, то должны будете выразить свое намерение явно, воспользовавшись функцией <code>std::move()</code> или оператором <code>static_cast&lt;T&amp;&amp;&gt;</code>.</p>
        <p>Спецификатор <code>= delete</code> можно задать для любой функции, а не только для копирующего конструктора и оператора присваивания. Тем самым вы ясно даете понять, что функция отсутствует. Но это еще не все — удаленная функция участвует в разрешении перегрузки, как любая другая, и вызывает ошибку компиляции, только если будет выбрана. Этим можно воспользоваться для исключения некоторых перегруженных вариантов. Например, если функция принимает параметр типа <code>short</code>, то сужение типа <code>int</code> можно предотвратить, написав перегруженный вариант, который принимает <code>int</code>, и объявив его удаленным:</p>
        <p>
          <code>void foo(short);</code>
        </p>
        <p>
          <code>void foo(int) = delete;</code>
        </p>
        <p>Любую попытку вызвать <code>foo</code> с параметром типа <code>int</code> компилятор встретит в штыки, так что вызывающей программе придётся явно привести параметр к типу <code>short</code>:</p>
        <p>
          <code>foo(42); &#8592;</code>
          <strong>Ошибка, перегрузка для int удалена</strong>
        </p>
        <p>
          <code>foo((short)42); &#8592;</code>
          <strong>Правильно</strong>
        </p>
      </section>
      <section>
        <title>
          <p>А.3. Умалчиваемые функции</p>
        </title>
        <p>Если механизм удаленных функций позволяет явно объявить, что функция не реализована, то назначение умалчиваемых (defaulted) функций прямо противоположное - это средство указать, что компилятор должен автоматически сгенерировать реализацию функции «по умолчанию». Разумеется, это можно делать только для функций, которые компилятор и так генерирует: конструкторов, деструкторов, копирующих и перемещающих конструкторов, копирующих и перемещающих операторов присваивания.</p>
        <p>Зачем это может понадобиться? Есть несколько причин.</p>
        <p>• <emphasis>Чтобы изменить видимость функции.</emphasis> По умолчанию генерируемые компилятором функции открыты. Если требуется, чтобы они были защищенными или даже закрытыми, то писать их придётся самостоятельно. Но объявив функцию умалчиваемой, вы можете заставить компилятор сгенерировать ее и одновременно изменить уровень доступа.</p>
        <p>• <emphasis>Для документирования.</emphasis> Если сгенерированной компилятором версии достаточно, то имеет смысл так прямо и сказать. Тогда всякий, кто впоследствии будет читать код, поймёт, что это сделано намеренно.</p>
        <p>• <emphasis>Чтобы заставить компилятор сгенерировать функцию, которую в противном случае он не стал бы генерировать.</emphasis> Обычно это касается конструкторов по умолчанию, которые автоматически генерируются, только если нет ни одного определенного пользователем конструктора. Если вы хотите, например, определить свой копирующий конструктор, то, объявив конструктор по умолчанию умалчиваемым, заставите компилятор сгенерировать его.</p>
        <p>• <emphasis>Чтобы сделать деструктор виртуальным и при этом генерируемым компилятором.</emphasis></p>
        <p>• <emphasis>Чтобы сгенерировать специальный вариант копирующего конструктора, например, принимающий параметр по неконстантной ссылке</emphasis> (по умолчанию генерируется конструктор, принимающий константную ссылку).</p>
        <p>• <emphasis>Чтобы воспользоваться специальными свойствами сгенерированных компилятором функций, который теряются, если вы сами пишете реализацию.</emphasis> Подробнее об этом чуть ниже.</p>
        <p>Умалчиваемые функции объявляются путем добавления спецификатора <code>= default</code>, например:</p>
        <p>
          <code>class Y {</code>
        </p>
        <p>
          <code>private:</code>
        </p>
        <p>
          <code> Y() = default; &#8592;</code>
          <strong>Изменяем видимость</strong>
        </p>
        <empty-line/>
        <p>
          <code>public:</code>
        </p>
        <p>
          <code> Y(Y&amp;) = default; &#8592;</code>
          <strong>Принимаем не-const ссылку</strong>
        </p>
        <p>
          <code> T&amp; operator=(const Y&amp;) = default;&#8592;&#9488;</code>
          <strong>объявляем умалчиваемой</strong>
        </p>
        <p>
          <code>                                   &#9474;</code>
          <strong>для документирования</strong>
        </p>
        <p>
          <code>protected:</code>
        </p>
        <p>
          <code> virtual ~Y() = default; &#8592;</code>
          <strong>Изменяем видимость и добавляем virtual</strong>
        </p>
        <p>
          <code>};</code>
        </p>
        <p>Выше я упомянул, что сгенерированные компилятором функции обладают специальными свойствами, которые невозможно получить от версии, написанной пользователем. Самое существенное отличие заключается в том, что сгенерированная компилятором функция может быть <emphasis>тривиальной</emphasis>. Отсюда вытекает ряд следствий.</p>
        <p>• Объекты с тривиальными копирующим конструктором, копирующим оператором присваивания и деструктором можно копировать с помощью <code>memcpy</code> или <code>memmove</code>.</p>
        <p>• Литеральные типы, используемые в <code>constexpr</code>-функциях (см. раздел А.4) обязаны обладать тривиальными конструктором, копирующим конструктором и деструктором.</p>
        <p>• Классы с тривиальными конструктором по умолчанию, копирующим конструктором, копирующим оператором присваивания и деструктором можно использовать в объединении (<code>union</code>), в котором определены пользовательские конструктор и деструктор.</p>
        <p>• Классы с тривиальными конструктором копирующим оператором присваивания можно использовать вместе с шаблонным классом <code>std::atomic&lt;&gt;</code> (см. раздел 5.2.6), то есть передавать значения такого типа атомарным операциям.</p>
        <p>Одного объявления функции со спецификатором <code>= default</code> недостаточно, чтобы сделать ее тривиальной, для этого класс должен удовлетворять всем прочим условиям, при которых соответствующая функция будет тривиальной. Однако явно написанная пользователем функция не будет тривиальной <emphasis>никогда</emphasis>.</p>
        <p>Второе различие между классами с функциями, сгенерированными компилятором и написанными пользователем, заключается в том, что класс без написанных пользователем конструкторов может быть <emphasis>агрегатным</emphasis> и, стало быть, допускать инициализацию с помощью агрегатного инициализатора:</p>
        <p>
          <code>struct aggregate {</code>
        </p>
        <p>
          <code> aggregate() = default;</code>
        </p>
        <p>
          <code> aggregate(aggregate const&amp;) = default;</code>
        </p>
        <p>
          <code> int a;</code>
        </p>
        <p>
          <code> double b;</code>
        </p>
        <p>
          <code>};</code>
        </p>
        <p>
          <code>aggregate x={42, 3.141};</code>
        </p>
        <p>В данном случае <code>x.a</code> инициализируется значением <code>42</code>, a <code>x.b</code> — значением <code>3.141</code>.</p>
        <p>Третье различие малоизвестно и относится только к конструктору по умолчанию, да и то лишь в классах, удовлетворяющих определенному условию. Рассмотрим такой класс:</p>
        <p>
          <code>struct X {</code>
        </p>
        <p>
          <code> int а;</code>
        </p>
        <p>
          <code>};</code>
        </p>
        <p>Если экземпляр класса <code>X</code> создается без инициализатора, то содержащееся в нем значение (<code>а</code>) типа <code>int</code> <emphasis>инициализируется по умолчанию</emphasis>. Если у объекта статический класс памяти, то значение инициализируется нулем, в противном случае начальное значение произвольно, что может привести к неопределённому поведению, если программа обращается к объекту раньше, чем ему будет присвоено значение:</p>
        <p>
          <code>X x1; &#8592;</code>
          <strong>значение x1.a не определено</strong>
        </p>
        <p>С другой стороны, если инициализировать экземпляр <code>X</code> путем явного вызова конструктора по умолчанию, то он получит значение 0:</p>
        <p>
          <code>X x2 = X(); &#8592;</code>
          <strong>x2.а == 0</strong>
        </p>
        <p>Это странное свойство распространяется также на базовые классы и члены классов. Если в классе имеется сгенерированный компилятором конструктор по умолчанию, и каждый член самого класса и всех его базовых классов также имеет сгенерированный компилятором конструктор по умолчанию, то переменные-члены самого класса и его базовых классов, принадлежащие встроенным типам, также будут иметь неопределенное значение или будут инициализированы нулями в зависимости от того, вызывался ли явно для внешнего класса его конструктор по умолчанию.</p>
        <p>У этого замысловатого и потенциально чреватого ошибками правила есть тем не менее применения, а, если вы пишете конструктор по умолчанию самостоятельно, то это свойство утрачивается; данные-члены (например, <code>а</code>) либо всегда инициализируются (коль скоро вы указали значение или явно вызвали конструктор по умолчанию), либо вообще не инициализируются (если вы этого не сделали):</p>
        <p>
          <code>X::X() : а() {}   &#8592;</code>
          <strong>всегда а == 0</strong>
        </p>
        <p>
          <code>X::X() : а(42) {} &#8592;</code>
          <strong>всегда а == 42</strong>
        </p>
        <p>
          <code>X::X() {}         &#8592;</code>
          <strong>(1)</strong>
        </p>
        <p>Если инициализация <code>а</code> при конструировании <code>X</code> не производится (как в третьем примере <strong>(1)</strong>), то <code>a</code> остается неинициализированным для нестатических экземпляров <code>X</code> и инициализируется нулем для экземпляров <code>X</code> со статическим временем жизни.</p>
        <p>Обычно, если вы вручную напишете хотя бы один конструктор, то компилятор не станет генерировать конструктор по умолчанию. Стало быть, если он вам все-таки нужен, его придётся написать самостоятельно, а тогда это странное свойство инициализации теряется. Однако явно объявив конструктор умалчиваемым, вы можете заставить компилятор сгенерировать конструктор по умолчанию и сохранить это свойство:</p>
        <p>
          <code>X::X() = default;</code>
        </p>
        <p>Это свойство используется в атомарных типах (см. раздел 5.2), в которых конструктор по умолчанию явно объявлен умалчиваемым. У таких типов начальное значение не определено, если только не выполняется одно из следующих условий: (а) задан статический класс памяти (тогда значение инициализируется нулем); (b) для инициализации нулем явно вызван конструктор по умолчанию; (с) вы сами явно указали начальное значение. Отметим, что в атомарных типах конструктор для инициализации значением объявлен как <code>constexpr</code> (см. раздел А.4), чтобы разрешить статическую инициализацию.</p>
      </section>
      <section>
        <title>
          <p>А.4. <code>constexpr</code>-функции</p>
        </title>
        <section>
          <p>Целые литералы, например <code>42</code>, — это <emphasis>константные выражения</emphasis>. Равно как и простые арифметические выражения, например <code>23*2-4</code>. Частью константного выражения могут быть также <code>const</code>-переменные любого целочисленного типа, которые сами инициализированы константным выражением:</p>
          <p>
            <code>const int i = 23;</code>
          </p>
          <p>
            <code>const int two_i = i * 2;</code>
          </p>
          <p>
            <code>const int four = 4;</code>
          </p>
          <p>
            <code>const int forty_two = two_i - four;</code>
          </p>
          <p>Помимо использования константных выражений для инициализации переменных, которые могут использоваться в других константных выражениях, есть ряд случаев, где разрешается применять <emphasis>только</emphasis> константные выражения.</p>
          <p>• Задание границ массива:</p>
          <p>
            <code>int bounds = 99;   &#9474;</code>
            <strong>Ошибка, bounds — не константное</strong>
          </p>
          <p>
            <code>int array[bounds];&#8592;&#9496;</code>
            <strong>выражение</strong>
          </p>
          <p>
            <code>const int bounds2 = 99;&#9474;</code>
            <strong>Правильно, bounds2 — константное</strong>
          </p>
          <p>
            <code>int array2[bounds2];  &#8592;&#9496;</code>
            <strong>выражение</strong>
          </p>
          <p>• Задание значения параметра шаблона, не являющего типом:</p>
          <p>
            <code>template&lt;unsigned size&gt;</code>
          </p>
          <p>
            <code>struct test {};  &#9474;</code>
            <strong>Ошибка, bounds —</strong>
          </p>
          <p>
            <code>                 &#9474;</code>
            <strong>не константное</strong>
          </p>
          <p>
            <code>test&lt;bounds&gt; is;&#8592;&#9496;</code>
            <strong>выражение</strong>
          </p>
          <p>
            <code>test&lt;bounds2 &gt; ia2;&#8592;&#9488;</code>
            <strong>Правильно, bounds2 —</strong>
          </p>
          <p>
            <code>                    &#9474;</code>
            <strong>константное выражение</strong>
          </p>
          <p>• Задание непосредственно в определении класса инициализатора для переменной-члена класса целочисленного типа со спецификаторами <code>static const</code>:</p>
          <p>
            <code>class X {</code>
          </p>
          <p>
            <code> static const int the_answer = forty_two;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>• Употребление в инициализаторах встроенных типов или агрегатов, применяемых для статической инициализации:</p>
          <p>
            <code>struct my_aggregate {</code>
          </p>
          <p>
            <code> int a;</code>
          </p>
          <p>
            <code> int b;</code>
          </p>
          <p>
            <code>}; </code>
          </p>
          <p>
            <code>static my_aggregate ma1 =&#9474;</code>
            <strong>Статическая</strong>
          </p>
          <p>
            <code> { forty_two, 123 };    &#8592;&#9496;</code>
            <strong>инициализация</strong>
          </p>
          <p>
            <code>int dummy = 257;                          &#9474;</code>
            <strong>Динамическая</strong>
          </p>
          <p>
            <code>static my_aggregate ma2 = {dummy, dummy};&#8592;&#9496;</code>
            <strong>инициализация</strong>
          </p>
          <p>Такая статическая инициализация полезна для предотвращения зависимости от порядка инициализации и состояний гонки.</p>
          <p>Всё это не ново и было описано еще в стандарте С++ 1998 года. Но в новом стандарте появилось и дополнение в части константных выражений — ключевое слово <code>constexpr</code>.</p>
          <p>Ключевое слово <code>constexpr</code> применяется главным образом как модификатор функции. Если параметр и возвращаемое функцией значение удовлетворяют определенным условиям, а тело функции достаточно простое, то в ее объявлении можно указать <code>constexpr</code> и использовать функцию в константных выражениях. Например:</p>
          <p>
            <code>constexpr int square(int x) {</code>
          </p>
          <p>
            <code> return x*x;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <code>int array[square(5)];</code>
          </p>
          <p>В этом случае массив <code>array</code> будет содержать 25 значений, потому что функция <code>square</code> объявлена как <code>constexpr</code>. Конечно, из того, что функцию <emphasis>можно</emphasis> использовать в константном выражении, еще не следует, что любой случай ее использования автоматически будет константным выражением:</p>
          <p>
            <code>int dummy = 4;           </code>
            <strong>(1) Ошибка, dummy — не константное</strong>
          </p>
          <p>
            <code>int array[square(dummy)];&#8592;&#9496;</code>
            <strong>выражение</strong>
          </p>
          <p>В этом примере <code>dummy</code> не является константным выражением <strong>(1)</strong>, поэтому не является таковым и <code>square(dummy)</code>. Это обычный вызов функции, и, следовательно, для задания границ массива array его использовать нельзя.</p>
        </section>
        <section>
          <title>
            <p>А.4.1. <code>constexpr</code> и определенные пользователем типы</p>
          </title>
          <p>До сих пор мы употребляли в примерах только встроенные типы — такие, как <code>int</code>. Но в новом стандарте С++ допускаются константные выражения любого типа, удовлетворяющего требованиям, предъявляемым к <emphasis>литеральному типу</emphasis>. Чтобы тип класса можно было считать литеральным, должны быть выполнены все следующие условия:</p>
          <p>• в классе должен существовать тривиальный копирующий конструктор;</p>
          <p>• в классе должен существовать тривиальный деструктор;</p>
          <p>• все нестатические переменные-члены данного класса и его базовых классов должны иметь тривиальный тип;</p>
          <p>• в классе должен существовать либо тривиальный конструктор по умолчанию, либо <code>constexpr</code>-конструктор, отличный от копирующего конструктора.</p>
          <p>О <code>constexpr</code>-конструкторах мы поговорим чуть ниже. А пока обратимся к классам с тривиальным конструктором по умолчанию. Пример такого класса приведён ниже:</p>
          <p>
            <code>class CX {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> int а;</code>
          </p>
          <p>
            <code> int b;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> CX() = default; &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> CX(int a_, int b_) : &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  a(a_), b(b_) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> int get_a() const {</code>
          </p>
          <p>
            <code>  return a;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> int get_b() const {</code>
          </p>
          <p>
            <code>  return b;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> int foo() const {</code>
          </p>
          <p>
            <code>  return a + b;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Здесь мы явно объявили конструктор по умолчанию <strong>(1)</strong> <emphasis>умалчиваемым</emphasis> (см. раздел А.3), чтобы сохранить его тривиальность, несмотря на наличие определённого пользователем конструктора <strong>(2)</strong>. Таким образом, этот тип удовлетворяет всем требованиям к литеральному типу и, значит, его можно использовать в константных выражениях. К примеру, можно написать <code>constexpr</code>-функцию, которая создает новые экземпляры этого класса:</p>
          <p>
            <code>constexpr CX create_cx() {</code>
          </p>
          <p>
            <code> return CX();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Можно также написать простую <code>constexpr</code>-функцию, которая копирует свой параметр:</p>
          <p>
            <code>constexpr CX clone(CX val) {</code>
          </p>
          <p>
            <code> return val;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Но это практически и всё, что можно сделать, — <code>constexpr</code>-функции разрешено вызывать только другие <code>constexpr</code>-функции. Тем не менее, допускается применять спецификатор <code>constexpr</code> к функциям-членам и конструкторам CX:</p>
          <p>
            <code>class CX {</code>
          </p>
          <p>
            <code>private:</code>
          </p>
          <p>
            <code> int а;</code>
          </p>
          <p>
            <code> int b;</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> CX() = default;</code>
          </p>
          <p>
            <code> constexpr CX(int a_, int b_): a(a_), b(b_) {}</code>
          </p>
          <empty-line/>
          <p>
            <code> constexpr int get_a() const { &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>  return a;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> constexpr int get_b() { &#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code>  return b;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <empty-line/>
          <p>
            <code> constexpr int foo() {</code>
          </p>
          <p>
            <code>  return a + b;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Отметим, что теперь квалификатор <code>const</code> в функции <code>get_a()</code> <strong>(1)</strong> избыточен, потому что он и так подразумевается ключевым словом <code>constexpr</code>. Функция <code>get_b()</code> достаточно «константная» несмотря на то, что квалификатор <code>const</code> опущен <strong>(2)</strong>. Это дает возможность строить более сложные <code>constexpr</code>-функции, например:</p>
          <p>
            <code>constexpr CX make_cx(int a) {</code>
          </p>
          <p>
            <code> return CX(a, 1);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>constexpr CX half_double(CX old) {</code>
          </p>
          <p>
            <code> return CX(old.get_a()/2, old.get_b()*2);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>constexpr int foo_squared(CX val) {</code>
          </p>
          <p>
            <code> return square(val.foo());</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>int array[foo_squared(</code>
          </p>
          <p>
            <code> half_double(make_cx(10)))]; &#8592;</code>
            <strong>49 элементов</strong>
          </p>
          <p>Всё это, конечно, интересно, но уж слишком много усилий для того, чтобы всего лишь вычислить границы массива или значение целочисленной константы. Основное же достоинство константных выражений и <code>constexpr</code>-функций в контексте пользовательских типов заключается в том, что объекты литерального типа, инициализированные константным выражением, инициализируются статически и, следовательно, не страдают от проблем, связанных с зависимостью от порядка инициализации и гонок.</p>
          <p>
            <code>CX si = half_double(CX(42, 19));</code>
          </p>
          <p>Это относится и к конструкторам. Если конструктор объявлен как <code>constexpr</code>, а его параметры — константные выражения, то такая инициализация считается <emphasis>константной инициализацией</emphasis> и происходит на этапе статической инициализации. <emphasis>Это одно из наиболее важных изменений в стандарте C++11 с точки зрения параллелизма</emphasis>: разрешив статическую инициализацию для определенных пользователем конструкторов, мы предотвращаем состояния гонки во время инициализации, поскольку объекты гарантированно инициализируются до начала выполнения программы.</p>
          <p>Особенно существенно это для таких классов, как <code>std::mutex</code> (см. раздел 3.2.1) и <code>std::atomic&lt;&gt;</code> (см. раздел 5.2.6), поскольку иногда мы хотим, чтобы некий глобальный объект синхронизировал доступ к другим переменным, но так, чтобы не было гонок при доступе к нему самому. Это было бы невозможно, если бы конструктор мьютекса мог стать жертвой гонки, поэтому конструктор по умолчанию в классе <code>std::mutex</code> объявлен как <code>constexpr</code>, чтобы инициализация мьютекса всегда производилась на этапе статической инициализации.</p>
        </section>
        <section>
          <title>
            <p>А.4.2. <code>constexpr</code>-объекты</p>
          </title>
          <p>До сих пор мы говорили о применении <code>constexpr</code> к функциям. Но этот спецификатор можно применять и к объектам. Чаще всего, так делают для диагностики; компилятор проверяет, что объект инициализирован константным выражением, <code>constexpr</code>-конструктором или агрегатным инициализатором, составленным из константных выражений. Кроме того, объект автоматически объявляется как <code>const</code>:</p>
          <p>
            <code>constexpr int i = 45;&#8592;</code>
            <strong>Правильно</strong>
          </p>
          <p>
            <code>constexpr std::string s("hello");&#8592;&#9488;</code>
            <strong>Ошибка, std::string —</strong>
          </p>
          <p>
            <code>int foo();                        &#9474;</code>
            <strong>не литеральный тип</strong>
          </p>
          <p>
            <code>constexpr int j = foo();&#8592;</code>
            <strong>Ошибка, foo() не объявлена как constexpr</strong>
          </p>
        </section>
        <section>
          <title>
            <p>A.4.3. Требования к <code>constexpr</code>-функциям</p>
          </title>
          <p>Чтобы функцию можно было объявить как <code>constexpr</code>, она должна удовлетворять нескольким требованиям. Если эти требования не выполнены, компилятор сочтет наличие спецификатора <code>constexpr</code> ошибкой. Требования таковы:</p>
          <p>• все параметры должны иметь литеральный тип;</p>
          <p>• возвращаемое значение должно иметь литеральный тип;</p>
          <p>• тело функции может содержать только предложение <code>return</code> и ничего больше;</p>
          <p>• выражение в предложении <code>return</code> должно быть константным;</p>
          <p>• любой конструктор или оператор преобразования, встречающийся в выражении для вычисления возвращаемого значения, должен быть объявлен как <code>constexpr</code>.</p>
          <p>На самом деле, это вполне понятные требования: у компилятора должна быть возможность встроить вызов функции в константное выражение, и при этом оно должно остаться константным. Кроме того, запрещается что-либо изменять; <code>constexpr</code>-функции являются <emphasis>чистыми</emphasis>, то есть не имеют побочных эффектов.</p>
          <p>К <code>constexpr</code>-функциям, являющимся членами класса, предъявляются дополнительные требования:</p>
          <p>• <code>constexpr</code> функции-члены не могут быть виртуальными;</p>
          <p>• класс, членом которого является функция, должен иметь литеральный тип.</p>
          <p>Для <code>constexpr</code>-конструкторов действуют другие правила:</p>
          <p>• тело конструктора должно быть пустым;</p>
          <p>• все базовые классы должны быть инициализированы;</p>
          <p>• все нестатические данные-члены должны быть инициализированы;</p>
          <p>• все выражения, встречающиеся в списке инициализации членов, должны быть константными;</p>
          <p>• конструкторы, выбранные для инициализации данных-членов и базовых классов, должны быть <code>constexpr</code>-конструкторами;</p>
          <p>• все конструкторы и операторы преобразования, используемые для конструирования данных-членов и базовых классов в соответствующем выражении инициализации, должны быть объявлены как <code>constexpr</code>.</p>
          <p>Это тот же набор правил, что и для функций, с тем отличием, что возвращаемого значения нет, а, значит, нет и предложения <code>return</code>. Вместо возврата значения конструктор инициализирует базовые классы и данные-члены в списке инициализации членов. Тривиальные копирующие конструкторы неявно объявлены как <code>constexpr</code>.</p>
        </section>
        <section>
          <title>
            <p>А.4.4. <code>constexpr</code> и шаблоны</p>
          </title>
          <p>Спецификатор <code>constexpr</code> в объявлении шаблона функции или функции-члене шаблонного класса игнорируется, если типы параметров и возвращаемого значения для данной конкретизации шаблона не являются литеральными. Это позволяет писать шаблоны функций, которые становятся <code>constexpr</code>-функциями, если параметры шаблона имеют подходящие типы, и обычными встраиваемыми функциями в противном случае. Например:</p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>constexpr T sum(T a, T b) {</code>
          </p>
          <p>
            <code> return a + b;</code>
          </p>
          <p>
            <code>}                             &#9474;</code>
            <strong>Правильно, sum&lt;int&gt;</strong>
          </p>
          <p>
            <code>constexpr int i = sum(3, 42);&#8592;&#9496;</code>
            <strong>constexpr</strong>
          </p>
          <p>
            <code>std::string s =</code>
          </p>
          <p>
            <code> sum(std::string("hello"),   &#9474;</code>
            <strong>Правильно, но sum&lt;std::string&gt;</strong>
          </p>
          <p>
            <code>     std::string(" world"));&#8592;&#9496;</code>
            <strong>He constexpr</strong>
          </p>
          <p>Функция должна удовлетворять также всем остальным требованиям, предъявляемым к <code>constexpr</code>-функциям. Нельзя включить в тело шаблона функции, объявленного как <code>constexpr</code>, несколько предложений только потому, что это шаблон; компилятор сочтет это ошибкой.</p>
        </section>
      </section>
      <section>
        <title>
          <p>А.5. Лямбда-функции</p>
        </title>
        <section>
          <p>Лямбда-функции — одно из самых интересных новшеств в стандарте C++11, потому что они позволяют существенно упростить код и исключить многие стереотипные конструкции, которые применяются при написании объектов, допускающих вызов. Синтаксис лямбда-функций в C++11 позволяет определить функцию в той точке выражения, где она необходима. Это отличное решение, например, для передачи предикатов функциям ожидания из класса <code>std::condition_variable</code> (как в примере из раздела 4.1.1), потому что дает возможность кратко выразить семантику в терминах доступных в данной точке переменных, а не запоминать необходимое состояние в переменных-членах класса с оператором вызова.</p>
          <p>В простейшем случае <emphasis>лямбда-выражение</emphasis> определяет автономную функцию без параметров, которая может пользоваться только глобальными переменными и функциями. У нее даже нет возвращаемого значения. Такое лямбда-выражение представляет собой последовательность предложений, заключенных в фигурные скобки, которым предшествуют квадратные скобки (так называемый <emphasis>лямбда-интродуктор</emphasis>):</p>
          <p>
            <code>[] { &#8592;</code>
            <strong>Лямбда-выражение начинается с []</strong>
          </p>
          <p>
            <code> do_stuff();     &#9474;</code>
            <strong>Конец определения</strong>
          </p>
          <p>
            <code> do_more_stuff();&#9474;</code>
            <strong>лямбда-выражения</strong>
          </p>
          <p>
            <code>} ();           &#8592;&#9496;</code>
            <strong>и его вызов</strong>
          </p>
          <p>В данном случае лямбда-выражение сразу вызывается, потому что за ним следуют круглые скобки, однако это необычно. Ведь если вы хотите вызывать его напрямую, то можно было бы вообще обойтись без лямбда-выражения и записать составляющие его предложения прямо в коде. Чаще лямбда-выражение передаётся в шаблон функции, который принимает допускающий вызов объект в качестве одного из параметров. Но тогда ему, скорее всего, нужны параметры или возвращаемое значение или то и другое вместе. Если лямбда-функция принимает параметры, то их можно указать после лямбда-интродуктора с помощью списка параметров, как для обычной функции. Так, в следующем примере мы выводим все элементы вектора на <code>std::cout</code>, разделяя их символами новой строки:</p>
          <p>
            <code>std::vector&lt;int&gt; data = make_data();</code>
          </p>
          <p>
            <code>std::for_each(data.begin(), data.end(),</code>
          </p>
          <p>
            <code> [](int i){std::cout &lt;&lt; i &lt;&lt; "\n";});</code>
          </p>
          <p>С возвращаемыми значениями всё почти так же просто. Если тело лямбда-функции состоит из единственного предложения <code>return</code>, то тип возвращаемого ей значения совпадает с типом возвращаемого выражения. Например, такую простую лямбда-функцию можно было бы использовать для проверки флага, ожидаемого условной переменной <code>std::condition_variable</code> (см. раздел 4.1.1).</p>
          <empty-line/>
          <p><strong>Листинг А.4.</strong> Простая лямбда-функция с выводимым типом возвращаемого значения</p>
          <p>
            <code>std::condition_variable cond;</code>
          </p>
          <p>
            <code> bool data_ready;</code>
          </p>
          <p>
            <code> std::mutex m;</code>
          </p>
          <empty-line/>
          <p>
            <code>void wait_for_data() {</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt; lk(m);</code>
          </p>
          <p>
            <code> cond.wait(lk, []{return data_ready;}); &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Тип значения, возвращаемого лямбда-функцией, которая передана <code>cond.wait()</code> <strong>(1)</strong>, выводится из типа переменной <code>data_ready</code>, то есть совпадает с <code>bool</code>. Когда условная переменная получает сигнал, она вызывает эту лямбда-функцию, захватив предварительно мьютекс, и <code>wait()</code> возвращает управление, только если <code>data_ready</code> равно <code>true</code>.</p>
          <p>Но что если невозможно написать тело лямбда-функции, так чтобы оно содержало единственное предложение <code>return</code>? В таком случае тип возвращаемого значения следует задать явно. Это <emphasis>можно</emphasis> сделать и тогда, когда тело функции состоит из единственного предложения <code>return</code>, но <emphasis>обязательно</emphasis>, если тело более сложное. Для задания типа возвращаемого значения нужно поставить после списка параметров функции стрелку (<code>-&gt;</code>), а за ней указать тип. Если лямбда-функция не имеет параметров, то список параметров (пустой) все равно необходим, иначе задать тип возвращаемого значения невозможно. Таким образом, предикат, проверяемый условной переменной, можно записать так:</p>
          <p>
            <code>cond.wait(lk, []()-&gt;bool{ return data_ready; });</code>
          </p>
          <p>Лямбда-функции с явно заданным типом возвращаемого значения можно использовать, например, для записи сообщений в журнал или для более сложной обработки:</p>
          <p>
            <code>cond.wait(lk, []()-&gt;bool {</code>
          </p>
          <p>
            <code> if (data_ready) {</code>
          </p>
          <p>
            <code>  std::cout &lt;&lt; "Данные готовы" &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code>  return true;</code>
          </p>
          <p>
            <code> } else {</code>
          </p>
          <p>
            <code>  std::cout &lt;&lt;</code>
          </p>
          <p>
            <code>   "Данные не готовы, продолжаю ждать" &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code>  return false;</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>});</code>
          </p>
          <p>Даже такие простые лямбда-функции весьма полезны и существенно упрощают код, но их истинная мощь проявляется, когда требуется запомнить локальные переменные.</p>
        </section>
        <section>
          <title>
            <p>A.5.1. Лямбда-функции, ссылающиеся на локальные переменные</p>
          </title>
          <p>Лямбда-функции с <emphasis>лямбда-интродуктором</emphasis> вида <code>[]</code> не могут ссылаться на локальные переменные из объемлющей области видимости; им разрешено использовать только глобальные переменные и то, что передано в параметрах. Чтобы получить доступ к локальной переменной, ее нужно <emphasis>захватить</emphasis> (capture). Проще всего захватить все переменные в локальной области видимости, указав лямбда-интродуктор вида <code>[=]</code>. Теперь лямбда-функция может получить доступ к <emphasis>копиям</emphasis> локальных переменных на тот момент, когда эта функция была создана.</p>
          <p>Рассмотрим этот механизм на примере следующей простой функции:</p>
          <p>
            <code>std::function&lt;int(int)&gt; make_offseter(int offset) {</code>
          </p>
          <p>
            <code> return [=](int j){return offset+j;};</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>При каждом вызове <code>make_offseter</code> с помощью обертки <code>std::function&lt;&gt;</code> создается новый содержащий лямбда-функцию объект. Возвращенная функция добавляет указанное смещение к любому переданному ей параметру. Например, следующая программа</p>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> std::function&lt;int(int)&gt; offset_42 = make_offseter(42);</code>
          </p>
          <p>
            <code> std::function&lt;int(int)&gt; offset_123 = make_offseter(123);</code>
          </p>
          <p>
            <code> std::cout &lt;&lt;</code>
          </p>
          <p>
            <code>  offset_42(12) &lt;&lt; "," &lt;&lt; offset_123(12) &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code> std::cout &lt;&lt;</code>
          </p>
          <p>
            <code>  offset_42(12) &lt;&lt; "," &lt;&lt; offset_123(12) &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>два раза выведет числа <code>54, 135</code>, потому что функция, возвращенная после первого обращения к <code>make_offseter</code>, всегда добавляет 42 к переданному ей аргументу Напротив, функция, возвращенная после второго обращения к <code>make_offseter</code>, добавляет к своему аргументу 123. Это самый безопасный вид захвата локальных переменных — все значения копируются, поэтому лямбда-функцию можно вернуть и вызывать вне контекста функции, в которой она была создана. Но это не единственно возможное решение, можно захватывать локальные переменные и по ссылке. В таком случае попытка вызвать лямбда-функцию после того, как переменные, на которые указывают ссылки, были уничтожены в результате выхода из области видимости объемлющей их функции или блока, приведёт к неопределённому поведению, точно так же, как обращение к уничтоженной переменной в любом другом случае.</p>
          <p>Лямбда-функция, захватывающая все локальные переменные по ссылке, начинается интродуктором <code>[&amp;]</code>:</p>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> int offset = 42;                &#8592;</code>
            <strong>(1)</strong>
          </p>
          <p>
            <code> std::function&lt;int(int)&gt; offset_a =</code>
          </p>
          <p>
            <code>  [&amp;](int j){return offset + j;};&#8592;</code>
            <strong>(2)</strong>
          </p>
          <p>
            <code> offset = 123;                   &#8592;</code>
            <strong>(3)</strong>
          </p>
          <p>
            <code> std::function&lt;int(int)&gt; offset_b =</code>
          </p>
          <p>
            <code>  [&amp;](int j){return offset + j;};&#8592;</code>
            <strong>(4)</strong>
          </p>
          <p>
            <code> std::cout &lt;&lt;</code>
          </p>
          <p>
            <code>  offset_a(12) &lt;&lt; "," &lt;&lt; offset_b(12) &lt;&lt; std::endl; &#8592;</code>
            <strong>(5)</strong>
          </p>
          <p>
            <code> offset = 99;                                       &#8592;</code>
            <strong>(6)</strong>
          </p>
          <p>
            <code> std::cout &lt;&lt;</code>
          </p>
          <p>
            <code>  offset_a(12) &lt;&lt; "," &lt;&lt; offset_b(12) &lt;&lt; std::endl; &#8592;</code>
            <strong>(7)</strong>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Если функция <code>make_offseter</code> из предыдущего примера захватывала копию смещения <code>offset</code>, то функция <code>offset_a</code> в этом примере, начинающаяся интродуктором <code>[&amp;]</code>, захватывает <code>offset</code> по ссылке <strong>(2)</strong>. Неважно, что начальное значение <code>offset</code> было равно 42 <strong>(1)</strong>; результат вызова <code>offset_a(12)</code> зависит от текущего значения <code>offset</code>. Значение <code>offset</code> было изменено на 123 <strong>(3)</strong> перед порождением второй (идентичной) лямбда-функции <code>offset_b</code> <strong>(4)</strong>, но эта вторая функция снова производит захват по ссылке, поэтому результат, как и прежде, зависит от текущего значения <code>offset</code>.</p>
          <p>Теперь при печати первой строки <strong>(5)</strong>, <code>offset</code> всё еще равно 123, поэтому печатаются числа <code>133, 135</code>. Однако к моменту печати второй строки <strong>(7)</strong> <code>offset</code> стало равно 99 <strong>(6)</strong>, поэтому печатается <code>111, 111</code>. И <code>offset_a</code>, и <code>offset_b</code> прибавляют текущее значение <code>offset</code> (99) к переданному аргументу (12).</p>
          <p>Но ведь это С++, поэтому вам не обязательно выбирать между всем или ничем; вполне можно захватывать одни переменные по значению, а другие по ссылке. Более того, можно даже указывать, какие именно переменные захватить. Нужно лишь изменить лямбда-интродуктор. Если требуется <emphasis>скопировать</emphasis> все видимые переменные, кроме одной-двух, то воспользуйтесь интродуктором <code>[=]</code>, но после знака равенства перечислите переменные, захватываемые по ссылке, предпослав им знаки амперсанда. В следующем примере печатается <code>1239</code>, потому что переменная <code>i</code> копируется в лямбда-функцию, a <code>j</code> и <code>k</code> захватываются по ссылке:</p>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> int i=1234, j=5678, k=9;</code>
          </p>
          <p>
            <code> std::function&lt;int()&gt; f=[=,&amp;j,&amp;k] {return i+j+k;};</code>
          </p>
          <p>
            <code> i = 1;</code>
          </p>
          <p>
            <code> j = 2;</code>
          </p>
          <p>
            <code> k = 3;</code>
          </p>
          <p>
            <code> std::cout &lt;&lt; f() &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Можно поступить и наоборот — по умолчанию захватывать по ссылке, но некоторое подмножество переменных копировать. В таком случае воспользуйтесь интродуктором <code>[&amp;]</code>, а после знака амперсанда перечислите переменные, захватываемые по значению. В следующем примере печатается <code>5688</code>, потому что <code>i</code> захватывается по ссылке, a <code>j</code> и <code>k</code> копируются:</p>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> int i=1234, j=5678, k= 9;</code>
          </p>
          <p>
            <code> std::function&lt;int()&gt; f=[&amp;,j,k] {return i+j+k;};</code>
          </p>
          <p>
            <code> i = 1;</code>
          </p>
          <p>
            <code> j = 2;</code>
          </p>
          <p>
            <code> k = 3;</code>
          </p>
          <p>
            <code> std::cout &lt;&lt; f() &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Если требуется захватить только именованные переменные, то можно опустить знак <code>=</code> или <code>&amp;</code> и просто перечислить захватываемые переменные, предпослав знак амперсанда тем, что должны захватываться по ссылке, а не по значению. В следующем примере печатается <code>5682</code>, потому что <code>i</code> и <code>k</code> захвачены по ссылке, a <code>j</code> скопирована</p>
          <p>
            <code>int main() {</code>
          </p>
          <p>
            <code> int i=1234, j=5678, k=9;</code>
          </p>
          <p>
            <code> std::function&lt;int()&gt; f=[&amp;i, j, &amp;k] {return i+j+k;};</code>
          </p>
          <p>
            <code> i =</code>
            <code>1;</code>
          </p>
          <p>
            <code> j = 2;</code>
          </p>
          <p>
            <code> k = 3;</code>
          </p>
          <p>
            <code> std::cout &lt;&lt; f() &lt;&lt; std::endl;</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Последний способ заодно гарантирует, что захвачены только необходимые переменные, потому что ссылка на локальную переменную, отсутствующую в списке захвата, приведёт к ошибке компиляции. Выбирая этот вариант, нужно соблюдать осторожность при доступе к членам класса, если лямбда-функция погружена в функцию-член класса. Члены класса нельзя захватывать непосредственно; если к ним необходим доступ из лямбда-функции, то необходимо захватить указатель <code>this</code>, включив его в список захвата. В следующем примере лямбда-функция захватывает <code>this</code> для доступа к члену класса <code>some_data</code>:</p>
          <p>
            <code>struct X {</code>
          </p>
          <p>
            <code> int some_data;</code>
          </p>
          <empty-line/>
          <p>
            <code> void foo(std::vector&lt;int&gt;&amp; vec) {</code>
          </p>
          <p>
            <code>  std::for_each(vec.begin(), vec.end(),</code>
          </p>
          <p>
            <code>   [this](int&amp; i){ i += some_data; });</code>
          </p>
          <p>
            <code> }</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В контексте параллелизма лямбда-функции особенно полезны для задания предикатов функции <code>std::condition_variable::wait()</code> (см. раздел 4.1.1) и в сочетании с <code>std::packaged_task&lt;&gt;</code> (раздел 4.2.1) или пулами потоков для упаковки небольших задач. Их можно также передавать конструктору <code>std::thread</code> в качестве функций потока (раздел 2.1.1) и в качестве исполняемой функции в таких параллельных алгоритмах, как <code>parallel_for_each()</code> (раздел 8.5.1).</p>
        </section>
      </section>
      <section>
        <title>
          <p>А.6. Шаблоны с переменным числом параметров</p>
        </title>
        <section>
          <p>Функции с переменным числом параметров, например <code>printf</code>, используются уже давно, а теперь появились и шаблоны с переменным числом параметров (variadic templates). Такие шаблоны применяются во многих местах библиотеки С++ Thread Library. Например, конструктор <code>std::thread</code> для запуска потока (раздел 2.1.1) — это шаблон функции с переменным числом параметров, a <code>std::packaged_task&lt;&gt;</code> (раздел 4.2.2) — шаблон класса с переменным числом параметров. С точки зрения пользователя, достаточно знать, что шаблон принимает неограниченное количество параметров, но если вы хотите написать такой шаблон или просто любопытствуете, как это работает, то детали будут небезынтересны.</p>
          <p>При объявлении шаблонов с переменным числом параметров, по аналогии с обычными функциями, употребляется многоточие (<code>...</code>) в списке параметров шаблона:</p>
          <p>
            <code>template&lt;typename ... ParameterPack&gt;</code>
          </p>
          <p>
            <code>class my_template {};</code>
          </p>
          <p>Переменное число параметров допустимо и в частичных специализациях шаблона, даже если основной шаблон содержит фиксированное число параметров. Например, основной шаблон <code>std::packaged_task&lt;&gt;</code> (раздел 4.2.1) — это простой шаблон с единственным параметром:</p>
          <p>
            <code>template&lt;typename FunctionType&gt;</code>
          </p>
          <p>
            <code>class packaged_task;</code>
          </p>
          <p>Однако этот основной шаблон нигде не конкретизируется, а служит лишь основой для частичных специализаций:</p>
          <p>
            <code>template&lt;typename ReturnType, typename ... Args&gt;</code>
          </p>
          <p>
            <code>class packaged_task&lt;ReturnType(Args...)&gt;;</code>
          </p>
          <p>Именно внутри частичной специализации и содержится реальное определение класса; в главе 4 мы видели, что для объявления задачи, которая принимает параметры типа <code>std::string</code> и <code>double</code> и возвращает результат в виде объекта <code>std::future&lt;int&gt;</code>, можно написать <code>std::packaged_task&lt;int(std::string, double)&gt;</code>.</p>
          <p>На примере этого объявления демонстрируются два дополнительных свойства шаблонов с переменным числом параметров. Первое сравнительно простое: разрешается в одном объявлении задавать как обычные параметры шаблона (скажем <code>ReturnType</code>), так и переменные (<code>Args</code>). Второе свойство — это использование <code>Args...</code> в списке аргументов специализации шаблона для обозначения того, что здесь должны быть перечислены фактические типы, подставляемые вместо <code>Args</code> в точке конкретизации шаблона. На самом деле, поскольку это частичная специализация, то работает она, как сопоставление с образцом; типы, встречающиеся в контексте конкретизации, запоминаются как <code>Args</code>. Переменное множество параметров <code>Args</code> называется <emphasis>пакетом параметров</emphasis> (parameter pack), а конструкция <code>Args...</code> — расширением пакета.</p>
          <p>Как и для обычных функций с переменным числом параметров, переменная часть может быть как пустым списком, так и содержать много элементов. Например, в конкретизации <code>std::packaged_task&lt;my_class()&gt;</code> параметром <code>ReturnType</code> является <code>my_class</code>, а пакет параметров <code>Args</code> пуст. С другой стороны, в конкретизации <code>std::packaged_task&lt;void(int, double, my_class&amp;, std::string*)&gt;</code> параметр <code>ReturnType</code> — это <code>void</code>, и <code>Args</code> — список, состоящий из элементов <code>int</code>, <code>double</code>, <code>my_class&amp;</code>, <code>std::string*</code>.</p>
        </section>
        <section>
          <title>
            <p>A.6.1. Расширение пакета параметров</p>
          </title>
          <p>Мощь шаблонов с переменным числом параметров связана с тем, что можно делать при расширении пакета, — мы отнюдь не ограничены простым расширением списка типов. Прежде всего, расширение пакета можно использовать всюду, где требуется список типов, например, в качестве списка аргументов другого шаблона:</p>
          <p>
            <code>template&lt;typename ... Params&gt;</code>
          </p>
          <p>
            <code>struct dummy {</code>
          </p>
          <p>
            <code> std::tuple&lt;Params...&gt; data;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>В данном случае единственная переменная-член <code>data</code> представляет собой конкретизацию <code>std::tuple&lt;&gt;</code>, содержащую все заданные типы, то есть в классе <code>dummy&lt;int, double, char&gt;</code> имеется член типа <code>std::tuple&lt;int, double, char&gt;</code>. Расширение пакета можно комбинировать с обычными типами:</p>
          <p>
            <code>template&lt;typename ... Params&gt;</code>
          </p>
          <p>
            <code>struct dummy2 {</code>
          </p>
          <p>
            <code> std::tuple&lt;std::string, Params...&gt; data;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>На этот раз класс <code>tuple</code> имеет дополнительный (первый) член типа <code>std::string</code>. Есть еще одна красивая возможность: разрешается определить образец, в который будут подставляться все элементы расширения пакета. Для этого в конце образца размещается многоточие <code>...</code>, обозначающее расширение пакета. Например, вместо кортежа элементов тех типов, которые перечислены в пакете параметров, можно создать кортеж указателей на такие типы или даже кортеж интеллектуальных указателей <code>std::unique_ptr&lt;&gt;</code> на них:</p>
          <p>
            <code>template&lt;typename ... Params&gt;</code>
          </p>
          <p>
            <code>struct dummy3 {</code>
          </p>
          <p>
            <code> std::tuple&lt;Params* ...&gt; pointers;</code>
          </p>
          <p>
            <code> std::tuple&lt;std::unique_ptr&lt;Params&gt; ...&gt; unique_pointers;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>Типовое выражение может быть сколь угодно сложным при условии, что в нем встречается пакет параметров и после него находится многоточие <code>...</code>, обозначающее расширение. Во время расширения пакета параметров каждый элемент пакета подставляется в типовое выражение и порождает соответственный элемент в результирующем списке. Таким образом, если пакет параметров <code>Params</code> содержит типы <code>int</code>, <code>int</code>, <code>char</code>, то расширение выражения <code>std::tuple&lt;std::pair&lt;std::unique_ptr&lt;Params&gt;, double&gt; ... &gt;</code> дает <code>std::tuple&lt;std::pair&lt;std::unique_ptr&lt;int&gt;, double&gt;</code>, <code>std::pair&lt;std::unique_ptr&lt;int&gt;, double&gt;</code>, <code>std::pair&lt;std::unique_ptr&lt;char&gt;, double&gt;&gt;</code>. Если расширение пакета используется в качестве списка аргументов шаблона, то шаблон не обязан иметь переменные параметры, но если таковых действительно нет, то размер пакета должен быть в точности равен количеству требуемых параметров шаблона:</p>
          <p>
            <code>template&lt;typename ... Types&gt;</code>
          </p>
          <p>
            <code>struct dummy4 {</code>
          </p>
          <p>
            <code> std::pair&lt;Types...&gt; data;</code>
          </p>
          <p>
            <code>};                   &#9474;</code>
            <strong>Правильно, данные имеют</strong>
          </p>
          <p>
            <code>dummy4&lt;int, char&gt; a;&#8592;&#9496;</code>
            <strong>вид std::pair&lt;int, char&gt;</strong>
          </p>
          <p>
            <code>dummy4&lt;int&gt; b; &#8592;</code>
            <strong>Ошибка, нет второго типа</strong>
          </p>
          <p>
            <code>dummy4&lt;int, int, int&gt; с;&#8592;</code>
            <strong>Ошибка, слишком много типов</strong>
          </p>
          <p>Еще один способ применения расширения пакета — объявление списка параметров функции:</p>
          <p>
            <code>template&lt;typename ... Args&gt;</code>
          </p>
          <p>
            <code>void foo(Args ... args);</code>
          </p>
          <p>При этом создается новый пакет параметров <code>args</code>, являющийся списком параметров функции, а не списком типов, и его можно расширить с помощью <code>...</code>, как и раньше. Теперь для объявления параметров функции можно использовать образец, в который производится подстановка типов из расширения пакета, — точно так же, как при подстановке расширения пакета в образец в других местах. Например, вот как это применяется в конструкторе <code>std::thread</code>, чтобы все аргументы функции принимались по ссылке на <emphasis>r</emphasis>-значение (см. раздел А.1):</p>
          <p>
            <code>template&lt;typename CallableType, typename ... Args&gt;</code>
          </p>
          <p>
            <code>thread::thread(CallableType&amp;&amp; func, Args&amp;&amp; ... args);</code>
          </p>
          <p>Теперь пакет параметров функции можно использовать для вызова другой функции, указав расширение пакета в списке аргументов вызываемой функции. Как и при расширении типов, образец можно использовать для каждого выражения в результирующем списке аргументов. Например, при работе со ссылками на r-значения часто применяется идиома, заключающаяся в использовании <code>std::forward&lt;&gt;</code> для сохранения свойства «является r-значением» переданных функции аргументов:</p>
          <p>
            <code>template&lt;typename ... ArgTypes&gt;</code>
          </p>
          <p>
            <code>void bar(ArgTypes&amp;&amp; ... args) {</code>
          </p>
          <p>
            <code> foo(std::forward&lt;ArgTypes&gt;(args)...);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Отметим, что в этом случае расширение пакета содержит как пакет типов <code>ArgTypes</code>, так и пакет параметров функции <code>args</code>, а многоточие расположено после всего выражения в целом. Если вызвать <code>bar</code> следующим образом:</p>
          <p>
            <code>int i;</code>
          </p>
          <p>
            <code>bar(i, 3.141, std::string("hello "));</code>
          </p>
          <p>то расширение примет такой вид:</p>
          <p>
            <code>template&lt;&gt;</code>
          </p>
          <p>
            <code>void bar&lt;int&amp;, double, std::string&gt;(</code>
          </p>
          <p>
            <code> int&amp; args_1,</code>
          </p>
          <p>
            <code> double&amp;&amp; args_2,</code>
          </p>
          <p>
            <code> std::string&amp;&amp; args_3) {</code>
          </p>
          <p>
            <code> foo(std::forward&lt;int&amp;&gt;(args_1),</code>
          </p>
          <p>
            <code> std::forward&lt;double&gt;(args_2),</code>
          </p>
          <p>
            <code> std::forward&lt;std::string&gt;(args_3));</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>и, следовательно, первый аргумент правильно передается функции <code>foo</code> как ссылка на <emphasis>l</emphasis>-значение, а остальные — как ссылки на <emphasis>r</emphasis>-значения.</p>
          <p>И последнее, что можно сделать с пакетом параметров, — это узнать его размер с помощью оператора <code>sizeof...</code>. Это совсем просто: <code>sizeof...(p)</code> возвращает число элементов в пакете параметров <code>p</code>. Неважно, является ли <code>p</code> пакетом параметров-типов или пакетом аргументов функции, — результат будет одинаковый. Это, пожалуй, единственный случай, где пакет параметров употребляется без многоточия, поскольку многоточие уже является частью оператора <code>sizeof...</code>. Следующая функция возвращает число переданных ей аргументов:</p>
          <p>
            <code>template&lt;typename ... Args&gt;</code>
          </p>
          <p>
            <code>unsigned count_args(Args ... args) {</code>
          </p>
          <p>
            <code> return sizeof... (Args);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>Как и для обычного оператора <code>sizeof</code>, результатом <code>sizeof...</code> является константное выражение, которое, следовательно, можно использовать для задания границ массива и т.п.</p>
        </section>
      </section>
      <section>
        <title>
          <p>А.7. Автоматическое выведение типа переменной</p>
        </title>
        <p>С++ — статически типизированный язык: тип любой переменной известен на этапе компиляции. Более того, программист обязан указать тип каждой переменной. В некоторых случаях имена оказываются очень громоздкими, например:</p>
        <p>
          <code>std::map&lt;std::string, std::unique_ptr&lt;some_data&gt;&gt; m;</code>
        </p>
        <p>
          <code>std::map&lt;std::string, std::unique_ptr&lt;some_data&gt;&gt;::iterator</code>
        </p>
        <p>
          <code>iter = m.find("my key");</code>
        </p>
        <p>Традиционно для решения этой проблемы использовались псевдонимы типов (<code>typedef</code>), позволяющие сократить длину идентификатора типа и избавиться от потенциальных проблем несовместимости типов. Этот способ работает и в C++11, но появился и новый: если переменная инициализируется в объявлении, то в качестве ее типа можно указать <code>auto</code>. Тогда компилятор автоматически выведет тип переменной из типа инициализатора. Следовательно, приведенный выше пример итератора можно записать и так:</p>
        <p>
          <code>auto iter = m.find("my key");</code>
        </p>
        <p>Спецификатор <code>auto</code> необязательно употреблять изолированно; его можно использовать в сочетании с другими спецификаторами для объявления <code>const</code>-переменных, а также указателей и ссылок. Вот несколько примеров объявления переменных с помощью <code>auto</code> и дополнительных конструкций:</p>
        <p>
          <code>auto i = 42;        // int</code>
        </p>
        <p>
          <code>auto&amp; j = i;        // int&amp;</code>
        </p>
        <p>
          <code>auto const k = i;   // int const</code>
        </p>
        <p>
          <code>auto* const p = &amp;i; // int * const</code>
        </p>
        <p>Правила выведения типа переменной основаны на правилах, применяемых в другом месте языка, где выводятся типы: параметры шаблонов функций. В объявлении вида</p>
        <p>
          <code>Какое-то-типовое-выражение-включающее-auto</code>
        </p>
        <p>
          <code>var = some-expression;</code>
        </p>
        <p>переменная <code>var</code> имеет тот же тип, который был бы выведен, если бы она встречалась в качестве параметра шаблона функции, объявленного с таким же типовым выражением, только <code>auto</code> заменяется именем типового параметра шаблона:</p>
        <p>
          <code>template&lt;typename T&gt;</code>
        </p>
        <p>
          <code>void f(type-expression var);</code>
        </p>
        <p>
          <code>f(some-expression);</code>
        </p>
        <p>Это означает, что тип массива сводится к указателю, а ссылки опускаются, если только в типовом выражении переменная явно не объявлена как ссылка. Например:</p>
        <p>
          <code>int some_array[45];</code>
        </p>
        <p>
          <code>auto p = some_array; // int*</code>
        </p>
        <p>
          <code>int&amp; r = *p;</code>
        </p>
        <p>
          <code>auto x = r;          // int</code>
        </p>
        <p>
          <code>auto&amp; y = r;         // int&amp;</code>
        </p>
        <p>Это позволяет существенно упростить объявление переменных, особенно в случаях, когда полный идентификатор типа очень длинный или даже неизвестен (например, тип результата вызова функции в шаблоне).</p>
      </section>
      <section>
        <title>
          <p>А.8. Поточно-локальные переменные</p>
        </title>
        <p>У поточно-локальной переменной имеется отдельный экземпляр в каждом потоке программы. Для объявления поточно-локальной переменной служит ключевое слово <code>thread_local</code>. Поточно-локальными могут быть переменные с областью видимости пространства имен, статические члены классов и локальные переменные. Говорят, что они имеют <emphasis>потоковое время жизни</emphasis> (thread storage duration):</p>
        <p>
          <code>thread_local int x;&#8592;&#9488;</code>
          <strong>Поточно-локальная переменная в</strong>
        </p>
        <p>
          <code>                    &#9474;</code>
          <strong>области видимости пространства</strong>
        </p>
        <p>
          <code>                    &#9474;</code>
          <strong>имен</strong>
        </p>
        <p>
          <code>class X                             &#9474;</code>
          <strong>Поточно-локальная</strong>
        </p>
        <p>
          <code>{                                   &#9474;</code>
          <strong>статическая пере-</strong>
        </p>
        <p>
          <code> static thread_local std::string s;&#8592;&#9496;</code>
          <strong>менная-член класса</strong>
        </p>
        <p>
          <code>};</code>
        </p>
        <p>
          <code>                                      &#9474;</code>
          <strong>Необходимо</strong>
        </p>
        <p>
          <code>static thread_local std::string X::s;<strong>&#8592;</strong>&#9496;</code>
          <strong>определение X::s</strong>
        </p>
        <empty-line/>
        <p>
          <code>void foo() {</code>
        </p>
        <p>
          <code>                                  &#9474;</code>
          <strong>Поточно-локальная</strong>
        </p>
        <p>
          <code> thread_local std::vector&lt;int&gt; v;&#8592;&#9496;</code>
          <strong>локальная переменная</strong>
        </p>
        <p>
          <code>}</code>
        </p>
        <p>Поточно-локальные переменные в области видимости пространства имен и поточно-локальные статические члены класса конструируются раньше первого использования переменной в той же единице трансляции, но <emphasis>насколько раньше</emphasis> не оговаривается. В одних реализациях поточно-локальные переменные могут конструироваться при запуске потока, в других — непосредственно перед первым использованием в каждом потоке, в третьих — еще в какой-то момент. Возможен и смешанный подход в зависимости от контекста. На самом деле, если ни одна из поточно-локальных переменных в данной единице трансляции не используется, то не гарантируется, что они вообще будут сконструированы. Это позволяет динамически загружать модули, содержащие поточно-локальные переменные — они будут сконструированы в данном потоке при первом обращении потока к переменной из динамически загруженного модуля.</p>
        <p>Поточно-локальные переменные, объявленные внутри функции, инициализируются, когда поток управления впервые проходит через объявление переменной в данном потоке. Если функция в данном потоке не вызывалась, то объявленные в ней поточно-локальные переменные не будут сконструированы. Точно такое же поведение характерно для локальных статических переменных, только в этом случае оно применяется в каждом потоке по отдельности.</p>
        <p>У поточно-локальных переменных есть и другие общие черты со статическими переменными — они инициализируются нулями перед последующей инициализацией (например, динамической) и, если конструктор поточно-локальной переменной возбуждает исключение, то вызывается функция <code>std::terminate()</code>, которая аварийно завершает приложение.</p>
        <p>Деструкторы всех поточно-локальных переменных, сконструированных в данном потоке, вызываются после возврата из функции потока в порядке, обратном конструированию. Поскольку порядок инициализации не определён, то необходимо гарантировать отсутствие взаимозависимостей между деструкторами таких переменных. Если деструктор поточно-локальной переменной возбуждает исключение, то вызывается функция <code>std::terminate()</code>, как и при конструировании.</p>
        <p>Поточно-локальные переменные, принадлежащие некоторому потоку, уничтожаются также в случае, когда <emphasis>данный поток</emphasis> вызывает <code>std::exit()</code> или возвращается из <code>main()</code> (что эквивалентно вызову <code>std::exit()</code> со значением, которое вернула <code>main()</code>). Если другие потоки продолжают работать, когда приложение завершается, то деструкторы принадлежащих им поточно-локальных переменных <emphasis>не</emphasis> вызываются.</p>
        <p>Хотя поточно-локальные переменные, принадлежащие разным потокам, имеют разные адреса, все же можно получать обычный указатель на такую переменную. Этот указатель адресует объект в том потоке, где указатель был получен, и, следовательно, его можно использовать для предоставления доступа к этому объекту из других потоков. Попытка доступа к уже уничтоженному объекту является неопределенным поведением (как всегда), потому, передавая указатель на поточно-локальную переменную в другой поток, следите за тем, чтобы он не разыменовывался после завершения потока-владельца.</p>
      </section>
      <section>
        <title>
          <p>А.9. Резюме</p>
        </title>
        <p>В этом приложении мы смогли лишь пробежаться по верхам новых языковых средств, появившихся в стандарте C++11, поскольку нас интересовали лишь те возможности, которые активно используются в библиотеке Thread Library. Из других средств стоит отметить статические утверждения, строго типизированные перечисления, делегирующие конструкторы, поддержку Unicode, псевдонимы шаблонов, новую универсальную последовательность инициализации, а также ряд других, более мелких изменений. Подробное описание всех новых средств выходит далеко за рамки этой книги и, пожалуй, заслуживает отдельного тома. Лучший из существующих на данный момент обзор всего множества изменений, наверное, приведён в FAQ'e по C++11<a l:href="#n21" type="note">[21]</a> Бьярна Страуструпа, хотя популярные учебники по С++ в скором времени, вероятно, будут переизданы с учетом всех новшеств.</p>
        <p>Я надеюсь, что в этом кратком введении в новые языковые средства мне все же удалось объяснить, как они соотносятся с библиотекой Thread Library, и что с его помощью вы сможете писать и понимать многопоточный код, в котором эти средства используются. Но не забывайте, что это отнюдь не полный справочник и не учебник по использованию новых возможностей языка. Если вы намерены активно пользоваться ими, то рекомендую приобрести достаточно подробную книгу, которая позволит задействовать их в полной мере.</p>
      </section>
    </section>
    <section>
      <title>
        <p>Приложение В.</p>
        <p>Краткое сравнение библиотек для написания параллельных программ</p>
      </title>
      <p>Поддержка параллелизма и многопоточности в языках программирования и библиотеках не является чем-то новым, хотя включение ее в стандарт С++ — действительно новшество. Например, в Java многопоточность поддерживалась уже в самой первой версии; на платформах, согласованных со стандартом POSIX, имеется интерфейс из языка С к средствам многопоточности, предоставляемым операционной системой, а язык Erlang поддерживает параллелизм на основе передачи сообщений. Существуют даже библиотеки классов для С++, например Boost, которые обертывают программный интерфейс к средствам многопоточности, существующим на данной платформе (будь то интерфейс POSIX С или нечто иное) и тем самым предоставляют переносимый интерфейс для всех поддерживаемых платформ.</p>
      <p>Для тех, кто уже имеет опыт написания многопоточных приложений и хотел бы воспользоваться им для разработки программ на С++ с применением новых возможностей, в этом приложении проводится сравнение средств, имеющихся в Java, POSIX С, С++ с библиотекой Boost Thread Library и С++11. Даются также перекрестные ссылки на соответствующие главы этой книги.</p>
      <table>
        <tr align="left">
          <th align="left" valign="top">Средство</th>
          <th align="left" valign="top">Java</th>
          <th align="left" valign="top">Posix C</th>
          <th align="left" valign="top">Boost Threads</th>
          <th align="left" valign="top">C++11</th>
          <th align="left" valign="top">Глава</th>
        </tr>
        <tr align="left">
          <td align="left" valign="top">Запуск потоков</td>
          <td align="left" valign="top">Класс <code>java.lang.thread</code></td>
          <td align="left" valign="top">Тип <code>pthread_t</code> и соответствующие функции API: <code>pthread_create()</code>, <code>pthread_detach()</code>, <code>pthread_join()</code></td>
          <td align="left" valign="top">Класс <code>boost::thread</code> и его функции-члены</td>
          <td align="left" valign="top">Класс <code>std::thread</code> и его функции-члены</td>
          <td align="left" valign="top">Глава 2</td>
        </tr>
        <tr align="left">
          <td align="left" valign="top">Взаимное исключение</td>
          <td align="left" valign="top">Блоки <code>synchronized</code></td>
          <td align="left" valign="top">Тип <code>pthread_mutex_t</code> и соответствующие функции API: <code>pthread_mutex_lock()</code>, <code>pthread_mutex_unlock()</code> и другие</td>
          <td align="left" valign="top">Класс <code>boost::mutex</code> и его функции-члены, шаблоны <code>boost::lock_guard&lt;&gt;</code> и <code>boost::unique_lock&lt;&gt;</code></td>
          <td align="left" valign="top">Класс <code>std::mutex</code> и его функции-члены, шаблоны <code>std::lock_guard&lt;&gt;</code> и <code>std::unique_lock&lt;&gt;</code></td>
          <td align="left" valign="top">Глава 3</td>
        </tr>
        <tr align="left">
          <td align="left" valign="top">Ожидание предиката</td>
          <td align="left" valign="top">Методы <code>wait()</code> и <code>notify()</code> класса <code>java.lang.Object</code>, используемые внутри блоков <code>synchronized</code></td>
          <td align="left" valign="top">Тип <code>pthread_cond_t</code> и соответствующие функции API: <code>pthread_cond_wait()</code>, <code>pthread_cond_timed_wait()</code> и другие</td>
          <td align="left" valign="top">Классы <code>boost::condition_variable</code> и <code>boost::condition_variable_any</code> и их функции-члены</td>
          <td align="left" valign="top">Классы <code>std::condition_variable</code> и <code>std::condition_variable_any</code> и их функции-члены</td>
          <td align="left" valign="top">Глава 4</td>
        </tr>
        <tr align="left">
          <td align="left" valign="top">Атомарные операции и модель памяти с учетом параллелизма</td>
          <td align="left" valign="top"><code>volatile</code>-переменные, типы в пакете <code>java.util.concurrent.atomic</code></td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top">Типы <code>std::atomic_xxx</code>, шаблон класса <code>std::atomic&lt;&gt;</code>, функция <code>std::atomic_thread_fence()</code></td>
          <td align="left" valign="top">Глава 5</td>
        </tr>
        <tr align="left">
          <td align="left" valign="top">Потокобезопасные контейнеры</td>
          <td align="left" valign="top">Контейнеры в пакете <code>java.util.concurrent</code>.</td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top">Главы 6 и 7</td>
        </tr>
        <tr align="left">
          <td align="left" valign="top">Будущие результаты</td>
          <td align="left" valign="top">Интерфейс <code>java.util.concurrent.future</code> и ассоциированные с ним классы</td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top">Шаблонные классы <code>boost::unique_future&lt;&gt;</code> и <code>boost::shared_future&lt;&gt;</code></td>
          <td align="left" valign="top">Шаблонные классы <code>std::future&lt;&gt;</code>, <code>std::shared_future&lt;&gt;</code>, и <code>std::atomic_future&lt;&gt;</code></td>
          <td align="left" valign="top">Глава 9</td>
        </tr>
        <tr align="left">
          <td align="left" valign="top">Пулы потоков</td>
          <td align="left" valign="top">Класс <code>java.util.concurrent.ThreadPoolExecutor</code></td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top">Глава 9</td>
        </tr>
        <tr align="left">
          <td align="left" valign="top">Прерывание потока</td>
          <td align="left" valign="top">Метод <code>interrupt()</code> класса <code>java.lang.Thread</code></td>
          <td align="left" valign="top">
            <code>pthread_cancel()</code>
          </td>
          <td align="left" valign="top">Функция-член <code>interrupt()</code> класса <code>boost::thread</code></td>
          <td align="left" valign="top">Отсутствует</td>
          <td align="left" valign="top"/>
        </tr>
      </table>
    </section>
    <section>
      <title>
        <p>Приложение С.</p>
        <p>Каркас передачи сообщений и полный пример программы банкомата</p>
      </title>
      <p>В разделе 4.1 мы познакомились с каркасом передачи сообщений между потоками, продемонстрировав его на примере программы банкомата. В этом приложении приводится полный код примера, включая и код каркаса передачи сообщений.</p>
      <p>В листинге С.1 показан код очереди сообщений. Сообщения хранятся в списке и представлены указателями на базовый класс. Сообщения конкретного типа обрабатываются шаблонным классом, производным от этого базового класса. В момент помещения сообщения в очередь конструируется подходящий экземпляр обертывающего класса и сохраняется указатель на него; операция извлечения возвращает именно этот указатель. Поскольку в классе <code>message_base</code> нет функций-членов, извлекающий поток должен привести указатель к нужному типу <code>wrapped_message&lt;T&gt;</code>, прежде чем сможет получить хранящееся сообщение.</p>
      <empty-line/>
      <p><strong>Листинг С.1.</strong> Простая очередь сообщений</p>
      <p>
        <code>#include &lt;mutex&gt;</code>
      </p>
      <p>
        <code>#include &lt;condition_variable&gt;</code>
      </p>
      <p>
        <code>#include &lt;queue&gt;</code>
      </p>
      <p>
        <code>#include &lt;memory&gt;</code>
      </p>
      <empty-line/>
      <p>
        <code>namespace messaging</code>
      </p>
      <p>
        <code>{                     &#9474;</code>
        <strong>Базовый класс</strong>
      </p>
      <p>
        <code>struct message_base {&#8592;&#9496;</code>
        <strong>элементов очереди</strong>
      </p>
      <p>
        <code> virtual ~message_base() {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>template &lt;typename Msg&gt; &#9474;</code>
        <strong>Для каждого типа сообщений</strong>
      </p>
      <p>
        <code>struct wrapped_message:&#8592;&#9496;</code>
        <strong>имеется специализация</strong>
      </p>
      <p>
        <code>message_base {</code>
      </p>
      <p>
        <code> Msg contents;</code>
      </p>
      <p>
        <code> explicit wrapped_message(Msg const&amp; contents_):</code>
      </p>
      <p>
        <code>  contents(contents_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>            &#9474;</code>
        <strong>Наша очередь</strong>
      </p>
      <p>
        <code>class queue&#8592;&#9496;</code>
        <strong>сообщений</strong>
      </p>
      <p>
        <code>{                                              &#9474;</code>
        <strong>В настоящей</strong>
      </p>
      <p>
        <code> std::mutex m;                                 &#9474;</code>
        <strong>очереди хранят-</strong>
      </p>
      <p>
        <code> std::condition_variable с;                    &#9474;</code>
        <strong>ся указатели на</strong>
      </p>
      <p>
        <code> std::queue&lt;std::shared_ptr&lt;message_base&gt; &gt; q;&#8592;&#9496;</code>
        <strong>message_base</strong>
      </p>
      <empty-line/>
      <p>
        <code>public:</code>
      </p>
      <p>
        <code> template&lt;typename T&gt;               &#9474;</code>
        <strong>Обернуть добав-</strong>
      </p>
      <p>
        <code> void push(T const&amp; msg)            &#9474;</code>
        <strong>ленное сообще-</strong>
      </p>
      <p>
        <code> {                                  &#9474;</code>
        <strong>ние и сохранить</strong>
      </p>
      <p>
        <code>  std::lock_guard&lt;std::mutex&gt; lk(m);&#9474;</code>
        <strong>указатель</strong>
      </p>
      <p>
        <code>  q.push( &#8592;&#9496;</code>
      </p>
      <p>
        <code>   std::make_shared&lt;wrapped_message&lt;T&gt; &gt;(msg));</code>
      </p>
      <p>
        <code>  с.notify_all();</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> std::shared_ptr&lt;message_base&gt; wait_and_pop()&#9474;</code>
        <strong>Блокирует до</strong>
      </p>
      <p>
        <code> {                                           &#9474;</code>
        <strong>появления в</strong>
      </p>
      <p>
        <code>  std::unique_lock&lt;std::mutex&gt; lk(m);        &#9474;</code>
        <strong>очереди хотя бы</strong>
      </p>
      <p>
        <code>  c.wait(lk, [&amp;]{ return !q.empty(); });    &#8592;&#9496;</code>
        <strong>одного элемента</strong>
      </p>
      <p>
        <code>  auto res = q.front();</code>
      </p>
      <p>
        <code>  q.pop();</code>
      </p>
      <p>
        <code>  return res;</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <p>
        <code>}</code>
      </p>
      <p>Отправкой сообщений занимается объект класса <code>sender</code>, показанного в листинге С.2. Это не более чем тонкая обертка вокруг очереди сообщений, которая позволяет только добавлять сообщения. При копировании экземпляров <code>sender</code> копируется только указатель на очередь, а не сама очередь.</p>
      <empty-line/>
      <p><strong>Листинг С.2.</strong> Класс <code>sender</code></p>
      <p>
        <code>namespace messaging {</code>
      </p>
      <p>
        <code> class sender {&#9474;</code>
        <strong>sender обертывает указатель</strong>
      </p>
      <p>
        <code> queue* q;    &#8592;&#9496;</code>
        <strong>на очередь</strong>
      </p>
      <empty-line/>
      <p>
        <code>public:     &#9474;</code>
        <strong>У сконструированного по умолчанию</strong>
      </p>
      <p>
        <code> sender() :&#8592;&#9496;</code>
        <strong>sender'a нет очереди</strong>
      </p>
      <p>
        <code> q(nullptr) {}</code>
      </p>
      <empty-line/>
      <empty-line/>
      <p>
        <code>                             &#9474;</code>
        <strong>Разрешаем конструирование</strong>
      </p>
      <p>
        <code> explicit sender(queue* q_):&#8592;&#9496;</code>
        <strong>из указателя на очередь</strong>
      </p>
      <p>
        <code>  q(q_) {}</code>
      </p>
      <empty-line/>
      <p>
        <code> template&lt;typename Message&gt;</code>
      </p>
      <p>
        <code> void send(Message const&amp; msg) {</code>
      </p>
      <p>
        <code>  if (q){        &#9474;</code>
        <strong>Отправка сообщения сводится</strong>
      </p>
      <p>
        <code>   q-&gt;push(msg);&#8592;&#9496;</code>
        <strong>к помещению его в очередь</strong>
      </p>
      <p>
        <code>  }</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <p>
        <code>}</code>
      </p>
      <p>Получение сообщений несколько сложнее. Мы не только должны дождаться появления сообщения в очереди, но еще и проверить, совпадает ли его тип с одним из известных нам типов, и вызвать соответствующий обработчик. Эта процедура начинается в классе <code>receiver</code>, показанном в листинге ниже.</p>
      <empty-line/>
      <p><strong>Листинг С.3.</strong> Класс <code>receiver</code></p>
      <p>
        <code>namespace messaging {</code>
      </p>
      <p>
        <code>class receiver {</code>
      </p>
      <p>
        <code> queue q; &#8592;</code>
        <strong>receiver владеет очередью</strong>
      </p>
      <empty-line/>
      <p>
        <code>public:              &#9474;</code>
        <strong>Разрешить неявное преобразование в объект</strong>
      </p>
      <p>
        <code> operator sender() {&#8592;&#9496;</code>
        <strong>sender, ссылающийся на эту очередь</strong>
      </p>
      <p>
        <code>  return sender(&amp;q);</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code>                     &#9474;</code>
        <strong>При обращении к функции ожидания</strong>
      </p>
      <p>
        <code> dispatcher wait() {&#8592;&#9496;</code>
        <strong>очереди создается диспетчер</strong>
      </p>
      <p>
        <code>  return dispatcher(&amp;q);</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <p>
        <code>}</code>
      </p>
      <p>Если <code>sender</code> только ссылается на очередь сообщений, то <code>receiver</code> ей владеет. Мы можем получить объект <code>sender</code>, ссылающийся на очередь, воспользовавшись неявным преобразованием. Процедура диспетчеризации сообщения начинается с обращения к функции <code>wait()</code>. При этом создается объект <code>dispatcher</code>, ссылающийся на очередь, которой владеет <code>receiver</code>. Класс <code>dispatcher</code> показан в следующем листинге; как видите, содержательная работа производится в его <emphasis>деструкторе</emphasis>. В данном случае работа состоит в ожидании сообщения и его диспетчеризации.</p>
      <empty-line/>
      <p><strong>Листинг С.4.</strong> Класс <code>dispatcher</code></p>
      <p>
        <code>namespace messaging {</code>
      </p>
      <p>
        <code>class close_queue {}; &#8592;</code>
        <strong>Сообщение о закрытии очереди</strong>
      </p>
      <empty-line/>
      <p>
        <code>class dispatcher {</code>
      </p>
      <p>
        <code> queue* q;                             &#9474;</code>
        <strong>Экземпляры</strong>
      </p>
      <p>
        <code> bool chained;                         &#9474;</code>
        <strong>диспетчера нельзя</strong>
      </p>
      <p>
        <code>                                       &#9474;</code>
        <strong>копировать</strong>
      </p>
      <p>
        <code> dispatcher(dispatcher const&amp;)=delete;&#8592;&#9496;</code>
      </p>
      <p>
        <code> dispatcher&amp; operator=(dispatcher const&amp;)=delete;</code>
      </p>
      <p>
        <code> template&lt;</code>
      </p>
      <p>
        <code>  typename Dispatcher,&#9474;</code>
        <strong>Разрешить экземплярам</strong>
      </p>
      <p>
        <code>  typename Msg,       &#9474;</code>
        <strong>TemplateDispatcher доступ</strong>
      </p>
      <p>
        <code>  typename Func&gt;     &#8592;&#9496;</code>
        <strong>к закрытым частям класса</strong>
      </p>
      <p>
        <code> friend class TemplateDispatcher;</code>
      </p>
      <p>
        <code> void wait_and_dispatch()</code>
      </p>
      <p>
        <code> {          </code>
        <strong>(1) В цикле ждем и диспетчеризуем</strong>
      </p>
      <p>
        <code>  for (;;) {&#8592;&#9496;</code>
        <strong>сообщения</strong>
      </p>
      <p>
        <code>   auto msg = q-&gt;wait_and_pop();</code>
      </p>
      <p>
        <code>   dispatch(msg);</code>
      </p>
      <p>
        <code>  }</code>
      </p>
      <p>
        <code> }              </code>
        <strong>(2) dispatch() смотрит, не пришло ли</strong>
      </p>
      <p>
        <code>                 &#9474;</code>
        <strong>сообщение close_queue, и, если</strong>
      </p>
      <p>
        <code> bool dispatch (&#8592;&#9496;</code>
        <strong>да, возбуждает исключение</strong>
      </p>
      <p>
        <code>  std::shared_ptr&lt;message_base&gt; const&amp; msg) {</code>
      </p>
      <p>
        <code>  if (dynamic_cast&lt;wrapped_message&lt;close_queue&gt;*&gt;(msg.get())) {</code>
      </p>
      <p>
        <code>   throw close_queue();</code>
      </p>
      <p>
        <code>  }</code>
      </p>
      <p>
        <code>  return false;</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code>public:                          &#9474;</code>
        <strong>Экземпляры диспетчера</strong>
      </p>
      <p>
        <code> dispatcher(dispatcher&amp;&amp; other):&#8592;&#9496;</code>
        <strong>можно перемещать</strong>
      </p>
      <p>
        <code>  q(other.q), chained(other.chained) {&#9474;</code>
        <strong>Объект-источник не должен</strong>
      </p>
      <p>
        <code>  other.chained = true;              &#8592;&#9496;</code>
        <strong>ждать сообщений</strong>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> explicit dispatcher(queue* q_): q(q_), chained(false) {}</code>
      </p>
      <empty-line/>
      <p>
        <code> template&lt;typename Message, typename Func&gt;</code>
      </p>
      <p>
        <code> TemplateDispatcher&lt;dispatcher, Message, Func&gt;</code>
      </p>
      <p>
        <code> handle(Func&amp;&amp; f)&#8592;&#9488;</code>
        <strong>Сообщения конкретного типа</strong>
      </p>
      <p>
        <code> {               </code>
        <strong>(3) обрабатывает TemplateDispatcher</strong>
      </p>
      <p>
        <code>  return TemplateDispatcher&lt;dispatcher, Message, Func&gt;(</code>
      </p>
      <p>
        <code>   q, this, std::forward&lt;Func&gt;(f));</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> ~dispatcher() noexcept(false)&#8592;&#9488;</code>
        <strong>Деструктор может</strong>
      </p>
      <p>
        <code> {                            </code>
        <strong>(4) возбудить исключение</strong>
      </p>
      <p>
        <code>  if (!chained) {</code>
      </p>
      <p>
        <code>   wait_and_dispatch();</code>
      </p>
      <p>
        <code>  }</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <p>
        <code>}</code>
      </p>
      <p>Экземпляр <code>dispatcher</code>, возвращенный функцией <code>wait()</code>, немедленно уничтожается, так как является временным объектом, и, как уже было сказало, вся работа выполняется в его деструкторе. Деструктор вызывает функцию <code>wait_and_dispatch()</code>, которая в цикле <strong>(1)</strong> ожидает сообщения и передает его функции <code>dispatch()</code>. Сама функция <code>dispatch()</code> <strong>(2)</strong> проста, как правда: она проверяет, не получено ли сообщение типа <code>close_queue</code>, и, если так, то возбуждает исключение; в противном случае возвращает <code>false</code>, извещая, что сообщение не обработало. Именно из-за исключения <code>close_queue</code> деструктор и помечен как <code>noexcept(false)</code> <strong>(4)</strong>; без этой аннотации действовала бы подразумеваемая спецификация исключений для деструктора — <code>noexcept(true)</code>, означающая, что исключения не допускаются, и тогда исключение <code>close_queue</code> привело бы к завершению программы.</p>
      <p>Но просто вызывать функцию <code>wait()</code> особого смысла не имеет — как правило, нам нужно обработать полученное сообщение. Для этого предназначена функция-член <code>handle()</code> <strong>(3)</strong>. Это шаблон, и тип сообщения нельзя вывести, поэтому необходимо явно указать, сообщение какого типа обрабатывается, и передать функцию (или допускающий вызов объект) для его обработки. Сама функция <code>handle()</code> передает очередь, текущий объект <code>dispatcher</code> и функцию-обработчик новому экземпляру шаблонного класса <code>TemplateDispatcher</code>, который обрабатывает сообщения указанного типа. Код этого класса показан в листинге С.5. Именно поэтому мы проверяем флаг <code>chained</code> в деструкторе перед тем, как приступить к ожиданию сообщения; он не только предотвращает ожидание объектами, содержимое которых перемещено, но и позволяет передать ответственность за ожидание новому экземпляру <code>TemplateDispatcher</code>.</p>
      <empty-line/>
      <p><strong>Листинг С.5.</strong> Шаблон класса <code>TemplateDispatcher</code></p>
      <p>
        <code>namespace messaging {</code>
      </p>
      <p>
        <code>template&lt;</code>
      </p>
      <p>
        <code> typename PreviousDispatcher, typename Msg, typename Func&gt;</code>
      </p>
      <p>
        <code>class TemplateDispatcher {</code>
      </p>
      <p>
        <code> queue* q;</code>
      </p>
      <p>
        <code> PreviousDispatcher* prev;</code>
      </p>
      <p>
        <code> Func f;</code>
      </p>
      <p>
        <code> bool chained;</code>
      </p>
      <empty-line/>
      <p>
        <code> TemplateDispatcher(TemplateDispatcher const&amp;) = delete;</code>
      </p>
      <p>
        <code> TemplateDispatcher&amp; operator=(</code>
      </p>
      <p>
        <code>  TemplateDispatcher const&amp;) = delete;</code>
      </p>
      <empty-line/>
      <p>
        <code> template&lt;</code>
      </p>
      <p>
        <code>  typename Dispatcher, typename OtherMsg, typename OtherFunc&gt;</code>
      </p>
      <p>
        <code> friend class TemplateDispatcher;&#8592;&#9488;</code>
        <strong>Все конкретизации</strong>
      </p>
      <p>
        <code> void wait_and_dispatch()         &#9474;</code>
        <strong>TemplateDispatcher</strong>
      </p>
      <p>
        <code> {                                &#9474;</code>
        <strong>дружат между собой</strong>
      </p>
      <p>
        <code>  for (;;) {</code>
      </p>
      <p>
        <code>   auto msg = q-&gt;wait_and_pop();</code>
      </p>
      <p>
        <code>   if (dispatch(msg))&#8592;&#9488;</code>
        <strong>Если мы обработали</strong>
      </p>
      <p>
        <code>   break;             &#9474;</code>
        <strong>сообщение выходим</strong>
      </p>
      <p>
        <code>  }                  </code>
        <strong>(1) из цикла</strong>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> bool dispatch(std::shared_ptr&lt;message_base&gt; const&amp; msg) {</code>
      </p>
      <p>
        <code>  if (wrapped_message&lt;Msg&gt;* wrapper =</code>
      </p>
      <p>
        <code>   dynamic_cast&lt;wrapped_message&lt;Msg&gt;*&gt;(</code>
      </p>
      <p>
        <code>   msg.get())) {       &#8592;&#9488;</code>
        <strong>Проверяем тип</strong>
      </p>
      <p>
        <code>   f(wrapper-&gt;contents);&#9474;</code>
        <strong>сообщения и</strong>
      </p>
      <p>
        <code>   return true;         &#9474;</code>
        <strong>вызываем</strong>
      </p>
      <p>
        <code>  }                    </code>
        <strong>(2) функцию</strong>
      </p>
      <p>
        <code>  else {</code>
      </p>
      <p>
        <code>   return prev-&gt;dispatch(msg);&#8592;&#9488;</code>
        <strong>Вызываем предыдущий</strong>
      </p>
      <p>
        <code>  }                           </code>
        <strong>(3) диспетчер в цепочке</strong>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code>public:</code>
      </p>
      <p>
        <code> TemplateDispatcher(TemplateDispatcher&amp;&amp; other):</code>
      </p>
      <p>
        <code>  q(other.q), prev(other.prev), f(std::move(other.f)),</code>
      </p>
      <p>
        <code>  chained(other.chained) {</code>
      </p>
      <p>
        <code>  other.chained = true;</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> TemplateDispatcher(</code>
      </p>
      <p>
        <code>  queue* q_, PreviousDispatcher* prev_, Func&amp;&amp; f_):</code>
      </p>
      <p>
        <code>  q(q_), prev(prev_), f(std::forward&lt;Func&gt;(f_)), chained(false)</code>
      </p>
      <p>
        <code> {</code>
      </p>
      <p>
        <code>  prev_-&gt;chained = true;</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> template&lt;typename OtherMsg, typename OtherFunc&gt;</code>
      </p>
      <p>
        <code> TemplateDispatcher&lt;TemplateDispatcher, OtherMsg, OtherFunc&gt;</code>
      </p>
      <p>
        <code> handle(OtherFunc&amp;&amp; of)&#8592;&#9488;</code>
        <strong>Дополнительные обработчики</strong>
      </p>
      <p>
        <code> {                     </code>
        <strong>(4) можно связать в цепочку</strong>
      </p>
      <p>
        <code>  return TemplateDispatcher&lt;</code>
      </p>
      <p>
        <code>   TemplateDispatcher, OtherMsg, OtherFunc&gt;(</code>
      </p>
      <p>
        <code>    q, this, std::forward&lt;OtherFunc&gt;(of));</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> ~TemplateDispatcher() noexcept(false)&#8592;&#9488;</code>
        <strong>Деструктор снова</strong>
      </p>
      <p>
        <code> {                                     &#9474;</code>
        <strong>помечен как</strong>
      </p>
      <p>
        <code>  if (!chained) {                     </code>
        <strong>(5) noexcept(false)</strong>
      </p>
      <p>
        <code>   wait_and_dispatch();</code>
      </p>
      <p>
        <code>  }</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <p>
        <code>}</code>
      </p>
      <p>Шаблон класса <code>TemplateDispatcher&lt;&gt;</code> устроен по образцу класса <code>dispatcher</code> и почти ничем не отличается от него. В частности, деструктор тоже вызывает <code>wait_and_dispatch()</code>, чтобы дождаться сообщения.</p>
      <p>Поскольку мы не возбуждаем исключения, если сообщение обработало, то теперь в цикле <strong>(1)</strong> нужно проверять, обработали мы сообщение или нет. Обработка прекращается, как только сообщение успешно обработало, чтобы в следующий раз можно было ждать очередного набора сообщений. Если найдено соответствие указанному типу сообщения, то вызывается предоставленная функция <strong>(2)</strong>, а не возбуждается исключение (хотя функция-обработчик может и сама возбудить исключение). Если же соответствие не найдено, то мы передаем сообщение предыдущему диспетчеру в цепочке <strong>(3)</strong>. В самом первом экземпляре это будет объект <code>dispatcher</code>, но если в функции <code>handle()</code> <strong>(4)</strong> вызовы сцеплялись, чтобы можно было обработать несколько типов сообщений, то предыдущим диспетчером может быть ранее созданный экземпляр <code>TemplateDispatcher&lt;&gt;</code>, который в свою очередь передаст сообщение предшествующему ему диспетчеру в цепочке, если не сможет обработать его сам. Поскольку любой обработчик может возбудить исключение (в том числе и обработчик самого первого объекта <code>dispatcher</code>, если встретит сообщение <code>close_queue</code>), то деструктор снова необходимо снабдить аннотацией <code>noexcept(false)</code> <strong>(5)</strong>.</p>
      <p>Этот простенький каркас позволяет помещать в очередь сообщения любого типа, а затем на принимающем конце отбирать те из них, которые мы можем обработать. Кроме того, он позволяет передавать ссылку на очередь, чтобы в нее можно было добавлять новые сообщения, оставляя при этом прижимающий конец недоступным извне.</p>
      <p>И чтобы закончить пример из главы 4, в листинге С.6 приведён код сообщений, в листингах С.7, С.8 и С.9 — различные конечные автоматы, а в листинге С.10 — управляющая программа.</p>
      <empty-line/>
      <p><strong>Листинг С.6.</strong> Сообщения банкомата</p>
      <p>
        <code>struct withdraw {</code>
      </p>
      <p>
        <code> std::string account;</code>
      </p>
      <p>
        <code> unsigned amount;</code>
      </p>
      <p>
        <code> mutable messaging::sender atm_queue;</code>
      </p>
      <empty-line/>
      <p>
        <code> withdraw(std::string const&amp; account_,</code>
      </p>
      <p>
        <code>  unsigned amount_, messaging::sender atm_queue_):</code>
      </p>
      <p>
        <code>   account(account_), amount(amount_), atm_queue(atm_queue_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct withdraw_ok {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct withdraw_denied {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct cancel_withdrawal {</code>
      </p>
      <p>
        <code> std::string account;</code>
      </p>
      <p>
        <code> unsigned amount;</code>
      </p>
      <empty-line/>
      <p>
        <code> cancel_withdrawal(std::string const&amp; account_,</code>
      </p>
      <p>
        <code>  unsigned amount_):</code>
      </p>
      <p>
        <code>   account(account_), amount(amount_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct withdrawal_processed {</code>
      </p>
      <p>
        <code> std::string account;</code>
      </p>
      <p>
        <code> unsigned amount;</code>
      </p>
      <empty-line/>
      <p>
        <code> withdrawal_processed(std::string const&amp; account_,</code>
      </p>
      <p>
        <code>  unsigned amount_):</code>
      </p>
      <p>
        <code>   account(account_), amount(amount_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct card_inserted {</code>
      </p>
      <p>
        <code> std::string account;</code>
      </p>
      <empty-line/>
      <p>
        <code> explicit card_inserted(std::string const&amp; account_):</code>
      </p>
      <p>
        <code>  account(account_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct digit_pressed {</code>
      </p>
      <p>
        <code> char digit;</code>
      </p>
      <empty-line/>
      <p>
        <code> explicit digit_pressed(char digit_):</code>
      </p>
      <p>
        <code>  digit(digit_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct clear_last_pressed {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct eject_card {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct withdraw_pressed {</code>
      </p>
      <p>
        <code> unsigned amount;</code>
      </p>
      <empty-line/>
      <p>
        <code> explicit withdraw_pressed(unsigned amount_):</code>
      </p>
      <p>
        <code>  amount(amount_) {}</code>
      </p>
      <empty-line/>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct cancel_pressed {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct issue_money {</code>
      </p>
      <p>
        <code> unsigned amount;</code>
      </p>
      <p>
        <code> issue_money(unsigned amount_):</code>
      </p>
      <p>
        <code>  amount(amount_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct verify_pin {</code>
      </p>
      <p>
        <code> std::string account;</code>
      </p>
      <p>
        <code> std::string pin;</code>
      </p>
      <p>
        <code> mutable messaging::sender atm_queue;</code>
      </p>
      <empty-line/>
      <p>
        <code> verify_pin(std::string const&amp; account_, std::string const&amp; pin_,</code>
      </p>
      <p>
        <code>  messaging::sender atm_queue_):</code>
      </p>
      <p>
        <code>   account(account_), pin(pin_), atm_queue(atm_queue_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct pin_verified {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct pin_incorrect {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct display_enter_pin {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct display_enter_card {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct display_insufficient_funds {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct display_withdrawal_cancelled {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct display_pin_incorrect_message {};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct display_withdrawal_options (};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct get_balance {</code>
      </p>
      <p>
        <code> std::string account;</code>
      </p>
      <p>
        <code> mutable messaging::sender atm_queue;</code>
      </p>
      <empty-line/>
      <p>
        <code> get_balance(</code>
      </p>
      <p>
        <code>  std::string const&amp; account_, messaging::sender atm_queue_):</code>
      </p>
      <p>
        <code>   account(account_), atm_queue(atm_queue_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct balance {</code>
      </p>
      <p>
        <code> unsigned amount;</code>
      </p>
      <empty-line/>
      <p>
        <code> explicit balance(unsigned amount_):</code>
      </p>
      <p>
        <code>  amount(amount_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct display_balance {</code>
      </p>
      <p>
        <code> unsigned amount;</code>
      </p>
      <empty-line/>
      <p>
        <code> explicit display_balance(unsigned amount_):</code>
      </p>
      <p>
        <code>  amount(amount_) {}</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p>
        <code>struct balance_pressed {};</code>
      </p>
      <empty-line/>
      <p><strong>Листинг С.7.</strong> Конечный автомат банкомата</p>
      <p>
        <code>class atm {</code>
      </p>
      <p>
        <code> messaging::receiver incoming;</code>
      </p>
      <p>
        <code> messaging::sender bank;</code>
      </p>
      <p>
        <code> messaging::sender interface_hardware;</code>
      </p>
      <p>
        <code> void (atm::*state)();</code>
      </p>
      <p>
        <code> std::string account;</code>
      </p>
      <p>
        <code> unsigned withdrawal_amount;</code>
      </p>
      <p>
        <code> std::string pin;</code>
      </p>
      <empty-line/>
      <p>
        <code> void process_withdrawal() {</code>
      </p>
      <p>
        <code>  incoming.wait().handle&lt;withdraw_ok&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](withdraw_ok const&amp; msg) {</code>
      </p>
      <p>
        <code>    interface_hardware.send(</code>
      </p>
      <p>
        <code>     issue_money(withdrawal_amount));</code>
      </p>
      <p>
        <code>    bank.send(</code>
      </p>
      <p>
        <code>     withdrawal_processed(account, withdrawal_amount));</code>
      </p>
      <p>
        <code>    state = &amp;atm::done_processing;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  ).handle&lt;withdraw_denied&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](withdraw_denied const&amp; msg) {</code>
      </p>
      <p>
        <code>    interface_hardware.send(display_insufficient_funds());</code>
      </p>
      <p>
        <code>    state = &amp;atm::done_processing;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  ).handle&lt;cancel_pressed&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](cancel_pressed const&amp; msg) {</code>
      </p>
      <p>
        <code>    bank.send(</code>
      </p>
      <p>
        <code>     cancel_withdrawal(account, withdrawal_amount));</code>
      </p>
      <p>
        <code>    interface_hardware.send(</code>
      </p>
      <p>
        <code>     display_withdrawal_cancelled());</code>
      </p>
      <p>
        <code>    state = &amp;atm::done_processing;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  );</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> void process_balance() {</code>
      </p>
      <p>
        <code>  incoming.wait().handle&lt;balance&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](balance const&amp; msg) {</code>
      </p>
      <p>
        <code>    interface_hardware.send(display_balance(msg.amount));</code>
      </p>
      <p>
        <code>    state = &amp;atm::wait_for_action;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  ).handle&lt;cancel_pressed&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](cancel_pressed const&amp; msg) {</code>
      </p>
      <p>
        <code>    state = &amp;atm::done_processing;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  );</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> void wait_for_action() {</code>
      </p>
      <p>
        <code>  interface_hardware.send(display_withdrawal_options());</code>
      </p>
      <p>
        <code>  incoming.wait().handle&lt;withdraw_pressed&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](withdraw_pressed const&amp; msg) {</code>
      </p>
      <p>
        <code>    withdrawal_amount = msg.amount;</code>
      </p>
      <p>
        <code>    bank.send(withdraw(account, msg.amount, incoming));</code>
      </p>
      <p>
        <code>    state = &amp;atm::process_withdrawal;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  ).handle&lt;balance_pressed&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](balance_pressed const&amp; msg) {</code>
      </p>
      <p>
        <code>    bank.send(get_balance(account, incoming));</code>
      </p>
      <p>
        <code>    state = &amp;atm::process_balance;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  ).handle&lt;cancel_pressed&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](cancel_pressed const&amp; msg) {</code>
      </p>
      <p>
        <code>    state = &amp;atm::done_processing;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  );</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> void verifying_pin() {</code>
      </p>
      <p>
        <code>  incoming.wait().handle&lt;pin_verified&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](pin_verified const&amp; msg) {</code>
      </p>
      <p>
        <code>    state = &amp;atm::wait_for_action;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  ).handle&lt;pin_incorrect&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](pin_incorrect const&amp; msg) {</code>
      </p>
      <p>
        <code>    interface_hardware.send(</code>
      </p>
      <p>
        <code>     display_pin_incorrect_message());</code>
      </p>
      <p>
        <code>    state = &amp;atm::done_processing;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  ).handle&lt;cancel_pressed&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](cancel_pressed const&amp; msg) {</code>
      </p>
      <p>
        <code>    state = &amp;atm::done_processing;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  );</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> void getting_pin() {</code>
      </p>
      <p>
        <code>  incoming.wait().handle&lt;digit_pressed&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](digit_pressed const&amp; msg) {</code>
      </p>
      <p>
        <code>    unsigned const pin_length = 4;</code>
      </p>
      <p>
        <code>    pin += msg.digit;</code>
      </p>
      <p>
        <code>    if (pin.length() == pin_length) {</code>
      </p>
      <p>
        <code>     bank.send(verify_pin(account, pin, incoming));</code>
      </p>
      <p>
        <code>     state = &amp;atm::verifying_pin;</code>
      </p>
      <p>
        <code>    }</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  ).handle&lt;clear_last_pressed&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](clear_last_pressed const&amp; msg) {</code>
      </p>
      <p>
        <code>    if (!pin.empty()) {</code>
      </p>
      <p>
        <code>     pin.pop_back();</code>
      </p>
      <p>
        <code>    }</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  ).handle&lt;cancel_pressed&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](cancel_pressed const&amp; msg) {</code>
      </p>
      <p>
        <code>    state = &amp;atm::done_processing;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  );</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> void waiting_for_card() {</code>
      </p>
      <p>
        <code>  interface_hardware.send(display_enter_card());</code>
      </p>
      <p>
        <code>  incoming.wait().handle&lt;card_inserted&gt;(</code>
      </p>
      <p>
        <code>   [&amp;](card_inserted const&amp; msg) {</code>
      </p>
      <p>
        <code>    account = msg.account;</code>
      </p>
      <p>
        <code>    pin = "";</code>
      </p>
      <p>
        <code>    interface_hardware.send(display_enter_pin());</code>
      </p>
      <p>
        <code>    state = &amp;atm::getting_pin;</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  );</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> void done_processing() {</code>
      </p>
      <p>
        <code>  interface_hardware.send(eject_card());</code>
      </p>
      <p>
        <code>  state = &amp;atm::waiting_for_card;</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> atm(atm const&amp;) = delete;</code>
      </p>
      <p>
        <code> atm&amp; operator=(atm const&amp;) = delete;</code>
      </p>
      <empty-line/>
      <p>
        <code>public:</code>
      </p>
      <p>
        <code> atm(messaging::sender bank_,</code>
      </p>
      <p>
        <code>  messaging::sender interface_hardware_):</code>
      </p>
      <p>
        <code>   bank(bank_), interface_hardware(interface_hardware_) {}</code>
      </p>
      <empty-line/>
      <p>
        <code> void done() {</code>
      </p>
      <p>
        <code>  get_sender().send(messaging::close_queue());</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> void run() {</code>
      </p>
      <p>
        <code>  state = &amp;atm::waiting_for_card;</code>
      </p>
      <p>
        <code>  try {</code>
      </p>
      <p>
        <code>   for (;;) {</code>
      </p>
      <p>
        <code>    (this-&gt;*state)();</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  } catch(messaging::close_queue const&amp;) {</code>
      </p>
      <p>
        <code>  }</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> messaging::sender get_sender() {</code>
      </p>
      <p>
        <code>  return incoming;</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p><strong>Листинг С.8.</strong> Конечный автомат банка</p>
      <p>
        <code>class bank_machine {</code>
      </p>
      <p>
        <code> messaging::receiver incoming;</code>
      </p>
      <p>
        <code> unsigned balance;</code>
      </p>
      <empty-line/>
      <p>
        <code>public:</code>
      </p>
      <p>
        <code> bank_machine():</code>
      </p>
      <p>
        <code>  balance(199) {}</code>
      </p>
      <empty-line/>
      <p>
        <code> void done() {</code>
      </p>
      <p>
        <code>  get_sender().send(messaging::close_queue());</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> void run() {</code>
      </p>
      <p>
        <code>  try {</code>
      </p>
      <p>
        <code>   for (;;) {</code>
      </p>
      <p>
        <code>    incoming.wait().handle&lt;verify_pin&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](verify_pin const&amp; msg) {</code>
      </p>
      <p>
        <code>      if (msg.pin == "1937") {</code>
      </p>
      <p>
        <code>       msg.atm_queue.send(pin_verified());</code>
      </p>
      <p>
        <code>      } else {</code>
      </p>
      <p>
        <code>       msg.atm_queue.send(pin_incorrect());</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;withdraw&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](withdraw const&amp; msg) {</code>
      </p>
      <p>
        <code>      if (balance &gt;= msg.amount) {</code>
      </p>
      <p>
        <code>       msg.atm_queue.send(withdraw_ok());</code>
      </p>
      <p>
        <code>       balance -= msg.amount;</code>
      </p>
      <p>
        <code>      } else {</code>
      </p>
      <p>
        <code>       msg.atm_queue.send(withdraw_denied());</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;get_balance&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](get_balance const&amp; msg) {</code>
      </p>
      <p>
        <code>      msg.atm_queue.send(::balance(balance));</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;withdrawal_processed&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](withdrawal_processed const&amp; msg) {</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;cancel_withdrawal&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](cancel_withdrawal const&amp; msg) {</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    );</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  } catch(messaging::close_queue const&amp;) {</code>
      </p>
      <p>
        <code>  }</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> messaging::sender get_sender() {</code>
      </p>
      <p>
        <code>  return incoming;</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p><strong>Листинг С.9.</strong> Конечный автомат пользовательского интерфейса</p>
      <p>
        <code>class interface_machine {</code>
      </p>
      <p>
        <code> messaging::receiver incoming;</code>
      </p>
      <empty-line/>
      <p>
        <code>public:</code>
      </p>
      <p>
        <code> void done() {</code>
      </p>
      <p>
        <code>  get_sender().send(messaging::close_queue());</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> void run() {</code>
      </p>
      <p>
        <code>  try {</code>
      </p>
      <p>
        <code>   for (;;) {</code>
      </p>
      <p>
        <code>    incoming.wait().handle&lt;issue_money&gt; (</code>
      </p>
      <p>
        <code>     [&amp;](issue_money const&amp; msg) {</code>
      </p>
      <p>
        <code>      {</code>
      </p>
      <p>
        <code>       std::lock_guard&lt;std::mutex&gt; lk(iom);</code>
      </p>
      <p>
        <code>       std::cout &lt;&lt; "Issuing "</code>
      </p>
      <p>
        <code>                 &lt;&lt; msg.amount &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;display_insufficient_funds&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](display_insufficient_funds const&amp; msg) {</code>
      </p>
      <p>
        <code>      {</code>
      </p>
      <p>
        <code>       std::lock_guard&lt;std::mutex&gt; lk(iom);</code>
      </p>
      <p>
        <code>       std::cout &lt;&lt; "Insufficient funds" &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;display_enter_pin&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](display_enter_pin const&amp; msg) {</code>
      </p>
      <p>
        <code>      {</code>
      </p>
      <p>
        <code>       std::lock_guard&lt;std::mutex&gt; lk(iom);</code>
      </p>
      <p>
        <code>       std::cout</code>
      </p>
      <p>
        <code>        &lt;&lt; "Please enter your PIN (0-9)" &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;display_enter_card&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](display_enter_card const&amp; msg) {</code>
      </p>
      <p>
        <code>      {</code>
      </p>
      <p>
        <code>       std::lock_guard&lt;std::mutex&gt; lk(iom);</code>
      </p>
      <p>
        <code>       std::cout &lt;&lt; "Please enter your card (I)"</code>
      </p>
      <p>
        <code>                 &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;display_balance&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](display_balance const&amp; msg) {</code>
      </p>
      <p>
        <code>      {</code>
      </p>
      <p>
        <code>       std::lock_guard&lt;std::mutex&gt; lk(iom);</code>
      </p>
      <p>
        <code>       std::cout</code>
      </p>
      <p>
        <code>        &lt;&lt; "The balance of your account is "</code>
      </p>
      <p>
        <code>        &lt;&lt; msg.amount &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;display_withdrawal_options&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](display_withdrawal_options const&amp; msg) {</code>
      </p>
      <p>
        <code>      {</code>
      </p>
      <p>
        <code>       std::lock_guard&lt;std::mutex&gt; lk(iom);</code>
      </p>
      <p>
        <code>       std::cout &lt;&lt; "Withdraw 50? (w)" &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>       std::cout &lt;&lt; "Display Balance? (b)"</code>
      </p>
      <p>
        <code>                 &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>       std::cout &lt;&lt; "Cancel? (c) " &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;display_withdrawal_cancelled&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](display_withdrawal_cancelled const&amp; msg) {</code>
      </p>
      <p>
        <code>      {</code>
      </p>
      <p>
        <code>       std::lock_guard&lt;std::mutex&gt; lk(iom);</code>
      </p>
      <p>
        <code>       std::cout &lt;&lt; "Withdrawal cancelled"</code>
      </p>
      <p>
        <code>                 &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;display_pin_incorrect_message&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](display_pin_incorrect_message const&amp; msg) {</code>
      </p>
      <p>
        <code>      {</code>
      </p>
      <p>
        <code>       std::lock_guard&lt;std::mutex&gt; lk(iom);</code>
      </p>
      <p>
        <code>       std::cout &lt;&lt; "PIN incorrect" &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    ).handle&lt;eject_card&gt;(</code>
      </p>
      <p>
        <code>     [&amp;](eject_card const&amp; msg) {</code>
      </p>
      <p>
        <code>      {</code>
      </p>
      <p>
        <code>       std::lock_guard&lt;std::mutex&gt; lk(iom);</code>
      </p>
      <p>
        <code>       std::cout &lt;&lt; "Ejecting card" &lt;&lt; std::endl;</code>
      </p>
      <p>
        <code>      }</code>
      </p>
      <p>
        <code>     }</code>
      </p>
      <p>
        <code>    );</code>
      </p>
      <p>
        <code>   }</code>
      </p>
      <p>
        <code>  } catch (messaging::close_queue&amp;) {</code>
      </p>
      <p>
        <code>  }</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <empty-line/>
      <p>
        <code> messaging::sender get_sender() {</code>
      </p>
      <p>
        <code>  return incoming;</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <p>
        <code>};</code>
      </p>
      <empty-line/>
      <p><strong>Листинг С.10.</strong> Управляющая программа</p>
      <p>
        <code>int main() {</code>
      </p>
      <p>
        <code> bank_machine bank;</code>
      </p>
      <p>
        <code> interface_machine interface_hardware;</code>
      </p>
      <empty-line/>
      <p>
        <code> atm machine(bank.get_sender(), interface_hardware.get_sender());</code>
      </p>
      <empty-line/>
      <p>
        <code> std::thread bank_thread(&amp;bank_machine::run, &amp;bank);</code>
      </p>
      <p>
        <code> std::thread if_thread(&amp;interface_machine::run,</code>
      </p>
      <p>
        <code>  &amp;interface_hardware);</code>
      </p>
      <p>
        <code> std::thread atm_thread(&amp;atm::run, &amp;machine);</code>
      </p>
      <empty-line/>
      <p>
        <code> messaging::sender atmqueue(machine.get_sender());</code>
      </p>
      <p>
        <code> bool quit_pressed = false;</code>
      </p>
      <empty-line/>
      <p>
        <code> while (!quit_pressed) {</code>
      </p>
      <p>
        <code>  char c = getchar();</code>
      </p>
      <p>
        <code>  switch(с) {</code>
      </p>
      <p>
        <code>  case '0':</code>
      </p>
      <p>
        <code>  case '1':</code>
      </p>
      <p>
        <code>  case '2':</code>
      </p>
      <p>
        <code>  case '3':</code>
      </p>
      <p>
        <code>  case '4':</code>
      </p>
      <p>
        <code>  case '5':</code>
      </p>
      <p>
        <code>  case '6':</code>
      </p>
      <p>
        <code>  case '7':</code>
      </p>
      <p>
        <code>  case '8':</code>
      </p>
      <p>
        <code>  case '9':</code>
      </p>
      <p>
        <code>   atmqueue.send(digit_pressed(с));</code>
      </p>
      <p>
        <code>   break;</code>
      </p>
      <p>
        <code>  case 'b':</code>
      </p>
      <p>
        <code>   atmqueue.send(balance_pressed());</code>
      </p>
      <p>
        <code>   break;</code>
      </p>
      <p>
        <code>  case 'w':</code>
      </p>
      <p>
        <code>   atmqueue.send(withdraw_pressed(50));</code>
      </p>
      <p>
        <code>   break;</code>
      </p>
      <p>
        <code>  case 'с':</code>
      </p>
      <p>
        <code>   atmqueue.send(cancel_pressed());</code>
      </p>
      <p>
        <code>   break;</code>
      </p>
      <p>
        <code>  case 'q':</code>
      </p>
      <p>
        <code>   quit_pressed = true;</code>
      </p>
      <p>
        <code>   break;</code>
      </p>
      <p>
        <code>  case 'i':</code>
      </p>
      <p>
        <code>   atmqueue.send(card_inserted("acc1234"));</code>
      </p>
      <p>
        <code>   break;</code>
      </p>
      <p>
        <code>  }</code>
      </p>
      <p>
        <code> }</code>
      </p>
      <p>
        <code> bank.done();</code>
      </p>
      <p>
        <code> machine.done();</code>
      </p>
      <p>
        <code> interface_hardware.done();</code>
      </p>
      <p>
        <code> atm_thread.join();</code>
      </p>
      <p>
        <code> bank_thread.join();</code>
      </p>
      <p>
        <code> if_thread.join();</code>
      </p>
      <p>
        <code>}</code>
      </p>
    </section>
    <section>
      <title>
        <p>Приложение D</p>
        <p>Справочник по библиотеке С++ Thread Library</p>
      </title>
      <section>
        <title>
          <p>D.1. Заголовок <code>&lt;<emphasis>chrono</emphasis>&gt;</code></p>
        </title>
        <section>
          <p>В заголовке <code>&lt;chrono&gt;</code> объявлены классы для представления моментов времени, интервалов и часов, которые служат источником объектов <code>time_point</code>. В каждом классе часов имеется статическая переменная-член <code>is_steady</code>, показывающая, являются ли данные часы <emphasis>стабильными</emphasis>. Стабильными называются часы, которые ходят с постоянной частотой и не допускают подведения. Единственные гарантированно стабильные часы представлены классом <code>std::chrono::steady_clock</code>.</p>
          <p>
            <emphasis>Содержимое заголовка</emphasis>
          </p>
          <p>
            <code>namespace std {</code>
          </p>
          <empty-line/>
          <p>
            <code>namespace chrono {</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Rep, typename Period = ratio&lt;1&gt;&gt;</code>
          </p>
          <p>
            <code>class duration;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;</code>
          </p>
          <p>
            <code> typename Clock,</code>
          </p>
          <p>
            <code> typename Duration = typename Clock::duration&gt;</code>
          </p>
          <p>
            <code>class time_point;</code>
          </p>
          <empty-line/>
          <p>
            <code>class system_clock;</code>
          </p>
          <p>
            <code>class steady_clock;</code>
          </p>
          <p>
            <code>typedef unspecified-clock-type high_resolution_clock;</code>
          </p>
          <empty-line/>
          <p>
            <code>}</code>
          </p>
          <empty-line/>
          <p>
            <code>}</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.1.1. Шаблон класса <code>std::chrono::duration</code></p>
          </title>
          <p>Шаблон класса s<code>td::chrono::duration</code> предназначен для представления интервалов. Параметры шаблона <code>Rep</code> и <code>Period</code> — это соответственно тип данных для хранения значения интервала и конкретизация шаблона класса <code>std::ratio</code>, которая задает промежуток времени (в виде долей секунды) между последовательными «тиками». Например, <code>std::chrono::duration&lt;int, std::milli&gt;</code> определяет количество миллисекунд, представимое значением типа <code>int</code>, s<code>td::chrono::duration&lt;short, std::ratio&lt;1, 50&gt;&gt;</code> — количество пятидесятых долей секунды, представимое значением типа <code>short</code>, а <code>std::chrono::duration&lt;long long, std::ratio&lt;60, 1&gt;&gt;</code> — количество минут, представимое значением типа <code>long long</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class Rep, class Period = ratio&lt;1&gt; &gt;</code>
          </p>
          <p>
            <code>class duration {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> typedef Rep rep;</code>
          </p>
          <p>
            <code> typedef Period period;</code>
          </p>
          <empty-line/>
          <p>
            <code> constexpr duration() = default;</code>
          </p>
          <p>
            <code> ~duration() = default;</code>
          </p>
          <empty-line/>
          <p>
            <code> duration(const duration&amp;) = default;</code>
          </p>
          <p>
            <code> duration&amp; operator=(const duration&amp;) = default;</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;class Rep2&gt;</code>
          </p>
          <p>
            <code> constexpr explicit duration(const Rep2&amp; r);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code> constexpr duration(const duration&lt;Rep2, Period2&gt;&amp; d);</code>
          </p>
          <empty-line/>
          <p>
            <code> constexpr rep count() const;</code>
          </p>
          <p>
            <code> constexpr duration operator+() const;</code>
          </p>
          <p>
            <code> constexpr duration operator-() const;</code>
          </p>
          <p>
            <code> duration&amp; operator++();</code>
          </p>
          <p>
            <code> duration operator++(int);</code>
          </p>
          <p>
            <code> duration&amp; operator--();</code>
          </p>
          <p>
            <code> duration operator--(int);</code>
          </p>
          <p>
            <code> duration&amp; operator+=(const duration&amp; d);</code>
          </p>
          <p>
            <code> duration&amp; operator-=(const duration&amp; d);</code>
          </p>
          <p>
            <code> duration&amp; operator*=(const rep&amp; rhs);</code>
          </p>
          <p>
            <code> duration&amp; operator/=(const rep&amp; rhs);</code>
          </p>
          <p>
            <code> duration&amp; operator%=(const rep&amp; rhs);</code>
          </p>
          <p>
            <code> duration&amp; operator%=(const duration&amp; rhs);</code>
          </p>
          <p>
            <code> static constexpr duration zero();</code>
          </p>
          <p>
            <code> static constexpr duration min();</code>
          </p>
          <p>
            <code> static constexpr duration max();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator==(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator !=(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator&lt;(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator&lt;=(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code>const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator&gt;(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator&gt;=(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class ToDuration, class Rep, class Period&gt;</code>
          </p>
          <p>
            <code>constexpr ToDuration duration_cast(</code>
          </p>
          <p>
            <code> const duration&lt;Rep, Period&gt;&amp; d);</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p><code>Rep</code> должен быть встроенным числовым типом или определенным пользователем типом со свойствами числа. <code>Period</code> должен быть конкретизацией шаблона <code>std::ratio&lt;&gt;</code>.</p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::REP, TYPEDEF</strong>
            </code>
          </p>
          <p>Это псевдоним типа для хранения числа тиков в значении <code>duration</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef Rep rep;</code>
          </p>
          <p><code>rep</code> — тип значения, используемого для хранения внутреннего представления объекта <code>duration</code>.</p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::PERIOD, TYPEDEF</strong>
            </code>
          </p>
          <p>Это псевдоним типа для конкретизации шаблона класса <code>std::ratio</code>, которая задает количество долей секунды, представляемых счетчиком интервала. Например, если <code>period</code> — это <code>std::ratio&lt;1, 50&gt;</code>, то объект <code>duration</code>, для которого <code>count()</code> равно <emphasis>N</emphasis>, представляет <emphasis>N</emphasis> пятидесятых долей секунды.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef Period period;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::chrono::duration</code> со значением по умолчанию.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr duration() = default;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Внутреннее значение <code>duration</code> (типа <code>rep</code>) инициализируется значением по умолчанию.</p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
            <strong>, КОНВЕРТИРУЮЩИЙ КОНСТРУКТОР ИЗ ЗНАЧЕНИЯ СЧЕТЧИКА</strong>
          </p>
          <p>Конструирует экземпляр <code>std::chrono::duration</code> с заданным значением счетчика.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class Rep2&gt;</code>
          </p>
          <p>
            <code>constexpr explicit duration(const Rep2&amp; r);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Внутреннее значение объекта <code>duration</code> инициализируется значением <code>static_cast&lt;rep&gt;(r)</code>.</p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p>Этот конструктор участвует в разрешении перегрузки, только если <code>Rep2</code> может быть неявно преобразован в <code>Rep</code>, и либо <code>Rep</code> — тип с плавающей точкой, либо <code>Rep2</code> <emphasis>не</emphasis> является типом с плавающей точкой.</p>
          <p>
            <emphasis>Постусловие</emphasis>
          </p>
          <p>
            <code>this-&gt;count() == static_cast&lt;rep&gt;(r)</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
            <strong>, КОНВЕРТИРУЮЩИЙ КОНСТРУКТОР ИЗ ДРУГОГО ЗНАЧЕНИЯ</strong>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
          </p>
          <p>Конструирует экземпляр <code>std::chrono::duration</code>, масштабируя значение счетчика другого объекта <code>std::chrono::duration</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class Rep2 , class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr duration(const duration&lt;Rep2, Period2&gt;&amp; d);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Внутреннее значение объекта <code>duration</code> инициализируется значением <code>duration_cast&lt;duration&lt;Rep, Period&gt;&gt;(d).count()</code>.</p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p>Этот конструктор участвует в разрешении перегрузки, только если <code>Rep</code> — тип с плавающей точкой, либо <code>Rep2</code> <emphasis>не</emphasis> является типом с плавающей точкой, и <code>Period2</code> — целое кратное <code>Period</code> (то есть <code>ratio_divide&lt;Period2, Period&gt;::den == 1</code>). Это позволяет избежать случайного обрезания (и, значит, потери точности) при сохранении интервала с меньшим периодом в переменной, представляющий интервал с большим периодом.</p>
          <p>
            <emphasis>Постусловие</emphasis>
          </p>
          <p>
            <code>this-&gt;count() == duration_cast&lt;duration&lt;Rep, Period&gt;&gt;(d).count()</code>
          </p>
          <p>
            <emphasis>Примеры</emphasis>
          </p>
          <p>
            <code>duration&lt; int, ratio&lt;1, 1000&gt;&gt; ms(5); &#8592;</code>
            <strong>5 миллисекунд</strong>
          </p>
          <p>
            <code>duration&lt;int, ratio&lt;1,1&gt;&gt; s(ms);&#8592;&#9488;</code>
            <strong>Ошибка: нельзя</strong>
          </p>
          <p>
            <code>                                 &#9474;</code>
            <strong>сохранить мс как</strong>
          </p>
          <p>
            <code>                                 &#9474;</code>
            <strong>целые секунды</strong>
          </p>
          <p>
            <code>duration&lt;double, ratio&lt;1, 1&gt;&gt; s2(ms);&#8592;&#9488;</code>
            <strong>Правильно:</strong>
          </p>
          <p>
            <code>                                      &#9474;</code>
            <strong>s2.count() == 0.005</strong>
          </p>
          <p>
            <code>duration&lt;int, ratio&lt;1, 1000000&gt;&gt; us(ms);&#8592;&#9488;</code>
            <strong>Правильно:</strong>
          </p>
          <p>
            <code>                                         &#9474;</code>
            <strong>us.count() == 5000</strong>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::COUNT</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Получает значение интервала.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr rep count() const;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Внутреннее значение объекта <code>duration</code> в виде значения типа <code>rep</code>.</p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR+</strong>
            </code>
            <strong>, УНАРНЫЙ ОПЕРАТОР ПЛЮС</strong>
          </p>
          <p>Пустая операция, возвращает копию <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr duration operator+() const;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR-</strong>
            </code>
            <strong>, УНАРНЫЙ ОПЕРАТОР МИНУС</strong>
          </p>
          <p>Возвращает интервал, в котором значение <code>count()</code> противоположно значению <code>this-&gt;count()</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr duration operator-() const;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>duration(-this-&gt;count());</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR++</strong>
            </code>
            <strong>, ОПЕРАТОР ПРЕДИНКРЕМЕНТА</strong>
          </p>
          <p>Инкрементирует внутренний счетчик.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration&amp; operator++();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>++this-&gt;internal_count;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR++</strong>
            </code>
            <strong>, ОПЕРАТОР ПОСТИНКРЕМЕНТА</strong>
          </p>
          <p>Инкрементирует внутренний счетчик и возвращает то значение <code>*this</code>, которое предшествовало выполнению операции.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration operator++(int);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>duration temp(*this);</code>
          </p>
          <p>
            <code>++(*this);</code>
          </p>
          <p>
            <code>return temp;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR--</strong>
            </code>
            <strong>, ОПЕРАТОР ПРЕДЕКРЕМЕНТА</strong>
          </p>
          <p>Декрементирует внутренний счетчик.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration&amp; operator--();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>--this-&gt;internal_count;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR--</strong>
            </code>
            <strong>, ОПЕРАТОР ПОСТДЕКРЕМЕНТА</strong>
          </p>
          <p>Декрементирует внутренний счетчик и возвращает то значение <code>*this</code>, которое предшествовало выполнению операции.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration operator--(int);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>duration temp(*this);</code>
          </p>
          <p>
            <code>--(*this);</code>
          </p>
          <p>
            <code>return temp;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR+=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Прибавляет счетчик другого объекта <code>duration</code> к внутреннему счетчику <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration&amp; operator+=(duration const&amp; other);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>internal_count += other.count();</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR-=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Вычитает счетчик другого объекта <code>duration</code> из внутреннего счетчика <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration&amp; operator-=(duration const&amp; other);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>internal_count-=other.count();</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR*=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Умножает внутренний счетчик <code>*this</code> на заданное значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration&amp; operator*=(rep const&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>internal_count*=rhs;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR/=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Делит внутренний счетчик <code>*this</code> на заданное значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration&amp; operator/=(rep const&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>internal_count/=rhs;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR%=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Записывает во внутренний счетчик <code>*this</code> остаток от его деления на заданное значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration&amp; operator%=(rep const&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>internal_count%=rhs;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::OPERATOR%=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Записывает во внутренний счетчик <code>*this</code> остаток от его деления на счетчик в другом объекте <code>duration</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration&amp; operator%=(duration const&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>internal_count %= rhs.count();</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::ZERO</strong>
            </code>
            <strong>, СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Возвращает объект <code>duration</code>, представляющий значение нуль.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr duration zero();</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>duration(duration_values&lt;rep&gt;::zero());</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::MIN</strong>
            </code>
            <strong>, СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Возвращает объект <code>duration</code>, представляющий минимально возможное для данной конкретизации значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr duration min();</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>duration(duration_values&lt;rep&gt;::min());</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION::MAX</strong>
            </code>
            <strong>, СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Возвращает объект <code>duration</code>, представляющий максимально возможное для данной конкретизации значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr duration max();</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>duration(duration_values&lt;rep&gt;::max());</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ НА РАВЕНСТВО</strong>
          </p>
          <p>Сравнивает два объекта <code>duration</code> на равенство, даже если они имеют разные представления и (или) периоды.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator==(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p>Либо для <code>lhs</code> определено неявное преобразование в <code>rhs</code>, либо наоборот. Если ни одна из частей не может быть неявно преобразована в другую или они являются различными представлениями <code>duration</code>, но каждая может быть неявно преобразована в другую, то выражение построено некорректно.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если <code>CommonDuration</code> — синоним <code>std::common_type&lt;duration&lt;Rep1, Period1&gt;, duration&lt;Rep2, Period2&gt;&gt;::type</code>, to <code>lhs==rhs</code> возвращает <code>CommonDuration(lhs).count() == CommonDuration(rhs).count()</code>.</p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ НА НЕРАВЕНСТВО</strong>
          </p>
          <p>Сравнивает два объекта <code>duration</code> на неравенство, даже если они имеют разные представления и (или) периоды.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator!=(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p>Либо для <code>lhs</code> определено неявное преобразование в <code>rhs</code>, либо наоборот. Если ни одна из частей не может быть неявно преобразовала в другую или они являются различными представлениями <code>duration</code>, но каждая может быть неявно преобразовала в другую, то выражение построено некорректно.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>!(lhs == rhs)</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ МЕНЬШЕ</strong>
          </p>
          <p>Проверяет, что один объект <code>duration</code> меньше другого, даже если они имеют разные представления и (или) периоды.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator&lt;(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p>Либо для <code>lhs</code> определено неявное преобразование в <code>rhs</code><strong>,</strong> либо наоборот. Если ни одна из частей не может быть неявно преобразована в другую или они являются различными представлениями <code>duration</code><strong>,</strong> по каждая может быть неявно преобразована в другую, то выражение построено некорректно.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если <code>CommonDuration</code> — синоним <code>std::common_type&lt; duration&lt; Rep1, Period1&gt;, duration&lt; Rep2, Period2&gt;&gt;::type</code>, то <code>lhs&lt;rhs</code> возвращает <code>CommonDuration(lhs).count() &lt; CommonDuration(rhs).count()</code>.</p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ БОЛЬШЕ</strong>
          </p>
          <p>Проверяет, что один объект <code>duration</code> больше другого, даже если они имеют разные представления и (или) периоды.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator&gt;(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p>Либо для <code>lhs</code> определено неявное преобразование в <code>rhs</code>, либо наоборот. Если ни одна из частей не может быть неявно преобразована в другую или они являются различными представлениями <code>duration</code>, но каждая может быть неявно преобразована в другую, то выражение построено некорректно.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>!((rhs&lt;lhs)||(rhs==lhs))</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ МЕНЬШЕ ИЛИ РАВНО</strong>
          </p>
          <p>Проверяет, что один объект <code>duration</code> меньше или равен другому, даже если они имеют разные представления и (или) периоды.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator&lt;=(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p>Либо для <code>lhs</code> определено неявное преобразование в <code>rhs</code>, либо наоборот. Если ни одна из частей не может быть неявно преобразовала в другую или они являются различными представлениями <code>duration</code>, но каждая может быть неявно преобразована в другую, то выражение построено некорректно.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>!(rhs&gt;lhs)</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ БОЛЬШЕ ИЛИ РАВНО</strong>
          </p>
          <p>Проверяет, что один объект <code>duration</code> больше или равен другому, даже если они имеют разные представления и (или) периоды.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class Rep1, class Period1, class Rep2, class Period2&gt;</code>
          </p>
          <p>
            <code>constexpr bool operator&gt;=(</code>
          </p>
          <p>
            <code> const duration&lt;Rep1, Period1&gt;&amp; lhs,</code>
          </p>
          <p>
            <code> const duration&lt;Rep2, Period2&gt;&amp; rhs);</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p>Либо для <code>lhs</code> определено неявное преобразование в <code>rhs</code>, либо наоборот. Если ни одна из частей не может быть неявно преобразована в другую или они являются различными представлениями <code>duration</code>, но каждая может быть неявно преобразована в другую, то выражение построено некорректно.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>!(lhs&lt;rhs)</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::DURATION_CAST</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Явно преобразует объект <code>std::chrono::duration</code> в заданную конкретизацию <code>std::chrono::duration</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class ToDuration, class Rep, class Period&gt;</code>
          </p>
          <p>
            <code>constexpr ToDuration duration_cast(</code>
          </p>
          <p>
            <code> const duration&lt;Rep, Period&gt;&amp; d);</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p><code>ToDuration</code> должен быть конкретизацией <code>std::chrono::duration</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>d</code>, преобразованное к типу интервала, заданного параметром <code>ToDuration</code>. При выполнении операции минимизируется потеря точности в результате преобразования интервалов с разными масштабами и типами представления.</p>
        </section>
        <section>
          <title>
            <p>D.1.2. Шаблон класса <code>std::chrono::time_point</code></p>
          </title>
          <p>Шаблон класса <code>std::chrono::time_point</code> представляет момент времени, измеренный по конкретным часам. Задается в виде интервала, прошедшего с момента <emphasis>эпохи</emphasis> данных часов. Параметр шаблона <code>Clock</code> задает часы (у разных часов должны быть разные типы), а параметр <code>Duration</code> — тип для измерения интервала от эпохи, который должен быть конкретизацией шаблона <code>std::chrono::duration</code>. По умолчанию <code>Duration</code> совпадает с подразумеваемым типом интервала, определенным в <code>Clock</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class Clock, class Duration = typename Clock::duration&gt;</code>
          </p>
          <p>
            <code>class time_point {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> typedef Clock clock;</code>
          </p>
          <p>
            <code> typedef Duration duration;</code>
          </p>
          <p>
            <code> typedef typename duration::rep rep;</code>
          </p>
          <p>
            <code> typedef typename duration::period period;</code>
          </p>
          <empty-line/>
          <p>
            <code> time_point();</code>
          </p>
          <p>
            <code> explicit time_point(const duration&amp; d);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;class Duration2&gt;</code>
          </p>
          <p>
            <code> time_point(const time_point&lt;clock, Duration2&gt;&amp; t);</code>
          </p>
          <empty-line/>
          <p>
            <code> duration time_since_epoch() const;</code>
          </p>
          <empty-line/>
          <p>
            <code> time_point&amp; operator+=(const duration&amp; d);</code>
          </p>
          <p>
            <code> time_point&amp; operator-=(const duration&amp; d);</code>
          </p>
          <empty-line/>
          <p>
            <code> static constexpr time_point min();</code>
          </p>
          <p>
            <code> static constexpr time_point max();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::TIME_POINT</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>time_point</code>, представляющий эпоху часов <code>Clock</code>; внутренний интервал инициализируется значением <code>Duration::zero()</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>time_point();</code>
          </p>
          <p>
            <emphasis>Постусловие</emphasis>
          </p>
          <p>Для сконструированного по умолчанию объекта <code>tp</code> типа <code>time_point</code> имеет место равенство <code>tp.time_since_epoch() == tp::duration::zero()</code>.</p>
          <p>
            <code>
              <strong>STD::CHRONO::TIME_POINT</strong>
            </code>
            <strong>, КОНСТРУКТОР ИЗ ИНТЕРВАЛА</strong>
          </p>
          <p>Конструирует объект <code>time_point</code>, представляющий заданный интервал от эпохи часов <code>Clock</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>explicit time_point(const duration&amp; d);</code>
          </p>
          <p>
            <emphasis>Постусловие</emphasis>
          </p>
          <p>Для объекта <code>tp</code> типа <code>time_point</code>, созданного конструктором <code>tp(d)</code> из некоторого интервала <code>d</code>, имеет место равенство <code>tp.time_since_epoch() == d</code>.</p>
          <p>
            <code>
              <strong>STD::CHRONO::TIME_POINT</strong>
            </code>
            <strong>, КОНВЕРТИРУЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует объект <code>time_point</code> из другого объекта <code>time_point</code> с таким же типом <code>Clock</code>, по другим типом <code>Duration</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template &lt;class Duration2&gt;</code>
          </p>
          <p>
            <code>time_point(const time_point&lt;clock, Duration2&gt;&amp; t);</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p>Для типа <code>Duration2</code> должно существовать неявное преобразование в тип <code>Duration</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Эквивалентно выражению <code>time_point(t.time_since_epoch())</code>.</p>
          <p>Значение, возвращенное функцией <code>t.time_since_epoch()</code> неявно преобразуется в объект типа <code>Duration</code>, который сохраняется в новом объекте типа <code>time_point</code>.</p>
          <p>
            <code>
              <strong>STD::CHRONO::TIME_POINT::TIME_SINCE_EPOCH</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Возвращает интервал от эпохи часов для данного объекта типа <code>time_point</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>duration time_since_epoch() const;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>duration</code>, хранящееся в <code>*this</code>.</p>
          <p>
            <code>
              <strong>STD::CHRONO::TIME_POINT::OPERATOR+=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Прибавляет указанный интервал <code>duration</code> к значению, хранящемуся в данном объекте <code>time_point</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>time_point&amp; operator+=(const duration&amp; d);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Прибавляет <code>d</code> к внутреннему интервалу <code>*this</code>, эквивалентно <code>this-&gt;internal_duration += d</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::TIME_POINT::OPERATOR-=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Вычитает указанный интерфейс <code>duration</code> из значения, хранящегося в данном объекте <code>time_point</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>time_point&amp; operator-=(const duration&amp; d);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вычитает <code>d</code> из внутреннего интервала <code>*this</code>, эквивалентно <code>this-&gt;internal_duration -= d</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::TIME_POINT::MIN</strong>
            </code>
            <strong>, СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Получает объект <code>time_point</code>, представляющий минимально возможное для данного типа значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>static constexpr time_point min();</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>time_point(time_point::duration::min())</code> (см. 11.1.1.15)</p>
          <p>
            <code>
              <strong>STD::CHRONO::TIME_POINT::MAX,</strong>
            </code>
            <strong>СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Получает объект <code>time_point</code>, представляющий максимально возможное для данного типа значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>static constexpr time_point max();</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>time_point(time_point::duration::max())</code> (см. 11.1.1.16)</p>
        </section>
        <section>
          <title>
            <p>D.1.3. Класс <code>std::chrono::system_clock</code></p>
          </title>
          <p>Класс <code>std::chrono::system_clock</code> предоставляет средства для получения времени от системных часов реального времени. Текущее время возвращает функция <code>std::chrono::system_clock::now()</code>. Объекты класса <code>std::chrono::system_clock::time_point</code> можно преобразовывать в тип <code>time_t</code> с помощью функции <code>std::chrono::system_clock::to_time_t()</code> и получать из этого типа с помощью функции <code>std::chrono::system_clock::to_time_point()</code>. Системные часы не <emphasis>стабильны</emphasis>, поэтому последующее обращение к <code>std::chrono::system_clock::now()</code> может вернуть момент времени, более ранний, чем при предыдущем обращении (например, если часы операционной системы были подведены вручную или автоматически синхронизировались с внешним источником времени).</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class system_clock {</code>
          </p>
          <empty-line/>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> typedef <emphasis>unspecified-integral-type</emphasis> rep;</code>
          </p>
          <p>
            <code> typedef std::ratio&lt;<emphasis>unspecified</emphasis>, <emphasis>unspecified</emphasis>&gt; period;</code>
          </p>
          <p>
            <code> typedef std::chrono::duration&lt;rep, period&gt; duration;</code>
          </p>
          <p>
            <code> typedef std::chrono::time_point&lt;system_clock&gt; time_point;</code>
          </p>
          <p>
            <code> static const bool is_steady = <emphasis>unspecified</emphasis>;</code>
          </p>
          <empty-line/>
          <p>
            <code> static time_point now() noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> static time_t to_time_t(const time_point&amp; t) noexcept;</code>
          </p>
          <p>
            <code> static time_point from_time_t(time_t t) noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::SYSTEM_CLOCK::REP</strong>
            </code>
            <strong>, TYPEDEF</strong>
          </p>
          <p>Псевдоним целочисленного типа, используемого для хранения количества тиков в интервале <code>duration</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef <emphasis>unspecified-integral-type</emphasis> rep;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::SYSTEM_CLOCK::PERIOD</strong>
            </code>
            <strong>, TYPEDEF</strong>
          </p>
          <p>Псевдоним типа для конкретизации шаблонного класса <code>std::ratio</code>, которая определяет наименьшее число секунд (или долей секунды) между различающимися значениями <code>duration</code> или <code>time_point</code>. Псевдоним <code>period</code> определяет <emphasis>точность</emphasis> часов, а не частоту тактов.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef std::ratio&lt;<emphasis>unspecified</emphasis>, <emphasis>unspecified</emphasis>&gt; period;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::SYSTEM_CLOCK::DURATION</strong>
            </code>
            <strong>, TYPEDEF</strong>
          </p>
          <p>Конкретизация шаблонного класса <code>std::chrono::duration</code>, в которой может храниться разность между любыми двумя моментами времени, полученными от системных часов реального времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef std::chrono::duration&lt;</code>
          </p>
          <p>
            <code> std::chrono::system_clock::rep,</code>
          </p>
          <p>
            <code> std::chrono::system_clock::period&gt; duration;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::SYSTEM_CLOCK::TIME_POINT</strong>
            </code>
            <strong>, TYPEDEF</strong>
          </p>
          <p>Конкретизация шаблонного класса <code>std::chrono::time_point</code>, в которой могут храниться моменты времени, полученные от системных часов реального времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef std::chrono::time_point&lt;std::chrono::system_clock&gt; time_point;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::SYSTEM_CLOCK::NOW</strong>
            </code>
            <strong>, СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Получает текущее время от системных часов реального времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>time_point now() noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Экземпляр <code>time_point</code>, представляющий текущее время по системным часам реального времени.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Возбуждает исключение <code>std::system_error</code> в случае ошибки.</p>
          <p><code>STD::CHRONO::SYSTEM_CLOCK::TO_TIME_T</code>, СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</p>
          <p>Преобразует объект типа <code>time_point</code> в объект типа <code>time_t</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>time_t to_time_t(time_point const&amp; t) noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Экземпляр <code>time_t</code>, представляющий тот же момент времени, что и <code>t</code>, округленный или обрезанный до секунд.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Возбуждает исключение <code>std::system_error</code> в случае ошибки.</p>
          <p>
            <code>
              <strong>STD::CHRONO::SYSТЕМ_CLOCK::FROM_TIME_T</strong>
            </code>
            <strong>, СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Преобразует объект типа <code>time_t</code> в объект типа <code>time_point</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>time_point from_time_t(time_t const&amp; t) noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Экземпляр <code>time_point</code>, представляющий тот же момент времени, что и <code>t</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Возбуждает исключение <code>std::system_error</code> в случае ошибки.</p>
        </section>
        <section>
          <title>
            <p>D.1.4. Класс <code>std::chrono::steady_clock</code></p>
          </title>
          <p>Класс <code>std::chrono::steady_clock</code> предоставляет доступ к системным стабильным часам. Текущее время возвращает функция <code>std::chrono::steady_clock::now()</code>. He существует фиксированного соотношения между значениями, возвращаемыми <code>std::chrono::steady_clock::now()</code> и показаниями часов реального времени. Стабильные часы не могут «идти в обратную сторону», поэтому если некое обращение к функции <code>std::chrono::steady_clock::now()</code> происходит-раньше другого обращения к ней же, то второе обращение должно вернуть момент времени, больший или равным первому. Часы ходят с частотой, настолько близкой к постоянной, насколько это возможно.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class steady_clock {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> typedef <emphasis>unspecified-integral-type</emphasis> rep;</code>
          </p>
          <p>
            <code> typedef std::ratio&lt;</code>
          </p>
          <p>
            <code><emphasis>  unspecified</emphasis>, <emphasis>unspecified</emphasis>&gt; period;</code>
          </p>
          <p>
            <code> typedef std::chrono::duration&lt;rep, period&gt; duration;</code>
          </p>
          <p>
            <code> typedef std::chrono::time_point&lt;steady_clock&gt;</code>
          </p>
          <p>
            <code> time_point;</code>
          </p>
          <p>
            <code> static const bool is_steady = true;</code>
          </p>
          <empty-line/>
          <p>
            <code> static time_point now() noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::STEADY_CLOCK::REP</strong>
            </code>
            <strong>, TYPEDEF</strong>
          </p>
          <p>Псевдоним целочисленного типа, используемого для хранения количества тиков в интервале <code>duration</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef <emphasis>unspecified-integral-type</emphasis> rep;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::STEADY_CLOCK::PERIOD</strong>
            </code>
            <strong>, TYPEDEF</strong>
          </p>
          <p>Псевдоним типа для конкретизации шаблонного класса <code>std::ratio</code>, которая определяет наименьшее число секунд (или долей секунды) между различающимися значениями <code>duration</code> или <code>time_point</code>. Псевдоним <code>period</code> определяет <emphasis>точность</emphasis> часов, а не частоту тактов.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef std::ratio&lt;<emphasis>unspecified</emphasis>, <emphasis>unspecified</emphasis>&gt; period;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::STEADY_CLOCK::DURATION</strong>
            </code>
            <strong>, TYPEDEF</strong>
          </p>
          <p>Конкретизация шаблонного класса <code>std::chrono::duration</code>, в которой может храниться разность между любыми двумя моментами времени, полученными от системных стабильных часов.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef std::chrono::duration&lt;</code>
          </p>
          <p>
            <code> std::chrono::steady_clock::rep,</code>
          </p>
          <p>
            <code> std::chrono::steady_clock::period&gt; duration;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::STEADY_CLOCK::TIME_POINT</strong>
            </code>
            <strong>, TYPEDEF</strong>
          </p>
          <p>Конкретизация шаблонного класса <code>std::chrono::time_point</code>, в которой могут храниться моменты времени, полученные от системных стабильных часов.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef std::chrono::time_point&lt;std::chrono::steady_clock&gt;</code>
          </p>
          <p>
            <code>time_point;</code>
          </p>
          <p>
            <code>
              <strong>STD::CHRONO::STEADY_CLOCK::NOW</strong>
            </code>
            <strong>, СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Получает текущее время от системных стабильных часов.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>time_point now() noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Экземпляр <code>time_point</code>, представляющий текущее время но системным стабильным часам.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Возбуждает исключение <code>std::system_error</code> в случае ошибки.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Если одно обращение к <code>std::chrono::steady_clock::now()</code> происходит-раньше другого, то момент времени <code>time_point</code>, возвращенный при первом обращении, меньше или равен моменту времени <code>time_point</code>, возвращенному при втором обращении.</p>
        </section>
        <section>
          <title>
            <p>D.1.5. Псевдоним типа <code>std::chrono::high_resolution_clock</code></p>
          </title>
          <p>Класс <code>std::chrono::high_resolution_clock</code> предоставляет доступ к системным часам максимально высокого разрешения. Как и для всех остальных часов, текущее время можно получить от функции <code>std::chrono::high_resolution_clock::now()</code>. Имя <code>std::chrono::high_resolution_clock</code> может быть псевдонимом класса <code>std::chrono::system_clock</code> или класса <code>std::chrono::steady_clock</code>, либо отдельным типом.</p>
          <p>Хотя тип <code>std::chrono::high_resolution_clock</code> дает самое высокое разрешение среди всех входящих в библиотеку часов, обращение к функции <code>std::chrono::high_resolution_clock::now()</code> все же занимает конечное время. Поэтому, пытаясь хронометрировать очень короткие операции, учитывайте накладные расходы на вызов этой функции.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class high_resolution_clock {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> typedef unspecified-integral-type rep;</code>
          </p>
          <p>
            <code> typedef std::ratio&lt;</code>
          </p>
          <p>
            <code><emphasis>  unspecified</emphasis>, <emphasis>unspecified</emphasis>&gt; period;</code>
          </p>
          <p>
            <code> typedef std::chrono::duration&lt;rep, period&gt; duration;</code>
          </p>
          <p>
            <code> typedef std::chrono::time_point&lt;</code>
          </p>
          <p>
            <code><emphasis>  unspecified</emphasis>&gt; time_point;</code>
          </p>
          <p>
            <code> static const bool is_steady = <emphasis>unspecified</emphasis>;</code>
          </p>
          <empty-line/>
          <p>
            <code> static time_point now() noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
        </section>
      </section>
      <section>
        <title>
          <p>D.2. Заголовок <code>&lt;condition_variable&gt;</code></p>
        </title>
        <section>
          <p>Заголовок <code>&lt;condition_variable&gt;</code> предоставляет доступ к условным переменным. Это базовый механизм синхронизации, который позволяет блокировать поток до получения уведомления о том, что выполнено некоторое условие или истек таймаут.</p>
          <p>Содержимое заголовка</p>
          <p>
            <code>namespace std {</code>
          </p>
          <p>
            <code>enum class cv_status { timeout, no_timeout };</code>
          </p>
          <empty-line/>
          <p>
            <code>class condition_variable;</code>
          </p>
          <p>
            <code>class condition_variable_any;</code>
          </p>
          <p>
            <code>}</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.2.1. Класс <code>std::condition_variable</code></p>
          </title>
          <p>Класс <code>std::condition_variable</code> позволяет потоку ждать выполнения условия.</p>
          <p>Экземпляры этого класса не удовлетворяют концепциям <code>CopyAssignable</code>, <code>CopyConstructible</code>, <code>MoveAssignable</code>, <code>MoveConstructible</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class condition_variable {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> condition_variable();</code>
          </p>
          <p>
            <code> ~condition_variable();</code>
          </p>
          <empty-line/>
          <p>
            <code> condition_variable(condition_variable const&amp;) = delete;</code>
          </p>
          <p>
            <code> condition_variable&amp; operator=(</code>
          </p>
          <p>
            <code>  condition_variable const&amp;) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> void notify_one() noexcept;</code>
          </p>
          <p>
            <code> void notify_all() noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> void wait(std::unique_lock&lt;std::mutex&gt;&amp; lock);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;typename Predicate&gt;</code>
          </p>
          <p>
            <code> void wait(std::unique_lock&lt;std::mutex&gt;&amp; lock, Predicate pred);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code> cv_status wait_until(</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt;&amp; lock,</code>
          </p>
          <p>
            <code>  const std::chrono::time_point&lt;Clock, Duration&gt;&amp; absolute_time);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;typename Clock, typename Duration, typename Predicate&gt;</code>
          </p>
          <p>
            <code> bool wait_until(</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt;&amp; lock,</code>
          </p>
          <p>
            <code>  const std::chrono::time_point&lt;Clock, Duration&gt;&amp; absolute_time,</code>
          </p>
          <p>
            <code>  Predicate pred);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code> cv_status wait_for(</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt;&amp; lock,</code>
          </p>
          <p>
            <code>  const std::chrono::duration&lt;Rep, Period&gt;&amp; relative_time);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;typename Rep, typename Period, typename Predicate&gt;</code>
          </p>
          <p>
            <code> bool wait_for(</code>
          </p>
          <p>
            <code>  std::unique_lock&lt;std::mutex&gt;&amp; lock,</code>
          </p>
          <p>
            <code>  const std::chrono::duration&lt;Rep, Period&gt;&amp; relative_time,</code>
          </p>
          <p>
            <code>  Predicate pred);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>void notify_all_at_thread_exit(</code>
          </p>
          <p>
            <code> condition_variable&amp;, unique_lock&lt;mutex&gt;);</code>
          </p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект типа <code>std::condition_variable</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>condition_variable();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует объект типа <code>std::condition_variable</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если сконструировать условную переменную не получилось.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::condition_variable</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~condition_variable();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Не существует потоков, заблокированных по <code>*this</code> в обращениях к <code>wait()</code>, <code>wait_for()</code> или <code>wait_until()</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE::NOTIFY_ONE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пробуждает один из потоков, ожидающих <code>std::condition_variable</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void notify_one() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пробуждает один из потоков, ожидающих <code>*this</code>, в точке вызова. Если таких потоков нет, функция не имеет никакого эффекта.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE::NOTIFY_ALL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пробуждает все потоки, ожидающие <code>std::condition_variable</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void notify_all() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пробуждает все потоки, ожидающие <code>*this</code>, в точке вызова. Если таких потоков нет, функция не имеет никакого эффекта.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE::WAIT</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable</code> не получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> либо не произойдёт ложное пробуждение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void wait(std::unique_lock&lt;std::mutex&gt;&amp; lock);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Значение <code>lock.owns_lock()</code> равно <code>true</code>, и блокировкой владеет вызывающий поток.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно разблокирует предоставленный объект <code>lock</code> и блокирует поток, пока он не будет разбужен обращением к <code>notify_one()</code> или <code>notify_all()</code> из другого потока либо не произойдёт ложное пробуждение. Перед возвратом управления из <code>wait()</code> объект <code>lock</code> снова блокируется.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено. Если объект <code>lock</code> был разблокирован при обращении к <code>wait()</code>, он снова блокируется при выходе из нее, даже если выход произошёл в результате исключения.</p>
          <cite>
            <p><strong>Примечание</strong>. Ложное пробуждение означает, что поток, вызвавший <code>wait()</code>, может быть разбужен, даже если ни один другой поток не обращался к <code>notify_one()</code> или <code>notify_all()</code>. Поэтому рекомендуется использовать перегруженный вариант <code>wait()</code>, который принимает предикат. Если это нежелательно, то рекомендуется вызывать <code>wait()</code> в цикле, где проверяется предикат, ассоциированный с условной переменной.</p>
          </cite>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE::WAIT</strong>
            </code>
            <strong>, ПЕРЕГРУЖЕННАЯ ФУНКЦИЯ-ЧЛЕН, ПРИНИМАЮЩАЯ ПРЕДИКАТ</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable</code> не получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> и при этом предикат равен <code>true</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Predicate&gt;</code>
          </p>
          <p>
            <code>void wait(std::unique_lock&lt;std::mutex&gt;&amp; lock, Predicate pred);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Выражение <code>pred()</code> должно быть допустимо и возвращать значение, преобразуемое в тип <code>bool</code>. Значение <code>lock.owns_lock()</code> должно быть равно <code>true</code>, и владельцем блокировки <code>lock</code> должен быть поток, вызвавший <code>wait()</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Эквивалентно циклу</p>
          <p>
            <code>while (!pred()) {</code>
          </p>
          <p>
            <code> wait(lock);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение, возбужденное в результате обращения к <code>pred</code>, или <code>std::system_error</code>, если действие не выполнено.</p>
          <cite>
            <p><strong>Примечание</strong>. Возможность ложного пробуждения означает, что функция <code>pred</code> может вызываться несколько раз (сколько именно, не определено). При любом вызове <code>pred</code> мьютекс, на который ссылается объект <code>lock</code>, гарантированно будет захвачен, и функция вернет управление тогда и только тогда, когда результатом вычисления <code>(bool)pred()</code> является <code>true</code>.</p>
          </cite>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE::WAIT_FOR</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable</code> не получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code>, либо не истечет таймаут, либо не произойдёт ложное пробуждение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>cv_status wait_for(</code>
          </p>
          <p>
            <code>std::unique_lock&lt;std::mutex&gt;&amp; lock,</code>
          </p>
          <p>
            <code>std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Значение <code>lock.owns_lock()</code> равно <code>true</code>, и блокировкой владеет вызывающий поток.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно разблокирует предоставленный объект <code>lock</code> и блокирует поток, пока он не будет разбужен обращением к <code>notify_one()</code> или <code>notify_all()</code> из другого потока, либо не истечет таймаут, заданный аргументом <code>relative_time</code>, либо не произойдёт ложное пробуждение. Перед возвратом управления из <code>wait_for()</code> объект <code>lock</code> снова блокируется.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>std::cv_status::no_timeout</code>, если поток был разбужен в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> либо ложного пробуждения. В противном случае <code>std::cv_status::timeout</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено. Если объект <code>lock</code> был разблокирован при обращении к <code>wait_for()</code>, он снова блокируется при выходе из нее, даже если выход произошёл в результате исключения.</p>
          <cite>
            <p><strong>Примечание</strong>. Ложное пробуждение означает, что поток, вызвавший <code>wait_for()</code>, может быть разбужен, даже если ни один другой поток не обращался к <code>notify_one()</code> или <code>notify_all()</code>. Поэтому рекомендуется использовать перегруженный вариант <code>wait_for()</code>, который принимает предикат. Если это нежелательно, то рекомендуется вызывать <code>wait_for()</code> в цикле, где проверяется предикат, ассоциированный с условной переменной. При этом необходимо следить, не истек ли таймаут. Во многих случаях предпочтительнее использовать функцию <code>wait_until()</code>. Поток может быть блокирован дольше, чем указано. Если возможно, истекшее время измеряется по стабильным часам.</p>
          </cite>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE::WAIT_FOR</strong>
            </code>
            <strong>, ПЕРЕГРУЖЕННАЯ ФУНКЦИЯ-ЧЛЕН, ПРИНИМАЮЩАЯ ПРЕДИКАТ</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable</code> не получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> и при этом предикат равен <code>true</code>, либо не истечет указанный таймаут.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Rep, typename Period, typename Predicate&gt;</code>
          </p>
          <p>
            <code>bool wait_for(</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt;&amp; lock,</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time,</code>
          </p>
          <p>
            <code> Predicate pred);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Выражение <code>pred()</code> должно быть допустимо и возвращать значение, преобразуемое в тип <code>bool</code>. Значение <code>lock.owns_lock()</code> должно быть равно <code>true</code>, и владельцем блокировки <code>lock</code> должен быть поток, вызвавший <code>wait_for()</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Эквивалентно следующему коду:</p>
          <p>
            <code>internal_clock::time_point end =</code>
          </p>
          <p>
            <code> internal_clock::now() + relative_time;</code>
          </p>
          <p>
            <code>while (!pred()) {</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; remaining_time =</code>
          </p>
          <p>
            <code>  end-internal_clock::now();</code>
          </p>
          <p>
            <code> if (wait_for(lock, remaining_time) == std::cv_status::timeout)</code>
          </p>
          <p>
            <code>  return pred();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <code>return true;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если последнее обращение к <code>pred()</code> вернуло <code>true</code>; <code>false</code>, если истекло время, заданное в аргументе <code>relative_time</code> и обращение к <code>pred()</code> вернуло <code>false</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Возможность ложного пробуждения означает, что функция <code>pred</code> может вызываться несколько раз (сколько именно, не определено). При любом вызове <code>pred</code> мьютекс, на который ссылается объект <code>lock</code>, гарантированно будет захвачен, и функция вернет управление тогда и только тогда, когда результатом вычисления <code>(bool)pred()</code> является <code>true</code> или истекло время, заданное в аргументе <code>relative_time</code>. Поток может быть блокирован дольше, чем указано. Если возможно, истекшее время измеряется по стабильным часам.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение, возбужденное в результате обращения к <code>pred</code>, или <code>std::system_error</code>, если действие не выполнено.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE::WAIT_UNTIL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable</code> не получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> либо не будет достигнут указанный момент времени, либо не произойдёт ложное пробуждение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>cv_status wait_until(</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt;&amp; lock,</code>
          </p>
          <p>
            <code> std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Значение <code>lock.owns_lock()</code> равно <code>true</code>, и владельцем блокировки <code>lock</code> является вызывающий поток.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно разблокирует предоставленный объект <code>lock</code> и блокирует поток, пока он не будет разбужен обращением к <code>notify_one()</code> или <code>notify_all()</code> из другого потока, либо функция <code>Clock::now()</code> не вернет время, большее или равное <code>absolute_time</code>, либо не произойдёт ложное пробуждение. Перед возвратом управления из <code>wait_until()</code> объект <code>lock</code> снова блокируется.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>std::cv_status::no_timeout</code>, если поток был разбужен в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> либо ложного пробуждения. В противном случае <code>std::cv_status::timeout</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено. Если объект <code>lock</code> был разблокирован при обращении к <code>wait_for()</code>, он снова блокируется при выходе из нее, даже если выход произошёл в результате исключения.</p>
          <cite>
            <p><strong>Примечание</strong>. Ложное пробуждение означает, что поток, вызвавший <code>wait_until()</code>, может быть разбужен, даже если ни один другой поток не обращался к <code>notify_one()</code> или <code>notify_all()</code>. Поэтому рекомендуется использовать перегруженный вариант <code>wait_until()</code>, который принимает предикат. Если это нежелательно, то рекомендуется вызывать <code>wait_until()</code> в цикле, где проверяется предикат, ассоциированный с условной переменной. Не дается никаких гарантий относительно того, сколько времени будет блокирован вызывающий поток. Гарантируется лишь, что если функция вернула <code>false</code>, то значение, возвращенное <code>Clock::now()</code>, больше или равно <code>absolute_time</code> в точке, где поток разблокировался.</p>
          </cite>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE::WAIT_UNTIL</strong>
            </code>
            <strong>, ПЕРЕГРУЖЕННАЯ ФУНКЦИЯ-ЧЛЕН, ПРИНИМАЮЩАЯ ПРЕДИКАТ</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable</code> не получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code>, и при этом предикат равен <code>true</code>, либо не будет достигнут указанный момент времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Clock, typename Duration, typename Predicate&gt;</code>
          </p>
          <p>
            <code>bool wait_until(</code>
          </p>
          <p>
            <code> std::unique_lock&lt;std::mutex&gt;&amp; lock,</code>
          </p>
          <p>
            <code> std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time,</code>
          </p>
          <p>
            <code> Predicate pred);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Выражение <code>pred()</code> должно быть допустимо и возвращать значение, преобразуемое в тип <code>bool</code>. Значение <code>lock.owns_lock()</code> должно быть равно <code>true</code>, и владельцем блокировки <code>lock</code> должен быть поток, вызвавший <code>wait_until()</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Эквивалентно следующему коду:</p>
          <p>
            <code>while (!pred()) {</code>
          </p>
          <p>
            <code> if (wait_until(lock, absolute_time) == std::cv_status::timeout)</code>
          </p>
          <p>
            <code>  return pred();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <code>return true;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если последнее обращение к <code>pred()</code> вернуло <code>true</code>; <code>false</code>, если функция <code>Clock::now()</code> вернула время, большее или равное <code>absolute_time</code>, и обращение к <code>pred()</code> вернуло <code>false</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Возможность ложного пробуждения означает, что функция <code>pred</code> может вызываться несколько раз (сколько именно, не определено). При любом вызове <code>pred</code> мьютекс, на который ссылается объект <code>lock</code>, гарантированно будет захвачен, и функция вернет управление тогда и только тогда, когда результатом вычисления <code>(bool)pred()</code> является <code>true</code> или функция <code>Clock::now()</code> вернула время, больше или равное <code>absolute_time</code>. Не дается никаких гарантий относительно того, сколько времени будет блокирован вызывающий поток. Гарантируется лишь, что если функция вернула <code>false</code>, то значение, возвращенное <code>Clock::now()</code>, больше или равно <code>absolute_time</code> в точке, где поток разблокировался.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение, возбужденное в результате обращения к <code>pred</code>, или <code>std::system_error</code>, если действие не выполнено.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::NOTIFY_ALL_AT_THREAD_EXIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Пробуждает все потоки, ожидающие <code>std::condition_variable</code>, при завершении текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void notify_all_at_thread_exit(</code>
          </p>
          <p>
            <code> condition_variable&amp; cv, unique_lock&lt;mutex&gt; lk);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Значение <code>lock.owns_lock()</code> равно <code>true</code>, и владельцем блокировки <code>lock</code> является вызывающий поток. Функция <code>lk.mutex()</code> должна возвращать такое же значение, как для любого объекта блокировки, передаваемого функциям-членам <code>wait()</code>, <code>wait_for()</code> или <code>wait_until()</code> объекта <code>cv</code> из одновременно ожидающих потоков.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Передает владение мьютексом, захваченным <code>lk</code>, внутреннему объекту и планирует отправку уведомления условной переменной <code>cv</code> при завершении вызывающего потока. Уведомление эквивалентно выполнению следующего кода:</p>
          <p>
            <code>lk.unlock();</code>
          </p>
          <p>
            <code>cv.notify_all();</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Возбуждает исключение <code>std::system_error</code>, если действие не выполнено.</p>
          <cite>
            <p><strong>Примечание</strong>. Блокировка удерживается до завершения потока, поэтому необходимо предпринимать меры для предотвращения взаимоблокировки. Рекомендуется завершать вызывающий поток как можно раньше и не выполнять в нем никаких блокирующих операций.</p>
          </cite>
          <p>Пользователь должен следить за тем, чтобы ожидающий поток не сделал ошибочного предположения о том, что в момент его пробуждения данный поток уже завершен, — в частности, из-за возможности ложного пробуждения. Для этого можно проверять в ожидающем потоке предикат, который может быть сделан истинным только уведомляющим потоком, причём это должно делаться под защитой мьютекса, который не освобождается до вызова <code>notify_all_at_thread_exit</code><strong>.</strong></p>
        </section>
        <section>
          <title>
            <p>D.2.2. Класс <code>std::condition_variable_any</code></p>
          </title>
          <p>Класс <code>std::condition_variable_any</code> позволяет потоку ждать выполнения условия. Если объект <code>std::condition_variable</code> можно использовать только с блокировкой типа <code>std::unique_lock&lt;std::mutex&gt;</code>, то <code>std::condition_variable_any</code> допустимо использовать с блокировкой <emphasis>любого</emphasis> типа, удовлетворяющего требованиям концепции <code>Lockable</code>.</p>
          <p>Экземпляры <code>std::condition_variable_any</code> не удовлетворяют концепциям <code>CopyAssignable</code>, <code>CopyConstructible</code>, <code>MoveAssignable</code>, <code>MoveConstructible</code>.</p>
          <p>Определение класса</p>
          <p>
            <code>class condition_variable_any {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> condition_variable_any();</code>
          </p>
          <p>
            <code> ~condition_variable_any();</code>
          </p>
          <empty-line/>
          <p>
            <code> condition_variable_any(</code>
          </p>
          <p>
            <code>  condition_variable_any const&amp;) = delete;</code>
          </p>
          <p>
            <code> condition_variable_any&amp; operator=(</code>
          </p>
          <p>
            <code>  condition_variable_any const&amp;) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> void notify_one() noexcept;</code>
          </p>
          <p>
            <code> void notify_all() noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Lockable&gt;</code>
          </p>
          <p>
            <code> void wait(Lockable&amp; lock);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;typename Lockable, typename Predicate&gt;</code>
          </p>
          <p>
            <code> void wait(Lockable&amp; lock, Predicate pred);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;typename Lockable, typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code> std::cv_status wait_until(</code>
          </p>
          <p>
            <code>  Lockable&amp; lock,</code>
          </p>
          <p>
            <code>  const std::chrono::time_point&lt;Clock, Duration&gt;&amp; absolute_time);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;</code>
          </p>
          <p>
            <code>  typename Lockable, typename Clock,</code>
          </p>
          <p>
            <code>  typename Duration, typename Predicate&gt;</code>
          </p>
          <p>
            <code> bool wait_until(</code>
          </p>
          <p>
            <code>  Lockable&amp; lock,</code>
          </p>
          <p>
            <code>  const std::chrono::time_point&lt;Clock, Duration&gt;&amp; absolute_time,</code>
          </p>
          <p>
            <code>  Predicate pred);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;typename Lockable, typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code> std::cv_status wait_for(</code>
          </p>
          <p>
            <code>  Lockable&amp; lock,</code>
          </p>
          <p>
            <code>  const std::chrono::duration&lt;Rep, Period&gt;&amp; relative_time);</code>
          </p>
          <empty-line/>
          <p>
            <code> template &lt;</code>
          </p>
          <p>
            <code>  typename Lockable, typename Rep,</code>
          </p>
          <p>
            <code>  typename Period, typename Predicate&gt;</code>
          </p>
          <p>
            <code> bool wait_for(</code>
          </p>
          <p>
            <code>  Lockable&amp; lock,</code>
          </p>
          <p>
            <code>  const std::chrono::duration&lt;Rep, Period&gt;&amp; relative_time,</code>
          </p>
          <p>
            <code>  Predicate pred);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE_ANY</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект типа <code>std::condition_variable_any</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>condition_variable_any();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует объект типа <code>std::condition_variable_any</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если сконструировать условную переменную не получилось.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE_ANY</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект s<code>td::condition_variable_any</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~condition_variable_any();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Не существует потоков, заблокированных по <code>*this</code> в обращениях к <code>wait()</code>, <code>wait_for()</code> или <code>wait_until()</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE_ANY::NOTIFY_ONE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пробуждает один из потоков, ожидающих <code>std::condition_variable_any</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void notify_one() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пробуждает один из потоков, ожидающих <code>*this</code>, в точке вызова. Если таких потоков нет, функция не имеет никакого эффекта.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable_any</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE_ANY::NOTIFY_ALL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пробуждает все потоки, ожидающие <code>std::condition_variable_any</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void notify_all() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пробуждает все потоки, ожидающие <code>*this</code>, в точке вызова. Если таких потоков нет, функция не имеет никакого эффекта.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable_any</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE::WAIT</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable_any</code> не получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> либо не произойдёт ложное пробуждение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Lockable&gt;</code>
          </p>
          <p>
            <code>void wait(Lockable&amp; lock);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Тип <code>Lockable</code> удовлетворяет требованиям концепции <code>Lockable</code> и <code>lock</code> владеет блокировкой.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно разблокирует предоставленный объект <code>lock</code> и блокирует поток, пока он не будет разбужен обращением к <code>notify_one()</code> или <code>notify_all()</code> из другого потока либо не произойдёт ложное пробуждение. Перед возвратом управления из <code>wait()</code> объект <code>lock</code> снова блокируется.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено. Если объект <code>lock</code> был разблокирован при обращении к <code>wait()</code>, он снова блокируется при выходе из нее, даже если выход произошёл в результате исключения.</p>
          <cite>
            <p><strong>Примечание</strong>. Ложное пробуждение означает, что поток, вызвавший <code>wait()</code>, может быть разбужен, даже если ни один другой поток не обращался к <code>notify_one()</code> или <code>notify_all()</code>. Поэтому рекомендуется использовать перегруженный вариант <code>wait()</code>, который принимает предикат. Если это нежелательно, то рекомендуется вызывать <code>wait()</code> в цикле, где проверяется предикат, ассоциированный с условной переменной.</p>
          </cite>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable_any</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE_ANY::WAIT</strong>
            </code>
            <strong>, ПЕРЕГРУЖЕННАЯ ФУНКЦИЯ-ЧЛЕН, ПРИНИМАЮЩАЯ ПРЕДИКАТ</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable_any</code> получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> и при этом предикат равен <code>true</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Lockable, typename Predicate&gt;</code>
          </p>
          <p>
            <code>void wait(Lockable&amp; lock, Predicate pred);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Выражение <code>pred()</code> должно быть допустимо и возвращать значение, преобразуемое в тип <code>bool</code>. Тип <code>Lockable</code> удовлетворяет требованиям концепции <code>Lockable</code> и <code>lock</code> владеет блокировкой.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Эквивалентно циклу</p>
          <p>
            <code>while (!pred()) {</code>
          </p>
          <p>
            <code> wait(lock);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение, возбужденное в результате обращения к <code>pred</code>, или <code>std::system_error</code>, если действие не выполнено.</p>
          <cite>
            <p><strong>Примечание</strong>. Возможность ложного пробуждения означает, что функция <code>pred</code> может вызываться несколько раз (сколько именно, не определено). При любом вызове <code>pred</code> мьютекс, на который ссылается объект <code>lock</code>, гарантированно будет захвачен, и функция вернет управление тогда и только тогда, когда результатом вычисления <code>(bool)pred()</code> является <code>true</code>.</p>
          </cite>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable_any</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE_ANY::WAIT_FOR</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable_any</code> получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code>, либо истечет таймаут, либо произойдёт ложное пробуждение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Lockable, typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>std::cv_status wait_for(</code>
          </p>
          <p>
            <code> Lockable&amp; lock,</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Тип <code>Lockable</code> удовлетворяет требованиям концепции <code>Lockable</code> и <code>lock</code> владеет блокировкой.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно разблокирует предоставленный объект <code>lock</code> и блокирует поток, пока он не будет разбужен обращением к <code>notify_one()</code> или <code>notify_all()</code> из другого потока, либо не истечет таймаут, заданный аргументом <code>relative_time</code>, либо не произойдёт ложное пробуждение. Перед возвратом управления из <code>wait_for()</code> объект <code>lock</code> снова блокируется.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>std::cv_status::no_timeout</code>, если поток был разбужен в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> либо ложного пробуждения. В противном случае <code>std::cv_status::timeout</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено. Если объект <code>lock</code> был разблокирован при обращении к <code>wait_for()</code>, он снова блокируется при выходе из нее, даже если выход произошёл в результате исключения.</p>
          <cite>
            <p><strong>Примечание</strong>. Ложное пробуждение означает, что поток, вызвавший <code>wait_for()</code>, может быть разбужен, даже если ни один другой поток не обращался к <code>notify_one()</code> или <code>notify_all()</code>. Поэтому рекомендуется использовать перегруженный вариант <code>wait_for()</code>, который принимает предикат. Если это нежелательно, то рекомендуется вызывать <code>wait_for()</code> в цикле, где проверяется предикат, ассоциированный с условной переменной. При этом необходимо следить, не истек ли таймаут. Во многих случаях предпочтительнее использовать функцию <code>wait_until()</code>. Поток может быть блокирован дольше, чем указано. Если возможно, истекшее время измеряется по стабильным часам.</p>
          </cite>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable_any</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE_ANY::WAIT_FOR</strong>
            </code>
            <strong>, ПЕРЕГРУЖЕННАЯ ФУНКЦИЯ-ЧЛЕН, ПРИНИМАЮЩАЯ ПРЕДИКАТ</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable_any</code> получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> и при этом предикат равен <code>true</code>, либо истечет указанный таймаут.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Lockable, typename Rep,</code>
          </p>
          <p>
            <code>         typename Period, typename Predicate&gt;</code>
          </p>
          <p>
            <code>bool wait_for(</code>
          </p>
          <p>
            <code> Lockable&amp; lock,</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time,</code>
          </p>
          <p>
            <code> Predicate pred);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Выражение <code>pred()</code> должно быть допустимо и возвращать значение, преобразуемое в тип <code>bool</code>. Тип <code>Lockable</code> удовлетворяет требованиям концепции <code>Lockable</code> и <code>lock</code> владеет блокировкой.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Эквивалентно следующему коду:</p>
          <p>
            <code>internal_clock::time_point end</code>
          </p>
          <p>
            <code> = internal_clock::now() + relative_time;</code>
          </p>
          <p>
            <code>while (!pred()) {</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; remaining_time =</code>
          </p>
          <p>
            <code>  end-internal_clock::now();</code>
          </p>
          <p>
            <code> if (wait_for(lock, remaining_time) == std::cv_status::timeout)</code>
          </p>
          <p>
            <code>  return pred();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <code>return true;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если последнее обращение к <code>pred()</code> вернуло <code>true</code>; <code>false</code>, если истекло время, заданное в аргументе <code>relative_time</code> и обращение к <code>pred()</code> вернуло <code>false</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Возможность ложного пробуждения означает, что функция <code>pred</code> может вызываться несколько раз (сколько именно, не определено). При любом вызове <code>pred</code> мьютекс, на который ссылается объект <code>lock</code>, гарантированно будет захвачен, и функция вернет управление тогда и только тогда, когда результатом вычисления <code>(bool)pred()</code> является <code>true</code> или истекло время, заданное в аргументе <code>relative_time</code>. Поток может быть блокирован дольше, чем указано. Если возможно, истекшее время измеряется по стабильным часам.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение, возбужденное в результате обращения к <code>pred</code>, или <code>std::system_error</code>, если действие не выполнено.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable_any</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE_ANY::WAIT_UNTIL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable_any</code> получит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> либо будет достигнут указанный момент времени, либо произойдёт ложное пробуждение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Lockable, typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>std::cv_status wait_until(</code>
          </p>
          <p>
            <code> Lockable&amp; lock,</code>
          </p>
          <p>
            <code> std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Тип <code>Lockable</code> удовлетворяет требованиям концепции <code>Lockable</code> и <code>lock</code> владеет блокировкой.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно разблокирует предоставленный объект <code>lock</code> и блокирует поток, пока он не будет разбужен обращением к <code>notify_one()</code> или <code>notify_all()</code> из другого потока, либо функция <code>Clock::now()</code> не вернет время, большее или равное <code>absolute_time</code>, либо не произойдёт ложное пробуждение. Перед возвратом управления из <code>wait_until()</code> объект <code>lock</code> снова блокируется.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>std::cv_status::no_timeout</code>, если поток был разбужен в результате обращения к <code>notify_one()</code> или <code>notify_all()</code> либо ложного пробуждения. В противном случае <code>std::cv_status::timeout</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если действие не выполнено. Если объект <code>lock</code> был разблокирован при обращении к <code>wait_for()</code>, он снова блокируется при выходе из нее, даже если выход произошёл в результате исключения.</p>
          <cite>
            <p><strong>Примечание</strong>. Ложное пробуждение означает, что поток, вызвавший <code>wait_until()</code>, может быть разбужен, даже если ни один другой поток не обращался к <code>notify_one()</code> или <code>notify_all()</code>. Поэтому рекомендуется использовать перегруженный вариант <code>wait_until()</code>, который принимает предикат. Если это нежелательно, то рекомендуется вызывать <code>wait_until()</code> в цикле, где проверяется предикат, ассоциированный с условной переменной. Не дается никаких гарантий относительно того, сколько времени будет блокирован вызывающий поток. Гарантируется лишь, что если функция вернула <code>false</code>, то значение, возвращенное <code>Clock::now()</code>, больше или равно <code>absolute_time</code> в точке, где поток разблокировался.</p>
          </cite>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable_any</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
          <p>
            <code>
              <strong>STD::CONDITION_VARIABLE_ANY::WAIT_UNTIL</strong>
            </code>
            <strong>, ПЕРЕГРУЖЕННАЯ ФУНКЦИЯ-ЧЛЕН, ПРИНИМАЮЩАЯ ПРЕДИКАТ</strong>
          </p>
          <p>Ожидает, пока условная переменная <code>std::condition_variable_any</code> но лучит сигнал в результате обращения к <code>notify_one()</code> или <code>notify_all()</code>, и при этом предикат равен <code>true</code>, либо будет достигнут указанный момент времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Lockable, typename Clock,</code>
          </p>
          <p>
            <code>         typename Duration, typename Predicate&gt;</code>
          </p>
          <p>
            <code>bool wait_until(</code>
          </p>
          <p>
            <code> Lockable&amp; lock,</code>
          </p>
          <p>
            <code> std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time,</code>
          </p>
          <p>
            <code> Predicate pred);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Выражение <code>pred()</code> должно быть допустимо и возвращать значение, преобразуемое в тип <code>bool</code>. Тип <code>Lockable</code> удовлетворяет требованиям концепции <code>Lockable</code> и <code>lock</code> владеет блокировкой.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Эквивалентно следующему коду:</p>
          <p>
            <code>while (!pred()) {</code>
          </p>
          <p>
            <code> if (wait_until(lock, absolute_time) == std::cv_status::timeout)</code>
          </p>
          <p>
            <code>  return pred();</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <code>return true;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если последнее обращение к <code>pred()</code> вернуло <code>true</code>; <code>false</code>, если функция <code>Clock::now()</code> вернула время, большее или равное <code>absolute_time</code>, и обращение к <code>pred()</code> вернуло <code>false</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Возможность ложного пробуждения означает, что функция <code>pred</code> может вызываться несколько раз (сколько именно, не определено). При любом вызове <code>pred</code> мьютекс, на который ссылается объект <code>lock</code>, гарантированно будет захвачен, и функция вернет управление тогда и только тогда, когда результатом вычисления <code>(bool)pred()</code> является <code>true</code> или функция <code>Clock::now()</code> вернула время, большее или равное <code>absolute_time</code>. Не дается никаких гарантий относительно того, сколько времени будет блокирован вызывающий поток. Гарантируется лишь, что если функция вернула <code>false</code>, то значение, возвращенное <code>Clock::now()</code>, больше или равно <code>absolute_time</code> в точке, где поток разблокировался.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение, возбужденное в результате обращения к <code>pred</code>, или <code>std::system_error</code>, если действие не выполнено.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к функциям <code>notify_one()</code>, <code>notify_all()</code>, <code>wait()</code>, <code>wait_for()</code> и <code>wait_until()</code> одного и того же объекта <code>std::condition_variable_any</code> сериализуются. Обращение к <code>notify_one()</code> или <code>notify_all()</code> будит только потоки, запущенные <emphasis>до</emphasis> этого обращения.</p>
        </section>
      </section>
      <section>
        <title>
          <p>D.3. Заголовок <code>&lt;atomic&gt;</code></p>
        </title>
        <section>
          <p>В заголовке <code>&lt;atomic&gt;</code> объявлены простые атомарные типы и операции над ними, а также шаблон класса для построения атомарной версии определённого пользователем типа, удовлетворяющего некоторым условиям.</p>
          <p>
            <emphasis>Содержимое заголовка</emphasis>
          </p>
          <p>
            <code>#define ATOMIC_BOOL_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_CHAR_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_SHORT_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_INT_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_LONG_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_LLONG_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_CHAR16_T_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_CHAR32_T_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_WCHAR_T_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_POINTER_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <empty-line/>
          <p>
            <code>#define ATOMIC_VAR_INIT(value) <emphasis>см. описание</emphasis></code>
          </p>
          <empty-line/>
          <p>
            <code>namespace std {</code>
          </p>
          <p>
            <code>enum memory_order;</code>
          </p>
          <p>
            <code>struct atomic_flag;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_bool;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_char;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_char16_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_char32_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_schar;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uchar;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_short;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_ushort;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_long;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_ulong;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_llong;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_ullong;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_wchar_t;</code>
          </p>
          <empty-line/>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int_least8_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint_least8_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int_least16_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint_least16_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int_least32_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint_least32_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int_least64_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint_least64_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int_fast8_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint_fast8_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int_fast16_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint_fast16_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int_fast32_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint_fast32_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int_fast64_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint_fast64_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int8_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint8_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int16_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint16_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int32_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint32_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_int64_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uint64_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_intptr_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uintptr_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_size_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_ssize_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_ptrdiff_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_intmax_t;</code>
          </p>
          <p>
            <code>typedef <emphasis>см. описание</emphasis> atomic_uintmax_t;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>struct atomic;</code>
          </p>
          <empty-line/>
          <p>
            <code>extern "C" void atomic_thread_fence(memory_order order);</code>
          </p>
          <p>
            <code>extern "C" void atomic_signal_fence(memory_order order);</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>T kill_dependency(T);</code>
          </p>
          <p>
            <code>}</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.3.1. <code>std::atomic_xxx</code>, псевдонимы типов</p>
          </title>
          <p>Для совместимости с ожидаемым стандартом С предоставляются псевдонимы <code>typedef</code> для атомарных целочисленных типов. Это псевдонимы либо соответствующей специализации <code>std::atomic&lt;T&gt;</code>, либо базового класса этой специализации с таким же интерфейсом.</p>
          <empty-line/>
          <p><strong>Таблица D.1.</strong> Псевдонимы атомарных типов и соответствующие им специализации <code>std::atomic&lt;&gt;</code></p>
          <table>
            <tr align="left">
              <th align="left" valign="top">
                <code>std::atomic_<emphasis>itype</emphasis></code>
              </th>
              <th align="left" valign="top">Специализация <code>std::atomic&lt;&gt;</code></th>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_char</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;char&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_schar</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;signed char&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_uchar</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned char&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_short</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;short&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_ushort</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned short&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_int</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;int&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_uint</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned int&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_long</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;long&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_ulong</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned long&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_llong</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;long long&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_ullong</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;unsigned long long&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_wchar_t</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;wchar_t&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_char16_t</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;char16_t&gt;</code>
              </td>
            </tr>
            <tr align="left">
              <td align="left" valign="top">
                <code>std::atomic_char32_t</code>
              </td>
              <td align="left" valign="top">
                <code>std::atomic&lt;char32_t&gt;</code>
              </td>
            </tr>
          </table>
        </section>
        <section>
          <title>
            <p>D.3.2. <code>ATOMIC_<emphasis>xxx</emphasis>_LOCK_FREE</code>, макросы</p>
          </title>
          <p>Эти макросы определяют, являются ли атомарные типы, соответствующие различным встроенным типам, свободными от блокировок.</p>
          <p>
            <emphasis>Объявления макросов</emphasis>
          </p>
          <p>
            <code>#define ATOMIC_BOOL_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_CHAR_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_SHORT_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_INT_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_LONG_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_LLONG_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_CHAR16_T_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_CHAR32_T_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_WCHAR_T_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>
            <code>#define ATOMIC_POINTER_LOCK_FREE <emphasis>см. описание</emphasis></code>
          </p>
          <p>Значением <code>ATOMIC_<emphasis>xxx</emphasis>_LOCK_FREE</code> может быть 0, 1 или 2. Значение 0 означает, что операции над знаковыми и беззнаковыми атомарными типами, соответствующими типу <code><emphasis>xxx</emphasis></code>, никогда не свободны от блокировок; 1 — что операции могут быть свободны от блокировок для одних экземпляров этих типов и не свободны для других; 2 — что операции всегда свободны от блокировок. Например, если ATOMIC<code>_INT_LOCK_FREE</code> равно 2, то операции над любыми экземплярами <code>std::atomic&lt;int&gt;</code> и <code>std::atomic&lt;unsigned&gt;</code> свободны от блокировок.</p>
          <p>Макрос <code>ATOMIC_POINTER_LOCK_FREE</code> позволяет узнать, свободны ли от блокировок операции над атомарными специализациями указателя <code>std::atomic&lt;T*&gt;</code>.</p>
        </section>
        <section>
          <title>
            <p>D.3.3. <code>ATOMIC_VAR_INIT</code>, макрос</p>
          </title>
          <p>Макрос <code>ATOMIC_VAR_INIT</code> позволяет инициализировать атомарную переменную конкретным значением.</p>
          <p>Объявление</p>
          <p>
            <code>#define ATOMIC_VAR_INIT(value) <emphasis>см. описание</emphasis></code>
          </p>
          <p>Макрос расширяется в последовательность лексем, которую можно использовать в выражении следующего вида для инициализации одного из стандартных атомарных типов указанным значением:</p>
          <p>
            <code>std::atomic&lt;type&gt; x = ATOMIC_VAR_INIT(val);</code>
          </p>
          <p>Указанное значение должно быть совместимо с неатомарным типом, соответствующим данной атомарной переменной, например:</p>
          <p>
            <code>std::atomic&lt;int&gt; i = ATOMIC_VAR_INIT(42);</code>
          </p>
          <p>
            <code>std::string s;</code>
          </p>
          <p>
            <code>std::atomic&lt;std::string*&gt; p = ATOMIC_VAR_INIT(&amp;s);</code>
          </p>
          <p>Такая инициализация не атомарна, то есть любой доступ из другого потока к инициализируемой переменной в случае, когда инициализация не происходит-раньше этого доступа, приводит к гонке за данными и, следовательно, к неопределённому поведению.</p>
        </section>
        <section>
          <title>
            <p>D.3.4. <code>std::memory_order</code>, перечисление</p>
          </title>
          <p>Перечисление <code>std::memory_order</code> применяется для задания упорядочения доступа к памяти при выполнении атомарных операций.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef enum memory_order {</code>
          </p>
          <p>
            <code> memory_order_relaxed, memory_order_consume,</code>
          </p>
          <p>
            <code> memory_order_acquire, memory_order_release,</code>
          </p>
          <p>
            <code> memory_order_acq_rel, memory_order_seq_cst</code>
          </p>
          <p>
            <code>} memory_order;</code>
          </p>
          <p>Операции, помеченные элементами этого перечисления, ведут себя, как описано ниже (подробное описание упорядочения доступа к памяти см. в главе 5).</p>
          <p>
            <code>
              <strong>STD::MEMORY_ORDER_RELAXED</strong>
            </code>
          </p>
          <p>Операция не обеспечивает никаких дополнительных ограничений на упорядочение.</p>
          <p>
            <code>
              <strong>STD::MEMORY_ORDER_RELEASE</strong>
            </code>
          </p>
          <p>Операция освобождения указанной ячейки памяти. Следовательно, она синхронизируется-с операцией захвата той же ячейки памяти, которая читает сохраненное значение.</p>
          <p>
            <code>
              <strong>STD::MEMORY_ORDER_ACQUIRE</strong>
            </code>
          </p>
          <p>Операция захвата указанной ячейки памяти. Если сохраненное значение было записано операцией освобождения, то сохранение синхронизируется-с этой операцией.</p>
          <p>
            <code>
              <strong>STD::MEMORY_ORDER_ACQ_REL</strong>
            </code>
          </p>
          <p>Операция чтения-модификации-записи. Ведет себя так, как будто одновременно заданы ограничения <code>std::memory_order_acquire</code> и <code>std::memory_order_release</code> для доступа к указанной ячейке памяти.</p>
          <p>
            <code>
              <strong>STD::MEMORY_ORDER_SEQ_CST</strong>
            </code>
          </p>
          <p>Операция является частью цепочки последовательно согласованных операций, на которой определено полное упорядочение. Кроме того, если это сохранение, то оно ведет себя как операция с ограничением <code>std::memory_order_release</code>, если загрузка — то как операция с ограничением <code>std::memory_order_acquire</code>, а если это операция чтения-модификации-записи, то она ведет себя как операция с обоими ограничениями <code>std::memory_order_acquire</code> и <code>std::memory_order_release</code>. <emphasis>Эта семантика по умолчанию подразумевается для всех операций</emphasis>.</p>
          <p>
            <code>
              <strong>STD::MEMORY_ORDER_CONSUME</strong>
            </code>
          </p>
          <p>Операция потребления указанной ячейки памяти.</p>
        </section>
        <section>
          <title>
            <p>D.3.5. <code>std::atomic_thread_fence</code>, функция</p>
          </title>
          <p>Функция <code>std::atomic_thread_fence()</code> вставляет в программу «барьер», чтобы принудительно обеспечить упорядочение доступа к памяти со стороны нескольких операций.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>extern "С" void atomic_thread_fence(std::memory_order order);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вставляет барьер с требуемыми ограничениями на упорядочение доступа к памяти.</p>
          <p>Барьер, для которого параметр <code>order</code> равен <code>std::memory_order_release</code>, <code>std::memory_order_acq_rel</code> или <code>std::memory_order_seq_cst</code> синхронизируется-с операцией захвата некоторой ячейки памяти, если эта операция читает значение, сохраненное атомарной операцией, следующей за барьером в том же потоке, где поставлен барьер.</p>
          <p>Операция освобождения синхронизируется-с барьером, для которого параметр <code>order</code> равен <code>std::memory_order_acquire</code>, <code>std::memory_order_acq_rel</code> или <code>std::memory_order_seq_cst</code>, если эта операция освобождения сохраняет значение, которое читается атомарной операцией, предшествующей барьеру, в том же потоке, где поставлен барьер.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
        </section>
        <section>
          <title>
            <p>D.3.6. <code>std::atomic_signal_fence</code>, функция</p>
          </title>
          <p>Функция <code>std::atomic_signal_fence()</code> вставляет в программу «барьер», чтобы принудительно обеспечить упорядочение доступа к памяти со стороны операций в некотором потоке и операций в обработчике сигнала, находящемся в том же потоке.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>extern "С" void atomic_signal_fence(std::memory_order order);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вставляет барьер с требуемыми ограничениями на упорядочение доступа к памяти. Функция эквивалентна <code>std::atomic_thread_fence(order)</code> с тем отличием, что ограничения применяются только к потоку и обработчику сигнала в том же потоке.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
        </section>
        <section>
          <title>
            <p>D.3.7. <code>std::atomic_flag</code>, класс</p>
          </title>
          <p>Класс <code>std::atomic_flag</code> предоставляет самый простой атомарный флаг. Это единственный тип данных в стандарте С++, который <emphasis>гарантированно</emphasis> свободен от блокировок (хотя в большинстве реализаций этим свойством обладают и многие другие атомарные типы).</p>
          <p>Объект типа <code>std::atomic_flag</code> может находиться в одном из двух состояний: <emphasis>установлен</emphasis> или <emphasis>сброшен</emphasis>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>struct atomic_flag {</code>
          </p>
          <p>
            <code> atomic_flag() noexcept = default;</code>
          </p>
          <p>
            <code> atomic_flag(const atomic_flag&amp;) = delete;</code>
          </p>
          <p>
            <code> atomic_flag&amp; operator=(const atomic_flag&amp;) = delete;</code>
          </p>
          <p>
            <code> atomic_flag&amp; operator=(const atomic_flag&amp;) volatile = delete;</code>
          </p>
          <p>
            <code> bool test_and_set(memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> bool test_and_set(memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> void clear(memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> void clear(memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>bool atomic_flag_test_and_set(volatile atomic_flag*) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_flag_test_and_set(atomic_flag*) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_flag_test_and_set_explicit(</code>
          </p>
          <p>
            <code> volatile atomic_flag*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_flag_test_and_set_explicit(</code>
          </p>
          <p>
            <code> atomic_flag*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>void atomic_flag_clear(volatile atomic_flag*) noexcept;</code>
          </p>
          <p>
            <code>void atomic_flag_clear(atomic_flag*) noexcept;</code>
          </p>
          <p>
            <code>void atomic_flag_clear_explicit(</code>
          </p>
          <p>
            <code> volatile atomic_flag*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>void atomic_flag_clear_explicit(</code>
          </p>
          <p>
            <code> atomic_flag*, memory_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>#define ATOMIC_FLAG_INIT <emphasis>unspecified</emphasis></code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_FLAG</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>He оговаривается, в каком состоянии находится сконструированный по умолчанию экземпляр <code>std::atomic_flag</code>: <emphasis>установлен</emphasis> или <emphasis>сброшен.</emphasis> Для объектов со статическим временем жизни обеспечивается статическая инициализация.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>std::atomic_flag() noexcept = default;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый объект <code>std::atomic_flag</code> в неопределенном состоянии.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::ATOMIC_FLAG</strong>
            </code>
            <strong>, ИНИЦИАЛИЗАЦИЯ МАКРОСОМ</strong>
            <code>
              <strong>ATOMIC_FLAG_INIT</strong>
            </code>
          </p>
          <p>Экземпляр типа <code>std::atomic_flag</code> может быть инициализирован макросом <code>ATOMIC_FLAG_INIT</code>, и в таком случае его начальное состояние — <emphasis>сброшен</emphasis>. Для объектов со статическим временем жизни обеспечивается статическая инициализация.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>#define ATOMIC_FLAG_INIT <emphasis>unspecified</emphasis></code>
          </p>
          <p>
            <emphasis>Использование</emphasis>
          </p>
          <p>
            <code>std::atomic_flag flag = ATOMIC_FLAG_INIT;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый объект <code>std::atomic_flag</code> в состоянии <emphasis>сброшен</emphasis>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::ATOMIC_FLAG::TEST_AND_SET</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно устанавливает флаг и проверяет, был ли он установлен.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool test_and_set(memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code>bool test_and_set(memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно устанавливает флаг.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если флаг был установлен в точке вызова; <code>false</code>, если флаг был сброшен.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_FLAG_TEST_AND_SET</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно устанавливает флаг и проверяет, был ли он установлен.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool atomic_flag_test_and_set(</code>
          </p>
          <p>
            <code> volatile atomic_flag* flag) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_flag_test_and_set(atomic_flag* flag) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return flag-&gt;test_and_set();</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_FLAG_TEST_AND_SET_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно устанавливает флаг и проверяет, был ли он установлен.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool atomic_flag_test_and_set_explicit(</code>
          </p>
          <p>
            <code> volatile atomic_flag* flag, memory_order order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_flag_test_and_set_explicit(</code>
          </p>
          <p>
            <code> atomic_flag* flag, memory_order order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return flag-&gt;test_and_set(order);</code>
          </p>
          <p>
            <code>STD::ATOMIC_FLAG::CLEAR</code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно сбрасывает флаг.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void clear(memory_order order = memory_order_seq_cst) volatile noexcept;</code>
          </p>
          <p>
            <code>void clear(memory_order order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Параметр order должен принимать одно из значений <code>std::memory_order_relaxed</code>, <code>std::memory_order_release</code> или <code>std::memory_order_seq_cst</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно сбрасывает флаг.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция сохранения для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_FLAG_CLEAR</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сбрасывает флаг.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void atomic_flag_clear(volatile atomic_flag* flag) noexcept;</code>
          </p>
          <p>
            <code>void atomic_flag_clear(atomic_flag* flag) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>flag-&gt;clear();</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_FLAG_CLEAR_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сбрасывает флаг.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void atomic_flag_clear_explicit(</code>
          </p>
          <p>
            <code> volatile atomic_flag* flag, memory_order order) noexcept;</code>
          </p>
          <p>
            <code>void atomic_flag_clear_explicit(</code>
          </p>
          <p>
            <code> atomic_flag* flag, memory_order order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return flag-&gt;clear(order);</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.3.8. Шаблон класса <code>std::atomic</code></p>
          </title>
          <p>Шаблон класса <code>std::atomic</code> является оберткой, позволяющей строить атомарные операции для любого типа, удовлетворяющего следующим условиям.</p>
          <p>Параметр шаблона <code>BaseТуре</code> должен:</p>
          <p>• иметь тривиальный конструктор по умолчанию;</p>
          <p>• иметь тривиальный копирующий оператор присваивания;</p>
          <p>• иметь тривиальный деструктор;</p>
          <p>• допускать побитовое сравнение на равенство.</p>
          <p>По существу, это означает, что конкретизация <code>std::atomic&lt;некоторый-встроенный-тип&gt;</code> допустима, как и конкретизация <code>std::atomic&lt;некоторая-простая-структура&gt;</code>, но такие вещи, как <code>std::atomic&lt;std::string&gt;</code>, недопустимы.</p>
          <p>Помимо основного шаблона, имеются специализации для встроенных целочисленных типов и указателей, которые предоставляют дополнительные операции, например <code>x++</code>.</p>
          <p>Экземпляры <code>std::atomic</code> не удовлетворяют требованиям концепций <code>CopyConstructible</code> и <code>CopyAssignable</code>, потому что такие операции невозможно выполнить атомарно.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>struct atomic {</code>
          </p>
          <p>
            <code> atomic() noexcept = default;</code>
          </p>
          <p>
            <code> constexpr atomic(BaseType) noexcept;</code>
          </p>
          <p>
            <code> BaseType operator=(BaseType) volatile noexcept;</code>
          </p>
          <p>
            <code> BaseType operator=(BaseType) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> atomic(const atomic&amp;) = delete;</code>
          </p>
          <p>
            <code> atomic&amp; operator=(const atomic&amp;) = delete;</code>
          </p>
          <p>
            <code> atomic&amp; operator=(const atomic&amp;) volatile = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> bool is_lock_free() const volatile noexcept;</code>
          </p>
          <p>
            <code> bool is_lock_free() const noexcept;</code>
          </p>
          <p>
            <code> void store(BaseType, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> void store(BaseType, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  noexcept;</code>
          </p>
          <p>
            <code> BaseType load(memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  const volatile noexcept;</code>
          </p>
          <p>
            <code> BaseType load(memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  const noexcept;</code>
          </p>
          <p>
            <code> BaseType exchange(BaseType, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> BaseType exchange(BaseType, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code>  BaseType &amp; old_value, BaseType new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst) volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code>  BaseType &amp; old_value, BaseType new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code>  BaseType &amp; old_value, BaseType new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order,</code>
          </p>
          <p>
            <code>  memory_order failure_order) volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code>  BaseType &amp; old_value, BaseType new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order,</code>
          </p>
          <p>
            <code>  memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code>  BaseType &amp; old_value, BaseType new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code>  BaseType &amp; old_value, BaseType new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code>  BaseType &amp; old_value, BaseType new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order,</code>
          </p>
          <p>
            <code>  memory_order failure_order) volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code>  BaseType &amp; old_value, BaseType new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order,</code>
          </p>
          <p>
            <code>  memory_order failure_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> operator BaseType() const volatile noexcept;</code>
          </p>
          <p>
            <code> operator BaseType() const noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_is_lock_free(</code>
          </p>
          <p>
            <code> volatile const atomic&lt;BaseType&gt;*) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code> bool atomic_is_lock_free(const atomic&lt;BaseType&gt;*)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_init(volatile atomic&lt;BaseType&gt;*, void*) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_init(atomic&lt;BaseType&gt;*, void*) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_exchange(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;*, memory_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_exchange(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;*, memory_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_exchange_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;*, memory_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_exchange_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;*, memory_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_store(volatile atomic&lt;BaseType&gt;*, BaseType) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_store(atomic&lt;BaseType&gt;*, BaseType) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_store_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;*, BaseType, memory_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_store_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;*, BaseType, memory_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_load(volatile const atomic&lt;BaseType&gt;*) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_load(const atomic&lt;BaseType&gt;*) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_load_explicit(</code>
          </p>
          <p>
            <code> volatile const atomic&lt;BaseType&gt;*, memory_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_load_explicit(</code>
          </p>
          <p>
            <code> const atomic&lt;BaseType&gt;*, memory_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;*,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;*,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;*, BaseType * old_value,</code>
          </p>
          <p>
            <code> BaseType new_value, memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;*,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;*,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;*,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;*,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;*,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <cite>
            <p><strong>Примечание</strong>. Хотя функции, не являющиеся членами класса, определены как шаблоны, они могут быть предоставлены в виде набора перегруженных функций, поэтому задавать явную спецификацию аргументов шаблона не следует.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::atomic</code> со значением, инициализированным по умолчанию.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>atomic() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый объект <code>std::atomic</code> со значением, инициализированным по умолчанию. Для объектов со статическим временем жизни обеспечивается статическая инициализация.</p>
          <cite>
            <p><strong>Примечание</strong>. Если время жизни объекта <code>std::atomic</code> не статическое, то значение, которое будет иметь объект, инициализированный конструктором по умолчанию, непредсказуемо.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::ATOMIC_INIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Неатомарно сохраняет указанное значение в объекте типа <code>std::atomic&lt;BaseType&gt;</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_init(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt; volatile* p, BaseType v) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_init(atomic&lt;BaseType&gt;* p, BaseType v) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Неатомарно сохраняет значение <code>v</code> в <code>*p</code>. Вызов <code>atomic_init()</code> с передачей в качестве аргумента объекта <code>atomic&lt;BaseType&gt;</code>, который не был сконструирован по умолчанию или над которым производились какие-нибудь операции после конструирования, является неопределенным поведением.</p>
          <cite>
            <p><strong>Примечание</strong>. Поскольку эта операция сохранения неатомарна, то одновременный доступ к объекту, на который указывает <code>p</code>, из другого потока (даже с помощью атомарной операции) представляет собой гонку за данными.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::ATOMIC</strong>
            </code>
            <strong>, КОНВЕРТИРУЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует экземпляр <code>std::atomic</code> из переданного значения типа <code>BaseType</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr atomic(BaseType b) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый объект <code>std::atomic</code> из значения <code>b</code>. Для объектов со статическим временем жизни обеспечивается статическая инициализация.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::ATOMIC</strong>
            </code>
            <strong>, КОНВЕРТИРУЮЩИЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Сохраняет новое значение в <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>BaseType operator=(BaseType b) volatile noexcept;</code>
          </p>
          <p>
            <code>BaseType operator=(BaseType b) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;store(b);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC::IS_LOCK_FREE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Сообщает, являются ли операции над <code>*this</code> свободными от блокировок.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool is_lock_free() const volatile noexcept;</code>
          </p>
          <p>
            <code>bool is_lock_free() const noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если операции над <code>*this</code> свободны от блокировок, иначе <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::ATOMIC_IS_LOCK_FREE</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Сообщает, являются ли операции над <code>*this</code> свободными от блокировок.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_is_lock_free(</code>
          </p>
          <p>
            <code> volatile const atomic&lt;BaseType&gt;* p) noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_is_lock_free(const atomic&lt;BaseType&gt;* p) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;is_lock_free();</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC::LOAD</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно загружает текущее значение объекта <code>std::atomic</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>BaseType load(memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> const volatile noexcept;</code>
          </p>
          <p>
            <code>BaseType load(</code>
          </p>
          <p>
            <code> memory_order order = memory_order_seq_cst) const noexcept;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Параметр <code>order</code> должен принимать одно из значений <code>std::memory_order_relaxed</code>, <code>std::memory_order_acquire</code>, <code>std: :memory_order_consume</code> или <code>std::memory_order_seq_cst</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно загружает текущее, хранящееся в <code>*this</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение, хранящееся в <code>*this</code>, в точке вызова.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция загрузки для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_LOAD</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно загружает текущее значение объекта <code>std::atomic</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_load(volatile const atomic&lt;BaseType&gt;* p) noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_load(const atomic&lt;BaseType&gt;* p) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;load();</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_LOAD_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно загружает текущее значение объекта <code>std::atomic</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_load_explicit(</code>
          </p>
          <p>
            <code> volatile const atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> memory_order order) noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_load_explicit(</code>
          </p>
          <p>
            <code> const atomic&lt;BaseType&gt;* p, memory_order order) noexcept;</code>
          </p>
          <p>Результат</p>
          <p>
            <code>return p-&gt;load(order);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC::OPERATOR</strong>
            </code>
            <strong>, ОПЕРАТОР ПРЕОБРАЗОВАНИЯ В ТИП BASETYPE</strong>
          </p>
          <p>Загружает значение, хранящееся в <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>operator BaseType() const volatile noexcept;</code>
          </p>
          <p>
            <code>operator BaseType() const noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;load();</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC::STORE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно сохраняет новое значение в объекте <code>atomic&lt;BaseType&gt;</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void store(</code>
          </p>
          <p>
            <code> BaseType new_value, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code>void store(</code>
          </p>
          <p>
            <code> BaseType new_value, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Параметр <code>order</code> должен принимать одно из значений <code>std::memory_order_relaxed</code>, <code>std::memory_order_release</code> или <code>std::memory_order_seq_cst</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно сохраняет значение <code>new_value</code> в <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция сохранения для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_STORE</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сохраняет новое значение в объекте <code>atomic&lt;BaseType&gt;</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_store(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;* p, BaseType new_value) noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_store(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;* p, BaseType new_value) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>p-&gt;store(new_value);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_STORE_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сохраняет новое значение в объекте <code>atomic&lt;BaseType&gt;</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_store_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;* p, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order order) noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>void atomic_store_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;* p, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order order) noexcept;</code>
          </p>
          <p>Результат</p>
          <p>
            <code>p-&gt;store(new_value, order);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC::EXCHANGE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно сохраняет новое значение и читает старое.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>BaseType exchange(</code>
          </p>
          <p>
            <code>BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order order = memory_order_seq_cst) volatile noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно сохраняет значение <code>new_value</code> в <code>*this</code> и извлекает прежнее значение <code>*this</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>*this</code> непосредственно перед сохранением.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_EXCHANGE</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сохраняет новое значение в объекте <code>atomic&lt;BaseType&gt;</code> и читает предыдущее значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_exchange(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;* p, BaseType new_value) noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_exchange(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;* p, BaseType new_value) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;exchange(new_value);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_EXCHANGE_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сохраняет новое значение в объекте <code>atomic&lt;BaseType&gt;</code> и читает предыдущее значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_exchange_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType new_value, memory_order order)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>BaseType atomic_exchange_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType new_value, memory_order order) noexcept;</code>
          </p>
          <p>Результат</p>
          <p>
            <code>return p-&gt;exchange(new_value, order);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC::COMPARE_EXCHANGE_STRONG</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно сравнивает значение с ожидаемым и, если они равны, сохраняет новое значение. Если значения не равны, то заменяет ожидаемое значение прочитанным.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool compare_exchange_strong(</code>
          </p>
          <p>
            <code> BaseType&amp; expected, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order order = std::memory_order_seq_cst)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code>bool compare_exchange_strong(</code>
          </p>
          <p>
            <code> BaseType&amp; expected, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order order = std::memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code>bool compare_exchange_strong(</code>
          </p>
          <p>
            <code> BaseType&amp; expected, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order, memory_order failure_order)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code>bool compare_exchange_strong(</code>
          </p>
          <p>
            <code> BaseType&amp; expected, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Параметр <code>failure_order</code> не должен быть равен <code>std::memory_order_release</code> или <code>std::memory_order_acq_rel</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно сравнивает <code>expected</code> со значением, хранящимся в <code>*this</code>, применяя побитовое сравнение, и сохраняет <code>new_value</code> в <code>*this</code>, если значения равны. В противном случае записывает в <code>expected</code> прочитанное значение.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если значение, хранящееся в <code>*this</code>, совпало с <code>expected</code>. В противном случае <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Этот перегруженный вариант функции с тремя параметрами эквивалентен перегруженному варианту с четырьмя параметрами, где <code>success_order == order</code> и <code>failure_order == order</code>, с тем отличием, что если <code>order</code> равно <code>std::memory_order_acq_rel</code>, то <code>failure_order</code> равно <code>std::memory_order_acquire</code>, а если <code>order</code> равно <code>std::memory_order_release</code>, то <code>failure_order</code> равно <code>std::memory_order_relaxed</code>.</p>
          </cite>
          <cite>
            <p><strong>Примечание</strong>. Если результат равен <code>true</code>, то это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>, с упорядочением доступа к памяти <code>success_order</code>; в противном случае это атомарная операция загрузки для ячейки памяти, содержащей <code>*this</code>, с упорядочением доступа к памяти <code>failure_order</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_COMPARE_EXCHANGE_STRONG</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сравнивает значение с ожидаемым и, если они равны, сохраняет новое значение. Если значения не равны, то заменяет ожидаемое значение прочитанным.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value) noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;compare_exchange_strong(*old_value, new_value);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_COMPARE_EXCHANGE_STRONG_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сравнивает значение с ожидаемым и, если они равны, сохраняет новое значение. Если значения не равны, то заменяет ожидаемое значение прочитанным.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order, memory_order failure_order)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order, memory_order failure_order)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;compare_exchange_strong(</code>
          </p>
          <p>
            <code>*old_value, new_value, success_order, failure_order) noexcept;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC::COMPARE_EXCHANGE_WEAK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно сравнивает значение с ожидаемым и, если они равны и обновление может быть произведено атомарно, то сохраняет новое значение. Если значения не равны или обновление не может быть произведено атомарно, то заменяет ожидаемое значение прочитанным.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool compare_exchange_weak(</code>
          </p>
          <p>
            <code> BaseType&amp; expected, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order order = std::memory_order_seq_cst)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code>bool compare_exchange_weak(</code>
          </p>
          <p>
            <code> BaseType&amp; expected, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order order = std::memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code>bool compare_exchange_weak(</code>
          </p>
          <p>
            <code> BaseType&amp; expected, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order, memory_order failure_order)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code>bool compare_exchange_weak(</code>
          </p>
          <p>
            <code> BaseType&amp; expected, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Параметр <code>failure_order</code> не должен быть равен <code>std::memory_order_release</code> или <code>std::memory_order_acq_rel</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно сравнивает <code>expected</code> со значением, хранящимся в <code>*this</code>, применяя побитовое сравнение, и сохраняет <code>new_value</code> в <code>*this</code>, если значения равны. Если значения не равны или обновление не может быть произведено атомарно, записывает в <code>expected</code> прочитанное значение.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если значение, хранящееся в <code>*this</code>, совпало с <code>expected</code> и <code>new_value</code> успешно сохранено в <code>*this</code>. В противном случае <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Этот перегруженный вариант функции с тремя параметрами эквивалентен перегруженному варианту с четырьмя параметрами, где <code>success_order == order</code> и <code>failure_order == order</code>, с тем отличием, что если <code>order</code> равно <code>std::memory_order_acq_rel</code>, то <code>failure_order</code> равно <code>std::memory_order_acquire</code>, а если order равно <code>std::memory_order_release</code>, то <code>failure_order</code> равно <code>std::memory_order_relaxed</code>.</p>
          </cite>
          <cite>
            <p><strong>Примечание</strong>. Если результат равен <code>true</code>, то это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>, с упорядочением доступа к памяти <code>success_order</code>; в противном случае это атомарная операция загрузки для ячейки памяти, содержащей <code>*this</code>, с упорядочением доступа к памяти <code>failure_order</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_COMPARE_EXCHANGE_WEAK</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сравнивает значение с ожидаемым и, если они равны и обновление может быть произведено атомарно, то сохраняет новое значение. Если значения не равны или обновление не может быть произведено атомарно, то заменяет ожидаемое значение прочитанным.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value) noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;compare_exchange_weak(*old_value, new_value);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_COMPARE_EXCHANGE_WEAK_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно сравнивает значение с ожидаемым и, если они равны и обновление может быть произведено атомарно, то сохраняет новое значение. Если значения не равны или обновление не может быть произведено атомарно, то заменяет ожидаемое значение прочитанным.</p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code>template&lt;typename BaseType&gt;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;BaseType&gt;* p,</code>
          </p>
          <p>
            <code> BaseType * old_value, BaseType new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;compare_exchange_weak(</code>
          </p>
          <p>
            <code> *old_value, new_value, success_order, failure_order);</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.3.9. Специализации шаблона <code>std::atomic</code></p>
          </title>
          <p>Предоставляются специализации шаблона <code>std::atomic</code> для целочисленных и указательных типов. Для целочисленных типов специализации обеспечивают атомарные операции сложения, вычитания и поразрядные в дополнение к имеющимся в основном шаблоне. Для указательных типов в дополнение к основному шаблону предоставляются арифметические операции над указателями.</p>
          <p>Имеются специализации для следующих целочисленных типов:</p>
          <p>
            <code>std::atomic&lt;bool&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;char&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;signed char&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned char&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;short&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned short&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;int&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;long&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned long&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;long long&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned long long&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;wchar_t&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;char16_t&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;char32_t&gt;</code>
          </p>
          <p>а также для типа <code>std::atomic&lt;T*&gt;</code> при любом типе <code>T</code>.</p>
        </section>
        <section>
          <title>
            <p>D.3.10. Специализации <code>std::atomic&lt;<emphasis>integral-type</emphasis>&gt;</code></p>
          </title>
          <p>Специализации <code>std::atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> шаблона класса <code>std::atomic</code> дают атомарный целочисленный тип для каждого фундаментального целочисленного типа, с полным набором операций.</p>
          <p>Ниже перечислены все такие специализации шаблона <code>std::atomic&lt;&gt;</code>:</p>
          <p>
            <code>std::atomic&lt;char&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;signed char&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned char&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;short&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned short&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;int&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;long&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned long&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;long long&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;unsigned long long&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;wchar_t&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;char16_t&gt;</code>
          </p>
          <p>
            <code>std::atomic&lt;char32_t&gt;</code>
          </p>
          <p>Экземпляры этих специализаций не удовлетворяют требованиям концепций <code>CopyConstructible</code> и <code>CopyAssignable</code>, поскольку такие операции невозможно выполнить атомарно.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template&lt;&gt;</code>
          </p>
          <p>
            <code>struct atomic&lt;<emphasis>integral-type</emphasis>&gt; {</code>
          </p>
          <p>
            <code> atomic() noexcept = default;</code>
          </p>
          <p>
            <code> constexpr atomic(integral-type) noexcept;</code>
          </p>
          <p>
            <code> bool operator=(integral-type) volatile noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> atomic(const atomic&amp;) = delete;</code>
          </p>
          <p>
            <code> atomic&amp; operator=(const atomic&amp;) = delete;</code>
          </p>
          <p>
            <code> atomic&amp; operator=(const atomic&amp;) volatile = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> bool is_lock_free() const volatile noexcept;</code>
          </p>
          <p>
            <code> bool is_lock_free() const noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> void store(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> void store(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> load(memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  const volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> load(</code>
          </p>
          <p>
            <code>  memory_order = memory_order_seq_cst) const noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> exchange(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>,</code>
          </p>
          <p>
            <code>  memory_order = memory_order_seq_cst) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> exchange(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis> &amp; old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis> &amp; old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> bool <emphasis>compare_exchange_strong</emphasis>(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis> &amp; old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order, memory_order failure_order)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis> &amp; old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order,</code>
          </p>
          <p>
            <code>  memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis> &amp; old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst) volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis> &amp; old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis> &amp; old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order, memory_order failure_order)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis> &amp; old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order,</code>
          </p>
          <p>
            <code>  memory_order failure_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> operator <emphasis>integral-type</emphasis>() const volatile noexcept;</code>
          </p>
          <p>
            <code> operator <emphasis>integral-type</emphasis>() const noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_add(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_add(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_sub(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_sub(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_and(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_and(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_or(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_or(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_xor(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> fetch_xor(</code>
          </p>
          <p>
            <code><emphasis>  integral-type</emphasis>, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator++() volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator++() noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator++(int) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator++(int) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator--() volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator--() noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator--(int) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator--(int) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code><emphasis> integral-type</emphasis> operator+=(<emphasis>integral-type</emphasis>) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator+=(<emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator-=(<emphasis>integral-type</emphasis>) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator-=(<emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator&amp;=(<emphasis>integral-type</emphasis>) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator&amp;=(<emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator|=(<emphasis>integral-type</emphasis>) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator|=(<emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator^=(<emphasis>integral-type</emphasis>) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> operator^=(<emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>bool atomic_is_lock_free(</code>
          </p>
          <p>
            <code> volatile const atomic&lt;<emphasis>integral-type</emphasis>&gt;*) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_is_lock_free(const atomic&lt;<emphasis>integral-type</emphasis>&gt;*) noexcept;</code>
          </p>
          <p>
            <code>void atomic_init(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code>void atomic_init(atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_exchange(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_exchange(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_exchange_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>, memory_order)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_exchange_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code>void atomic_store(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code>void atomic_store(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code>void atomic_store_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code>void atomic_store_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_load(</code>
          </p>
          <p>
            <code> volatile const atomic&lt;<emphasis>integral-type</emphasis>&gt;*) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_load(</code>
          </p>
          <p>
            <code> const atomic&lt;<emphasis>integral-type</emphasis>&gt;*) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_load_explicit(</code>
          </p>
          <p>
            <code> volatile const atomic&lt;<emphasis>integral-type</emphasis>&gt;*, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_load_explicit(</code>
          </p>
          <p>
            <code> const atomic&lt;<emphasis>integral-type</emphasis>&gt;*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis> * old_value,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> new_value) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> * old_value, <emphasis>integral-type</emphasis> new_value) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> * old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> * old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> * old_value, <emphasis>integral-type</emphasis> new_value) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> * old_value, <emphasis>integral-type</emphasis> new_value) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> * old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> * old_value, <emphasis>integral-type</emphasis> new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> atomic_fetch_add(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_add(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_add_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>,</code>
          </p>
          <p>
            <code> memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_add_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_sub(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_sub(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_sub_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_sub_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_and(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_and(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_and_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_and_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_or(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_or(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_or_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_or_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_xor(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_xor(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_xor_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;*,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_xor_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;*, <emphasis>integral-type</emphasis>, memory_order) noexcept;</code>
          </p>
          <p>Те операции, которые предоставляются также основным шаблоном (см. D.3.8), имеют точно такую же семантику.</p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::FETCH_ADD</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно загружает значение и заменяет его суммой его самого и аргумента <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>fetch_add(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> fetch_add(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно возвращает прежнее значение <code>*this</code> и сохраняет в <code>*this</code> значение <code>old-value + i</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>*this</code> непосредственно перед сохранением.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_ADD</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его суммой этого значения и аргумента <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>integral-<emphasis>type</emphasis> atomic_fetch_add(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_add(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_add(i);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_ADD_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ</strong>
          </p>
          <p>
            <strong>КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его суммой этого значения и аргумента <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_add_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i,</code>
          </p>
          <p>
            <code> memory_order order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_add_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i,</code>
          </p>
          <p>
            <code> memory_order order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_add(i,order);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::FETCH_SUB</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно читает значение и заменяет его разностью этого значения и аргумента <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> fetch_sub(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i,</code>
          </p>
          <p>
            <code> memory_order order = memory_order_seq_cst) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> fetch_sub(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i,</code>
          </p>
          <p>
            <code> memory_order order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно возвращает прежнее значение <code>*this</code> и сохраняет в <code>*this</code> значение <code>old-value - i</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>*this</code> непосредственно перед сохранением.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_SUB</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его разностью этого значения и аргумента <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_sub(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_sub(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_sub(i);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_SUB_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его разностью этого значения и аргумента <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_sub_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_sub_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_sub(i, order);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::FETCH_AND</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно загружает значение и заменяет его результатом операции поразрядное-и между этим значением и аргументом <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> fetch_and(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> fetch_and(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно возвращает прежнее значение <code>*this</code> и сохраняет в <code>*this</code> значение <code>old-value &amp; i</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>*this</code> непосредственно перед сохранением.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_AND</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его результатом операции поразрядное-и между этим значением и аргументом <code>i</code>. <emphasis>Объявление</emphasis></p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_and(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_and(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_and(i);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_AND_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его результатом операции поразрядное-и между этим значением и аргументом <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_and_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_and_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_and(i,order);</code>
          </p>
          <p>
            <code>
              <emphasis>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::FETCH_OR</emphasis>
            </code>
            <emphasis>, ФУНКЦИЯ-ЧЛЕН</emphasis>
          </p>
          <p>Атомарно загружает значение и заменяет его результатом операции поразрядное-или между этим значением и аргументом <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> fetch_or(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> fetch_or(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно возвращает прежнее значение <code>*this</code> и сохраняет в <code>*this</code> значение <code>old-value | i</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>*this</code> непосредственно перед сохранением.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_OR</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его результатом операции поразрядное-или между этим значением и аргументом <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_or(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_or(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_or(i);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_OR_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его результатом операции поразрядное-или между этим значением и аргументом <emphasis>i</emphasis>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-typ</emphasis>e atomic_fetch_or_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_or_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_or(i, order);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::FETCH_XOR</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно загружает значение и заменяет его результатом операции поразрядное исключающее-или между этим значением и аргументом i.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> fetch_xor(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> fetch_xor(</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно возвращает прежнее значение <code>*this</code> и сохраняет в <code>*this</code> значение <code>old-value ^ i</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>*this</code> непосредственно перед сохранением.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_XOR</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его результатом операции поразрядное исключающее-или между этим значением и аргументом <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_xor(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_xor(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p, <emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_xor(i);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_XOR_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;<emphasis>integral-type</emphasis>&gt;</code> и заменяет его результатом операции поразрядное исключающее-или между этим значением и аргументом <code>i</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_xor_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;<emphasis>integral-type</emphasis>&gt;* p,</code>
          </p>
          <p>
            <code><emphasis> integral-type</emphasis> i, memory_order order) noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> atomic_fetch_xor_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;<emphasis>integral-type</emphasis>&gt;* p,</code>
          </p>
          <p>
            <code> integral-type i, memory_order order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_xor(i,order);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::OPERATOR++</strong>
            </code>
            <strong>, ОПЕРАТОР ПРЕДИНКРЕМЕНТА</strong>
          </p>
          <p>Атомарно инкрементирует значение, хранящееся в <code>*this</code>, и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator++() volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator++() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_add(1) + 1;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::OPERATOR++</strong>
            </code>
            <strong>, ОПЕРАТОР ПОСТИНКРЕМЕНТА</strong>
          </p>
          <p>Атомарно инкрементирует значение, хранящееся в <code>*this</code>, и возвращает старое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator++(int) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator++(int) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_add(1);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::OPERATOR--</strong>
            </code>
            <strong>, ОПЕРАТОР ПРЕДЕКРЕМЕНТА</strong>
          </p>
          <p>Атомарно декрементирует значение, хранящееся в <code>*this</code>, и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator--() volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator--() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_sub(1) - 1;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::OPERATOR--</strong>
            </code>
            <strong>, ОПЕРАТОР ПОСТДЕКРЕМЕНТА</strong>
          </p>
          <p>Атомарно декрементирует значение, хранящееся в <code>*this</code>, и возвращает старое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator--(int) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator--(int) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_sub(1);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::OPERATOR+=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Атомарно складывает значение аргумента со значением, хранящимся в <code>*this</code>, и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator+=(integral-type i) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator+=(integral-type i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_add(i) + i;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::OPERATOR-=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Атомарно вычитает значение аргумента из значения, хранящегося в <code>*this</code>, и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator-=(<emphasis>integral-type</emphasis> i) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator-=(<emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_sub(i, std::memory_order_seq_cst) - i;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::OPERATOR&amp;=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Атомарно заменяет значение, хранящееся в <code>*this</code>, результатом операции поразрядное-и между этим значением и значением аргумента и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator&amp;=(<emphasis>integral-type</emphasis> i) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator&amp;=(<emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_and(i) &amp; i;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::OPERATOR|=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Атомарно заменяет значение, хранящееся в <code>*this</code>, результатом операции поразрядное-или между этим значением и значением аргумента и возвращает новое значение.</p>
          <p>
            <code>Объявление</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator|=(<emphasis>integral-type</emphasis> i) volatile noexcept;</code>
          </p>
          <p>
            <code><emphasis>integral-type</emphasis> operator|=(<emphasis>integral-type</emphasis> i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_or(i, std::memory_order_seq_cst) | i;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;INTEGRAL-TYPE&gt;::OPERATOR^=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Атомарно заменяет значение, хранящееся в <code>*this</code>, результатом операции поразрядное исключающее-или между этим значением и значением аргумента и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>integral-type operator^=(integral-type i) volatile noexcept;</code>
          </p>
          <p>
            <code>integral-type operator^=(integral-type i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_xor(i, std::memory_order_seq_cst) ^ i;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;T*&gt;</strong>
            </code>
            <strong>, ЧАСТИЧНАЯ СПЕЦИАЛИЗАЦИЯ</strong>
          </p>
          <p>Частичная специализация <code>std::atomic&lt;T*&gt;</code> шаблона <code>std::atomic</code> предоставляет атомарный тип для любого указательного типа, с полным набором операций.</p>
          <p>Экземпляры <code>std::atomic&lt;T*&gt;</code> не удовлетворяют требованиям концепций <code>CopyConstructible</code> и <code>CopyAssignable</code>, поскольку такие операции невозможно выполнить атомарно.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template&lt;typename T&gt;</code>
          </p>
          <p>
            <code>struct atomic&lt;T*&gt; {</code>
          </p>
          <p>
            <code> atomic() noexcept = default;</code>
          </p>
          <p>
            <code> constexpr atomic(T*) noexcept;</code>
          </p>
          <p>
            <code> bool operator=(T*) volatile;</code>
          </p>
          <p>
            <code> bool operator=(T*);</code>
          </p>
          <empty-line/>
          <p>
            <code> atomic(const atomic&amp;) = delete;</code>
          </p>
          <p>
            <code> atomic&amp; operator=(const atomic&amp;) = delete;</code>
          </p>
          <p>
            <code> atomic&amp; operator=(const atomic&amp;) volatile = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> bool is_lock_free() const volatile noexcept;</code>
          </p>
          <p>
            <code> bool is_lock_free() const noexcept;</code>
          </p>
          <p>
            <code> void store(T*, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> void store(T*, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> T* load(memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  const volatile noexcept;</code>
          </p>
          <p>
            <code> T* load(memory_order = memory_order_seq_cst) const noexcept;</code>
          </p>
          <p>
            <code> T* exchange(T*, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> T* exchange(T*, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code>  T* &amp; old_value, T* new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code>  T* &amp; old_value, T* new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code>  T* &amp; old_value, T* new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order, memory_order failure_order)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_strong(</code>
          </p>
          <p>
            <code>  T* &amp; old_value, T* new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order,</code>
          </p>
          <p>
            <code>  memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code>  T* &amp; old_value, T* new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst) volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code>  T* &amp; old_value, T* new_value,</code>
          </p>
          <p>
            <code>  memory_order order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code>  T* &amp; old_value, T* new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order, memory_order failure_order)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> bool compare_exchange_weak(</code>
          </p>
          <p>
            <code>  T* &amp; old_value, T* new_value,</code>
          </p>
          <p>
            <code>  memory_order success_order,</code>
          </p>
          <p>
            <code>  memory_order failure_order) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> operator T*() const volatile noexcept;</code>
          </p>
          <p>
            <code> operator T*() const noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> T* fetch_add(</code>
          </p>
          <p>
            <code>  ptrdiff_t, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> T* fetch_add(</code>
          </p>
          <p>
            <code>  ptrdiff_t, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> T* fetch_sub(</code>
          </p>
          <p>
            <code>  ptrdiff_t, memory_order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code>  volatile noexcept;</code>
          </p>
          <p>
            <code> T* fetch_sub(</code>
          </p>
          <p>
            <code>  ptrdiff_t, memory_order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <code> T* operator++() volatile noexcept;</code>
          </p>
          <p>
            <code> T* operator++() noexcept;</code>
          </p>
          <p>
            <code> T* operator++(int) volatile noexcept;</code>
          </p>
          <p>
            <code> T* operator++(int) noexcept;</code>
          </p>
          <p>
            <code> T* operator--() volatile noexcept;</code>
          </p>
          <p>
            <code> T* operator--() noexcept;</code>
          </p>
          <p>
            <code> T* operator--(int) volatile noexcept;</code>
          </p>
          <p>
            <code> T* operator--(int) noexcept;</code>
          </p>
          <p>
            <code> T* operator+=(ptrdiff_t) volatile noexcept;</code>
          </p>
          <p>
            <code> T* operator+=(ptrdiff_t) noexcept;</code>
          </p>
          <p>
            <code> T* operator-=(ptrdiff_t) volatile noexcept;</code>
          </p>
          <p>
            <code> T* operator-=(ptrdiff_t) noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>bool atomic_is_lock_free(volatile const atomic&lt;T*&gt;*) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_is_lock_free(const atomic&lt;T*&gt;*) noexcept;</code>
          </p>
          <p>
            <code>void atomic_init(volatile atomic&lt;T*&gt;*, T*) noexcept;</code>
          </p>
          <p>
            <code>void atomic_init(atomic&lt;T*&gt;*, T*) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_exchange(volatile atomic&lt;T*&gt;*, T*) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_exchange(atomic&lt;T*&gt;*, T*) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_exchange_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;*, T*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_exchange_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;*, T*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>void atomic_store(volatile atomic&lt;T*&gt;*, T*) noexcept;</code>
          </p>
          <p>
            <code>void atomic_store(atomic&lt;T*&gt;*, T*) noexcept;</code>
          </p>
          <p>
            <code>void atomic_store_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;*, T*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>void atomic_store_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;*, T*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_load(volatile const atomic&lt;T*&gt;*) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_load(const atomic&lt;T*&gt;*) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_load_explicit(</code>
          </p>
          <p>
            <code> volatile const atomic&lt;T*&gt;*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_load_explicit(</code>
          </p>
          <p>
            <code> const atomic&lt;T*&gt;*, memory_order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;*, T** old_value, T* new_value) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;*, T** old_value, T* new_value) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;*, T** old_value, T* new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_strong_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;*, T** old_value, T* new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;*, T** old_value, T* new_value) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;*, T** old_value, T* new_value) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;*,</code>
          </p>
          <p>
            <code> T** old_value, T* new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code>bool atomic_compare_exchange_weak_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;*, T** old_value, T* new_value,</code>
          </p>
          <p>
            <code> memory_order success_order,</code>
          </p>
          <p>
            <code> memory_order failure_order) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_add(volatile atomic&lt;T*&gt;*, ptrdiff_t) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_add(atomic&lt;T*&gt;*, ptrdiff_t) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_add_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;*, ptrdiff_t, memory_order) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_add_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;*, ptrdiff_t, memory_order) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_sub(volatile atomic&lt;T*&gt;*, ptrdiff_t) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_sub(atomic&lt;T*&gt;*, ptrdiff_t) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_sub_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;*, ptrdiff_t, memory_order) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_sub_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;*, ptrdiff_t, memory_order) noexcept;</code>
          </p>
          <p>Те операции, которые предоставляются также основным шаблоном (см. приложение D.3.8), имеют точно такую же семантику.</p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;T*&gt;::FETCH_ADD</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно загружает значение, заменяет его суммой этого значения и аргумента <code>i</code>, применяя стандартные правила арифметики указателей, и возвращает старое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* fetch_add(</code>
          </p>
          <p>
            <code> ptrdiff_t i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code>T* fetch_add(</code>
          </p>
          <p>
            <code> ptrdiff_t i, memory_order order = memory_order_seq_cst) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно возвращает текущее значение <code>*this</code> и сохраняет в <code>*this</code> значение <code>old-value + i</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>*this</code> непосредственно перед сохранением.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_ADD_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;T*&gt;</code> и заменяет его суммой этого значения и аргумента <code>i</code>, применяя стандартные правила арифметики указателей.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* atomic_fetch_add_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;* p, ptrdiff_t i, memory_order order)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_add_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;* p, ptrdiff_t i, memory_order order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_add(i, order);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;T*&gt;::FETCH_SUB</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Атомарно загружает значение, заменяет его разностью этого значения и аргумента <code>i</code>, применяя стандартные правила арифметики указателей, и возвращает старое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* fetch_sub(</code>
          </p>
          <p>
            <code> ptrdiff_t i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> volatile noexcept;</code>
          </p>
          <p>
            <code>T* fetch_sub(</code>
          </p>
          <p>
            <code> ptrdiff_t i, memory_order order = memory_order_seq_cst)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Атомарно возвращает текущее значение <code>*this</code> и сохраняет в <code>*this</code> значение <code>old-value - i</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Значение <code>*this</code> непосредственно перед сохранением.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это атомарная операция чтения-модификации-записи для ячейки памяти, содержащей <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_SUB</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;T*&gt;</code> и заменяет его разностью этого значения и аргумента <code>i</code>, применяя стандартные правила арифметики указателей.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* atomic_fetch_sub(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;* p, ptrdiff_t i) noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_sub(atomic&lt;T*&gt;* p, ptrdiff_t i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_sub(i);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC_FETCH_SUB_EXPLICIT</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Атомарно читает значение из экземпляра <code>atomic&lt;T*&gt;</code> и заменяет его разностью этого значения и аргумента <code>i</code>, применяя стандартные правила арифметики указателей.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* atomic_fetch_sub_explicit(</code>
          </p>
          <p>
            <code> volatile atomic&lt;T*&gt;* p, ptrdiff_t i, memory_order order)</code>
          </p>
          <p>
            <code> noexcept;</code>
          </p>
          <p>
            <code>T* atomic_fetch_sub_explicit(</code>
          </p>
          <p>
            <code> atomic&lt;T*&gt;* p, ptrdiff_t i, memory_order order) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return p-&gt;fetch_sub(i, order);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;T*&gt;::OPERATOR++</strong>
            </code>
            <strong>, ОПЕРАТОР ПРЕДИНКРЕМЕНТА</strong>
          </p>
          <p>Атомарно инкрементирует значение, хранящееся в <code>*this</code>, применяя стандартные правила арифметики указателей, и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* operator++() volatile noexcept;</code>
          </p>
          <p>
            <code>T* operator++() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_add(1) + 1;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;T*&gt;::OPERATOR++</strong>
            </code>
            <strong>, ОПЕРАТОР ПОСТИНКРЕМЕНТА</strong>
          </p>
          <p>Атомарно инкрементирует значение, хранящееся в <code>*this</code>, и возвращает старое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* operator++(int) volatile noexcept;</code>
          </p>
          <p>
            <code>T* operator++(int) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_add(1);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;T*&gt;::OPERATOR--</strong>
            </code>
            <strong>, ОПЕРАТОР ПРЕДЕКРЕМЕНТА</strong>
          </p>
          <p>Атомарно декрементирует значение, хранящееся в <code>*this</code>, применяя стандартные правила арифметики указателей, и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* operator--() volatile noexcept;</code>
          </p>
          <p>
            <code>T* operator--() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_sub(1) - 1;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;T*&gt;::OPERATOR--</strong>
            </code>
            <strong>, ОПЕРАТОР ПОСТДЕКРЕМЕНТА</strong>
          </p>
          <p>Атомарно декрементирует значение, хранящееся в <code>*this</code>, применяя стандартные правила арифметики указателей, и возвращает старое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* operator--(int) volatile noexcept;</code>
          </p>
          <p>
            <code>T* operator--(int) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_sub(1);</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;T*&gt;::OPERATOR+=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Атомарно складывает значение аргумента со значением, хранящимся в <code>*this</code>, применяя стандартные правила арифметики указателей, и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* operator+=(ptrdiff_t i) volatile noexcept;</code>
          </p>
          <p>
            <code>T* operator+=(ptrdiff_t i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_add(i) + i;</code>
          </p>
          <p>
            <code>
              <strong>STD::ATOMIC&lt;T*&gt;::OPERATOR-=</strong>
            </code>
            <strong>, СОСТАВНОЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Атомарно вычитает значение аргумента из значения, хранящегося в <code>*this</code>, применяя стандартные правила арифметики указателей, и возвращает новое значение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>T* operator-=(ptrdiff_t i) volatile noexcept;</code>
          </p>
          <p>
            <code>T* operator-=(ptrdiff_t i) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>return this-&gt;fetch_sub(i) - i;</code>
          </p>
        </section>
      </section>
      <section>
        <title>
          <p>D.4. Заголовок <code>&lt;future&gt;</code></p>
        </title>
        <section>
          <p>В заголовке <code>&lt;future&gt;</code> объявлены средства для обработки результатов асинхронных операций, которые могли быть выполнены в другом потоке.</p>
          <p>
            <emphasis>Содержимое заголовка</emphasis>
          </p>
          <p>
            <code>namespace std {</code>
          </p>
          <p>
            <code>enum class future_status {</code>
          </p>
          <p>
            <code> ready, timeout, deferred</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>enum class future_errc {</code>
          </p>
          <p>
            <code> broken_promise,</code>
          </p>
          <p>
            <code> future_already_retrieved,</code>
          </p>
          <p>
            <code> promise_already_satisfied,</code>
          </p>
          <p>
            <code> no_state</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>class future_error;</code>
          </p>
          <empty-line/>
          <p>
            <code>const error_category&amp; future_category();</code>
          </p>
          <p>
            <code>error_code make_error_code(future_errc e);</code>
          </p>
          <p>
            <code>error_condition make_error_condition(future_errc e);</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename ResultType&gt;</code>
          </p>
          <p>
            <code>class future;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename ResultType&gt;</code>
          </p>
          <p>
            <code>class shared_future;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename ResultType&gt;</code>
          </p>
          <p>
            <code>class promise;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename FunctionSignature&gt;</code>
          </p>
          <p>
            <code>class packaged_task; // определение не предоставляется</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename ResultType, typename ... Args&gt;</code>
          </p>
          <p>
            <code>class packaged_task&lt;ResultType (Args...)&gt;;</code>
          </p>
          <empty-line/>
          <p>
            <code>enum class launch {</code>
          </p>
          <p>
            <code> async, deferred</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename FunctionType, typename ... Args&gt;</code>
          </p>
          <p>
            <code>future&lt;result_of&lt;FunctionType(Args...)&gt;::type&gt;</code>
          </p>
          <p>
            <code>async(FunctionType&amp;&amp; func, Args&amp;&amp; ... args);</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename FunctionType, typename ... Args&gt;</code>
          </p>
          <p>
            <code>future&lt;result_of&lt;FunctionType(Args...)&gt;::type&gt;</code>
          </p>
          <p>
            <code>async(std::launch policy, FunctionType&amp;&amp; func, Args&amp;&amp; ... args);</code>
          </p>
          <p>
            <code>}</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.4.1. Шаблон класса <code>std::future</code></p>
          </title>
          <p>Шаблон класса <code>std::future</code> предоставляет средства для ожидания результата асинхронной операции, начатой в другом потоке, и используется в сочетании с шаблонами классов <code>std::promise</code> и <code>std::packaged_task</code> и шаблоном функции <code>std::async</code>, которая применяется для возврата асинхронного результата. В каждый момент времени только один экземпляр <code>std::future</code> может ссылаться на данный асинхронный результат.</p>
          <p>Экземпляры <code>std::future</code> удовлетворяют требованиям концепций <code>MoveConstructible</code> и <code>MoveAssignable</code>, но не концепций <code>CopyConstructible</code> и <code>CopyAssignable</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template&lt;typename ResultType&gt;</code>
          </p>
          <p>
            <code>class future {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> future() noexcept;</code>
          </p>
          <p>
            <code> future(future&amp;&amp;) noexcept;</code>
          </p>
          <p>
            <code> future&amp; operator=(future&amp;&amp;) noexcept;</code>
          </p>
          <p>
            <code> ~future();</code>
          </p>
          <empty-line/>
          <p>
            <code> future(future const&amp;) = delete;</code>
          </p>
          <p>
            <code> future&amp; operator=(future const&amp;) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> shared_future&lt;ResultType&gt; share();</code>
          </p>
          <empty-line/>
          <p>
            <code> bool valid() const noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code><emphasis> см. описание</emphasis> get();</code>
          </p>
          <empty-line/>
          <p>
            <code> void wait();</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code> future_status wait_for(</code>
          </p>
          <p>
            <code>  std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code> future_status wait_until(</code>
          </p>
          <p>
            <code>  std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::FUTURE</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::future</code>, с которым не связан асинхронный результат.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>future() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый экземпляр <code>std::future</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>valid()</code> возвращает <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::FUTURE</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует объект <code>std::future</code>, передавая владение асинхронным результатом от другого объекта <code>std::future</code> вновь сконструированному.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>future(future&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый экземпляр <code>std::future</code> путем перемещения содержимого объекта <code>other</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с объектом <code>other</code> перед вызовом конструктора, ассоциируется с вновь сконструированным объектом <code>std::future</code>. С объектом <code>other</code> больше не ассоциирован никакой асинхронный результат. Функция <code>this-&gt;valid()</code> возвращает то же значение, которое возвращала функция <code>other.valid()</code> перед вызовом конструктора. Функция <code>other.valid()</code> возвращает <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::FUTURE</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Передает владение асинхронным результатом, ассоциированным с объектом <code>std::future</code>, другому объекту.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>future(future&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Передает владение асинхронным состоянием между экземплярами <code>std::future</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с объектом other перед вызовом оператора, ассоциируется с <code>*this</code>. Объект <code>*this</code> перестаёт быть владельцем своего прежнего асинхронного состояния (если оно было с ним ассоциировано), и если эта ссылка на асинхронное состояние была последней, то оно уничтожается. Функция <code>this-&gt;valid()</code> возвращает то же значение, которое возвращала функция <code>other</code>, <code>valid()</code> перед вызовом оператора. Функция <code>other.valid()</code> возвращает <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::FUTURE</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::future</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~future();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>. Если с <code>*this</code> была ассоциирована последняя ссылка на асинхронный результат (при условии, что с <code>*this</code> вообще что-то ассоциировано), то этот асинхронный результат уничтожается.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::FUTURE::SHARE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Конструирует новый экземпляр <code>std::shared_future</code> и передаёт ему владение асинхронным результатом, ассоциированным с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>shared_future&lt;ResultType&gt; share();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Эквивалентно <code>shared_future&lt;ResultType&gt;(std::move(*this))</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с объектом <code>*this</code> перед вызовом <code>share()</code> (если с ним что-то было ассоциировано), ассоциируется с вновь сконструированным экземпляром <code>std::shared_future</code>. Функция <code>this-&gt;valid()</code> возвращает <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::FUTURE::VALID</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Проверяет, ассоциирован ли с экземпляром <code>std::future</code> асинхронный результат. <emphasis>Объявление</emphasis></p>
          <p>
            <code>bool valid() const noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если с <code>*this</code> ассоциирован асинхронный результат, иначе <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::FUTURE::WAIT</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Если состояние, ассоциированное с <code>*this</code>, содержит отложенную функцию, то эта функция вызывается. В противном случае ждет, пока будет готов асинхронный результат, ассоциированный с данным экземпляром <code>std::future</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void wait();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;valid()</code> должно возвращать <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если ассоциированное состояние содержит отложенную функцию, то вызывает эту функцию и сохраняет возвращенное ей значение или объект-исключение в виде асинхронного результата. В противном случае блокирует поток до момента готовности асинхронного результата, ассоциированного с <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::FUTURE::WAIT_FOR</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ждет, когда будет готов асинхронный результат, ассоциированный с данным экземпляром <code>std::future</code>, или истечет заданное время.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>future_status wait_for(</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;valid()</code> должно возвращать <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если асинхронный результат, ассоциированный с <code>*this</code>, содержит отложенную функцию, полученную обращением к <code>std::async</code>, и эта функция, еще не начала исполняться, то возвращает управление немедленно без блокирования потока. В противном случае блокирует поток до момента готовности асинхронного результата, ассоциированного с <code>*this</code>, или до истечения времени, заданного в аргументе <code>relative_time</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>std::future_status::deferred</code>, если асинхронный результат, ассоциированный с <code>*this</code>, содержит отложенную функцию, полученную обращением к <code>std::async</code>, и эта функция, еще не начала исполняться. <code>std::future_status::ready</code>, если асинхронный результат, ассоциированный с <code>*this</code>, готов, <code>std::future_status::timeout</code>, если истекло время, заданное в аргументе <code>relative_time</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Поток может быть заблокирован на время, превышающее указанное. Если возможно, время измеряется по стабильным часам.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::FUTURE::WAIT_UNTIL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ждет, когда будет готов асинхронный результат, ассоциированный с данным экземпляром <code>std::future</code>, или наступит заданный момент времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>future_status wait_until(</code>
          </p>
          <p>
            <code>std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;valid()</code> должно возвращать <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если асинхронный результат, ассоциированный с <code>*this</code>, содержит отложенную функцию, полученную обращением к <code>std::async</code>, и эта функция, еще не начала исполняться, то возвращает управление немедленно без блокирования потока. В противном случае блокирует поток до момента готовности асинхронного результата, ассоциированного с <code>*this</code>, или до момента, когда функция <code>Clock::now()</code> вернет время, большее или равное <code>absolute_time</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>std::future_status::deferred</code>, если асинхронный результат, ассоциированный с <code>*this</code>, содержит отложенную функцию, полученную обращением к <code>std::async</code>, и эта функция, еще не начала исполняться. <code>std::future_status::ready</code>, если асинхронный результат, ассоциированный с <code>*this</code>, готов, <code>std::future_status::timeout</code>, если <code>Clock::now()</code> вернула время, большее или равное <code>absolute_time</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Не дается никаких гарантий относительно того, сколько времени будет блокирован вызывающий поток. Гарантируется лишь, что если функция вернула <code>std::future_status::timeout</code>, то значение, возвращенное <code>Clock::now()</code>, больше или равно <code>absolute_time</code> в точке, где поток разблокировался.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::FUTURE::GET</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Если ассоциированное состояние содержит отложенную функцию, полученную в результате обращения к <code>std::async</code>, то вызывает эту функцию и возвращает результат. В противном случае ждет готовности асинхронного результата, ассоциированного с экземпляром <code>std::future</code>, а затем либо возвращает сохраненное в нем значение, либо возбуждает сохраненное в нем исключение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void future&lt;void&gt;::get();</code>
          </p>
          <p>
            <code>R&amp; future&lt;R&amp;&gt;::get();</code>
          </p>
          <p>
            <code>R future&lt;R&gt;::get();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;valid()</code> должно возвращать <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если состояние, ассоциированное с <code>*this</code>, содержит отложенную функцию, то вызывает эту функцию и возвращает результат или возбуждает хранящееся исключение. В противном случае блокирует поток до момента готовности асинхронного результата, ассоциированного с <code>*this</code>. Если в результате хранится исключение, возбуждает его, иначе возвращает хранящееся значение.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Если ассоциированное состояние содержит отложенную функцию, то возвращает результат вызова этой функции. Иначе, если <code>ResultType</code> — <code>void</code>, то функция просто возвращает управление. Если <code>ResultType</code> — <code>R&amp;</code> для некоторого типа <code>R</code>, то возвращает хранящуюся ссылку. Иначе возвращает хранящееся значение.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение, возбужденное отложенной функцией или сохраненное в асинхронном результате (если таковое имеется).</p>
          <p>
            <emphasis>Постусловие</emphasis>
          </p>
          <p>
            <code>this-&gt;valid() == false</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.4.2. Шаблон класса <code>std::shared_future</code></p>
          </title>
          <p>Шаблон класса <code>std::shared_future</code> предоставляет средства для ожидания результата асинхронной операции, начатой в другом потоке, и используется в сочетании с шаблонами классов <code>std::promise</code> и <code>std::packaged_task</code> и шаблоном функции <code>std::async</code>, которая применяется для возврата асинхронного результата. В каждый момент времени ссылаться на один и тот же асинхронный результат могут несколько объектов <code>std::shared_future</code>. Экземпляры <code>std::shared_future</code> удовлетворяют требованиям концепций <code>CopyConstructible</code> и <code>CopyAssignable</code>. Разрешается также конструировать объект <code>std::shared_future</code> перемещением из объекта <code>std::future</code> с тем же самым параметром <code>ResultType</code>.</p>
          <p>Обращения к данному экземпляру <code>std::shared_future</code> не синхронизированы. Поэтому доступ к одному экземпляру <code>std::shared_future</code> из разных потоков без внешней синхронизации <emphasis>не безопасен</emphasis>. Однако обращения к ассоциированному состоянию синхронизированы, поэтому несколько потоков могут <emphasis>безопасно</emphasis> обращаться к разным экземплярам <code>std::shared_future</code>, которые разделяют одно и то же ассоциированное состояние, без внешней синхронизации.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template&lt;typename ResultType&gt;</code>
          </p>
          <p>
            <code>class shared_future {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code>shared_future() noexcept;</code>
          </p>
          <p>
            <code>shared_future(future&lt;ResultType&gt;&amp;&amp;) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>shared_future(shared_future&amp;&amp;) noexcept;</code>
          </p>
          <p>
            <code>shared_future(shared_future const&amp;);</code>
          </p>
          <p>
            <code>shared_future&amp; operator=(shared_future const&amp;);</code>
          </p>
          <p>
            <code>shared_future&amp; operator=(shared_future&amp;&amp;) noexcept;</code>
          </p>
          <p>
            <code>~shared_future();</code>
          </p>
          <empty-line/>
          <p>
            <code>bool valid() const noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code><emphasis>см. описание</emphasis> get() const;</code>
          </p>
          <empty-line/>
          <p>
            <code>void wait() const;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>future_status wait_for(</code>
          </p>
          <p>
            <code>std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time) const;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>future_status wait_until(</code>
          </p>
          <p>
            <code>std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time)</code>
          </p>
          <p>
            <code>const;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::shared_future</code>, с которым не ассоциирован асинхронный результат.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>shared_future() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый экземпляр <code>std::shared_future</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Функция <code>valid()</code> вновь сконструированного экземпляра возвращает <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует один объект <code>std::shared_future</code> из другого, передавая владение асинхронным результатом, ассоциированным со старым объектом <code>std::shared_future</code>, вновь сконструированному.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>shared_future(shared_future&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый экземпляр <code>std::shared_future</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с объектом <code>other</code> перед вызовом конструктора, ассоциируется с вновь сконструированным объектом <code>std::shared_future</code>. С объектом <code>other</code> больше не ассоциирован никакой асинхронный результат.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE</strong>
            </code>
            <strong>, КОНСТРУКТОР MOVE-FROM-</strong>
            <code>
              <strong>STD::FUTURE</strong>
            </code>
          </p>
          <p>Конструирует объект <code>std::shared_future</code> из объекта <code>std::future</code>, передавая владение асинхронным результатом, ассоциированным с объектом <code>std::future</code>, вновь сконструированному объекту <code>std::shared_future</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>shared_future(std::future&lt;ResultType&gt;&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый экземпляр <code>std::shared_future</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с объектом other перед вызовом конструктора, ассоциируется с вновь сконструированным объектом <code>std::shared_future</code>. С объектом <code>other</code> больше не ассоциирован никакой асинхронный результат.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE</strong>
            </code>
            <strong>, КОПИРУЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует один объект <code>std::shared_future</code> из другого, так что исходный объект и копия ссылаются на асинхронный результат, ассоциированный с исходным объектом <code>std::shared_future</code>, если таковой был.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>shared_future(shared_future const&amp; other);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый экземпляр <code>std::shared_future</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ранее ассоциированный с объектом <code>other</code> перед вызовом конструктора, теперь ассоциирован как с вновь сконструированным объектом <code>std::shared_future</code>, так и с объектом <code>other</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::shared_future</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~shared_future();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>. Если больше не существует объекта <code>std::promise</code> или <code>std::packaged_task</code>, ассоциированного с асинхронным результатом, который ассоциирован с <code>*this</code>, и это последний экземпляр <code>std::shared_future</code>, ассоциированный с этим асинхронным результатом, то асинхронный результат уничтожается.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE::VALID</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Проверяет, ассоциирован ли асинхронный результат с данным экземпляром <code>std::shared_future</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool valid() const noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если с <code>*this</code> ассоциирован асинхронный результат, иначе <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE::WAIT</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Если состояние, ассоциированное с <code>*this</code>, содержит отложенную функцию, то эта функция вызывается. В противном случае ждет, когда будет готов асинхронный результат, ассоциированный с данным экземпляром <code>std::shared_future</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void wait() const;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;valid()</code> должна возвращать <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Обращения из нескольких потоков к функциям <code>get()</code> и <code>wait()</code> экземпляров <code>std::shared_future</code>, разделяющих одно и то же ассоциированное состояние, сериализуются. Если ассоциированное состояние содержит отложенную функцию, то первое обращение к <code>get()</code> или <code>wait()</code> приводит к вызову этой функции и сохранению возвращенного ей значения или возбужденного ей исключения в асинхронном результате. Блокирует поток, пока не будет готов асинхронный результат, ассоциированный с <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE::WAIT_FOR</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ждет, когда будет готов асинхронный результат, ассоциированный с данным экземпляром <code>std::shared_future</code>, или истечет заданное время.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>future_status wait_for(</code>
          </p>
          <p>
            <code>std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time) const;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;valid()</code> должно возвращать <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если асинхронный результат, ассоциированный с <code>*this</code>, содержит отложенную функцию, полученную обращением к <code>std::async</code>, и эта функция, еще не начала исполняться, то возвращает управление немедленно без блокирования потока. В противном случае блокирует поток до момента готовности асинхронного результата, ассоциированного с <code>*this</code>, или до истечения времени, заданного в аргументе <code>relative_time</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>std::future_status::deferred</code>, если асинхронный результат, ассоциированный с <code>*this</code>, содержит отложенную функцию, полученную обращением к <code>std::async</code>, и эта функция, еще не начала исполняться. <code>std::future_status::ready</code>, если асинхронный результат, ассоциированный с <code>*this</code>, готов, <code>std::future_status::timeout</code>, если истекло время, заданное в аргументе <code>relative_time</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Поток может быть заблокирован на время, превышающее указанное. Если возможно, время измеряется по стабильным часам.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE::WAIT_UNTIL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ждет, когда будет готов асинхронный результат, ассоциированный с данным экземпляром <code>std::shared_future</code>, или наступит заданный момент времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>bool wait_until(</code>
          </p>
          <p>
            <code>std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time) const;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;valid()</code> должно возвращать <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если асинхронный результат, ассоциированный с <code>*this</code>, содержит отложенную функцию, полученную обращением к <code>std::async</code>, и эта функция, еще не начала исполняться, то возвращает управление немедленно без блокирования потока. В противном случае блокирует поток до момента готовности асинхронного результата, ассоциированного с <code>*this</code>, или до момента, когда функция <code>Clock::now()</code> вернет время, большее или равное <code>absolute_time</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>std::future_status::deferred</code>, если асинхронный результат, ассоциированный с <code>*this</code>, содержит отложенную функцию, полученную обращением к <code>std::async</code>, и эта функция, еще не начала исполняться. <code>std::future_status::ready</code>, если асинхронный результат, ассоциированный с <code>*this</code>, готов, <code>std::future_status::timeout</code>, если <code>Clock::now()</code> вернула время, большее или равное a<code>bsolute_time</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Не дается никаких гарантий относительно того, сколько времени будет блокирован вызывающий поток. Гарантируется лишь, что если функция вернула <code>std::future_status::timeout</code>, то значение, возвращенное <code>Clock::now()</code>, больше или равно <code>absolute_time</code> в точке, где поток разблокировался.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SHARED_FUTURE::GET</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Если ассоциированное состояние содержит отложенную функцию, полученную в результате обращения к <code>std::async</code>, то вызывает эту функцию и возвращает результат. В противном случае ждет готовности асинхронного результата, ассоциированного с экземпляром <code>std::shared_future</code>, а затем либо возвращает сохраненное в нем значение, либо возбуждает сохраненное в нем исключение.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void shared_future&lt;void&gt;::get() const;</code>
          </p>
          <p>
            <code>R&amp; shared_future&lt;R&amp;&gt;::get() const;</code>
          </p>
          <p>
            <code>R const&amp; shared_future&lt;R&gt;::get() const;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;valid()</code> должно возвращать <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Обращения из нескольких потоков к функциям <code>get()</code> и <code>wait()</code> экземпляров <code>std::shared_future</code>, разделяющих одно и то же ассоциированное состояние, сериализуются. Если ассоциированное состояние содержит отложенную функцию, то первое обращение к <code>get()</code> или <code>wait()</code> приводит к вызову этой функции и сохранению возвращенного ей значения или возбужденного ей исключения в асинхронном результате.</p>
          <p>Блокирует поток, пока не будет готов асинхронный результат, ассоциированный с <code>*this</code>. Если в результате хранится исключение, возбуждает его, иначе возвращает хранящееся значение.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Если <code>ResultType</code> — <code>void</code>, то функция просто возвращает управление. Если <code>ResultType</code> — <code>R&amp;</code> для некоторого типа <code>R</code>, то возвращает хранящуюся ссылку. Иначе возвращает константную ссылку на хранящееся значение.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Хранящееся исключение, если таковое имеется.</p>
        </section>
        <section>
          <title>
            <p>D.4.3. Шаблон класса <code>std::packaged_task</code></p>
          </title>
          <p>Шаблон класса <code>std::packaged_task</code> упаковывает функцию или другой допускающий вызов объект, так что при вызове функции через экземпляр <code>std::packaged_task</code> результат сохраняется в виде асинхронного результата, который может быть получен с помощью объекта <code>std::future</code>.</p>
          <p>Экземпляры <code>std::packaged_task</code> удовлетворяют требованиям концепций <code>MoveConstructible</code> и <code>MoveAssignable</code>, но не <code>CopyConstructible</code> и <code>CopyAssignable</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template&lt;typename FunctionType&gt;</code>
          </p>
          <p>
            <code>class packaged_task; // не определен</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename ResultType, typename... ArgTypes&gt;</code>
          </p>
          <p>
            <code>class packaged_task&lt;ResultType(ArgTypes...)&gt; {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code>packaged_task() noexcept;</code>
          </p>
          <p>
            <code>packaged_task(packaged_task&amp;&amp;) noexcept;</code>
          </p>
          <p>
            <code>~packaged_task();</code>
          </p>
          <empty-line/>
          <p>
            <code>packaged_task&amp; operator=(packaged_task&amp;&amp;) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>packaged_task(packaged_task const&amp;) = delete;</code>
          </p>
          <p>
            <code>packaged_task&amp; operator=(packaged_task const&amp;) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code>void swap(packaged_task&amp;) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Callable&gt;</code>
          </p>
          <p>
            <code>explicit packaged_task(Callable&amp;&amp; func);</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Callable, typename Allocator&gt;</code>
          </p>
          <p>
            <code>packaged_task(</code>
          </p>
          <p>
            <code>std::allocator_arg_t, const Allocator&amp;, Callable&amp;&amp;);</code>
          </p>
          <empty-line/>
          <p>
            <code>bool valid() const noexcept;</code>
          </p>
          <p>
            <code>std::future&lt;ResultType&gt; get_future();</code>
          </p>
          <p>
            <code>void operator()(ArgTypes...);</code>
          </p>
          <p>
            <code>void make_ready_at_thread_exit(ArgTypes...); void reset();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::packaged_task</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>packaged_task() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::packaged_task</code>, с которым не ассоциировала ни задача, ни асинхронный результат.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK</strong>
            </code>
            <strong>, КОНСТРУИРОВАНИЕ ИЗ ДОПУСКАЮЩЕГО ВЫЗОВ ОБЪЕКТА</strong>
          </p>
          <p>Конструирует экземпляр <code>std::packaged_task</code>, с которым ассоциированы задача и асинхронный результат.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Callable&gt;</code>
          </p>
          <p>
            <code>packaged_task(Callable&amp;&amp; func);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Должно быть допустимо выражение <code>func(args...)</code>, где каждый элемент <code>args-<emphasis>i</emphasis></code> в списке <code>args...</code> должен быть значением соответственного типа <code>ArgTypes-<emphasis>i</emphasis></code> в списке <code>ArgTypes...</code>. Возвращаемое значение должно допускать преобразование в тип <code>ResultType</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::packaged_task</code>, с которым ассоциированы еще <emphasis>не готовый</emphasis> асинхронный результат типа <code>ResultType</code> и задача типа <code>Callable</code>, полученная копированием <code>func</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::bad_alloc</code>, если конструктор не смог выделить память для асинхронного результата. Любое исключение, возбуждаемое копирующим или перемещающим конструктором <code>Callable</code>.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK</strong>
            </code>
            <strong>, КОНСТРУИРОВАНИЕ ИЗ ДОПУСКАЮЩЕГО ВЫЗОВ ОБЪЕКТА С РАСПРЕДЕЛИТЕЛЕМ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::packaged_task</code>, с которым ассоциированы задача и асинхронный результат, применяя предоставленный распределитель для выделения памяти под асинхронный результат и задачу</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Allocator, typename Callable&gt;</code>
          </p>
          <p>
            <code>packaged_task(</code>
          </p>
          <p>
            <code>std::allocator_arg_t, Allocator const&amp; alloc, Callable&amp;&amp; func);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Должно быть допустимо выражение <code>func(args...)</code>, где каждый элемент <code>args-<emphasis>i</emphasis></code> в списке <code>args...</code> должен быть значением соответственного типа <code>ArgTypes-<emphasis>i</emphasis></code> в списке <code>ArgTypes...</code>. Возвращаемое значение должно допускать преобразование в тип <code>ResultType</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::packaged_task</code>, с которым ассоциированы еще <emphasis>не готовый</emphasis> асинхронный результат типа <code>ResultType</code> и задача типа <code>Callable</code>, полученная копированием <code>func</code>. Память под асинхронный результат и задачу выделяется с помощью распределителя <code>alloc</code> или его копии.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбуждаемое распределителем в случае неудачной попытки выделить память под асинхронный результат или задачу. Любое исключение, возбуждаемое копирующим или перемещающим конструктором <code>Callable</code>.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует один объект <code>std::packaged_task</code> из другого, передавая владение асинхронным результатом и задачей, ассоциированными с объектом <code>other</code>, вновь сконструированному.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>packaged_task(packaged_task&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый экземпляр <code>std::packaged_task</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат и задача, которые были ассоциированы с объектом <code>other</code> до вызова конструктора, ассоциируются со вновь сконструированным объектом <code>std::packaged_task</code>. С объектом <code>other</code> больше не связан никакой асинхронный результат.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Передает владение ассоциированным асинхронным результатом от одного объекта <code>std::packaged_task</code> другому.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>packaged_task&amp; operator=(packaged_task&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Передает владение асинхронным результатом и задачей, ассоциированными с объектом <code>other</code>, объекту <code>*this</code> и отбрасывает ранее ассоциированный асинхронный результат, как если бы было выполнено предложение <code>std::packaged_task(other).swap(*this)</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат и задача, которые были ассоциированы с объектом <code>other</code> до вызова перемещающего оператора присваивания, ассоциируются с <code>*this</code>. С объектом <code>other</code> больше не связан никакой асинхронный результат.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK::SWAP</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Обменивает владение асинхронными результатами, ассоциированными с двумя объектами <code>std::packaged_task</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void swap(packaged_task&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Обменивает владение асинхронными результатами и задачами, ассоциированными с объектами <code>other</code> и <code>*this</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат и задача, которые были ассоциированы с объектом <code>other</code> до вызова <code>swap</code> (если таковые действительно были), ассоциируются с <code>*this</code>. Асинхронный результат и задача, которые были ассоциировать с объектом <code>*this</code> до вызова <code>swap</code> (если таковые действительно были), ассоциируются с <code>other</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::packaged_task</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~packaged_task();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>. Если с <code>*this</code> ассоциирован асинхронный результат и в этом результате не хранится задача или исключение, то результат становится <emphasis>готов</emphasis>, причем в него помещается исключение <code>std::future_error</code> с кодом ошибки <code>std::future_errc::broken_promise</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK::GET_FUTURE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Извлекает экземпляр <code>std::future</code> для асинхронного результата, ассоциированного с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>std::future&lt;ResultType&gt; get_future();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>С <code>*this</code> ассоциирован асинхронный результат.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Экземпляр <code>std::future</code> для асинхронного результата, ассоциированного с <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::future_error</code> с кодом ошибки <code>std::future_errc::future_already_retrieved</code>, если объект <code>std::future</code> уже был получен для этого асинхронного результата с помощью предшествующего обращения к <code>get_future()</code>.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK::RESET</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ассоциирует экземпляр <code>std::packaged_task</code> с новым асинхронным результатом для той же задачи.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void reset();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>С <code>*this</code> ассоциирована асинхронная задача.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Эквивалентно <code>*this = packaged_task(std::move(f))</code>, где <code>f</code> &#8213; хранимая задача, ассоциированная с <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::bad_alloc</code>, если не удалось выделить память для нового асинхронного результата.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK::VALID</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Проверяет, ассоциированы ли с <code>*this</code> задача и асинхронный результат.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool valid() const noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если с <code>*this</code> ассоциированы задача и асинхронный результат, иначе <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK::OPERATOR()</strong>
            </code>
            <strong>, ОПЕРАТОР ВЫЗОВА</strong>
          </p>
          <p>Вызывает задачу, ассоциированную с экземпляром <code>std::packaged_task</code>, и сохраняет возвращенное ей значение или исключение в ассоциированном асинхронном результате.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void operator()(ArgTypes... args);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>С <code>*this</code> ассоциирована задача.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вызывает ассоциированную задачу, как если бы было выполнено предложение <code>INVOKE(func, args...)</code>. Если вызов завершается нормально, то сохраняет возвращенное значение в асинхронном результате, ассоциированном с <code>*this</code>. Если задача возбуждает исключение, то сохраняет это исключение в асинхронном результате, ассоциированном с <code>*this</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с <code>*this</code>, готов и содержит значение или исключение. Все потоки, ожидающие асинхронного результата, разблокируются.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::future_error</code> с кодом ошибки <code>std::future_errc::promise_already_satisfied</code>, если в асинхронном результате уже находится значение или исключение.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Успешное обращение к оператору вызова синхронизируется-с обращением к <code>std::future&lt;ResultType&gt;::get()</code> или <code>std::shared_future&lt;ResultType&gt;::get()</code>, которое извлекает хранимое значение или исключение.</p>
          <p>
            <code>
              <strong>STD::PACKAGED_TASK::MAKE_READY_AT_THREAD_EXIT</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Вызывает задачу, ассоциированную с экземпляром <code>std::packaged_task</code>, и сохраняет возвращенное ей значение или исключение в ассоциированном асинхронном результате, но не делает этот результат готовым раньше момента завершения потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void make_ready_at_thread_exit(ArgTypes... args);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>С <code>*this</code> ассоциирована задача.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вызывает ассоциированную задачу, как если бы было выполнено предложение <code>INVOKE(func, args...)</code>. Если вызов завершается нормально, то сохраняет возвращенное значение в асинхронном результате, ассоциированном с <code>*this</code>. Если задача возбуждает исключение, то сохраняет это исключение в асинхронном результате, ассоциированном с <code>*this</code>. Планирует перевод ассоциированного асинхронного результата в состояние готовности в момент завершения потока.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с <code>*this</code>, содержит значение или исключение, но не является готовым до завершения текущего потока. Все потоки, ожидающие асинхронного результата, будут разблокированы, когда текущий поток завершится.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::future_error</code> с кодом ошибки <code>std::future_errc::promise_already_satisfied</code>, если в асинхронном результате уже находится значение или исключение. Исключение типа <code>std::future_error</code> с кодом ошибки <code>std::future_errc::no_state</code>, если с <code>*this</code> не ассоциировано асинхронное состояние. <emphasis>Синхронизация</emphasis></p>
          <p>Завершение потока, в котором была успешно вызвала функция <code>make_ready_at_thread_exit()</code>, синхронизируется-с обращением к <code>std::future&lt;ResultType&gt;::get()</code> или <code>std::shared_future&lt;ResultType&gt;::get()</code>, которое извлекает хранимое значение или исключение.</p>
        </section>
        <section>
          <title>
            <p>D.4.4. Шаблон класса <code>std::promise</code></p>
          </title>
          <p>Шаблон класса <code>std::promise</code> предоставляет средства для установки асинхронного результата, который может быть получен в другом потоке с помощью экземпляра <code>std::future</code><strong>.</strong></p>
          <p>Параметр <code>ResultType</code> — это тип значения, сохраняемого в асинхронном результате.</p>
          <p>Объект <code>std::future</code><strong>,</strong> ассоциированный с асинхронным результатом конкретного экземпляра <code>std::promise</code><strong>,</strong> можно получить путем обращения к функции-члену <code>get_future()</code>. В асинхронный результат записывается либо значение типа <code>ResultType</code> функцией-членом <code>set_value()</code>, либо исключение функцией-членом <code>set_exception()</code><strong>.</strong></p>
          <p>Экземпляры <code>std::promise</code> удовлетворяют требованиям концепций <code>MoveConstructible</code> и <code>MoveAssignable</code>, но не <code>CopyConstructible</code> <strong>или</strong> <code>CopyAssignable</code><strong>.</strong></p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template&lt;typename ResultType&gt;</code>
          </p>
          <p>
            <code>class promise {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code>promise();</code>
          </p>
          <p>
            <code>promise(promise&amp;&amp;) noexcept;</code>
          </p>
          <p>
            <code>~promise();</code>
          </p>
          <p>
            <code>promise&amp; operator=(promise&amp;&amp;) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Allocator&gt;</code>
          </p>
          <p>
            <code>promise(std::allocator_arg_t, Allocator const&amp;);</code>
          </p>
          <empty-line/>
          <p>
            <code>promise(promise const&amp;) = delete;</code>
          </p>
          <p>
            <code>promise&amp; operator=(promise const&amp;) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code>void swap(promise&amp;) noexcept;</code>
          </p>
          <p>
            <code>std::future&lt;ResultType&gt; get_future();</code>
          </p>
          <empty-line/>
          <p>
            <code>void set_value(see description);</code>
          </p>
          <p>
            <code>void set_exception(std::exception_ptr p);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::PROMISE</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::promise</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>promise();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::promise</code>, с которым ассоциировал неготовый асинхронный результат типа <code>ResultType</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::bad_alloc</code>, если конструктор не смог выделить память для асинхронного результата.</p>
          <p>
            <code>
              <strong>STD::PROMISE</strong>
            </code>
            <strong>, КОНСТРУКТОР С РАСПРЕДЕЛИТЕЛЕМ</strong>
          </p>
          <p>Конструирует экземпляр std::promise, применяя предоставленный распределитель для выделения памяти под ассоциированный асинхронный результат.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Allocator&gt;</code>
          </p>
          <p>
            <code>promise(std::allocator_arg_t, Allocator const&amp; alloc);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::promise</code>, с которым ассоциировал неготовый асинхронный результат типа <code>ResultType</code>. Память под асинхронный результат выделяется с помощью распределителя <code>alloc</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбуждаемое распределителем в случае неудачной попытки выделить память под асинхронный результат.</p>
          <p>
            <code>
              <strong>STD::PROMISE</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует один объект <code>std::promise</code> из другого, передавая владение асинхронным результатом от объекта <code>other</code> вновь сконструированному.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>promise(promise&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый экземпляр <code>std::promise</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, который был ассоциирован с объектом <code>other</code> до вызова конструктор, ассоциируется с вновь сконструированным объектом <code>std::promise</code>. С объектом <code>other</code> больше не ассоциирован никакой асинхронный результат.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PROMISE</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Передает владение асинхронным результатом, ассоциированным с объектом <code>std::promise</code>, другому объекту.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>promise&amp; operator=(promise&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Передает владение асинхронным результатом, ассоциированным с <code>*this</code>. Если с <code>*this</code> уже был ассоциирован асинхронный результат, то результат становится <emphasis>готов</emphasis>, причем в него помещается исключение <code>std::future_error</code> с кодом ошибки <code>std::future_errc::broken_promise</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, который был ассоциирован с объектом <code>other</code> до вызова перемещающего оператора присваивания, ассоциируется с <code>*this</code>. С объектом <code>other</code> больше не ассоциирован никакой асинхронный результат.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>*this</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PROMISE::SWAP</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Обменивает владение асинхронными результатами, ассоциированными с двумя объектами <code>std::promise</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void swap(promise&amp; other);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Обменивает владение асинхронными результатами, ассоциированными с объектами <code>other</code> и <code>*this</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, который был ассоциирован с объектом <code>other</code> до вызова <code>swap</code> (если таковой действительно был), ассоциируется с <code>*this</code>. Асинхронный результат, который был ассоциирован с объектом <code>*this</code> до вызова <code>swap</code> (если таковой действительно был), ассоциируется с <code>other</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PROMISE</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::promise</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~promise();</code>
          </p>
          <p>Результат</p>
          <p>Уничтожает <code>*this</code>. Если с <code>*this</code> ассоциирован асинхронный результат и в этом результате не хранится задача или исключение, то результат становится <emphasis>готов</emphasis>, причем в него помещается исключение <code>std::future_error</code> с кодом ошибки <code>std::future_errc::broken_promise</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::PROMISE::GET_FUTURE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Извлекает экземпляр <code>std::future</code> для асинхронного результата, ассоциированного с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>std::future&lt;ResultType&gt; get_future();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>С <code>*this</code> ассоциировал асинхронный результат.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Экземпляр <code>std::future</code> для асинхронного результата, ассоциированного с <code>*this</code>.</p>
          <p>
            <code>Исключения</code>
          </p>
          <p>Исключение типа <code>std::future_error</code> с кодом ошибки <code>std::future_errc::future_already_retrieved</code>, если объект <code>std::future</code> уже был получен для этого асинхронного результата с помощью предшествующего обращения к <code>get_future()</code>.</p>
          <p>
            <code>
              <strong>STD::PROMISE::SET_VALUE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Сохраняет значение в асинхронном результате, ассоциированном с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void promise&lt;void&gt;::set_value();</code>
          </p>
          <p>
            <code>void promise&lt;R&amp;&gt;::set_value(R&amp; r);</code>
          </p>
          <p>
            <code>void promise&lt;R&gt;::set_value(R const&amp; r);</code>
          </p>
          <p>
            <code>void promise&lt;R&gt;::set_value(R&amp;&amp; r);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>С <code>*this</code> ассоциирован асинхронный результат.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Сохраняет <code>r</code> в асинхронном результате, ассоциированном с <code>*this</code>, если <code>ResultType</code> — не <code>void</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с <code>*this</code>, готов и содержит значение. Все потоки, ожидающие асинхронного результата, разблокируются.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::future_error</code> с кодом ошибки <code>std::future_errc::promise_already_satisfied</code>, если в асинхронном результате уже находится значение или исключение. Любое исключение, возбужденное копирующим или перемещающим конструктором <code>r</code>.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к <code>set_value()</code>, <code>set_value_at_thread_exit()</code>, <code>set_exception()</code> и <code>set_exception_at_thread_exit()</code> сериализуются. Успешное обращение к <code>set_value()</code> происходит-раньше обращения к функции <code>std::future&lt;ResultType&gt;::get()</code> или <code>std::shared_future&lt;ResultType&gt;::get()</code>, которая извлекает сохраненное значение.</p>
          <p>
            <code>
              <strong>STD::PROMISE::SET_VALUE_AT_THREAD_EXIT</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Сохраняет значение в асинхронном результате, ассоциированном с <code>*this</code>, но не делает этот результат готовым раньше момента завершения потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void promise&lt;void&gt;::set_value_at_thread_exit();</code>
          </p>
          <p>
            <code>void promise&lt;R&amp;&gt;::set_value_at_thread_exit(R&amp; r);</code>
          </p>
          <p>
            <code>void promise&lt;R&gt;::set_value_at_thread_exit(R const&amp; r);</code>
          </p>
          <p>
            <code>void promise&lt;R&gt;::set_value_at_thread_exit(R&amp;&amp; r);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>С <code>*this</code> ассоциирован асинхронный результат.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Сохраняет <code>r</code> в асинхронном результате, ассоциированном с <code>*this</code>, если <code>ResultType</code> — не <code>void</code>. Помечает, что в асинхронном результате хранится значение. Планирует перевод ассоциированного асинхронного результата в состояние готовности в момент завершения потока.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с <code>*this</code>, содержит значение, но не является готовым до завершения текущего потока. Все потоки, ожидающие асинхронного результата, будут разблокированы, когда текущий поток завершится.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::future_error</code> с кодом ошибки <code>std::future_errc::promise_already_satisfied</code>, если в асинхронном результате уже находится значение или исключение. Любое исключение, возбужденное копирующим или перемещающим конструктором <code>r</code>.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к <code>set_value()</code>, <code>set_value_at_thread_exit()</code>, <code>set_exception()</code> и <code>set_exception_at_thread_exit()</code> сериализуются. Успешное обращение к <code>set_value()</code> происходит-раньше обращения к функции <code>std::future&lt;ResultType&gt;::get()</code> или <code>std::shared_future&lt;ResultType&gt;::get()</code>, которая извлекает сохраненное значение.</p>
          <p>
            <code>
              <strong>STD::PROMISE::SET_EXCEPTION</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН КЛАССА</strong>
          </p>
          <p>Сохраняет исключение в асинхронном результате, ассоциированном с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void set_exception(std::exception_ptr e);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>С <code>*this</code> ассоциирован асинхронный результат. <code>(bool)e</code> равно <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Сохраняет <code>e</code> в асинхронном результате, ассоциированном с <code>*this</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с <code>*this</code>, готов и содержит исключение. Все потоки, ожидающие асинхронного результата, разблокируются.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::future_error</code> с кодом ошибки <code>std::future_errc::promise_already_satisfied</code>, если в асинхронном результате уже находится значение или исключение.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к <code>set_value()</code>, <code>set_value_at_thread_exit()</code>, <code>set_exception()</code> и <code>set_exception_at_thread_exit()</code> сериализуются. Успешное обращение к <code>set_value()</code> происходит-раньше обращения к функции <code>std::future&lt;ResultType&gt;::get()</code> или <code>std::shared_future&lt;ResultType&gt;::get()</code>, которая извлекает сохраненное исключение.</p>
          <p>
            <code>
              <strong>STD::PROMISE::SET_EXCEPTION_AT_THREAD_EXIT,</strong>
            </code>
            <strong>ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Сохраняет исключение в асинхронном результате, ассоциированном с <code>*this</code>, но не делает этот результат готовым раньше момента завершения потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void set_exception_at_thread_exit(std::exception_ptr e);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>С <code>*this</code> ассоциирован асинхронный результат, <code>(bool)e</code> равно <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Сохраняет <code>e</code> в асинхронном результате, ассоциированном с <code>*this</code>. Планирует перевод ассоциированного асинхронного результата в состояние готовности в момент завершения потока.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Асинхронный результат, ассоциированный с <code>*this</code>, содержит исключение, но не является готовым до завершения текущего потока. Все потоки, ожидающие асинхронного результата, будут разблокированы, когда текущий поток завершится. <emphasis>Исключения</emphasis></p>
          <p>Исключение типа <code>std::future_error</code> с кодом ошибки <code>std::future_errc::promise_already_satisfied</code>, если в асинхронном результате уже находится значение или исключение.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Обращения к <code>set_value()</code>, <code>set_value_at_thread_exit()</code>, <code>set_exception()</code> и <code>set_exception_at_thread_exit()</code> сериализуются. Успешное обращение к <code>set_value()</code> происходит-раньше обращения к функции <code>std::future&lt;ResultType&gt;::get()</code> или <code>std::shared_future&lt;ResultType&gt;::get()</code>, которая извлекает сохраненное исключение.</p>
        </section>
        <section>
          <title>
            <p>D.4.5. Шаблон функции <code>std::async</code></p>
          </title>
          <p>Шаблон функции <code>std::async</code> дает простой способ выполнить автономную асинхронную задачу с использованием доступного аппаратного параллелизма. Обращение к <code>std::async</code> возвращает объект <code>std::future</code>, который содержит результат задачи. В зависимости от политики запуска задача выполняется либо асинхронно в отдельном потоке, либо синхронно в том потоке, который вызвал функции-члены <code>wait()</code> или <code>get()</code> объекта <code>std::future</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>enum class launch {</code>
          </p>
          <p>
            <code>async, deferred</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Callable, typename... Args&gt;</code>
          </p>
          <p>
            <code>future&lt;result_of&lt;Callable(Args...)&gt;::type&gt;</code>
          </p>
          <p>
            <code>async(Callable&amp;&amp; func, Args&amp;&amp; ... args);</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Callable, typename ... Args&gt;</code>
          </p>
          <p>
            <code>future&lt;result_of&lt;Callable(Args...)&gt;::type&gt;</code>
          </p>
          <p>
            <code>async(launch policy, Callable&amp;&amp; func, Args&amp;&amp; ... args);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Выражение <code>INVOKE(func, args)</code> допустимо для переданных значений <code>func</code> и <code>args</code>. Тип <code>Callable</code> и все члены <code>Args</code> удовлетворяют требованиям концепции <code>MoveConstructible</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует копии <code>func</code> и <code>args...</code> во внутренней памяти (далее обозначаются <code>fff</code> и <code>xyz...</code> соответственно).</p>
          <p>Если <code>policy</code> равно <code>std::launch::async</code>, то вызывает функцию <code>INVOKE(fff, xyz...)</code> в отдельном потоке. Возвращенный объект <code>std::future</code> становится <emphasis>готов</emphasis>, когда этот поток завершится, и будет содержать либо возвращенное функцией значение, либо возбужденное ей исключение. Деструктор последнего будущего объекта, ассоциированного с асинхронным состоянием возвращенного объекта <code>std::future</code>, блокирует поток, пока будущий результат не будет <emphasis>готов</emphasis>.</p>
          <p>Если <code>policy</code> равно <code>std::launch::deferred</code>, то <code>fff</code> и <code>xyz...</code> сохраняются в возвращенном объекте <code>std::future</code> как отложенный вызов функции. При первом обращении к функции-члену <code>wait()</code> или <code>get()</code> будущего результата, который разделяет то же самое ассоциированное состояние, функция <code>INVOKE(fff, xyz...)</code> синхронно вызывается в потоке, который обратился к <code>wait()</code> или <code>get()</code>.</p>
          <p>В ответ на вызов функции <code>get()</code> этого объекта <code>std::future</code> либо возвращается значение, полученное от <code>INVOKE(fff, xyz...)</code>, либо возбуждается исключение, которое имело место в этой функции.</p>
          <p>Если <code>policy</code> равно <code>std::launch::async | std::launch::deferred</code> или аргумент <code>policy</code> опущен, то поведение такое же, как если бы была задана политика <code>std::launch::async</code> или <code>std::launch::deferred</code>. Реализация сама выбирает нужное поведение при каждом вызове, чтобы в максимальной степени задействовать доступный аппаратный параллелизм, не вызывая при этом превышения лимита.</p>
          <p>В любом случае функция <code>std::async</code> возвращает управление немедленно.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Завершение вызова функции происходит-раньше успешного возврата из функций <code>wait()</code>, <code>get()</code>, <code>wait_for()</code> и <code>wait_until()</code> любого экземпляра <code>std::future</code> или <code>std::shared_future</code>, который ссылается на то же ассоциированное состояние, что и объект <code>std::future</code>, возвращенный функцией <code>std::async</code>. Если <code>policy</code> равно <code>std::launch::async</code>, то завершение потока, в котором имел место вызов <code>std::async</code>, также происходит-раньше успешного возврата из этих функций.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p><code>std::bad_alloc</code>, если не удалось выделить внутреннюю память или <code>std::future_error</code>, если не удалось добиться желаемого эффекта, или исключение, возбужденное в ходе конструирования <code>fff</code> или <code>xyz...</code>.</p>
        </section>
      </section>
      <section>
        <title>
          <p>D.5. Заголовок <code>&lt;mutex&gt;</code></p>
        </title>
        <section>
          <p>В заголовке <code>&lt;mutex&gt;</code> объявлены средства, обеспечивающие взаимное исключение: типы мьютексов и блокировок, различные функции и механизм, гарантирующий, что некая операция выполнена ровно один раз.</p>
          <p>
            <emphasis>Содержимое заголовка</emphasis>
          </p>
          <p>
            <code>namespace std {</code>
          </p>
          <p>
            <code>class mutex;</code>
          </p>
          <p>
            <code>class recursive_mutex;</code>
          </p>
          <p>
            <code>class timed_mutex;</code>
          </p>
          <p>
            <code>class recursive_timed_mutex;</code>
          </p>
          <empty-line/>
          <p>
            <code>struct adopt_lock_t;</code>
          </p>
          <p>
            <code>struct defer_lock_t;</code>
          </p>
          <p>
            <code>struct try_to_lock_t;</code>
          </p>
          <empty-line/>
          <p>
            <code>constexpr adopt_lock_t adopt_lock{};</code>
          </p>
          <p>
            <code>constexpr defer_lock_t defer_lock{};</code>
          </p>
          <p>
            <code>constexpr try_to_lock_t try_to_lock{};</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename LockableType&gt;</code>
          </p>
          <p>
            <code>class lock_guard;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename LockableType&gt;</code>
          </p>
          <p>
            <code>class unique_lock;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename LockableType1, typename... LockableType2&gt;</code>
          </p>
          <p>
            <code>void lock(LockableType1&amp; m1, LockableType2&amp; m2...);</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename LockableType1, typename... LockableType2&gt;</code>
          </p>
          <p>
            <code>int try_lock(LockableType1&amp; m1, LockableType2&amp; m2...);</code>
          </p>
          <empty-line/>
          <p>
            <code>struct once_flag;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Callable, typename... Args&gt;</code>
          </p>
          <p>
            <code>void call_once(once_flag&amp; flag, Callable func, Args args...);</code>
          </p>
          <p>
            <code>}</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.5.1. Класс <code>std::mutex</code></p>
          </title>
          <p>Класс <code>std::mutex</code> предоставляет базовые средства взаимного исключения и синхронизации потоков, применяемые для защиты разделяемых данных. Перед тем как обращаться к данным, защищаемым мьютексом, этот мьютекс необходимо <emphasis>захватить</emphasis> (или <emphasis>заблокировать</emphasis>), вызвав функцию <code>lock()</code> или <code>try_lock()</code>. В любой момент времени удерживать мьютекс может только один поток; если другой поток попытается захватить тот же мьютекс, то функция <code>try_lock()</code> вернет ошибку, а функция <code>lock()</code> приостановит выполнение потока. Закончив операции над разделяемыми данными, поток должен вызвать функцию <code>unlock()</code>, чтобы освободить мьютекс и дать другим потокам возможность захватить его.</p>
          <p>Экземпляр <code>std::mutex</code> удовлетворяет требованиям концепции <code>Lockable</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class mutex {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> mutex(mutex const&amp;)=delete;</code>
          </p>
          <p>
            <code> mutex&amp; operator=(mutex const&amp;)=delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> constexpr mutex() noexcept;</code>
          </p>
          <p>
            <code> ~mutex();</code>
          </p>
          <empty-line/>
          <p>
            <code> void lock();</code>
          </p>
          <p>
            <code> void unlock();</code>
          </p>
          <p>
            <code> bool try_lock();</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::MUTEX</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::mutex</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr mutex() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::mutex</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Вновь сконструированный объект <code>std::mutex</code> первоначально не захвачен.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::MUTEX</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::mutex</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~mutex();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Объект <code>*this</code> не должен быть захвачен.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::MUTEX::LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Захватывает объект <code>std::mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void lock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток не должен удерживать мьютекс <code>*this</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Блокирует текущий поток, пока мьютекс <code>*this</code> не будет захвачен.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен текущим потоком.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code> в случае ошибки.</p>
          <p>
            <code>
              <strong>STD::MUTEX::TRY_LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить объект <code>std::mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool try_lock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток не должен удерживать мьютекс <code>*this</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пытается захватить объект <code>std::mutex</code> для текущего потока без блокирования.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызывающий поток захватил мьютекс, иначе <code>false</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен вызывающим потоком, если функция вернула <code>true</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Функция может не захватить мьютекс (и вернуть <code>false</code>), даже если никакой другой поток не удерживает <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::MUTEX::UNLOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Освобождает объект <code>std::mutex</code>, удерживаемый текущим потоком.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void unlock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток должен удерживать мьютекс <code>*this</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Освобождает мьютекс <code>std::mutex</code>, удерживаемый текущим потоком.</p>
          <p>Если другие потоки были блокированы в ожидании <code>*this</code>, то один из них разблокируется.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> не захвачен вызывающим потоком.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
        </section>
        <section>
          <title>
            <p>D.5.2. Класс <code>std::recursive_mutex</code></p>
          </title>
          <p>Класс <code>std::recursive_mutex</code> предоставляет базовые средства взаимного исключения и синхронизации потоков, применяемые для защиты разделяемых данных. Перед тем как обращаться к данным, защищаемым мьютексом, этот мьютекс необходимо <emphasis>захватить</emphasis> (или <emphasis>заблокировать</emphasis>), вызвав функцию <code>lock()</code> или <code>try_lock()</code>. В любой момент времени удерживать мьютекс может только один поток; если другой поток попытается захватить тот же мьютекс, то функция <code>try_lock()</code> вернет ошибку, а функция <code>lock()</code> приостановит выполнение потока. Закончив операции над разделяемыми данными, поток должен вызвать функцию <code>unlock()</code>, чтобы освободить мьютекс и дать другим потокам возможность захватить его.</p>
          <p>Этот мьютекс называетс<emphasis>я рекурсивным</emphasis>, потому что поток, удерживающий мьютекс типа <code>std::recursive_mutex</code>, может снова обратиться к функции <code>lock()</code> или <code>try_lock()</code>, что приведёт к увеличению счетчика захватов. Никакой другой поток не сможет захватить этот мьютекс, пока владеющий им поток не вызовет функцию <code>unlock</code> столько раз, сколько было успешных вызовов <code>lock()</code> или <code>try_lock()</code>.</p>
          <p>Экземпляр <code>std::recursive_mutex</code> удовлетворяет требованиям концепции <code>Lockable</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class recursive_mutex {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> recursive_mutex(recursive_mutex const&amp;) = delete;</code>
          </p>
          <p>
            <code> recursive_mutex&amp; operator=(recursive_mutex const&amp;) = delete;</code>
          </p>
          <p>
            <code> recursive_mutex() noexcept;</code>
          </p>
          <p>
            <code> ~recursive_mutex();</code>
          </p>
          <empty-line/>
          <p>
            <code> void lock();</code>
          </p>
          <p>
            <code> void unlock();</code>
          </p>
          <p>
            <code> bool try_lock() noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::RECURSIVE_MUTEX</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::recursive_mutex</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>recursive_mutex() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::recursive_mutex</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Вновь сконструированный объект <code>std::recursive_mutex</code> первоначально не захвачен.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если не удалось создать экземпляр <code>std::recursive_mutex</code>.</p>
          <p>
            <code>
              <strong>STD::RECURSIVE_MUTEX</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::recursive_mutex</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~recursive_mutex();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Объект <code>*this</code> не должен быть захвачен.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::RECURSIVE_MUTEX::LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Захватывает объект <code>std::recursive_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void lock();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Блокирует текущий поток, пока мьютекс <code>*this</code> не будет захвачен.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен текущим потоком. Если вызывающий поток уже удерживал <code>*this</code>, то счетчик захватов увеличивается на единицу.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code> в случае ошибки.</p>
          <p>
            <code>
              <strong>STD::RECURSIVE_MUTEX::TRY_LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить объект <code>std::recursive_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool try_lock() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пытается захватить объект <code>std::recursive_mutex</code> для текущего потока без блокирования.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызывающий поток захватил мьютекс, иначе <code>false</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен вызывающим потоком, если функция вернула <code>true</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Если вызывающий поток уже удерживал <code>*this</code>, то функция возвращает <code>true</code>, и счетчик захватов <code>*this</code> текущим потоком увеличивается на единицу. Если текущий поток не удерживал <code>*this</code>, то функция может не захватить мьютекс (и вернуть <code>false</code>), даже если никакой другой поток не удерживает <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::RECURSIVE_MUTEX::UNLOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Освобождает объект <code>std::recursive_mutex</code>, удерживаемый текущим потоком.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void unlock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток должен удерживать мьютекс <code>*this</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Освобождает мьютекс <code>std::recursive_mutex</code>, удерживаемый текущим потоком. Если это последний захват <code>*this</code> данным потоком, и другие потоки были блокированы в ожидании <code>*this</code>, то один из них разблокируется.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Количество захватов <code>*this</code> вызывающим потоком, уменьшается на единицу.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
        </section>
        <section>
          <title>
            <p>D.5.3. Класс <code>std::timed_mutex</code></p>
          </title>
          <p>Класс <code>std::timed_mutex</code> предоставляет поддержку блокировок с таймаутами сверх базовых средств взаимного исключения и синхронизации, предоставляемых классом <code>std::mutex</code>. Перед тем как обращаться к данным, защищаемым мьютексом, этот мьютекс необходимо <emphasis>захватить</emphasis> (или <emphasis>заблокировать</emphasis>), вызвав функцию l<code>ock()</code>, <code>try_lock()</code>, <code>try_lock_for()</code> или <code>try_lock_until()</code>. Если мьютекс уже захвачен другим потоком, то функция <code>try_lock()</code> вернет ошибку, функция <code>lock()</code> приостановит выполнение потока до получения мьютекса, а функции <code>try_lock_for()</code> и <code>try_lock_until()</code> приостановят выполнение потока до получения мьютекса или истечения таймаута. Закончив операции над разделяемыми данными, поток должен вызвать функцию <code>unlock()</code> (вне зависимости от того, какой функцией мьютекс был захвачен), чтобы освободить мьютекс и дать другим потокам возможность захватить его.</p>
          <p>Экземпляр <code>std::timed_mutex</code> удовлетворяет требованиям концепции <code>TimedLockable</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class timed_mutex {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> timed_mutex(timed_mutex const&amp;)=delete;</code>
          </p>
          <p>
            <code> timed_mutex&amp; operator=(timed_mutex const&amp;)=delete;</code>
          </p>
          <p>
            <code> timed_mutex();</code>
          </p>
          <p>
            <code> ~timed_mutex();</code>
          </p>
          <empty-line/>
          <p>
            <code> void lock();</code>
          </p>
          <p>
            <code> void unlock();</code>
          </p>
          <p>
            <code> bool try_lock();</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code> bool try_lock_for(</code>
          </p>
          <p>
            <code>  std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code> bool try_lock_until(</code>
          </p>
          <p>
            <code>  std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::TIMED_MUTEX</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::timed_mutex</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>timed_mutex();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::timed_mutex</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Вновь сконструированный объект <code>std::timed_mutex</code> первоначально не захвачен.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если не удалось создать экземпляр <code>std::timed_mutex</code>.</p>
          <p>
            <code>
              <strong>STD::TIMED_MUTEX</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::timed_mutex</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~timed_mutex();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Объект <code>*this</code> не должен быть захвачен.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::TIMED_MUTEX::LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Захватывает объект <code>std::timed_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void lock();</code>
          </p>
          <p>Предусловия</p>
          <p>Вызывающий поток не должен удерживать мьютекс <code>*this</code></p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Блокирует текущий поток, пока мьютекс <code>*this</code> не будет захвачен.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен текущим потоком.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code> в случае ошибки.</p>
          <p>
            <code>
              <strong>STD::TIMED_MUTEX::TRY_LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить объект <code>std::timed_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool try_lock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток не должен удерживать мьютекс <code>*this</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пытается захватить объект <code>std::timed_mutex</code> для текущего потока без блокирования.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызывающий поток захватил мьютекс, иначе <code>false</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен вызывающим потоком, если функция вернула <code>true</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Функция может не захватить мьютекс (и вернуть <code>false</code>), даже если никакой другой поток не удерживает <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::TIMED_MUTEX::TRY_LOCK_FOR</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить объект <code>std::timed_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>bool try_lock_for(</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток не должен удерживать мьютекс <code>*this</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пытается захватить объект <code>std::timed_mutex</code> для текущего потока в течение времени, заданного аргументом <code>relative_time</code>. Если <code>relative_time.count()</code> равно нулю или отрицательно, то функция возвращается немедленно, как если бы это был вызов <code>try_lock()</code>. В противном случае вызывающий поток приостанавливается до получения мьютекса или до истечения времени, заданного аргументом <code>relative_time</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызывающий поток захватил мьютекс, иначе <code>false</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен вызывающим потоком, если функция вернула <code>true</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Функция может не захватить мьютекс (и вернуть <code>false</code>), даже если никакой другой поток не удерживает <code>*this</code>. Поток может быть блокирован дольше, чем указано. Если возможно, истекшее время измеряется по стабильным часам.</p>
          </cite>
          <p>
            <code>
              <strong>STD::TIMED_MUTEX::TRY_LOCK_UNTIL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить объект <code>std::timed_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>bool try_lock_until(</code>
          </p>
          <p>
            <code> std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток не должен удерживать мьютекс <code>*this</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пытается захватить объект <code>std::timed_mutex</code> для текущего потока, пока не наступит момент времени, заданный аргументом <code>absolute_time</code>. Если в момент вызова <code>absolute_time &lt;= Clock::now()</code>, то функция возвращается немедленно, как если бы это был вызов <code>try_lock()</code>. В противном случае вызывающий поток приостанавливается до получения мьютекса или до наступления момента времени, большего или равного <code>absolute_time</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызывающий поток захватил мьютекс, иначе <code>false</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен вызывающим потоком, если функция вернула <code>true</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Функция может не захватить мьютекс (и вернуть <code>false</code>), даже если никакой другой поток не удерживает <code>*this</code>. Не дается никаких гарантий относительно того, сколько времени будет блокирован вызывающий поток. Гарантируется лишь, что если функция вернула <code>false</code>, то значение, возвращенное <code>Clock::now()</code>, больше или равно <code>absolute_time</code> в точке, где поток разблокировался.</p>
          </cite>
          <p>
            <code>
              <strong>STD::TIMED_MUTEX::UNLOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Освобождает объект <code>std::timed_mutex</code>, удерживаемый текущим потоком.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void unlock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток должен удерживать мьютекс <code>*this</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Освобождает мьютекс <code>*this</code>, удерживаемый текущим потоком. Если другие потоки были блокированы в ожидании <code>*this</code>, то один из них разблокируется.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> не захвачен вызывающим потоком.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
        </section>
        <section>
          <title>
            <p>D.5.4. Класс <code>std::recursive_timed_mutex</code></p>
          </title>
          <p>Класс <code>std::recursive_timed_mutex</code> предоставляет поддержку блокировок с таймаутами сверх базовых средств взаимного исключения и синхронизации, предоставляемых классом <code>std::recursive_mutex</code>. Перед тем как обращаться к данным, защищаемым мьютексом, этот мьютекс необходимо <emphasis>захватить</emphasis> (или <emphasis>заблокировать</emphasis>), вызвав функцию <code>lock()</code>, <code>try_lock()</code>, <code>try_lock_for()</code> или <code>try_lock_until()</code>. Если мьютекс уже захвачен другим потоком, то функция <code>try_lock()</code> вернет ошибку, функция <code>lock()</code> приостановит выполнение потока до получения мьютекса, а функции <code>try_lock_for()</code> и <code>try_lock_until()</code> приостановят выполнение потока до получения мьютекса или истечения таймаута. Закончив операции над разделяемыми данными, поток должен вызвать функцию <code>unlock()</code> (вне зависимости от того, какой функцией мьютекс был захвачен), чтобы освободить мьютекс и дать другим потокам возможность захватить его.</p>
          <p>Этот мьютекс называется <emphasis>рекурсивным</emphasis>, потому что поток, удерживающий мьютекс типа <code>std::recursive_timed_mutex</code>, может снова захватить его любой функцией захвата. Никакой другой поток не сможет захватить этот мьютекс, пока владеющий им поток не вызовет функцию <code>unlock</code> столько раз, сколько было успешных вызовов функций захвата.</p>
          <p>Экземпляр <code>std::recursive_timed_mutex</code> удовлетворяет требованиям концепции <code>TimedLockable</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class recursive_timed_mutex {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> recursive_timed_mutex(recursive_timed_mutex const&amp;)=delete;</code>
          </p>
          <p>
            <code> recursive_timed_mutex&amp; operator=(</code>
          </p>
          <p>
            <code>  recursive_timed_mutex const&amp;)=delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> recursive_timed_mutex();</code>
          </p>
          <p>
            <code> ~recursive_timed_mutex();</code>
          </p>
          <empty-line/>
          <p>
            <code> void lock();</code>
          </p>
          <p>
            <code> void unlock();</code>
          </p>
          <p>
            <code> bool try_lock() noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code> bool try_lock_for(</code>
          </p>
          <p>
            <code>  std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code> bool try_lock_until(</code>
          </p>
          <p>
            <code>  std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::RECURSIVE_TIMED_MUTEX</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::recursive_timed_mutex</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>recursive_timed_mutex();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::recursive_timed_mutex</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Вновь сконструированный объект <code>std::recursive_timed_mutex</code> первоначально не захвачен.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если не удалось создать экземпляр <code>std::recursive_timed_mutex</code>.</p>
          <p>
            <code>
              <strong>STD::RECURSIVE_TIMED_MUTEX</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::recursive_timed_mutex</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~recursive_timed_mutex();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Объект <code>*this</code> не должен быть захвачен.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::RECURSIVE_TIMED_MUTEX::LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Захватывает объект <code>std::recursive_timed_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void lock();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Блокирует текущий поток, пока мьютекс <code>*this</code> не будет захвачен.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен текущим потоком. Если вызывающий поток уже удерживал <code>*this</code>, то счетчик захватов увеличивается на единицу.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code> в случае ошибки.</p>
          <p>
            <code>
              <strong>STD::RECURSIVE_TIMED_MUTEX::TRY_LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить объект <code>std::recursive_timed_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool try_lock() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пытается захватить объект <code>std::recursive_timed_mutex</code> для текущего потока без блокирования.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызывающий поток захватил мьютекс, иначе <code>false</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен вызывающим потоком, если функция вернула <code>true</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Если вызывающий поток уже удерживал <code>*this</code>, то функция возвращает <code>true</code>, и счетчик захватов <code>*this</code> текущим потоком увеличивается на единицу. Если текущий поток не удерживал <code>*this</code>, то функция может не захватить мьютекс (и вернуть <code>false</code>), даже если никакой другой поток не удерживает <code>*this</code>.</p>
          </cite>
          <p>
            <code>
              <strong>STD::RECURSIVE_TIMED_MUTEX::TRY_LOCK_FOR</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить объект <code>std::recursive_timed_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>bool try_lock_for(</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пытается захватить объект <code>std::recursive_timed_mutex</code> для текущего потока в течение времени, заданного аргументом <code>relative_time</code>. Если <code>relative_time.count()</code> равно нулю или отрицательно, то функция возвращается немедленно, как если бы это был вызов <code>try_lock()</code>. В противном случае вызывающий поток приостанавливается до получения мьютекса или до истечения времени, заданного аргументом <code>relative_time</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызывающий поток захватил мьютекс, иначе <code>false</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен вызывающим потоком, если функция вернула <code>true</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Если вызывающий поток уже удерживал <code>*this</code>, то функция возвращает <code>true</code>, и счетчик захватов <code>*this</code> текущим потоком увеличивается на единицу. Если текущий поток не удерживал <code>*this</code>, то функция может не захватить мьютекс (и вернуть <code>false</code>), даже если никакой другой поток не удерживает <code>*this</code>. Поток может быть блокирован дольше, чем указано. Если возможно, истекшее время измеряется по стабильным часам.</p>
          </cite>
          <p>
            <code>
              <strong>STD::RECURSIVE_TIMED_MUTEX::TRY_LOCK_UNTIL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить объект <code>std::recursive_timed_mutex</code> для текущего потока.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>bool try_lock_until(</code>
          </p>
          <p>
            <code> std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пытается захватить объект <code>std::recursive_timed_mutex</code> для текущего потока, пока не наступит момент времени, заданный аргументом <code>absolute_time</code>. Если в момент вызова <code>absolute_time &lt;= Clock::now()</code>, то функция возвращается немедленно, как если бы это был вызов <code>try_lock()</code>. В противном случае вызывающий поток приостанавливается до получения мьютекса или до наступления момента времени, большего или равного <code>absolute_time</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызывающий поток захватил мьютекс, иначе <code>false</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> захвачен вызывающим потоком, если функция вернула <code>true</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Если вызывающий поток уже удерживал <code>*this</code>, то функция возвращает <code>true</code>, и счетчик захватов <code>*this</code> текущим потоком увеличивается на единицу. Если текущий поток не удерживал <code>*this</code>, то функция может не захватить мьютекс (и вернуть <code>false</code>), даже если никакой другой поток не удерживает <code>*this</code>. Не дается никаких гарантий относительно того, сколько времени будет блокирован вызывающий поток. Гарантируется лишь, что если функция вернула <code>false</code>, то значение, возвращенное <code>Clock::now()</code>, больше или равно <code>absolute_time</code> в точке, где поток разблокировался.</p>
          </cite>
          <p>
            <code>
              <strong>STD::RECURSIVE_TIMED_MUTEX::UNLOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Освобождает объект <code>std::recursive_timed_mutex</code>, удерживаемый текущим потоком.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void unlock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток должен удерживать мьютекс <code>*this</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Освобождает мьютекс <code>*this</code>, удерживаемый текущим потоком. Если это последний захват <code>*this</code> данным потоком, и другие потоки были блокированы в ожидании <code>*this</code>, то один из них разблокируется.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Количество захватов <code>*this</code> вызывающим потоком, уменьшается на единицу.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
        </section>
        <section>
          <title>
            <p>D.5.5. Шаблон класса <code>std::lock_guard</code></p>
          </title>
          <p>Шаблон класса <code>std::lock_guard</code> предоставляет простую обертку владения блокировкой. Тип блокируемого мьютекса задается параметром шаблона <code>Mutex</code> и должен удовлетворять требованиям концепции <code>Lockable</code>. Заданный мьютекс захватывается в конструкторе и освобождается в деструкторе. Тем самым мы получаем простое средство захвата мьютекса в некотором блоке кода, которое гарантирует освобождение мьютекса при выходе из блока вне зависимости от того, как этот выход произведен: по достижении закрывающей скобки, в результате предложения, меняющего поток управления, например <code>break</code> или <code>return</code>, или вследствие исключения.</p>
          <p>Экземпляры <code>std::lock_guard</code> не удовлетворяют требованиям концепций <code>MoveConstructible</code>, <code>CopyConstructible</code> и <code>CopyAssignable</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class Mutex&gt;</code>
          </p>
          <p>
            <code>class lock_guard {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> typedef Mutex mutex_type;</code>
          </p>
          <empty-line/>
          <p>
            <code> explicit lock_guard(mutex_type&amp; m);</code>
          </p>
          <p>
            <code> lock_guard(mutex_type&amp; m, adopt_lock_t);</code>
          </p>
          <p>
            <code> ~lock_guard();</code>
          </p>
          <empty-line/>
          <p>
            <code> lock_guard(lock_guard const&amp;) = delete;</code>
          </p>
          <p>
            <code> lock_guard&amp; operator=(lock_guard const&amp;) = delete;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::LOCK_GUARD</strong>
            </code>
            <strong>, ЗАХВАТЫВАЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует экземпляр <code>std::lock_guard</code>, который захватывает указанный мьютекс.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>explicit lock_guard(mutex_type&amp; m);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::lock_guard</code>, который ссылается на указанный мьютекс. Вызывает <code>m.lock()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбуждаемое <code>m.lock()</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> владеет блокировкой <code>m</code>.</p>
          <p>
            <code>
              <strong>STD::LOCK_GUARD</strong>
            </code>
            <strong>, КОНСТРУКТОР, ПЕРЕНИМАЮЩИЙ БЛОКИРОВКУ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::lock_guard</code>, который владеет блокировкой указанного мьютекса.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>lock_guard(mutex_type&amp; m, std::adopt_lock_t);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток должен владеть блокировкой <code>m</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::lock_guard</code>, который ссылается на указанный мьютекс и принимает владение блокировкой <code>m</code>, удерживаемой вызывающим потоком.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>*this</code> владеет блокировкой <code>m</code>, удерживаемой вызывающим потоком.</p>
          <p>
            <code>
              <strong>STD::LOCK_GUARD</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает экземпляр <code>std::lock_guard</code> и освобождает соответствующий мьютекс.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~lock_guard();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вызывает <code>m.unlock()</code> для мьютекса <code>m</code>, заданного при конструировании <code>*this</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
        </section>
        <section>
          <title>
            <p>D.5.6. Шаблон класса <code>std::unique_lock</code></p>
          </title>
          <p>Шаблон класса <code>std::unique_lock</code> предоставляет более общую обертку владения блокировкой, чем <code>std::lock_guard</code>. Тип блокируемого мьютекса задается параметром шаблона <code>Mutex</code> и должен удовлетворять требованиям концепции <code>BasicLockable</code>. Вообще говоря, заданный мьютекс захватывается в конструкторе и освобождается в деструкторе, хотя имеются также дополнительные конструкторы и функции-члены, предлагающие другие возможности. Тем самым мы получаем средство захвата мьютекса в некотором блоке кода, которое гарантирует освобождение мьютекса при выходе из блока вне зависимости от того, как этот выход произведен: по достижении закрывающей скобки, в результате предложения, меняющего поток управления, например <code>break</code> или <code>return</code>, или вследствие исключения.</p>
          <p>Функции ожидания в классе <code>std::condition_variable</code> требуют объекта <code>std::unique_lock&lt;std::mutex&gt;</code>, и любая конкретизация шаблона <code>std::unique_lock</code> может быть использована в качестве параметра типа <code>Lockable</code> в любом варианте функции <code>wait</code> из класса <code>std::condition_variable_any</code>.</p>
          <p>Если тип <code>Mutex</code> удовлетворяет требованиям концепции <code>Lockable</code>, то им удовлетворяет и тип <code>std::unique_lock&lt;Mutex&gt;</code>. Если, кроме того, тип <code>Mutex</code> удовлетворяет требованиям концепции <code>TimedLockable</code>, то им удовлетворяет и тип <code>std::unique_lock&lt;Mutex&gt;</code>.</p>
          <p>Экземпляры <code>std::unique_lock</code> удовлетворяют требованиям концепций <code>MoveConstructible</code> и <code>MoveAssignable</code>, но не <code>CopyConstructible</code> и <code>CopyAssignable</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class Mutex&gt;</code>
          </p>
          <p>
            <code>class unique_lock {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> typedef Mutex mutex_type;</code>
          </p>
          <empty-line/>
          <p>
            <code> unique_lock() noexcept;</code>
          </p>
          <p>
            <code> explicit unique_lock(mutex_type&amp; m);</code>
          </p>
          <p>
            <code> unique_lock(mutex_type&amp; m, adopt_lock_t);</code>
          </p>
          <p>
            <code> unique_lock(mutex_type&amp; m, defer_lock_t) noexcept;</code>
          </p>
          <p>
            <code> unique_lock(mutex_type&amp; m, try_to_lock_t);</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code> unique_lock(</code>
          </p>
          <p>
            <code>  mutex_type&amp; m,</code>
          </p>
          <p>
            <code>  std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code> unique_lock(</code>
          </p>
          <p>
            <code>  mutex_type&amp; m,</code>
          </p>
          <p>
            <code>  std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <empty-line/>
          <p>
            <code> ~unique_lock();</code>
          </p>
          <p>
            <code> unique_lock(unique_lock const&amp;) = delete;</code>
          </p>
          <p>
            <code> unique_lock&amp; operator=(unique_lock const&amp;) = delete;</code>
          </p>
          <empty-line/>
          <p>
            <code> unique_lock(unique_lock&amp;&amp;);</code>
          </p>
          <p>
            <code> unique_lock&amp; operator=(unique_lock&amp;&amp;);</code>
          </p>
          <empty-line/>
          <p>
            <code> void swap(unique_lock&amp; other) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> void lock();</code>
          </p>
          <p>
            <code> bool try_lock();</code>
          </p>
          <p>
            <code> template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code> bool try_lock_for(</code>
          </p>
          <p>
            <code>  std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <p>
            <code> template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code> bool try_lock_until(</code>
          </p>
          <p>
            <code>  std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <code> void unlock();</code>
          </p>
          <empty-line/>
          <p>
            <code> explicit operator bool() const noexcept;</code>
          </p>
          <p>
            <code> bool owns_lock() const noexcept;</code>
          </p>
          <p>
            <code> Mutex* mutex() const noexcept;</code>
          </p>
          <p>
            <code> Mutex* release() noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, с которым не ассоциирован мьютекс.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>unique_lock() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, с которым не ассоциирован мьютекс.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;mutex() == NULL</code>, <code>this-&gt;owns_lock() == false</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, ЗАХВАТЫВАЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, который захватывает указанный мьютекс.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>explicit unique_lock(mutex_type&amp; m);</code>
          </p>
          <p>Результат</p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, который ссылается на указанный мьютекс. <code>Вызывает m.lock()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбуждаемое <code>m.lock()</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;owns_lock() == true</code>, <code>this-&gt;mutex() == &amp;m</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, КОНСТРУКТОР, ПЕРЕНИМАЮЩИЙ БЛОКИРОВКУ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, который владеет блокировкой указанного мьютекса.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>unique_lock(mutex_type&amp; m, std::adopt_lock_t);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Вызывающий поток должен владеть блокировкой <code>m</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, который ссылается на указанный мьютекс и принимает владение блокировкой <code>m</code>, удерживаемой вызывающим потоком.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;owns_lock() == true</code>, <code>this-&gt;mutex() == &amp;m</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, КОНСТРУКТОР ОТЛОЖЕННОЙ БЛОКИРОВКИ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, который не владеет блокировкой указанного мьютекса.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>unique_lock(mutex_type&amp; m, std::defer_lock_t) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, который ссылается на указанный мьютекс.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;owns_lock() == false</code>, <code>this-&gt;mutex() == &amp;m</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, КОНСТРУКТОР ПРОБНОЙ БЛОКИРОВКИ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, ассоциированный с указанным мьютексом, и пытается захватить этот мьютекс.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>unique_lock(mutex_type&amp; m, std::try_to_lock_t);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Тип <code>Mutex</code>, которым конкретизирован шаблон <code>std::unique_lock</code>, должен удовлетворять требованиям концепции <code>Lockable</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, который ссылается на указанный мьютекс. Вызывает <code>m.try_lock()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;owns_lock()</code> возвращает результат вызова <code>m.try_lock()</code>, <code>this-&gt;mutex() == &amp;m</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, КОНСТРУКТОР ПРОБНОЙ БЛОКИРОВКИ С ОТНОСИТЕЛЬНЫМ ТАЙМАУТОМ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, ассоциированный с указанным мьютексом, и пытается захватить этот мьютекс.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>unique_lock(</code>
          </p>
          <p>
            <code> mutex_type&amp; m,</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Тип <code>Mutex</code>, которым конкретизирован шаблон <code>std::unique_lock</code>, должен удовлетворять требованиям концепции <code>TimedLockable</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, который ссылается на указанный мьютекс. Вызывает <code>m.try_lock_for(relative_time)</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;owns_lock()</code> возвращает результат вызова <code>m.try_lock_for()</code>, <code>this-&gt;mutex() == &amp;m</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, КОНСТРУКТОР ПРОБНОЙ БЛОКИРОВКИ С АБСОЛЮТНЫМ ТАЙМАУТОМ</strong>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, ассоциированный с указанным мьютексом, и пытается захватить этот мьютекс.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>unique_lock(</code>
          </p>
          <p>
            <code> mutex_type&amp; m,</code>
          </p>
          <p>
            <code> std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Тип <code>Mutex</code>, которым конкретизирован шаблон <code>std::unique_lock</code>, должен удовлетворять требованиям концепции <code>TimedLockable</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>, который ссылается на указанный мьютекс. Вызывает <code>m.try_lock_until(relative_time)</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;owns_lock()</code> возвращает результат вызова <code>m.try_lock_until()</code>, <code>this-&gt;mutex() == &amp;m</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Передает владение блокировкой от существующего объекта <code>std::unique_lock</code> вновь сконструированному.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>unique_lock(unique_lock&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::unique_lock</code>. Если объект <code>other</code> владел блокировкой мьютекса до вызова конструктора, то теперь этой блокировкой владеет вновь сконструированный объект <code>std::unique_lock</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Для вновь сконструированного объекта <code>std::unique_lock x</code>, <code>x.mutex()</code> равно значению <code>other.mutex()</code> до вызова конструктора, а <code>x.owns_lock()</code> равно значению <code>other.owns_lock()</code> до вызова конструктора. <code>other.mutex() == NULL</code>, <code>other.owns_lock() == false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Объекты <code>std::unique_lock</code> не удовлетворяют требованиям концепции <code>CopyConstructible</code>, поэтому копирующего конструктора не существует, существует только этот перемещающий конструктор.</p>
          </cite>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Передает владение блокировкой от одного объекта <code>std: :unique_ lock</code> другому.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>unique_lock&amp; operator=(unique_lock&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если <code>this-&gt;owns_lock()</code> возвращала <code>true</code> до вызова этого оператора, то вызывает <code>this-&gt;unlock()</code>. Если объект <code>other</code> владел блокировкой мьютекса до присваивания, то теперь этой блокировкой владеет <code>*this</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this.mutex()</code> равно значению <code>other.mutex()</code> до присваивания, а <code>this.owns_lock()</code> равно значению <code>other.owns_lock()</code> до присваивания. <code>other.mutex() == NULL</code>, <code>other.owns_lock() == false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Объекты <code>std::unique_lock</code> не удовлетворяют требованиям концепции <code>CopyAssignable</code>, поэтому копирующего оператора присваивания не существует, существует только этот перемещающий оператор присваивания.</p>
          </cite>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает экземпляр <code>std::unique_lock</code> и освобождает соответствующий мьютекс, если им владел уничтоженный экземпляр.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~unique_lock();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если <code>this-&gt;owns_lock()</code> возвращает <code>true</code>, то вызывает <code>this-&gt;mutex()-&gt;unlock()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::SWAP</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Обменивает владение ассоциированными блокировками мьютекса между двумя объектами <code>std::unique_lock</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void swap(unique_lock&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если <code>other</code> владел блокировкой мьютекса до вызова, то теперь этой блокировкой владеет <code>*this</code>. Если <code>*this</code> владел блокировкой мьютекса до вызова, то теперь этой блокировкой владеет <code>other</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this.mutex()</code> равно значению <code>other.mutex()</code> до вызова, <code>other.mutex()</code> равно значению <code>this.mutex()</code> до вызова, <code>this.owns_lock()</code> равно значению <code>other.owns_lock()</code> до вызова, <code>other.owns_lock()</code> равно значению <code>this.owns_lock()</code> до вызова.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::SWAP</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Обменивает владение ассоциированными блокировками мьютекса между двумя объектами <code>std::unique_lock</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void swap(unique_lock&amp; lhs, unique_lock&amp; rhs) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>lhs.swap(rhs)</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Захватывает мьютекс, ассоциированный с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void lock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;mutex() != NULL</code>, <code>this-&gt;owns_lock() == false</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вызывает <code>this-&gt;mutex()-&gt;lock()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбужденное <code>this-&gt;mutex()-&gt;lock()</code>. Исключение типа <code>std::system_error</code> с кодом ошибки <code>std::errc::operation_not_permitted</code>, если <code>this-&gt;mutex() == NULL</code>. Исключение типа <code>std::system_error</code> с кодом ошибки <code>std::errc::resource_deadlock_would_occur</code>, если <code>this-&gt;owns_lock() == true</code> в момент вызова.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;owns_lock() == true</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::TRY_LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить мьютекс, ассоциированный с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool try_lock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Тип <code>Mutex</code>, которым конкретизируется шаблон <code>std::unique_lock</code>, должен удовлетворять требованиям концепции <code>Lockable</code>. <code>this-&gt;mutex() != NULL</code>, <code>this-&gt;owns_lock() == false</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вызывает <code>this-&gt;mutex ()-&gt;try_lock()</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызов <code>this-&gt;mutex()-&gt;try_lock()</code> вернул <code>true</code>, иначе <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбужденное <code>this-&gt;mutex()-&gt;try_lock()</code>. Исключение типа <code>std::system_error</code> с кодом ошибки <code>std::errc::operation_not_permitted</code>, если <code>this-&gt;mutex() == NULL</code>. Исключение типа <code>std::system_error</code> с кодом ошибки <code>std::errc::resource_deadlock_would_occur</code>, если <code>this-&gt;owns_lock() == true</code> в момент вызова.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Если функция возвращает <code>true</code>, то <code>this-&gt;owns_lock() == true</code>, иначе <code>this-&gt;owns_lock() == false</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::UNLOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Освобождает мьютекс, ассоциированный с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void unlock();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;mutex() != NULL</code>, <code>this-&gt;owns_lock() == true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вызывает <code>this-&gt;mutex()-&gt;unlock()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбужденное <code>this-&gt;mutex()-&gt;unlock()</code>. Исключение типа <code>std::system_error</code> с кодом ошибки <code>std::errc::operation_not_permitted</code>, если <code>this-&gt;owns_lock() == false</code> в момент вызова.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;owns_lock() == false</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::TRY_LOCK_FOR</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить мьютекс, ассоциированный с <code>*this</code>, в течение указанного времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>bool try_lock_for(</code>
          </p>
          <p>
            <code>std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Тип <code>Mutex</code>, которым конкретизируется шаблон <code>std::unique_lock</code>, должен удовлетворять требованиям концепции <code>TimedLockable</code>. <code>this-&gt;mutex() != NULL</code>, <code>this-&gt;owns_lock() == false</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вызывает <code>this-&gt;mutex ()-&gt;try_lock_for(relative_time)</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызов <code>this-&gt;mutex()-&gt;try_lock_for()</code> вернул <code>true</code>, иначе <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбужденное <code>this-&gt;mutex()-&gt;try_lock_for()</code>. Исключение типа <code>std::system_error</code> с кодом ошибки <code>std::errc::operation_not_permitted</code>, если <code>this-&gt;mutex() == NULL</code>. Исключение типа <code>std::system_error</code> с кодом ошибки <code>std::errc::resource_deadlock_would_occur</code>, если <code>this-&gt;owns_lock() == true</code> в момент вызова.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Если функция вернула <code>true</code>, то <code>this-&gt;owns_lock() == true</code>, иначе <code>this-&gt;owns_lock() == false</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::TRY_LOCK_UNTIL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Пытается захватить мьютекс, ассоциированный с <code>*this</code>, в течение указанного времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>bool try_lock_until(</code>
          </p>
          <p>
            <code>std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Тип <code>Mutex</code>, которым конкретизируется шаблон <code>std::unique_lock</code>, должен удовлетворять требованиям концепции <code>TimedLockable</code>. <code>this-&gt;mutex() != NULL</code>, <code>this-&gt;owns_lock() == false</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Вызывает <code>this-&gt;mutex()-&gt;try_lock_until(absolute_time)</code>.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если вызов <code>this-&gt;mutex()-&gt;try_lock_until()</code> вернул <code>true</code>, иначе <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбужденное <code>this-&gt;mutex()-&gt;try_lock_until()</code>. Исключение типа <code>std::system_error</code> с кодом ошибки <code>std::errc::operation_not_permitted</code>, если <code>this-&gt;mutex() == NULL</code>. Исключение типа <code>std::system_error</code> с кодом ошибки <code>std::errc::resource_deadlock_would_occur</code>, если <code>this-&gt;owns_lock() == true</code> в момент вызова.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Если функция вернула <code>true</code>, то <code>this-&gt;owns_lock() == true</code>, иначе <code>this-&gt;owns_lock() == false</code>.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::OPERATOR BOOL</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Проверяет, владеет ли <code>*this</code> блокировкой мьютекса.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>explicit operator bool() const noexcept;</code>
          </p>
          <p>Возвращаемое значение <code>this-&gt;owns_lock()</code>. <emphasis>Исключения</emphasis></p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Это оператор явного преобразования, поэтому он вызывается неявно только в контекстах, где результат используется как булевское значение, а не тогда, когда результат трактуется как целое, равное 0 или 1.</p>
          </cite>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::OWNS_LOCK</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Проверяет, владеет ли <code>*this</code> блокировкой мьютекса.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool owns_lock() const noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если <code>*this</code> владеет блокировкой мьютекса, иначе <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::MUTEX</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Возвращает мьютекс, ассоциированный с <code>*this</code>, если таковой имеется.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>mutex_type* mutex() const noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Указатель на мьютекс, ассоциированный с <code>*this</code>, если таковой имеется, иначе <code>NULL</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::UNIQUE_LOCK::RELEASE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Возвращает мьютекс, ассоциированный с <code>*this</code>, если таковой имеется, и разрывает эту ассоциацию.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>mutex_type* release() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Разрывает ассоциацию мьютекса с <code>*this</code>, не освобождая блокировку.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Указатель на мьютекс, ассоциированный с <code>*this</code>, если таковой имеется, иначе <code>NULL</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;mutex() == NULL</code>, <code>this-&gt;owns_lock() == false.</code></p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Если <code>this-&gt;owns_lock()</code> вернула бы до этого обращения <code>true</code>, то с этого момента за освобождение мьютекса отвечает вызывающая программа.</p>
          </cite>
        </section>
        <section>
          <title>
            <p>D.5.7. Шаблон функции <code>std::lock</code></p>
          </title>
          <p>Шаблон функции <code>std::lock</code> предоставляет возможность захватить сразу несколько мьютексов, не опасаясь возникновения взаимоблокировки из-за несогласованного порядка захвата.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename LockableType1, typename... LockableType2&gt;</code>
          </p>
          <p>
            <code>void lock(LockableType1&amp; m1, LockableType2&amp; m2...);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Типы параметров <code>LockableType1</code>, <code>LockableType2</code>, … должны удовлетворять требованиям концепции <code>Lockable</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Захватывает все объекты <code>m1</code>, <code>m2</code>, … допускающих блокировку типов, обращаясь к функциям-членам <code>lock()</code>, <code>try_lock()</code> и <code>unlock()</code> этих типов в порядке, который гарантированно не приводит к взаимоблокировкам, но в остальном не специфицирован.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Текущий поток захватывает все переданные в аргументах объекты.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбуждаемое обращениями к функциям <code>lock()</code>, <code>try_lock()</code> и <code>unlock()</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Если исключение распространяется за пределы <code>std::lock</code>, то для любого объекта <code>m1</code>, <code>m2</code>, …, для которого в результате обращения к <code>lock()</code> или <code>try_lock()</code> была успешно получена блокировка, гарантированно будет вызвана функция <code>unlock()</code>.</p>
          </cite>
        </section>
        <section>
          <title>
            <p>D.5.8. Шаблон функции <code>std::try_lock</code></p>
          </title>
          <p>Шаблон функции <code>std::try_lock</code> предоставляет возможность захватить сразу несколько допускающих блокировку объектов, так что либо захвачены все, либо ни один.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename LockableType1, typename... LockableType2&gt;</code>
          </p>
          <p>
            <code>int try_lock(LockableType1&amp; m1, LockableType2&amp; m2...);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Типы параметров <code>LockableType1</code>, <code>LockableType2</code>, … должны удовлетворять требованиям концепции <code>Lockable</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Пытается захватить все объекты <code>m1</code>, <code>m2</code>, … допускающих блокировку типов, обращаясь по очереди к функции <code>try_lock()</code> каждого из них. Если <code>try_lock()</code> вернёт <code>false</code> или возбудит исключение, то уже захваченные блокировки освобождаются путем вызова функции <code>unlock()</code> соответствующего объекта.</p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>-1, если были захвачены все блокировки (то есть все вызовы <code>try_lock()</code> вернули <code>true</code>), в противном случае начинающийся с нуля индекс объекта, для которого вызов <code>try_lock()</code> вернул <code>false</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Если функция вернула -1, то текущий поток захватил все переданные в аргументах объекты. В противном случае все объекты, которая функция успела захватить, освобождены.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Любое исключение, возбуждаемое обращениями к функции <code>try_lock</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Если исключение распространяется за пределы <code>std::try_lock</code>, то для любого объекта <code>m1</code>, <code>m2</code>, …, для которого в результате обращения к <code>try_lock()</code> была успешно получена блокировка, гарантированно будет вызвана функция <code>unlock()</code>.</p>
          </cite>
        </section>
        <section>
          <title>
            <p>D.5.9. Класс <code>std::once_flag</code></p>
          </title>
          <p>Экземпляры класса <code>std::once_flag</code> используются совместно с шаблоном функции <code>std::call_once</code> для гарантии того, что некая функция будет вызвала ровно один раз, даже если ее могут вызывать одновременно несколько потоков.</p>
          <p>Экземпляры <code>std::once_flag</code> не удовлетворяют требованиям концепций <code>CopyConstructible</code>, <code>CopyAssignable</code>, <code>MoveConstructible</code> и <code>MoveAssignable</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>struct once_flag {</code>
          </p>
          <p>
            <code> constexpr once_flag() noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> once_flag(once_flag const&amp;) = delete;</code>
          </p>
          <p>
            <code> once_flag&amp; operator=(once_flag const&amp;) = delete;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <code>
              <strong>STD::ONCE_FLAG</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Создает объект <code>std::once_flag</code> в состоянии, обозначающем, что ассоциированная функция еще не вызывалась.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>constexpr once_flag() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует новый экземпляр <code>std::once_flag</code>, оставляя его в состоянии, означающем, что ассоциированная функция еще не вызывалась. Поскольку в конструкторе присутствует квалификатор <code>constexpr</code>, то экземпляр со статическим временем жизни конструируется на этапе статической инициализации, что предотвращает состояние гонки и зависимость от порядка инициализации.</p>
        </section>
        <section>
          <title>
            <p>D.5.10. Шаблон функции <code>std::call_once</code></p>
          </title>
          <p>Шаблон функции <code>std::call_once</code> используется совместно с объектом <code>std::once_flag</code> для гарантии того, что некая функция будет вызвала ровно один раз, даже если ее могут вызывать одновременно несколько потоков.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Callable, typename... Args&gt;</code>
          </p>
          <p>
            <code>void call_once(</code>
          </p>
          <p>
            <code> std::once_flag&amp; flag, Callable func, Args args...);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p>Выражение <code>INVOKE(func, args)</code> допустимо для переданных значений <code>func</code> и <code>args</code>. Тип <code>Callable</code> и все члены <code>Args</code> удовлетворяют требованиям концепции <code>MoveConstructible</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Обращения к <code>std::call_once</code> с одним и тем же объектом <code>std::once_flag</code> сериализуются. Если раньше не было результативного обращения к <code>std::call_once</code> с данным объектом <code>std::once_flag</code>, то аргумент <code>func</code> (или его копия) вызывается так, будто имело место обращение к <code>INVOKE(func, args)</code>, причем вызов <code>std::call_once</code> считается результативным тогда и только тогда, когда вызов <code>func</code> завершился без возбуждения исключения. Если имело место исключение, то оно передается вызывающей программе. Если ранее уже было результативное обращение к <code>std::call_once</code> с данным объектом <code>std::once_flag</code>, то новый вызов <code>std::call_once</code> возвращает управление, не вызывая <code>func</code>.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Возврат из результативного вызова <code>std::call_once</code> с объектом <code>std::once_flag</code> происходит-раньше всех последующих вызовов <code>std::call_once</code> с тем же объектом <code>std::once_flag</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если желаемого эффекта добиться не удалось, или любое исключение, возбужденное при обращении к <code>func</code>.</p>
        </section>
      </section>
      <section>
        <title>
          <p>D.6. Заголовок <code>&lt;ratio&gt;</code></p>
        </title>
        <section>
          <p>В заголовке <code>&lt;ratio&gt;</code> объявлены средства для поддержки арифметических операций с рациональными числами на этапе компиляции.</p>
          <p>
            <emphasis>Содержимое заголовка</emphasis>
          </p>
          <p>
            <code>namespace std {</code>
          </p>
          <p>
            <code>template&lt;intmax_t N, intmax_t D=1&gt;</code>
          </p>
          <p>
            <code>class ratio;</code>
          </p>
          <empty-line/>
          <p>
            <code>// арифметические операции с рациональными числами</code>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>using ratio_add = <emphasis>см. описание</emphasis>;</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>using ratio_subtract = <emphasis>см. описани</emphasis>е;</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>using ratio_multiply = <emphasis>см. описание</emphasis>;</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class Rl, class R2&gt;</code>
          </p>
          <p>
            <code>using ratio_divide = <emphasis>см. описание</emphasis>;</code>
          </p>
          <empty-line/>
          <p>
            <code>// сравнение рациональных чисел</code>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>struct ratio_equal;</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>struct ratio_not_equal;</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>struct ratio_less;</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>struct ratio_less_equal;</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>struct ratio_greater;</code>
          </p>
          <empty-line/>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>struct ratio_greater_equal;</code>
          </p>
          <empty-line/>
          <p>
            <code>typedef ratio&lt;1, 1000000000000000000&gt; atto;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1, 1000000000000000&gt; femto;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1, 1000000000000&gt; pico;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1, 1000000000&gt; nano;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1, 1000000&gt; micro;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1, 1000&gt; milli;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1, 100&gt; centi;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1, 10&gt; deci;</code>
          </p>
          <p>
            <code>typedef ratio&lt;10, 1&gt; deca;</code>
          </p>
          <p>
            <code>typedef ratio&lt;100, 1&gt; hecto;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1000, 1&gt; kilo;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1000000, 1&gt; mega;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1000000000, 1&gt; giga;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1000000000000, 1&gt; tera;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1000000000000000, 1&gt; peta;</code>
          </p>
          <p>
            <code>typedef ratio&lt;1000000000000000000, 1&gt; exa;</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.6.1. Шаблон класса <code>std::ratio</code></p>
          </title>
          <p>Шаблон класса <code>&lt;std::ratio&gt;</code> предоставляет механизм для выполнения на этапе компиляции арифметических операций с рациональными числами, например: деления пополам (<code>std::ratio&lt;1, 2&gt;</code>), нахождения двух третей (<code>std::ratio&lt;2, 3&gt;</code>) пятнадцати сорок третьих (<code>std::ratio&lt;15, 43&gt;</code>). В стандартной библиотеке С++ этот шаблон используется для задания периода при конкретизации шаблона класса <code>std::chrono::duration</code>.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;intmax_t N, intmax_t D = 1&gt;</code>
          </p>
          <p>
            <code>class ratio {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> typedef ratio&lt;num, den&gt; type;</code>
          </p>
          <empty-line/>
          <p>
            <code> static constexpr intmax_t num = <emphasis>см. ниже</emphasis>;</code>
          </p>
          <p>
            <code> static constexpr intmax_t den = <emphasis>см. ниже</emphasis>;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <p>
            <emphasis>Требования</emphasis>
          </p>
          <p><code>D</code> не может быть равно нулю.</p>
          <p>
            <emphasis>Описание</emphasis>
          </p>
          <p><code>num</code> и <code>den</code> — соответственно числитель и знаменатель дроби <code>N/D</code> после сокращения без общих множителей. Значение <code>den</code> всегда положительно. Если <code>N</code> и <code>D</code> одного знака, то <code>num</code> положительно, иначе <code>num</code> отрицательно.</p>
          <p>
            <emphasis>Примеры</emphasis>
          </p>
          <p>
            <code>ratio&lt;4,6&gt;::num == 2</code>
          </p>
          <p>
            <code>ratio&lt;4,6&gt;::den == 3</code>
          </p>
          <p>
            <code>ratio&lt;4,-6&gt;::num == -2</code>
          </p>
          <p>
            <code>ratio&lt;4,-6&gt;::den == 3</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.6.2. Псевдоним шаблона <code>std::ratio_add</code></p>
          </title>
          <p>Псевдоним шаблона <code>std::ratio_add</code> предоставляет механизм сложения двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>using ratio_add = std::ratio&lt;<emphasis>см. ниже</emphasis>&gt;;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p><code>ratio_add&lt;R1,R2&gt;</code> определяется как псевдоним конкретизации <code>std::ratio</code>, представляющий сумму дробей, представленных параметрами <code>R1</code> и <code>R2</code>, если эту сумму можно вычислить без переполнения. Если при вычислении возникает переполнение, то программа считается некорректной. В отсутствии переполнения <code>std::ratio_add&lt;R1, R2&gt;</code> будет иметь такие же значения <code>num</code> и <code>den</code>, как в конкретизации <code>std::ratio&lt;R1::num * R2::den + R2::num * R1::den, R1::den * R2::den&gt;</code>.</p>
          <p>
            <emphasis>Примеры</emphasis>
          </p>
          <p>
            <code>std::ratio_add&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;2,5&gt; &gt;::num == 11</code>
          </p>
          <p>
            <code>std::ratio_add&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;2,5&gt; &gt;::den == 15</code>
          </p>
          <p>
            <code>std::ratio_add&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;7,6&gt; &gt;::num == 3</code>
          </p>
          <p>
            <code>std::ratio_add&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;7,6&gt; &gt;::den == 2</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.6.3. Псевдоним шаблона <code>std::ratio_subtract</code></p>
          </title>
          <p>Псевдоним шаблона <code>std::ratio_subtract</code> предоставляет механизм вычитания двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>using ratio_subtract = std::ratio&lt;с<emphasis>м. ниже</emphasis>&gt;;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p><code>ratio_subtract&lt;R1, R2&gt;</code> определяется как псевдоним конкретизации <code>std::ratio</code>, представляющий разность дробей, представленных параметрами <code>R1</code> и <code>R2</code>, если эту разность можно вычислить без переполнения. Если при вычислении возникает переполнение, то программа считается некорректной. В отсутствии переполнения <code>std::ratio_subtract&lt;R1, R2&gt;</code> будет иметь такие же значения <code>num</code> и <code>den</code>, как в конкретизации <code>std::ratio&lt;R1::num * R2::den - R2::num * R1::den, R1::den * R2::den&gt;</code>.</p>
          <p>
            <emphasis>Примеры</emphasis>
          </p>
          <p>
            <code>std::ratio_subtract&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;1,5&gt; &gt;::num == 2</code>
          </p>
          <p>
            <code>std::ratio_subtract&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;1,5&gt; &gt;::den == 15</code>
          </p>
          <p>
            <code>std::ratio_subtract&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;7,6&gt; &gt;::num == -5</code>
          </p>
          <p>
            <code>std::ratio_subtract&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;7,6&gt; &gt;::den == 6</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.6.4. Псевдоним шаблона <code>std::ratio_multiply</code></p>
          </title>
          <p>Псевдоним шаблона <code>std::ratio_multiply</code> предоставляет механизм умножения двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>using ratio_multiply = std::ratio&lt;<emphasis>см. ниже</emphasis>&gt;;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p><code>ratio_multiply&lt;R1, R2&gt;</code> определяется как псевдоним конкретизации <code>std::ratio</code>, представляющий произведение дробей, представленных параметрами <code>R1</code> и <code>R2</code>, если это произведение можно вычислить без переполнения. Если при вычислении возникает переполнение, то программа считается некорректной. В отсутствии переполнения <code>std::ratio_multiply&lt;R1, R2&gt;</code> будет иметь такие же значения <code>num</code> и <code>den</code>, как в конкретизации <code>std::ratio&lt;R1::num * R2::num, R1::den * R2::den&gt;</code>.</p>
          <p>
            <emphasis>Примеры</emphasis>
          </p>
          <p>
            <code>std::ratio_multiply&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;2,5&gt; &gt;::num == 2</code>
          </p>
          <p>
            <code>std::ratio_multiply&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;2,5&gt; &gt;::den == 15</code>
          </p>
          <p>
            <code>std::ratio_multiply&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;15,7&gt; &gt;::num == 5</code>
          </p>
          <p>
            <code>std::ratio_multiply&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;15,7&gt; &gt;::den == 7</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.6.5. Псевдоним шаблона <code>std::ratio_divide</code></p>
          </title>
          <p>Псевдоним шаблона <code>std::ratio_divide</code> предоставляет механизм деления двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>using ratio_divide = std::ratio&lt;<emphasis>см. ниже</emphasis>&gt;;</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p><code>ratio_divide&lt;R1, R2&gt;</code> определяется как псевдоним конкретизации <code>std::ratio</code>, представляющий частное дробей, представленных параметрами <code>R1</code> и <code>R2</code>, если это частное можно вычислить без переполнения. Если при вычислении возникает переполнение, то программа считается некорректной. В отсутствии переполнения <code>std::ratio_divide&lt;R1, R2&gt;</code> будет иметь такие же значения <code>num</code> и <code>den</code>, как в конкретизации <code>std::ratio&lt;R1::num * R2::den, R1::den * R2::num&gt;</code>.</p>
          <p>
            <emphasis>Примеры</emphasis>
          </p>
          <p>
            <code>std::ratio_divide&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;2,5&gt; &gt;::num == 5</code>
          </p>
          <p>
            <code>std::ratio_divide&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;2,5&gt; &gt;::den == 6</code>
          </p>
          <p>
            <code>std::ratio_divide&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;15,7&gt; &gt;::num == 7</code>
          </p>
          <p>
            <code>std::ratio_divide&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;15,7&gt; &gt;::den == 45</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.6.6. Шаблон класса <code>std::ratio_equal</code></p>
          </title>
          <p>Шаблон класса <code>std::ratio_equal</code> предоставляет механизм сравнения двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>class ratio_equal:</code>
          </p>
          <p>
            <code> public std::integral_constant&lt;</code>
          </p>
          <p>
            <code>  bool, (R1::num == R2::num) &amp;&amp; (R1::den == R2::den)&gt; {};</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
          <p>
            <emphasis>Примеры</emphasis>
          </p>
          <p>
            <code>std::ratio_equal&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;2,6&gt; &gt;::value</code>
          </p>
          <p>
            <code> == true</code>
          </p>
          <p>
            <code>std::ratio_equal&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;1,6&gt; &gt;::value</code>
          </p>
          <p>
            <code> == false</code>
          </p>
          <p>
            <code>std::ratio_equal&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;2,3&gt; &gt;::value</code>
          </p>
          <p>
            <code> == false</code>
          </p>
          <p>
            <code>std::ratio_equal&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;1,3&gt; &gt;::value</code>
          </p>
          <p>
            <code> == true</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.6.7. Шаблон класса <code>std::ratio_not_equal</code></p>
          </title>
          <p>Шаблон класса <code>std::ratio_not_equal</code> предоставляет механизм сравнения двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>class ratio_not_equal:</code>
          </p>
          <p>
            <code> public std::integral_constant&lt;</code>
          </p>
          <p>
            <code>  bool, !ratio_equal&lt;R1,R2&gt;::value&gt; {};</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
          <p>
            <emphasis>Примеры</emphasis>
          </p>
          <p>
            <code>std::ratio_not_equal&lt;</code>
          </p>
          <p>
            <code> std::ratio&lt;1,3&gt;, std::ratio&lt;2,6&gt; &gt;::value == false</code>
          </p>
          <p>
            <code>std::ratio_not_equal&lt;</code>
          </p>
          <p>
            <code> std::ratio&lt;1,3&gt;, std::ratio&lt;1,6&gt; &gt;::value == true</code>
          </p>
          <p>
            <code>std::ratio_not_equal&lt;</code>
          </p>
          <p>
            <code> std::ratio&lt;1,3&gt;, std::ratio&lt;2,3&gt; &gt;::value == true</code>
          </p>
          <p>
            <code>std::ratio_not_equal&lt;</code>
          </p>
          <p>
            <code> std::ratio&lt;1,3&gt;, std::ratio&lt;1,3&gt; &gt;::value == false</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.6.8. Шаблон класса <code>std::ratio_less</code></p>
          </title>
          <p>Шаблон класса <code>std::ratio_less</code> предоставляет механизм сравнения двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>class ratio_less:</code>
          </p>
          <p>
            <code> public std::integral_constant&lt;bool, <emphasis>см. ниже</emphasis>&gt; {};</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p><code>std::ratio_less&lt;R1,R2&gt;</code> наследует шаблону <code>std::integral_constant&lt;bool, value&gt;</code>, где <code>value</code> — это <code>(R1::num*R2::den) &lt; (R2::num*R1::den)</code>. Если возможно, реализация должна использовать такой метод вычисления результата, при котором не возникает переполнения. Если при вычислении возникает переполнение, то программа считается некорректной.</p>
          <p>
            <emphasis>Примеры</emphasis>
          </p>
          <p>
            <code>std::ratio_less&lt;std::ratio&lt;1,3&gt;, std::ratio&lt;2,6&gt; &gt;::value</code>
          </p>
          <p>
            <code> == false</code>
          </p>
          <p>
            <code>std::ratio_less&lt;std::ratio&lt;1,6&gt;, std::ratio&lt;1,3&gt; &gt;::value</code>
          </p>
          <p>
            <code> == true</code>
          </p>
          <p>
            <code>std::ratio_less&lt;</code>
          </p>
          <p>
            <code> std::ratio&lt;999999999,1000000000&gt;,</code>
          </p>
          <p>
            <code> std::ratio&lt;1000000001,1000000000&gt; &gt;::value == true</code>
          </p>
          <p>
            <code>std::ratio_less&lt;</code>
          </p>
          <p>
            <code> std::ratio&lt;1000000001,1000000000&gt;,</code>
          </p>
          <p>
            <code> std::ratio&lt;999999999,1000000000&gt; &gt;::value == false</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.6.9. Шаблон класса <code>std::ratio_greater</code></p>
          </title>
          <p>Шаблон класса <code>std::ratio_greater</code> предоставляет механизм сравнения двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>class ratio_greater:</code>
          </p>
          <p>
            <code> public std::integral_constant&lt;</code>
          </p>
          <p>
            <code>  bool, ratio_less&lt;R2, R1&gt;::value&gt; {};</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
        </section>
        <section>
          <title>
            <p>D.6.10. Шаблон класса <code>std::ratio_less_equal</code></p>
          </title>
          <p>Шаблон класса <code>std::ratio_less_equal</code> предоставляет механизм сравнения двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>class ratio_less_equal:</code>
          </p>
          <p>
            <code> public std::integral_constant&lt;</code>
          </p>
          <p>
            <code>  bool, !ratio_less&lt;R2, R1&gt;::value&gt; {};</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
        </section>
        <section>
          <title>
            <p>D.6.11. Шаблон класса <code>std::ratio_greater_equal</code></p>
          </title>
          <p>Шаблон класса <code>std::ratio_greater_equal</code> предоставляет механизм сравнения двух значений <code>std::ratio</code> на этапе компиляции с применением правил арифметических операций с рациональными числами.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>template &lt;class R1, class R2&gt;</code>
          </p>
          <p>
            <code>class ratio_greater_equal:</code>
          </p>
          <p>
            <code> public std::integral_constant&lt;</code>
          </p>
          <p>
            <code>  bool, !ratio_less&lt;R1,R2&gt;::value&gt; {};</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>R1</code> и <code>R2</code> должны быть конкретизациями шаблона <code>std::ratio</code>.</p>
        </section>
      </section>
      <section>
        <title>
          <p>D.7. Заголовок <code>&lt;thread&gt;</code></p>
        </title>
        <section>
          <p>В заголовке <code>&lt;thread&gt;</code> объявлены средства для идентификации и управления потоками, а также функции для приостановки потоков.</p>
          <p>
            <emphasis>Содержимое заголовка</emphasis>
          </p>
          <p>
            <code>namespace std {</code>
          </p>
          <empty-line/>
          <p>
            <code>class thread;</code>
          </p>
          <empty-line/>
          <p>
            <code>namespace this_thread {</code>
          </p>
          <p>
            <code>thread::id get_id() noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>void yield() noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>void sleep_for(</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; sleep_duration);</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>void sleep_until(</code>
          </p>
          <p>
            <code> std::chrono::time_point&lt;Clock, Duration&gt; wake_time);</code>
          </p>
          <p>
            <code>}</code>
          </p>
          <p>
            <code>}</code>
          </p>
        </section>
        <section>
          <title>
            <p>D.7.1. Класс <code>std::thread</code></p>
          </title>
          <p>Класс s<code>td::thread</code> применяется для управления потоком выполнения. В нем имеются средства для запуска нового потока и ожидания завершения потока, а также для идентификации потоков. Также в класс включены другие функции для управления потоком выполнения.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class thread {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> // Типы</code>
          </p>
          <p>
            <code> class id;</code>
          </p>
          <p>
            <code> typedef <emphasis>implementation-defined</emphasis></code>
          </p>
          <p>
            <code> native_handle_type; // необязательно</code>
          </p>
          <empty-line/>
          <p>
            <code> // Конструкторы и деструкторы</code>
          </p>
          <p>
            <code> thread() noexcept;</code>
          </p>
          <p>
            <code> ~thread();</code>
          </p>
          <empty-line/>
          <p>
            <code> template&lt;typename Callable, typename Args...&gt;</code>
          </p>
          <p>
            <code> explicit thread(Callable&amp;&amp; func, Args&amp;&amp;... args);</code>
          </p>
          <empty-line/>
          <p>
            <code> // Копирование и перемещение</code>
          </p>
          <p>
            <code> thread(thread const&amp; other) = delete;</code>
          </p>
          <p>
            <code> thread(thread&amp;&amp; other) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> thread&amp; operator=(thread const&amp; other) = delete;</code>
          </p>
          <p>
            <code> thread&amp; operator=(thread&amp;&amp; other) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> void swap(thread&amp; other) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> void join();</code>
          </p>
          <p>
            <code> void detach();</code>
          </p>
          <p>
            <code> bool joinable() const noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> id get_id() const noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code> native_handle_type native_handle();</code>
          </p>
          <empty-line/>
          <p>
            <code> static unsigned hardware_concurrency() noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>void swap(thread&amp; lhs, thread&amp; rhs);</code>
          </p>
          <p>
            <code>
              <strong>STD::THREAD::ID</strong>
            </code>
            <strong>, КЛАСС</strong>
          </p>
          <p>Экземпляр класса <code>std::thread::id</code> идентифицирует конкретный поток выполнения.</p>
          <p>
            <emphasis>Определение класса</emphasis>
          </p>
          <p>
            <code>class thread::id {</code>
          </p>
          <p>
            <code>public:</code>
          </p>
          <p>
            <code> id() noexcept;</code>
          </p>
          <p>
            <code>};</code>
          </p>
          <empty-line/>
          <p>
            <code>bool operator==(thread::id x, thread::id y) noexcept;</code>
          </p>
          <p>
            <code>bool operator!=(thread::id x, thread::id y) noexcept;</code>
          </p>
          <p>
            <code>bool operator&lt;(thread::id x, thread::id y) noexcept;</code>
          </p>
          <p>
            <code>bool operator&lt;=(thread::id x, thread::id y) noexcept;</code>
          </p>
          <p>
            <code>bool operator&gt;(thread::id x, thread::id y) noexcept;</code>
          </p>
          <p>
            <code>bool operator&gt;=(thread::id x, thread::id y) noexcept;</code>
          </p>
          <empty-line/>
          <p>
            <code>template&lt;typename charT, typename traits&gt;</code>
          </p>
          <p>
            <code>basic_ostream&lt;charT, traits&gt;&amp;</code>
          </p>
          <p>
            <code> operator&lt;&lt;(basic_ostream&lt;charT, traits&gt;&amp;&amp; out, thread::id id);</code>
          </p>
          <cite>
            <p><strong>Примечание</strong>. Значение <code>std::thread::id</code>, идентифицирующее конкретный поток выполнения, должно отличаться от значения экземпляра <code>std::thread::id,</code> сконструированного по умолчанию, и от значения, представляющего любой другой поток.</p>
          </cite>
          <cite>
            <p><strong>Примечание</strong>. Значения <code>std::thread::id</code> для конкретных потоков непредсказуемы и могут различаться при разных прогонах одной и той же программы.</p>
          </cite>
          <p>Экземпляры <code>std::thread::id</code> удовлетворяют требованиям концепций <code>CopyConstructible</code> и <code>CopyAssignable</code>, поэтому их можно копировать и присваивать друг другу</p>
          <p>
            <code>
              <strong>STD::THREAD::ID</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::thread::id</code>, который не представляет никакой поток выполнения.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>id() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::thread::id</code>, с которым связано особое значение, интерпретируемое как <emphasis>не поток</emphasis>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечания</strong>. Во всех сконструированных по умолчанию экземпляров <code>std::thread::id</code> хранится одно и то же значение.</p>
          </cite>
          <p>
            <code>
              <strong>STD::THREAD::ID</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ НА РАВЕНСТВО</strong>
          </p>
          <p>Сравнивает два экземпляра <code>std::thread::id</code>, проверяя, представляют ли они один и тот же поток.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool operator==(</code>
          </p>
          <p>
            <code> std::thread::id lhs, std::thread::id rhs) noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если <code>lhs</code> и <code>rhs</code> представляют один и тот же поток выполнения или оба имеют значение <emphasis>не поток</emphasis>, <code>false</code>, если <code>lhs</code> и <code>rhs</code> представляют разные потоки или один представляет поток, а другой имеет значение <emphasis>не поток</emphasis>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD::ID</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ НА НЕРАВЕНСТВО</strong>
          </p>
          <p>Сравнивает два экземпляра <code>std::thread::id</code>, проверяя, представляют ли они разные потоки.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool operator!=(</code>
          </p>
          <p>
            <code> std::thread::id lhs, std::thread::id rhs) noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>!(lhs==rhs)</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD::ID</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ МЕНЬШЕ</strong>
          </p>
          <p>Сравнивает два экземпляра <code>std::thread::id</code>, проверяя, предшествует ли один из них другому в смысле отношения полного порядка, существующего на множестве значений идентификаторов потоков.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool operator&lt;(</code>
          </p>
          <p>
            <code> std::thread::id lhs, std::thread::id rhs) noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если значение <code>lhs</code> предшествует значению <code>rhs</code> в смысле отношения полного порядка, существующего на множестве значений идентификаторов потоков. Если <code>lhs != rhs</code>, то истинно ровно одно из утверждений <code>lhs &lt; rhs</code> и <code>rhs &lt; lhs</code>, тогда как второе ложно. Если <code>lhs == rhs</code>, то оба утверждения <code>lhs &lt; rhs</code> и <code>rhs &lt; lhs</code> ложны.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Особое значение <emphasis>не поток</emphasis>, которое хранится в сконструированном по умолчанию экземпляре <code>std::thread::id</code>, меньше любого другого экземпляра <code>std::thread::id</code>, представляющего поток выполнения. Если два экземпляра <code>std::thread::id</code> равны, то ни один из них не меньше другого. Любое множество различных значений <code>std::thread::id</code> полностью упорядочено, и этот порядок остается непротиворечивым на всем протяжении работы программы. Порядок может изменяться при разных прогонах одной и той же программы.</p>
          </cite>
          <p>
            <code>
              <strong>STD::THREAD::ID</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ МЕНЬШЕ ИЛИ РАВНО</strong>
          </p>
          <p>Сравнивает два экземпляра <code>std::thread::id</code>, проверяя, предшествует ли один из них другому в смысле отношения полного порядка, существующего на множестве значений идентификаторов потоков, или оба экземпляра совпадают.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool operator&lt;=(</code>
          </p>
          <p>
            <code> std::thread::id lhs, std::thread::id rhs) noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>!(rhs &lt; lhs)</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD::ID</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ БОЛЬШЕ</strong>
          </p>
          <p>Сравнивает два экземпляра <code>std::thread::id</code>, проверяя, следует ли один из них за другим в смысле отношения полного порядка, существующего на множестве значений идентификаторов потоков.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool operator&gt;(</code>
          </p>
          <p>
            <code> std::thread::id lhs, std::thread::id rhs) noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>
            <code>rhs &lt; lhs</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD::ID</strong>
            </code>
            <strong>, ОПЕРАТОР СРАВНЕНИЯ БОЛЬШЕ ИЛИ РАВНО</strong>
          </p>
          <p>Сравнивает два экземпляра <code>std::thread::id</code>, проверяя, следует ли один из них за другим в смысле отношения полного порядка, существующего на множестве значений идентификаторов потоков, или оба экземпляра совпадают.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool operator&gt;=(</code>
          </p>
          <p>
            <code> std::thread::id lhs, std::thread::id rhs) noexcept;</code>
          </p>
          <p>Возвращаемое значение</p>
          <p>
            <code>!(lhs &lt; rhs)</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD::ID</strong>
            </code>
            <strong>, ОПЕРАТОР ВСТАВКИ В ПОТОК</strong>
          </p>
          <p>Выводит строковое представление значения <code>std::thread::id</code> в указанный поток.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename charT, typename traits&gt;</code>
          </p>
          <p>
            <code>basic_ostream&lt;charT, traits&gt;&amp;</code>
          </p>
          <p>
            <code>operator&lt;&lt;(basic_ostream&lt;charT, traits&gt;&amp;&amp; out, thread::id id);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Выводит строковое представление значения <code>std::thread::id</code> в указанный поток. <emphasis>Возвращаемое значение</emphasis></p>
          <p>
            <code>out</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Формат строкового представления не специфицирован. Равные экземпляры имеют одинаковое представление, неравные — различное.</p>
          </cite>
          <p>
            <code>
              <strong>STD::THREAD::NATIVE_HANDLE_TYPE</strong>
            </code>
            <strong>, ПСЕВДОНИМ ТИПА</strong>
          </p>
          <p><code>native_handle_type</code> — это псевдоним типа, который можно использовать в сочетании с платформенно-зависимыми API.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>typedef implementation-defined native_handle_type;</code>
          </p>
          <cite>
            <p><strong>Примечание</strong>. Этот псевдоним типа необязателен. Если он определен, то реализация должна предоставить тип, пригодный для использования в сочетании с платформенно-зависимыми API.</p>
          </cite>
          <p>
            <code>
              <strong>STD::THREAD::NATIVE_HANDLE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Возвращает значение типа <code>native_handle_type</code>, представляющее поток выполнения, ассоциированный с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>native_handle_type native_handle();</code>
          </p>
          <cite>
            <p><strong>Примечание</strong>. Эта функция необязательна. Если она имеется, то возвращаемое значение должно быть пригодно для использования в сочетании с платформенно-зависимыми API.</p>
          </cite>
          <p>
            <code>
              <strong>STD::THREAD</strong>
            </code>
            <strong>, КОНСТРУКТОР ПО УМОЛЧАНИЮ</strong>
          </p>
          <p>Конструирует объект <code>std::thread</code>, с которым не ассоциирован никакой поток выполнения.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>thread() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::thread</code>, с которым не ассоциирован никакой поток выполнения.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Для вновь сконструированного объекта x типа <code>std::thread x.get_id()==id()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD</strong>
            </code>
            <strong>, КОНСТРУКТОР</strong>
          </p>
          <p>Конструирует экземпляр <code>std::thread</code>, ассоциированный с новым потоком выполнения.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Callable, typename Args...&gt;</code>
          </p>
          <p>
            <code>explicit thread(Callable&amp;&amp; func, Args&amp;&amp;... args);</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>func</code> и каждый элемент списка <code>args</code> должен удовлетворять требованиям концепции <code>MoveConstructible</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::thread</code> и ассоциирует с ним вновь созданный потоком выполнения. Копирует или перемещает аргумент <code>func</code> и все элементы списка <code>args</code> во внутреннюю память, где они хранятся на протяжении всего времени жизни потока выполнения. Вызывает <code>INVOKE(copy-of-func, copy-of-args)</code> в новом потоке выполнения.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Для вновь сконструированного объекта <code>x</code> типа <code>std::thread x.get_id() != id()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Исключение типа <code>std::system_error</code>, если не удалось запустить новый поток. Любое исключение, возбужденное при копировании <code>func</code> или <code>args</code> во внутреннюю память.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Вызов этого конструктора происходит-раньше выполнения переданной функции во вновь созданном потоке выполнения.</p>
          <p>
            <code>
              <strong>STD::THREAD</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ КОНСТРУКТОР</strong>
          </p>
          <p>Передает владение потоком выполнения от существующего объекта <code>std::thread</code> вновь созданному.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>thread(thread&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Конструирует экземпляр <code>std::thread</code>. Если с объектом <code>other</code> перед вызовом конструктора был ассоциирован поток выполнения, то теперь этот поток оказывается ассоциирован с вновь созданным объектом <code>std::thread</code>. В противном случае с вновь созданным объектом std::thread не ассоциирован никакой поток.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p>Для вновь сконструированного объекта <code>x</code> типа <code>std::thread x.get_id()</code> равно значению <code>other.get_id()</code> до вызова конструктора, <code>other.get_id() == id()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Объекты <code>std::thread</code> не удовлетворяют требованиям концепции <code>CopyConstructible</code>, поэтому копирующего конструктора не существует, существует только этот перемещающий конструктор.</p>
          </cite>
          <p>
            <code>
              <strong>STD::THREAD</strong>
            </code>
            <strong>, ДЕСТРУКТОР</strong>
          </p>
          <p>Уничтожает объект <code>std::thread</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>~thread();</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Уничтожает <code>*this</code>. Если с <code>*this</code> ассоциирован поток выполнения (<code>this-&gt;joinable()</code> возвращает <code>true</code>), то вызывает <code>std::terminate()</code>, то есть аварийно завершает программу.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD</strong>
            </code>
            <strong>, ПЕРЕМЕЩАЮЩИЙ ОПЕРАТОР ПРИСВАИВАНИЯ</strong>
          </p>
          <p>Передает владение потоком выполнения от одного объекта <code>std::thread</code> другому.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>thread&amp; operator=(thread&amp;&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если до вызова этого оператора <code>this-&gt;joinable()</code> возвращала <code>true</code>, то вызывает <code>std::terminate()</code> для аварийного завершения программы. Если с <code>other</code> до вызова оператора был ассоциирован поток выполнения, то после вызова он оказывается ассоциирован с <code>*this</code>. В противном случае с <code>*this</code> не ассоциирован никакой поток выполнения.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;get_id()</code> равно значению <code>other.get_id()</code> до вызова конструктора. <code>other.get_id() == id()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <cite>
            <p><strong>Примечание</strong>. Объекты <code>std::thread</code> не удовлетворяют требованиям концепции <code>CopyAssignable</code>, поэтому копирующего оператора присваивания не существует, существует только этот перемещающий оператор присваивания.</p>
          </cite>
          <p>
            <code>
              <strong>STD::THREAD::SWAP</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Обменивает владение ассоциированными потоками выполнения между двумя объектами <code>std::thread</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void swap(thread&amp; other) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Если с <code>other</code> до вызова функции был ассоциирован поток выполнения, то после вызова он оказывается ассоциирован с <code>*this</code>. В противном случае с <code>*this</code> не ассоциирован никакой поток выполнения. Если с <code>*this</code> до вызова функции был ассоциирован поток выполнения, то после вызова он оказывается ассоциирован с <code>other</code>. В противном случае с <code>other</code> не ассоциирован никакой поток выполнения.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;get_id()</code> равно значению <code>other.get_id()</code> до вызова функции. <code>other.get_id()</code> равно значению <code>this-&gt;get_id()</code> до вызова функции.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD::SWAP</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Обменивает владение ассоциированными потоками выполнения между двумя объектами <code>std::thread</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void swap(thread&amp; lhs, thread&amp; rhs) noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>
            <code>lhs.swap(rhs)</code>
          </p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD::JOINABLE</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Опрашивает, ассоциирован ли с <code>*this</code> поток выполнения.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>bool joinable() const noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p><code>true</code>, если с <code>*this</code> ассоциирован поток выполнения, иначе <code>false</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD::JOIN</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Ожидает завершения потока выполнения, ассоциированного с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void jоin();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;joinable()</code> должна возвращать <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Блокирует текущий поток, пока не завершится поток, ассоциированный с <code>*this</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;get_id() == id()</code>. Поток выполнения, который был ассоциирован с <code>*this</code> до вызова этой функции, завершился.</p>
          <p>
            <emphasis>Синхронизация</emphasis>
          </p>
          <p>Завершение потока выполнения, который был ассоциирован с <code>*this</code> до вызова этой функции, происходит-раньше возврата из <code>jоin()</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p><code>std::system_error</code>, если требуемого эффекта добиться не удалось или если <code>this-&gt;joinable()</code> возвращает <code>false</code>.</p>
          <p>
            <code>
              <strong>STD::THREAD::DETACH</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Отсоединяет поток выполнения, ассоциированный с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void detach();</code>
          </p>
          <p>
            <emphasis>Предусловия</emphasis>
          </p>
          <p><code>this-&gt;joinable()</code> возвращает <code>true</code>.</p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Отсоединяет поток выполнения, ассоциированный с <code>*this</code>.</p>
          <p>
            <emphasis>Постусловия</emphasis>
          </p>
          <p><code>this-&gt;get_id() == id()</code>, <code>this-&gt;joinable() == false</code>. Поток выполнения, который был ассоциирован с <code>*this</code> до вызова этой функции, отсоединен и более не ассоциирован ни с каким объектом <code>std::thread</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p><code>std::system_error</code>, если требуемого эффекта добиться не удалось или если <code>this-&gt;joinable()</code> возвращает <code>false</code> в момент вызова.</p>
          <p>
            <code>
              <strong>STD::THREAD::GET_ID</strong>
            </code>
            <strong>, ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Возвращает значение типа s<code>td::thread::id</code>, идентифицирующее поток выполнения, ассоциированный с <code>*this</code>.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>thread::id get_id() const noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Если с <code>*this</code> ассоциирован поток выполнения, то возвращает экземпляр <code>std::thread::id</code>, который идентифицирует этот поток. В противном случае возвращает сконструированный по умолчанию экземпляр <code>std::thread::id</code>.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THREAD::HARDWARE_CONCURRENCY</strong>
            </code>
            <strong>, СТАТИЧЕСКАЯ ФУНКЦИЯ-ЧЛЕН</strong>
          </p>
          <p>Возвращает информацию о том, сколько потоков могут одновременно работать на имеющемся оборудовании.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>unsigned hardware_concurrency() noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Количество потоков, которые могут одновременно исполняться на имеющемся оборудовании. Например, это может быть число процессоров. Если информация недоступна или определена неточно, возвращает 0.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
        </section>
        <section>
          <title>
            <p>D.7.2. Пространство имен <code>this_thread</code></p>
          </title>
          <p>Функции из пространства имен <code>std::this_thread</code> применяются к вызывающему потоку.</p>
          <p>
            <code>
              <strong>STD::THIS_THREAD::GET_ID</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Возвращает значение типа <code>std::thread::id</code>, идентифицирующее текущий поток выполнения.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>thread::id get_id() noexcept;</code>
          </p>
          <p>
            <emphasis>Возвращаемое значение</emphasis>
          </p>
          <p>Экземпляр <code>std::thread::id</code>, идентифицирующий текущий поток выполнения.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THIS_THREAD::YIELD</strong>
            </code>
            <strong>, ФУНКЦИЯ, HE ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Информирует библиотеку о том, что поток, вызвавший эту функцию, в данный момент не хочет выполняться. Обычно используется в коротких циклах, чтобы не потреблять излишне много процессорного времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>void yield() noexcept;</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Предоставляет библиотеке возможность запланировать другой поток вместо текущего.</p>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THIS_THREAD::SLEEP_FOR</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Приостанавливает выполнение текущего потока на указанное время.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Rep, typename Period&gt;</code>
          </p>
          <p>
            <code>void sleep_for(</code>
          </p>
          <p>
            <code> std::chrono::duration&lt;Rep, Period&gt; const&amp; relative_time);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Приостанавливает выполнение текущего потока на указанное время <code>relative_time</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Поток может быть блокирован дольше, чем указано. Если возможно, истекшее время измеряется по стабильным часам.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
          <p>
            <code>
              <strong>STD::THIS_THREAD::SLEEP_UNTIL</strong>
            </code>
            <strong>, ФУНКЦИЯ, НЕ ЯВЛЯЮЩАЯСЯ ЧЛЕНОМ КЛАССА</strong>
          </p>
          <p>Приостанавливает выполнение текущего потока до указанного момента времени.</p>
          <p>
            <emphasis>Объявление</emphasis>
          </p>
          <p>
            <code>template&lt;typename Clock, typename Duration&gt;</code>
          </p>
          <p>
            <code>void sleep_until(</code>
          </p>
          <p>
            <code> std::chrono::time_point&lt;Clock, Duration&gt; const&amp; absolute_time);</code>
          </p>
          <p>
            <emphasis>Результат</emphasis>
          </p>
          <p>Приостанавливает выполнение текущего потока до наступления момента <code>absolute_time</code> по указанным часам <code>Clock</code>.</p>
          <cite>
            <p><strong>Примечание</strong>. Не дается никаких гарантий относительно того, сколько времени будет блокирован вызывающий поток. Гарантируется лишь, что значение, возвращенное <code>Clock::now()</code>, больше или равно <code>absolute_time</code> в точке, где поток разблокировался.</p>
          </cite>
          <p>
            <emphasis>Исключения</emphasis>
          </p>
          <p>Нет.</p>
        </section>
      </section>
    </section>
    <section>
      <title>
        <p>Ресурсы</p>
      </title>
      <section>
        <title>
          <p>Печатные ресурсы</p>
        </title>
        <p>Cargill, Tom, "Exception Handling: A False Sense of Security," in С++ Report 6, no. 9, (November-December 1994). Доступно также по адресу http://www.informit.com/content/images/020163371x/supplements/Exception_Handling_Article.html.</p>
        <p>Hoare, C.A.R., Communicating Sequential Processes (Prentice Hall International, 1985), ISBN 0131532898. Доступно также по адресу http://www.usingcsp.com/cspbook.pdf.<a l:href="#n22" type="note">[22]</a></p>
        <p>Michael, Maged M., "Safe Memory Reclamation for Dynamic Lock-Free Objects Using Atomic Reads and Writes" in PODС '02: Proceedings of the Twenty-first Annual Symposium on Principles of Distributed Computing (2002), ISBN 1-58113-485-1.</p>
        <p>–––. U.S. Patent and Trademark Office application 20040107227, "Method for efficient implementation of dynamic lock-free data structures with safe memory reclamation."</p>
        <p>Sutter, Herb, Exceptional С++: 47 Engineering Puzzles, Programming Problems, and Solutions (Addison Wesley Professional, 1999), ISBN 0-201-61562-2.<a l:href="#n23" type="note">[23]</a></p>
        <p>–––.The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software, в Dr. Dobb's Journal 30, no. 3 (March 2005). Доступно также по адресу http://www.gotw.ca/publications/concurrency-ddj.htm.</p>
      </section>
      <section>
        <title>
          <p>Сетевые ресурсы</p>
        </title>
        <p>Atomic Ptr Plus Project Home, http://atomic-ptr-plus.sourceforge.net/.</p>
        <p>Boost С++ library collection, http://www.boost.org.</p>
        <p>C++0x/C++11 Support in GCC, http://gcc.gnu.org/projects/cxx0x.html.</p>
        <p>C++11 — The Recently Approved New ISO С++ Standard, http://www.research.att.com/~bs/C++0xFAQ.html.</p>
        <p>Erlang Programming Language, http://www.erlang.org/.</p>
        <p>GNU General Public License, http://www.gnu.org/licenses/gpl.html.</p>
        <p>Haskell Programming Language, http://www.haskell.org/.</p>
      </section>
    </section>
  </body>
  <body name="notes">
    <title>
      <empty-line/>
    </title>
    <section id="n1">
      <title>
        <p>1</p>
      </title>
      <p>Страница состояния компилятора GNU С++0х/С++11 http://gcc.gnu.org/projects/cxx0x.html.</p>
    </section>
    <section id="n2">
      <title>
        <p>2</p>
      </title>
      <p>Реализация <code>just::thread</code> библиотеки C++ Standard Thread Library, http://www.stdthread.co.uk.</p>
    </section>
    <section id="n3">
      <title>
        <p>3</p>
      </title>
      <p>Библиотеки Boost для С++, http://www.boost.org.</p>
    </section>
    <section id="n4">
      <title>
        <p>4</p>
      </title>
      <p>Tom Cargill «Exception Handling: A False Sense of Security» в журнале <emphasis>C++ Report</emphasis> 6, № 9 (ноябрь-декабрь 1994). Доступна также по адресу http://www.informit.com/content/images/020163371х/supplements/Exception_Handling_Article.html.</p>
    </section>
    <section id="n5">
      <title>
        <p>5</p>
      </title>
      <p>Herb Sutter, Exceptional C++: 47 Engineering Puzzles, Programming Problems, and Solutions (Addison Wesley Professional, 1999).</p>
    </section>
    <section id="n6">
      <title>
        <p>6</p>
      </title>
      <p>Howard E. Hinnant, “Multithreading API for C++0X-A Layered Approach,” С++ Standards Committee Paper N2094, http://www.open-std.org/jtcl/sc22/wg21/docs/papers/2006/n2094.html.</p>
    </section>
    <section id="n7">
      <title>
        <p>7</p>
      </title>
      <p>В книге «Путеводитель для путешествующих автостопом по галактике» был построен компьютер Deep Thought, который должен был найти «ответ на главный вопрос жизни, Вселенной и всего на свете». Оказалось, что ответ на вопрос — 42.</p>
    </section>
    <section id="n8">
      <title>
        <p>8</p>
      </title>
      <p>promise — обещание. Прим. перев.</p>
    </section>
    <section id="n9">
      <title>
        <p>9</p>
      </title>
      <p>http://www.haskell.org/.</p>
    </section>
    <section id="n10">
      <title>
        <p>10</p>
      </title>
      <p><emphasis>Communicating Sequential Processes,</emphasis> C.A.R. Hoare, Prentice Hall, 1985. Бесплатная онлайновая версия доступна по адресу http://www.usingcsp.com/cspbook.pdf.</p>
    </section>
    <section id="n11">
      <title>
        <p>11</p>
      </title>
      <p>О том, что такое спекулятивное исполнение, см. http://en.wikipedia.org/wiki/Speculative_execution. Прим. перев.</p>
    </section>
    <section id="n12">
      <title>
        <p>12</p>
      </title>
      <p>«Safe Memory Reclamation for Dynamic Lock-Free Objects Using Atomic Reads and Writes», Maged M. Michael, в сборнике <emphasis>PODC '02: Proceedings of the Twenty-first Annual Symposium on Principles of Distributed Computing</emphasis> (2002), ISBN 1-58113-485-1.</p>
    </section>
    <section id="n13">
      <title>
        <p>13</p>
      </title>
      <p>Maged M. Michael, U.S. Patent and Trademark Office application number 20040107227, «Method for efficient implementation of dynamic lock-free data structures with safe memory reclamation».</p>
    </section>
    <section id="n14">
      <title>
        <p>14</p>
      </title>
      <p>GNU General Public License http://www.gnu.org/licenses/gpl.html.</p>
    </section>
    <section id="n15">
      <title>
        <p>15</p>
      </title>
      <p>IBM Statement of Non-Assertion of Named Patents Against OSS, http://www.ibm.com/ibm/licensing/patents/</p>
    </section>
    <section id="n16">
      <title>
        <p>16</p>
      </title>
      <p>Atomic Ptr Plus Project, http://atomic-ptr-plus.sourceforge.net/.</p>
    </section>
    <section id="n17">
      <title>
        <p>17</p>
      </title>
      <p>http://www.mpi-forum.org/</p>
    </section>
    <section id="n18">
      <title>
        <p>18</p>
      </title>
      <p>http://www.openmp.org/</p>
    </section>
    <section id="n19">
      <title>
        <p>19</p>
      </title>
      <p>http://setiathome.ssl.berkeley.edu/</p>
    </section>
    <section id="n20">
      <title>
        <p>20</p>
      </title>
      <p>http://threadingbuildingblocks.org/</p>
    </section>
    <section id="n21">
      <title>
        <p>21</p>
      </title>
      <p>http://www.research.att.com/~bs/C++0xFAQ.html</p>
    </section>
    <section id="n22">
      <title>
        <p>22</p>
      </title>
      <p>Имеется русский перевод. Ч. Хоар «Взаимодействующие последовательные процессы», Мир, 1989. <emphasis>Прим. перев</emphasis>.</p>
    </section>
    <section id="n23">
      <title>
        <p>23</p>
      </title>
      <p>Имеется русский перевод. Герб Саттер «Решение сложных задач на C++», Вильямс, 2008. <emphasis>Прим. перев</emphasis>.</p>
    </section>
  </body>
  <binary id="img_13.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAaAAAADrAQMAAAAVENABAAAACXBIWXMAAB7CAAAewwF3y0R/
AAAABlBMVEUAAAD///+l2Z/dAAAFRElEQVR4nO3aTY/bRBgA4KwWyTdyrcTBR46V2MOiotY/
gd/AkQsVHyqgVplFe9hjjj1ANz+jQipNohwihIQPHFZVl3WiVcllVWdlhB1szzAfdnbG9nje
DLBLUeZQye08zng+35lph1ikzpuGOmhzhF2LX8JmU0eZDcptULJrgdKVBYKU759BoU3xwsgC
RVMLlHkWCJK2aIu26N9EQ/PMUkfebHOEPR9tjFbeYLgxImh4bQhdH0Kbo17PAqGvTaaOlo55
0X3jhsYW3RSada6SSyM66XFXiw6kXF3aJaXHHS3qqGgGQbiCRhCkhEh9Qo6kx0sdSpCKuhC0
lB/6aoivRXMVKaWtIywKMlGRUto6Ss6X7K3rD/c5UkpbR9FqwvJ1VTRvRyQP/HJvM16jidwI
TYgMyhzfEbdAtLRZlz4RpEHso8WHP+85BWKl/QjvkjO3GaUJKZup9yg+/pAhXtpHOPJOg2YU
03IUH47y+AXL1eel7fWiwQ+DZhSSuGgmTPL4F454adGzKPjea0SJSxZFM1G0OOGIlxY9WQRf
NVfE0h3Qbz8UaDX1JfTrIuArSh1djg480UIUvXzsS8V7cvL6YTMS+6eZQN/uB1JF3H16kWqQ
KCR7NUZ3vgxekKLKcSfff5UGLShhrya3kjhg9cgbF3vZ51E6aEGZy/6c5CQISdGNKEtT/jId
wvLwFh32KmlHrqMi09AQ6VBFhkFYpLGKDMO9SEqkaJxYirSUXw2dwhL51dDJMpNfDZ2WrRYA
q6XGblGbqQi2fLalG0TYacpmQElqgYgVWtgg1wJZHdWRb2zQtR1rLWxOqGbdpmwGBElbtEVb
9J9DQxvkWSCrU+wIWSCyRX8DKdEhGNnEEZD0v0RyROtCkRyrAmq7jgAXd3W0A0VyaG8+v25A
kH5XQ8quBIqUXQkUYUBcVEME2FAcrS9+D1tyVtH64nfckrOKxN5yCG4ojv7kyOUNlUGGO0Mx
yvAK3+cNdQkJRxkKvffxpzjgDRVBAl+OhnfwF9lANBQUHTjv9T7hC5OzAXL3ez/zzPSXIDfH
DHmD2w/O2BaIbTSAFYFR0H1w/BMRaydkK8TO04jvvn3vnVC0sg9DK1rnx+iuz8/N+DkiABF2
+sWLNqcIsm1QhsaE1gOg/6noSJetDdmMXMh+sIYgIU4NKQc9ULTUZmtBc222CtKtGvK6Va1U
7fp0AEXyP3bakHwA4179ffXcSEWab61eHIBQ9eIAhCoXBzBUuTiAocrFAQwpIwaKRC0voGia
OMXIysqZyYweR1HRTBgNoOjpIi2byfP6QPQuO6MSzXSMHH5hbUR0bUvLZjole0MPgrKQLQGi
mX7ED4cIgpZvsflWNNM5Tp+DEP2R8uKARDh9BkMhu6sRAUWUpx/AkD/zyoAiyuM9KHLLyC/K
wyMYCuJ5GflFmd93QYgnEflFmFsoEpFfXDxBh4Zjgw5bkWb6HbcizbQ8AyNpAeANpUWapaZ6
caBH0gxZvTjQI2kubl8AdAs1GMkhQeuitkbsdmrj4IOhTcKcZKdAE0NuGfFwjSFgTFDuNZLs
PgFHHwUKPkvYr4lw1BgvF+j0t5itEKyhjkbGnWuBXl5wxBrKS/ZAaLlzMg55B+uyDVhsMOUv
TacCOWzXYIzMOcqJH4S3xS+tROXD0GtW5fSb0lFmPG5Yowv2flp76T0SAFFw9jH7EtpOf/TM
x4IlGp2zJ9ojfs/Nx01lL+eG9b3VORyJRHt50jX/H+natiFD5v1dw7bBfGvVMEcYe1HTbGTs
EE3zXrAZupltAxiBj7U0K2Fr+guefapYp3uxpQAAAABJRU5ErkJggg==</binary>
  <binary id="img_18.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAswAAAFsAQMAAADi630qAAAACXBIWXMAAB7CAAAewwF3y0R/
AAAABlBMVEUAAAD///+l2Z/dAAACmklEQVR4nO3bMW/aQBTAcSoqeanitQPCQ4eurboUCcGY
sV+hVYesjbIEBTVMHcs3KF+kVZ0lbOErWELCY4xucdSTHQtDgvG9a1VhVab/Nx16dz/M82F8
tmmkVUXUqJAOGhXFp5rSYUWlTqChoaGhoaGhD5RO1mdS2bnlKpzUzxteOTPKG/0HoZTZjKmc
vlx1itNl3jtMZ3nDK2fGeeORLmU2Y7ZpLdLaQitoaGhoaGhoaCOt3WYAXXt6HdDQ0NDQ0ND/
AV3PK2YS3ZczZXp3TI0vfEJDQ0NDQ0NDHxat6/o8X0X1qPixTGhoaGjovdITKTmbSRm1aWip
R9K30tOplJlDQ0NDQwv0SDqvd3wp03ygxUVB1fR2xNIH3NxRsEVxMbdLi7WDhoaGhoaGhoaG
PlR6jwEN/e/puLie3O5TTF2amMKq1tmh7wpdC3QhZf5STrZfhHulf0JDQ++TjtYXq27LdLQ+
LngiHT+x0uvsrEwH+btqV6SjP6LHIh0f/yWt8qImbpkO83s8d3ORVo97xEhHUdvraCN9FbR6
F1Y6ilz3R/LFM9P++2fO68RQ61CN/OdHH1IbHbx66rzVDddMf+2ez9+YdmOoWufLm5M0tNDX
vWywPp2Z6Ul3oF6a6d5QXR+nUws9bg+UhW4NlCPQXbVws8ljob8Nlo4+E+lT5Ur0fOFZvjLZ
4BWtLFstFSSj3+n+b7a6KdNZrV+ItV6cxPIxZFNribbNkOHy5mPsWOhpNkM6Iu0Ph07HTI90
fHSWHcBk2u8Ns3kt0UGSuAJ9pXX7IrJtdZR8dr8nv24P56cAGhoaGhoaGhoaGhoaGhoaGhoa
GhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaur50hf82roC+B8ClQc6ReA62AAAAAElF
TkSuQmCC</binary>
  <binary id="img_19.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAxgAAAFtAQMAAAC+w158AAAACXBIWXMAAB7CAAAewwF3y0R/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</binary>
  <binary id="img_21.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAGsAAAA8CAIAAADuVtMUAAADdUlEQVR4nO2bP3aCMByAw3s9
CjrwegI8AbB0Yu0GI1nYHN1c6ghbVycXygn0BD4G4C40EUFsiQIJCSDfou1rS94n+f0Lfcuy
DMxQ8CZ6AaNnNkjLBAymu9UCgq/k6MgiLj92g6Et6T56VYWtYOwGNS/LXHQT7oWtYOwGxTMb
pGU2SMtskJbZIC2zQVoIBosyq4L1k3la/wvqQBKdADBFXZ1gEJVZiYJK/ferNlz36ytFVN1P
pvyo4ULaC+lLyLsYf7LW+nrXyYapQhgl6B2nhTUEV9Se0BUQDYYHH23ccttin6q54LOoUUEy
eCcQ7WEdf1lskZooWTLccNkTpExywIZ0qfCEvBxvXsRvnQFRbxALVGnjsiRJFL89aKqD/VqD
uUCDqG/exRXqDKbxGWUNssCGu/hFTmBqDIZbeLJ+jgMrWwbLvcHLwPyE3+nSWdjcfFzcG5Sd
Y+YIWklnmJ+TXMN8w1Q69skC83MS9Ac3SpJlCXoNUue5wrEbZHxOEto6il4e0iZ7WbOSYuwG
mYL8+agaaxcMZoM51RwKWpW0s8EcnEOXKKa2s4eZqMEuXdOfaVRTJmqww+wDd2LlPLQFEzXY
njTYnzoNQKdgkMU5SS7wu0NNPnaDjM5JHgks0jQhfo7dIJthLxZorYnDFPNuvvwHIQbbNZ79
ge+uaJ258Sc+lCQ5kp3l1g41UpHD32DrxrM/5OU7gLrkP5gKpzs7MDzvwyY65G2wZeMZ2qvY
7e9GfR4DksiH0Id4vxB+gq/BTo2nUJ475mawe+M5cLgZ7N54Dhyeu7hZ4/mvpfUlWLy9hXxR
R6n/j884GmzYeN5Fnp4zCQv4GezceNYynKNUfpmkc+M5cHgZpGg8Bw4ng10bT80jN6RtKI/0
qo3krcCi+fD6Ncik8WTBJT1hjftKI5kXWLSpql+DTBpPVqQxUNUT3IbO7Trh4Wy6dLG5513M
ovFkRBqAj+MaSPoh9LTi0dIYPHrCqhHC54O8nuZMgwgYQPuwgL7Zudpl36LvKQbtUy7CDXKi
kCUjhf41GDIR+CoGb7I090tdXBQCJgJfxWAClCLe5f/YsQ0NhYnAFzEYxsAo86/srC2obz4t
85vFk36vYDDdHYBRzVY4n/hnhU2LOXWDRTMC/ahSk6JgaAW0ZcyVqRskFEuy47F6VnfqBvtn
NkjLL8Nd9HLKlbxcAAAAAElFTkSuQmCC</binary>
  <binary id="img_1_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAiYAAAC0BAMAAABS0foUAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_2_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAiYAAABoBAMAAAA3LSZAAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_3_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAMkAAAEVBAMAAAC4Y9zWAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_4.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAMkAAAFGBAMAAAAyeaaPAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_5_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAeMAAAJYBAMAAACjvJMgAAAAMFBMVEUAAAAREREiIiIzMzNE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=</binary>
  <binary id="img_6_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAkQAAAKPBAMAAAB+4cgeAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_7_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAkQAAAEiBAMAAADqi9CzAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_8_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAkQAAAGkBAMAAAAiYid2AAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_9_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAkQAAAGlBAMAAADpPvTTAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_10_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAkQAAAJbBAMAAAD3TpYnAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_11_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAkQAAAEKBAMAAAABdFfoAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_12_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAcIAAAGgBAMAAADLCnonAAAAMFBMVEUAAAAREREiIiIzMzNE
RERVVVVmZmZ3d3eIiIiZmZmqqqq7u7vMzMzd3d3u7u7///97EBgKAAAAB3RJTUUH4gYXBSEF
L+ipKAAAIABJREFUeJztvXt8VNd1MMrv5mvTe9s/mtRt0zT9vholdfxI0kjCDwhuYxB2/MqN
edmusdMgJDDGNAYj8XRsbCRAQG1sJPGQek1iIQlQG2wECGlugw0YJM1X2zz0mDm/Wz8ASbPX
H36ApDlr3/0858zMmZlzpBmB+31rpHmcs89+rb3Xa6+99jjqBPhg6pcfpgE62zQupoX0bGtH
R2/I/pPQa1/iX8WNXiuB/cW6rhPFPKuSMtA5yLS9HY5i5Jsjd5HMWaVUf+LhOqDJWwjnDJoI
GJuG/Ub+kQDWHYh7xCVHtxzic06TSTI4kbKFJ8IUncBK4ekdFxyJOfD2oPiLb4RIrO7xP5GX
+HM0SWQhO8WRgUyPsif4A+gRWEKSuoV41ojtuIRKOeqsK4nuf7GJ0c7LkQOoMigkZkStBoJn
ZPKEbBzGNDFuHrqO0i8VoMCho43xlMag7l2G6hV3KQWA21T1kcrb8y5PpRilyFvoWusRzvkM
Z+ERUs5DenYk/XZNAbAWxozCOFp61khL6a91SDVKadJR+qWC9JTmSw5JcYji/5qYh6MaRmIe
Oi8k4HBkRPoaAo7D5JQm+TwcbbPHsNvS8cOxq0mWANKMUkguYgjAmF/ei007uez74HbRR0kp
aSkIqS3xqVjVAZN8d1xI1IzAFvLiboob8cK9W+U9Qjp+CK4IcunMhHrGJkNHmiQSLCR8hUxI
d+loaXx6WTtGYYn8VIqQ1v3Yi6s4/CIRihxF0ORY/hb/BAlPouQprREBtVvEdTuendA7icxB
5uQTn5BqlKLrPMTu+oaGTsK+EKmYsjSIsmwi9E7Vbt4AWUVKAGQz5E2eKRFNUFXnDQIL0SIx
otYSRacAKA3aJ0DaUeryyMt5OT98nBLRIIZK3rNEY4uIzudVJ7znQeqzonlWV7KfvQ2d4lt/
o1DYpWrk6BQxDnqPtInL0YagXbh/OJHaEpXA8dnvra2hD35KBGJUrwPHgCkNGaxtHL/CGME7
gDeAUPFHBC5ZYrK+oQ15h/TXi7bwhhEi7SOgElE4VN/KniEYrdsvZoXoTv8TM8UodeeHSF8w
6OcPQvOTRn9jaWekbH0bvDu/09xL3zW6SnaRvdgN3UUV5qWyspo+1kHnYaAGDy03QDSTiA6J
bhZtYHNxQCrSxLJSiPHAvxOzgs8D3qVDbcq+AWD6H6bp9EMXC9grBnz8+OB3Cp/+4jszf9T3
pzMmDU8tnDQ8EXaH58760+hEeD28ZFZ++P2Ch+481kTogcCVOy9OmP40QFfnwE6MRBhWTqzc
C+aRRtaufpZhT8NeNA83CPGJ9OzDdzsjoVAYjzx6imBjY5jCYBNApGGHQfu3B5My6GQNTE1L
wY2WwssGfv7ge1uGJl7+Q7x18E7zhsuTcebAJPpqx0L6evuN9PXOBfRA7bGmoTvfb6Lwb8bg
5PcXD91h4jtPX7o3ur66fCfuebIFBjbUNRFgLSRVDcUwuKJykyAoZxaZv9lXVV29Aw4/0hCO
bm/YRXCoCejJHa/tjxQ3r/DPG9NpT4mjAl4J48dP/FtJ+Z9/8YSxpO/GNyZ9+Bysbf/zhrnB
3vofd9wGLwZ6m3/cdqzp4g/ev3ulcezJ3zzweie5DejwypOBSCQUDmO0lqJJzc0Mh6yDN9Ae
bCZ0hSCWZg0cxlAoEkKzVky+nRQHWUftCUeDg1voiaBvVSA9LY2jNEhfZvPwpy8XzPyHy4+T
F4auy73xP2uN10M5BVOMX9z6UHBtwfjg2vxnat/fcmXye7MfWvxvEx66cyuQaWwSnXmMRFta
TreyFgIxS8vWsFYzxDUXt0Hl9h0LBMeAalwZOd3SchTMXZRE1pc/BnSIIbtr+U5ypnpjZcDv
REwpl7rzQzYPyccPvhfAo5/cSQv7voeFHz0Ba3tvpq933cRmXf/Kte3foL8NHGu6wkbp8OTd
gcEHX+/EWxlC3lgZiVZvr95LB9j8PLsvtAlxiHOb/jKoPHy4nRNTIGeHt+ChhuqdxGS3+1aR
jUD4KIWBbYEvKhr3Gj4nYhq51E2mQbrWgM9/+sF9Fyde/kb37UM39RYM3tE7IXozbL10U++P
2yjd3XNT7z+2vh648oP3Np2Z/F7bxTvfv//cJEL7N51rk6WyAYj1OPwEpQOUYQjOkTNAI7SX
85rBPQHJNvgoPQdmBdKhAJIWNhv7NlPTbws9yaXxvbK1Ez9+vHd63ubL1+UtGsrNuw9/OWXO
8CT6686HZsxtIrg7NH3GkoZ84+LkD76et/9AcPBHQ9PztqD5m9q+R7kcQPDQyqNwrmXdwkj3
ocbgpYd7qsyh+adWRmZxAY1MZP/8y6knj5KLFXtmh3sOrWwl2/ZtC+K6hj3BEfDD1NpTghwB
GCE0YpCBVrgw5yiaoQ4gkaOAYRiAgaMR1schwj5DYYLhSKgT+Sft6WCD8XSneVQIbmZ7eyua
Va3t0NPTHja7K9sIvLuhEw6yhzG6Q8pE2HG0FfDw3n7ob29tpT11O5H0Vx8F6neYppFLDRL/
gGMx6Yuf2hIGaI1ByqVCApPil33BlsCpkjP1NZlrFRf+hmusHIFakrZVDvrEoRe5NB6HoNdV
yODTcrkJ5KqUvUIkRW8lj3EtRK48qbbqr+Imz5CATNDOJLaebavBURbqbIgW631DCrkU3GQa
qUfIurJpj7qbtfQvF9mEWgSEWotI+nG0eolJojK5qDnVi089R1oVppUaAkpkR7sL/bYwtY6f
IEPI1ti6u6UbKt0gLrGqk7WcZrVSDWHVCVSvDjoe1qo+ym61nvcHaW3eLsK8VsATV27j6qd/
ulVMDgTnk0ofBBJzdbSQ3l6a5nkXBdlDsbFDzcKcVOgzbWhMZS9NItPYMMrKIHWOSxh9hq6Q
fmUmW8Zb3SKkWV1NTGcvdZFpMgJjtqSVWi5FN5nmSwf+5dIvG6S36n/J25hSLv2vsAY8Arn0
Swep7KXoLtN8qQCT41BcT8PxvxSQYh7C/wIrpKCs+sm88Ubyl2w1MJNlWA5+vCTfNu8vGUBK
yRvgLNBscUTQAikm+ABmtpwTYq3E+j22Mg0SIJDN5nEspfYRPmNksXAJmO15kIrSAD3XFsoi
hMOhcCQcimS1jFBzKo8hOFuUPZhVNG/WvLy8u2dlsYyiWbOKilPSUsxm94ZC706f8NLE7BYR
CYVpjIEutoUkFQ2IvRdLcWN/oesVatZNvbstOsVIyDSTMzOB+8atcicBy6s+xt3bxffbtUiR
hGB34YQVBsLbcxDjeierEDdKM86pUDuomAdn3NPKrcbRAiO7wn1c5vEtzHxZks/3LJ2wwRC+
CnBgEcZ6YmcXstpCAdwQHGm+655W5UMDfbdlUzRMyDpuz0zmS+SuRN1L8yrCnNWLhQ1cu8bM
fDlJIR6Hme5dNq/N5in3tAmBTa4q0St3kDGU77MxSoFaCzCsgWwGroyVMsiSJt/rniOHrMxD
yVqE+1ekbsrdrU5ZlDf7k/u0Z+IYQHYoDcrVMcCewgkrDTZAY9m/OSNIxszglfEWai9UPgzZ
DJzdKtd0Y5LAW/dlXcOwIDs4FMu42C1moPJkdAJGC4Lx/gJZgyy0UPkqmM1TZ7fqVfLYUQr4
5pwxY/lZojQCgQsNe3ncAXyGDt9mYPyCcpYgsy2Uq+/cXbh5yiOtlpAbJ6NxWXXrmuwtVMZC
RloIjk/hodGzpGBjmDN5cEMUH7ZXbidjxC8yjUPhg9E85eHWlL4+jFUuaXJRRiHu5Vg3tlw5
0CnQJ/5bA0fnPi5eV7VX2x2flMZ1uKuzBU/EqOappRMqDOFYmcQuKSpz4Q6IzSajehvYXgIZ
pjQMh3Uz7mnj3kEY44ASVwEgZqEbErMA4+L6caQgBwgwPTB/I8hdCZaFwh3hH/yD/Vw2Z+S4
Ec93jP+JhJp1U2aLjRVpM0U0C9Jan8HxH+ta5fzmMhOdMA6kFx0q3x35M/4TUfuvWYstoAwU
qKNHMPW9+9mpFQbfWUNBJY+PNGHXHeDYHKIep9RynhPPSIIMSjaS3m56OUAtDOjtRon/ih7I
irJ84uyl1HZ5cX7a/ZKs20Eg8O42kFtL0uCQ3yXDN2jJLYlNIxGFTttXWmKqYBwiQQuJ8l/h
zv5UiEO140diRrhZyk9GWIQeuBE4C+RbaCxMg9xU4lJ9hN1rUDgsgtxYZGdI1JsTYGRAHDud
NZqpGpuOT7kECBZu4hHEUkYOTX+402IsoB0YXRJrIDh4O+hRlyRNBgDG9TQeaWxsPHKkpaVF
/rP3xrhPfoP/aGQveaOx4cgR/hSDlgae4sXxd7OLjTwrnlI9zZ84ctStjUL52Lq5m2fHC+d5
8acbjowWZA6NGlrGHXh2VpF4WTCPQVHMZ9E8J8yayS7Pmz1zKfsq0swszMsrKCiaOY+lZeln
qgdl4lkzZxrJurfrpleLrBJl5o56iOtF8l9etirCfyb5LyqaZz/C3qePOyh1G4zp3vh/l2FJ
8bAheTpwS4yhpW6NIDvHd1xbyG9HCu/R9My2o8chWv4rk7tWpZMSUqpIM+jtf/DmuIPUfir5
fJBEFRy/yeC9IDIx38i7u1XtIozLQlQf3Fso5INz3009A21K6lKfpMTU8TClB8Y1o+zwGO6T
+I9a+NBe3dFfPIjcvbd77oSVYUlXQG+CtZAoej1JCzkBNad2CmIKNr91uh5YdbWcyi2XhJT9
okcep8mshVTtYrQGZbI2OjoIIPJaTlOYQrRuKlcjbK96lUq6rsu077gaDmX7X34MtfOHs+Ot
HzEBpGzZAVO+qGP/KsPhQVU5UN4aLrNQ/et9AuLtXO6tBpjdhfkrDADQ4oTaS2AVIH4kHaWs
Z14rCKreRe1H7gDdRKvqdsSrlC/QXaxwaHedxb+S/WsgQz/OuwlMaQvlAmmCPY3aWSVrIa9H
2Ztz0ClpJhl/3tbxYgtW8CbHobyWCn22DCcXWswlebmLegrzGQklDtEOHN/Q6rV3kkvYUD54
G8T48GcMdKvYKKV2k+NV7PiX1PdYhQ6Oz8stniJIqN0YmzDEzqZ3kjWQZVdGX9mS1K6ISXGX
rqI6FXvUwiGNHYbJQE7Crh9OGZ83YYVBTYi/qz7tSmHSUcoTrsMrt6OrMSdToOehLtFL30D/
z/IZDm8Lyv34Chxr33GQqoWViHNrstc+EBxfU1In8Ur2ErTRXHtdbk5uXs49nTwKgdy+ZO30
kpwRbe5GaSovpDKkn0zMqg+YnIfUTy/iwRzWQNbC8feE0yXlGSflFvx+GSXm9M7sNVDMQ8ke
T9U3eIP6+rvyFOQ8nDLl9oaA6LcUo5S1kMKZ+1BKFJkHEBxffIFfjvcI149n6ON/ubk5KRPm
XH/9YjE0ktJSzi3YeO6f5n8nrPc2HpCSN9IXjva2ZxZO9779hBB2UvBDhkMm2755P9r8NtMt
5KNUCBevZIGcffpEulEK5Tx2xtA0IysLpoLyaRzCC4IcItVmGS3gCbqoTSm2vUb/sPa1Uv2T
Ks0MkXy6GNPwQ05LefcuolnbInBA4/AFQ6s7Dv9stLeCgtZdbKVG2hQVG9EtRn2BJfj0OQ84
5H0xmD0PG0sDZjikCRYhL72aTKLitz5cLKSVlPyQZ2DC2s3ZwaCQS5vltxdSVCPZ0+nuf7pY
9EBKHEoB+fxPSHZcbCQ/FIW8AJYCFStGOzRqrdI6nnd+qkFOrUSfaUqTipaKx8zpTdlydeMa
sKjQC06FwNaqnR8QfyH+axwgxyGrdxp+KOwf79ybFecMpT3F4NB5N+lPpNqMYtt8XVr62WIv
Mo3AfHR6Fri+IDBvarn0hdRdGD8y49bD3Gv30RM0lY5PJT+korvefix1bUcIaI1S0UKXYWrN
S2ov06h5Co51VvVUXKs/XSySpOGHQqcmwwX+w7SkByWXiprH4VAHhCCoVrb0ohdPJqKUhak2
SykOmrjMyechTSvTKF1892qajb0mQj8U35zzUKz8yK98hwtEhDVOmJsIqjiCkc2InXK9iAih
iCqLjQ0oaCkwfpiClmp7Nxm8wUAryn0GWyjspTQOh5JyqEHJmtjCW6rUWlQizNAaarbJxKL1
POpaPEsTtNQDDkVp+OLqzPvVgrTTiO+M49s8YqB1oFXIwhhpaYeB8pYOxN69FHqCPZ10oDHM
2vtJELpXthjQEz4d7m0zW03sORofAOIjj7RU1AUufjfZPr5RgYNb2Bfh7KK+RwyBrJPVJcGe
4j27oK9kXQ12baiqIFWVy9nofAvg5PzqNuxauX5H35poOUbLSyvEw3Y+Yh564IdSliBL9md6
2xxK/dCmpdaN4ZWX9glJG+vppSAcYX17os18kprzAqG+1XiuidJKgEgbUmIWtYXMLXDSOBvA
9QmjND0t1V/Y+P9kYhZMUvCmTUtV5kJHOLFABec8saON0BaGsz0AzcRcxfSAhacP1QKsB2LW
sKlprgYwNxvn4WDD0ToDDGpb3Rilod74oUxuTg9kXHKL44f6KkLXvSIUEpBIdalBWhh/2Ejg
EDF3IVxcueFIEKGSoW8X6wNGUwluISfhrR3VewFNw2Fe/FTPw3S0VCan3K82s00EaS9NoKVo
ll9oI9gfBKjFCwE+SkkzQDlENlF6cbOIlvQGULKXMxOmA5JNcJIc52ukcLzNkb8XudTxHYZn
BDPO9V34Iaf+Z9f0LyB09xzEe0P1QTjcfqrz8saTFbS74mjYLOt4NwBwNohkx+kW6F7FqO72
0/MCQ4+G6g06JWBzRbR0i+QVsHAoLfBzMs7ywY2Wshm3K1pqwIldQI6U7QAYqqoGs255MPLu
+h0GdJVvZ5zlIqM2h6v2modXNBpwfv3hNnKofCcltztz17Q0eQtjcMiY7LQUA9o/YCw/jJEv
UTl/yi/c3YkgUeHIxKocHdgMREg4wmeGUCnq9D2AjnH2kQ9aKmvE/WozbHM74KSlSgtCp32J
KK90aYtSQg67LAQaKbvqRVz2bbiWOCoo5VLwwA/lD8SLt8eLfqMFd36YwJVAS4+WMmwtHKvk
6jI4UShpKaTT8Z2AS7Zk1OgmVmZcaKnDkBGv7Vu39UK27QNAnQYP8Qjnhx7lUgXki0mZ1S9i
+KHVmGQ9Hut0E59KWUudC4fpKY2DH4pH0JzblmFzhqtcmgaSp4xb6UzPLWJoqXg7MymTLYQY
fpgsVZJBAxAzimmMpUo+mN6aGIdDpoBFZwQyRmxEBQ8kyKX2zfRPx1+KUw2k1Jaalsb85MT6
7ccyicRYfqgIox2MkxGOcBjsuoPa3xPhCyke5CsxD33RUpZ8eILhYhAZISSTS4WXlDTO7Fkv
v3JXVxFbnr3MPW3YiulbiJ+m1YBj+KG6dGBNJnmii1yKihmg4HmHSwy9BkWpOs7AfGMXbkjv
XcYpDU1LSxOu4OAN8qSIjAC60lLg1iZWqwgrJ1LF/S3CTI8ivFiORxK+VMt0RQ914FIbplkD
TrhEaOa2RKGrRZhf7d7+bnm4p3K9QaAOcKCyfB8eruhbb3SXbzTIydK6LXAmkHaUosShL1rK
xw+5eGMm1zAOaG+TGI7fXTK/KrBtYyVTcSsBo9sPb8TmhWcXkModZTXDpXuK9uOVGo849K5b
6EtgLqnNWAMhCQ7xjU0ksry160nRQjx9eAXtL1/X1r+88+RTF1aRuhpuTPRGS8Grjm/XiX5y
M0kwvo4IeBYHHCukdiGkyoD+4nVFTxKoItC/rmQ5oQcXkuHidcULzwbgQhMMPu0hf2kR9jkP
uehWGMiY/O3EodMStYdCtKSx8aiwVpyoGFhA+0u3tQ3Pbzi685Ma2lyLVzZ7YIjprfoutJTD
+5MzNBHlGjBatFRXGbpLWzrM6paexkhDZUvg4o4jpR3NC88tCFXtO7VvaPnpyo1woS1Fvhqk
NTGFT5QrP2QUOzq1M0OWU6QHXHBIaXPxvFXkUtG8lWbRsqLNfctmr6t4aeH5oqauoqIKUldU
PN8462G5z4M10R2HaByY40Vm8gTONWCdP5JIJMSo9kAIeMwqoL3hEOOG7JoZChEIs8tY5cUB
Rss0vuahOIVmcFrYMaZGDmBbhGNoqZBK+bqatH0KB0TUztv8FBw0d3gp/iOtH/qhpbL4tZsw
I010+CYmrnJbacRbrIXIWwidT5VMYyQv34WWCmJ35fZMDFNUOn6c1Gb1nTY9yS92raj0e07f
RC+01CUX0ZlLdtHM+H9bvvovJCDFIRzKqaoWe6VFMe0IQsUPPdu8nZcpnJuYGQcbl3noWuDI
pkT6FdIk/JAr+9MDmaE0bpao+EQKfc5x6W0HgWVNTF6DRH4oryOemUQ9jJR0IH2iRJYJOARr
o48uRm+40TQgbenC2yStT1QigBDdZmRmrU3LpRKHcr45+865+BVbB/GBSf/4I9xjyPvaU9wd
fPsxjDf8+ATU/FDACxlfREf4aGS0lIquw/5bg6O3DmOiTGMjT3t+oCKr9nZgtYUuJfAnP/Qw
D1Nk8eoiHP0qjWN1zQC988e5EQcs9qiuoK6+lTDJDjlA+HDEOOTZ4+DtxmhnIqvoMTEPwYXS
ZAA+WzxCfkgFoTO3bhnJAY8xgLbU9nIoFEkNYQH8G2Gf6VKzVKH3Pej4KWoHn9yRAWoqd8ky
6fr5qflTPcJ0rwl/thhHyA8FQUdzSc0oUQiWnzfQ5tKykrLSkpKykmRv7J9D6fRintK+x//i
QaRdV9aUziKcEodMd75vRAeR2u2jlq++UImsM2qTvKmn3grEXU4cg3rPrHTRHNE8FJVhXH+U
MWxQ4ZDHp0xvw1bRMw4EEsSfOEBqbf1Oq+OnKBQICK4/iskI1LZioNw0kQpkOnosGN+ihHyl
Mqk9OEfKD7n72YTgaGfimzKmgh8h90DAY95aUPCt4yvgbiAH5oyOX4Bae0IewiX9YJBSzYFg
ItL0S8s99gYa3+sWVmG8WjB462jURKQO7ckzsBb6LGfEtJQ38/XVoxumcEzPQ++P+GihlAJH
wg8lsJtdN8KoxikccOzl9vjI7qBPJWTEOBTS7ZLaka9663ULn/Bbf6N0hHKpehboJ3eMitLY
a8Den9ntfx6OjJYKIGQqX0AYeSv1Or4PeN1fC0euHwpAcuZHvsqLedi5ju8ZOA79PTJSmYZK
ATxawA+iH+Fc1Cszvmq8O+DL3j6aeSiS4JuPjcLCD2/6o6UwsnmY/F4afsgBh24Nj9DCPzJa
CrsDPjoUR8UP1TrQq49rOd43wQG/Mg0XsyUOfTw1Uh3fKvPSbaNYwjjmi5YK+/fugI6+6OmZ
0c5DLuKurRmZYDMCuZT7ADMc+iNto6ClVI7zi3egFXrK34x0+ER5AwizR4KEx3/0/syo+CEH
NAv3y0Cgngu1S/DHDxHqEQ8ESF8bdY185VrEKHEo3AbP3swYhul/qIJPWsqyf3s/04DxNcPH
I6OchzwVjU4NAg4nmE88lO+bH350E7wevPQ3PkZputgmnvKAd+5HHFwDI5iKcXGi0hZ1Jadt
d/jVm7SJwhOMhh+KRMDwN4HQwfso8cWm9NqTn0cwOv7m3UfyJvuwf/n1L3UD1sYDc7Dvz0fi
d+qTltLI9PyZ08c/7ku8yMA8pDB4K1zJS7QQpQP0zw+fyc3Lzdviq6TR0VIOfNfVK5su5z7t
V8dQa0++mrg1Lzc3z7sTAWaCHwIPrnnpji/GT/LgXR7/rD8ccnaRk5PzHcMzN5T8cBQ6vsyD
WxafqfuTG/y7EYn9+D4eAviYtfBv/JWTgXmIYYLnpubkpPe9jnvS9sXw+ABnF3k5N6Urxnk/
E7SUDrw0q6QsJydvjbfkTvBJaRCH8nJyfuRPQhw1P2SoOJ97/Xg2eu5PEv482YPOdXyvD5kP
5eQs8tUpo8ch79Dm3Ly8nLzv+jXu+rV5c8o4Ny93s79yRotDkdB8jTVxfE4KopXkQb/rFkBf
ycvxY4oCmjq2CfUkOzC9NLokb3xe3hp/6jr1ay/l+vb7ed82wNdxVKPmh1R01PDP8vLyJvsc
pejbXor045wbPAboAOVw5EOmSZYtj78I3T/Oy/mub7nNJ6VhSLw4/g6fkoVnfoixP5x+g8Jl
4DijNYafkqml41vewB5gKM+zlV0urqXHofBpSD+1EV/Nzd3ssWgVVhykbyLS1Av4MRB96OnE
FX6014HVV2G0EtPVg1xqRwOPC/9sqbyyxpG54x9L4WfmqINtuFLzEFKfdRzTk0u2eEypdmmm
1/GRRjwNIKDRh25Pn0wVLqJBUDsm+6t5U/Ly2Ss15OfnTf0he5uSn6df7Ct71H6pn/x9Qljk
nS6mAsP1qyyXKaIEOyNRnq6RLCtvKpuJ+Ulezq/8iWlB7TEkd+c94/Vo73ns5fEQ8ClB4bHg
Qab5hbeS2Z/nY8tn5xtisgiZhs+kl7Pgm7hV4TB5C3Xsy3mZLx1eNFCtW8gZySO02j5NDv+m
GJchSZ9cAVWQVu10gjxiKKZZmZE4BJiBKnKt9qFW/j22i5UKfqvjhsdGwkXUT9uRcmGpEbP2
5LLfIhG0Z5vXXtwq1+HS80OYK6sXW5B1Qa88pSwZYiuHdKkgcIqWQlysrzQ1T33bTveKQeU8
TKfjQ6FqhLNkt1qkSWGVw7G41EBt8xaUJvm+p5GDxqGRNIWNwwRvQJdvHkH11lJeLHqJi5Gk
bm7ZxiV5xQBv+iEUptFW4oag8wdYAziuCksFLXXGVHAtwUNDaNLacRyCJ1pa6Ee/8ZRK4dA9
xpDb8HZrAuoOTAJiHlIv6/gw13lIjl2q5fznTmcg5iMuAxCUBpLFp3HMaLBK0vmpON/giKNE
XVu6Nki9rQGzeagz0SdQkPjGqtIEJ9HMwfL6VfXTErIAOUrd45c6M6bap9nKRl4laLvIOjom
5vGthor15ZGWOnOKi43B446gPtxQd4Zj9unrQu6WedqjVM9DGvOwo41gB1u3Ko9gbUekOoJ7
AohR6imO8Fwap1QjjbWqkdi9c0oEiMsMFYKpnof8keS01PHbuVqgF/BIE0U33Dhq4WnOwnAZ
AAAgAElEQVQeKhxC7MOAkXY1ItUVs1X1q05hdhhWJ1j1GGizw8RKjh9LS3Xt9dwWP9noaAGd
udjgJmILD63BaBMob2BdrbjqC1rqaR4WOvKQjRjYFlCUTM7NgRXssysIClGUdhXvVwdpgdqH
xaM7bsIj8nlFSyFJ/FKq925T4ZRwhAfZpSDVSh58jyW5EMThWo5LrZ3y8HyxbZT80Bst1RxP
NxDxUlAel6aoDNSzb3sMa55B5GCTdWQelV+Adq2iJw0lHC+VwaXddskiXlxFjjfxc4Cgr3i5
0V9UvpNG1j0cIOdqtu0ix5dVMCweBDh4T3mQHGxd13qyZmgFRkvmBzEWkUKm8bJnxhqlGDZI
WIrYQ0FGzNrDBCMdEST9bUfY3SfRbA+3h7H3KJPILrAO7j3dSfs7Iu0G6engIUp6nsLL+1UN
Evmho4l9i+hbYRFK6VD4eDCyfsAg5yr6V9KBWbvaBxaG6ljvlLNUmzoAeor3tQ7VYDWebe1e
rQwuNg5pWlqqcKjoWORh6HpK1ASHAmxUFi8nWFW2GaLzl7NRaj6Fw+vWF+0aWFa0C/BCLcVt
yxaSc/N7ipr6lpXsI81FC1az6SOzlLQUqCstBVJB66WScvBoxIAjDOd11KhDsgHwyubwOYbf
JxGH9zOE9c+hdLgJDmFlJLISYqM5S0rjYc8MFCqLGm3AIRlhCAaDQMqME9wbqhHPtfX8hODw
02ieKD5ac2JVz3KDXqxFs/foG+Gh4sNPGnW7zq+IlLZuW00H5tg4jOOHzpLfjW4yRQisgfoN
hLWQ0I1hPIdkE8LFksqyABswlM1DNj2HaxCjzxmHsaRs+ZOxOxog/SjVtHSu4rTkpNFl8FCb
wEdpdDGaq+HUjg3ksInLGVqfA7hcYZC67Q3rgniultCT1WVseJXsx5caD5f2r+Lz0HxAiUNu
tNQCcvlULaAJhBjhcwFoYFTqJEAlmrsoDj4R4gGk1rPGbWEpo/sZ4d7CcFhH2JzB7eEYHKaj
NAm0dKjpEJGEg43S6HNAFg1XNW6kDSZUsUHzHCVXail9ray0NEAvNNHhktJ1BpwvbjMrt80v
71qNw4twQDsyKt3CSUsdAthwqYHwzho+t88HWMf2G8f3967EgU1sqFQYPZ0UmgHMTaQd+2sI
jWwaLsbjrXiURCc4+LStH6bHoZa6IhU7KTE7WF36gmiuotGnBwO4F5sRF7DZsAjo+RoCB3dF
OozwhRoyuMg8HhwoObySrGs1O4ZXwMlVGH1ciXRKPzyWSEuFsWI+oxlvLkIsq2YjvnvD+rBZ
WtlETq3fa9CD1eWMaJ5lxLy+eiO+u3EfwerqcqO/rKqCDk6k8bTUm46vKA3B5l0Ig3cDRLr2
hkllR3PTxX3ds40L+959OIyM0vSvW76SnF9eXRY8tK50Z39pZdGq5tk9s2pOrK8qDW0rZ/R8
6GnqwGGyeN6Am7jUEGY0p72T9WxPJyMpHZTyWC6EkXDGR67sJzDQCsgvYZSJEjTSQfGTpzkO
tcwvKI0XnyjNLfhWPtZ7ww9TOFW5fhdcKltIonXL6zsjZevr2yiup/3bq3dAZE/5xvCh7Xt2
4qEN9XuPNPTU74/WrW+E7qrtDcELAZVXolyq5Wwebat7M8oI+rJYJcw41Ew05fZOpxjEnjzf
5pT2fOuHLId3Of/m8eEikTDFXsbkIoYZQbOTU7HmoIj2yxII0Z+RCi6QCyCc0YfZzzeI2p2d
Si7F7roKMWb4ig/fxUnUaRbSy1OKbfwkA1SXiDg3gNuujVi51KtMU6hkJnJ6OViqEpc4xPm0
qAu9FLSMUpbmqPUslBigLUr/ELQU3OImcqmeiGZZeqe09En1Qe3JR7UKQLQUo7SrmNXhrb71
w+ieBTJSL8qjdyNcfhTMQx6kIc48FfGAOGvhkqiQ7Ig6eoKHDbKWLFLINEKIFSESQUYdUI/p
UBmy8fymbKaIQihbqi2mGofpRmmcfsjHmVxZIaIj5ZEacuYQvYcQZUdqFFqrMKCmkkIqKI6f
SEuF9s5TgTwh1oqS71TpUd6UoUCJ7hVxnkc8Dj3rh3o0gBoOasgIfFKxPVKfX6+Gi5a49W5k
OWVAjynJDx1xhI0YFRTsD7m4qNV70OJ/8qFn5WHNw/Q6vhpZSs1FZx3ccna8u2jeEpbKiAzJ
zpmhEkHU3o8DWkuxOjk2sUsZ3vXDuVZuWi1Vg955xWo7WAXGWiNizB5aP0wil6oRroe3VMIs
pRtUQHOLdSSpvndbW6FmO1rbU3IJOBoJ9mc8JOIcNT9MIpdKrZnn39UAmjqrrBi3PBImQS8u
Nd71w7kYg6/YNE5pS6YiGIsuV0ihWwiyK6kjHppvqAhKemc6k2C2NZmbbOYSX4A1gMU8TEdL
ZcpCaypIW4leZtJnMlJJRuRPa964+B7YK+Qu9tKYJup5GKkzrPFhceETTVjlGYfe9EOX3FwJ
iaLroTQlQ2qbN6UDDT3bjcihHUxCaWZCaP36Nmg52n00PFy1F+DUhkP7uZ9T2qUcsKyJHmip
Mn5GGlrRbAjCkUD4SCtGjnTS7o2kh7ZjB7y7wzTrjf692xmNPKKthiC4VaJlkQpa6uSHNi3l
RXUvKytpOl5Ssou1kI3K0rKnzLp/OFccritd1hZdVrIsAOcCLgMknqSmpzSxMg0blJe/ndf0
ztR7h6fcfuW6nLYlUycOT7nrud+Ei6P3DeU9VPv2lB99dNd3apjoHQpjJGx2YAh6DTDbSYKT
lhsOHU00mxf2hsqDfSuZHsh6rKN3BQyu2LZv+Mnw+dXnKyLrmuBybfrVONDcInkLnTgU8MUT
Xzw4M/xi13O7zy3+/Il/hHnnnx78/qswKzrp4y0fP1EIL4Y/aALoKSzbAYPzTy7oLSUHa+G1
+Y8mVsa20yTG82aIb26j0WVl5QuYvmagWVnMvrz1ZHi4uKzqqbP74UQbDKZ1Zkel43uJQavl
UoTLj72560b8j8DAvHOPHdhSRN5r7T04+dcw27y3v+fXj09rXBL4aD8jg4e5YPrrChPqYbhm
aBNTOmLLAG3zjqOltmTK2hUtadnYCGyUwrkVLctppLK0c+iRIw2bPm6CE01wsdaTTCM+vdBS
LeN/cd1f75tofhg489UrOdcHSvBA70MFrIWzomy4TpmTNyOf45DCYSbHkUNsoh3GgZrLCxua
mxJpulrlTtQPOamOvHE0jJWtA0ex943W8LnN3aWdhxYeXzFQ2hHaf35jz7Zd9JO2REqdAN71
Q20RxsuLuuZMpL9rjfz20JyLDy6DY8fn9N/yKkyL3v/+6ouP3xPqg4+4IfgwVzEOM63tMInW
fLLhcEMgPmc9D5OcM3OopKwCT5aULRwoY+TmUil7K1t5vrizubRkY3RdSckK47iRfh+Zfx2f
ksuPX5k801hy/rnfnVt8+c654XkfLr7wvVdJUWTSvwfe/7tC8lrwg/1sGh3mXLIBqfEuHay9
VJNIS611fPe1Jxo6eroD8XRjp3m6vT2MLUfbO093RtqNSEtLGPtb2ltJlZf9Oa8YHmOyW54K
cPm63C1vT/3JYH7BhT+5q/aXUydd+c6MH72c/7Xpv3f21ilz3i+4g3zcxJpzInykc6C8PUy7
9v5mNZa2Hk6IQGjpFu5x9S0JyjJSUIvvCy0mWuHBlxHSeyrYtjbJaEh0RyNGq9rw8M5ow16Y
dbjNPLSv41JDQ8PuUH1Hq1nVif1hHoW3agPprqrqpP1VO3biyeUbDOoUDsQ3i1s0x+mHVOpL
2keICF1CHn/I5Rmh/CJ6kkvTWxMtHKppKA+KFF53XEMtptRQgumHam+ukAsIU/4JP1oSkVvF
aChxlKLtqWDh0K6yPcUcGnuMg6SXEK1yDZh6w6GlInEDinAH5U0okSo1mojdXNyWUXlAjSe5
5qcjxyb0uKKliTKNbqJ6VDmfKv1UHmJpVSdF6/jbWqVbeJiHWmeXzl3CMMP+eqV0LEwaRDkP
SBGNgPK7jY+sauUsOD4kkUu13UMaSNSs1Eiz/dpSNFCmtOZhWlpq4ZBr3PKsU5CGJoJSsQmr
/kblQSctfap96DZnOC2l1F23iNPg7fHrYe45Ya0h+sjT+qFTCdStdY4StBz0Yp5H6lYrtDTg
WJ8oGWJOR7ICagdEtrxL0LIBybTo5jFgFb81mH4eypRzXXtPi1mQeNdDXyf6RCV5PNF+41qV
BEDbFyPVPFQ4xJiCtR6rGZb4dBA6B+fS6RLK0Fb9WH4IFpKsrC0LjzKHKvlRW4NS9uUrciZ4
w6E2Y7jVNhFn6YkAjdPxOQ7tDpE9pqevJQOo1jqbTbUq6lZIeu1J0lKkhW4j3RI5UgxKR5q4
BioPWicO0WqLMtxT6nAJsi8mfkkGr4TFhwcdfwYkzmaMaZgruUwFEKdbcIuwB23BXxmcllJ/
/jRpIBnK3BIq/fCA2jMDrwjzGlFrE07HbWVOd16M/4JMgAKwUyuWuTWMnmxtCIWGttnHZqKv
ak9yQKLtcOD6J4GLP+RZOXR0fBp4Pn/KlKn5U/OnjOSPAft0gLial6tsbclbKGkp0l9Mkc84
QGSdL2qVr2uWn8czz4tLmfCUuJ//bbEXQss0QA4uW+Z1J4NXWFYSFoQxHQ4Zat5YVuwty+Ip
xcWeki4rni+LteZhhucgpTadSDsPPUjxFhT6qABYdhq9h4ELg/7/Ccp/+V1d5kDV9oj0tJTP
YyIeQvHiPxGI/UJ5i30tDBNHQeKP+96J+1Ye/BOl14rSD4WIa7nn+nvF7jbTl8V3Igl+Gn7I
9STPpJRJsIiapibvOCWcUzqSmHupysfYnwo87CHV3WJ3VdzOO6pFqKWWeuhSZHybUck02QGt
a40s1le8DmGZUgoTUOccUTFLM/LdZ4yhEcHoY5tYwKTNVIPTDbKHQw2jjH0Z/0Chr/aB7/g0
/kDlPPo4UQ5Y6je8ib+YeyOBNPMwxpiQNjPwiUM6kljQniAmzwzENrHB7zyEEcQv9QlXcR4K
YfxLR0sTuUUayD4t9XsOaSoAIdNQP1J0RmUaN+CZp4xt4rf0dDsVYwEc6xZZg0ziUFpW/YxS
9BtFaUSQQVqK1C+38B1zzz/44IfpMuI0camX9QTrCXCc2ZVFyDgOfUxFxwmPWYPM8UOu1sJS
omKpeH0o2zjkfT36mHsSEI9yWgp8Fdh78VbUiOzBCM8KcklMy4KcH9b5EWvGYB6ONo6wBm5I
OrCIUZq+232dHmSd6ZxFyNg8xLMTjJnGr2/2MQvHgpZmJG4iB4a4C3lzlnblPpDSCOV8gr+N
CcfPDD9knTWUe8OMreOfu6bmIaSzl/rIC6l5F4+AW+tnlMqz87KMxQzNQ77L5Rd5ubn5AT/E
X5+dl0XwFXMvDcDWP8nN+w6Ad2KaTXupDRmjpZS+mZuXc4MfUdZxpnPWAJh+mPyuTxyeyc3N
8cEsOOgzLLMJmZJpGCou5+TlPODrkTGahxmhpXxBZjgnJ3eNj8U4GAs7TWZi0Apg7CIvZ3yT
5QniBRgOj2dZasPU89D9kWR54TM5+UHv4WF5RmOCwzTz0EsPqwVDeD13guF4PHnG+rlrgx+6
7Z1KAOnhdizvG5gQlcb9QWV19Hm+xYjAS/xSr3AmZ5L3gq014OxbMdL6ROmdcdr52naNsZxZ
5b2LOQ/otNrPJzZWrH1PGayuhXlIfRw1Gh2/2HvBwk36qs9DWZUQCcuzvDmExcHfJAbC/Aq7
3j+lJkJUslBEf3Wkkxd4DhEpvF71eSinyEszPUJBboHXpLNEsWM0D5PfVT5R/6gcsuYVzZpV
xP7n8Tf+S//x3zL87LPzRKJZKiLtrHl2Kn5D/WaQL7dIjsE8TG9rA+HnHeNDEb/ApPy2rE0Q
Lo7RTmBYM1406NjwQy9rT3wvN1KwSaOKMRtDXVGcFKg9Ip2pnaAoMnXsx8/yPPTgI8zqMR0g
3lYPMYiKv+3c6hIPytHZ4eedbfUpvX6odpRY+wC0Lx/qXQN2g9He30ItD1RqO7cq12KQe9fG
Ssf34CMct8ODKodF29/LO+gm2ji86vwQ3aLsykfjf6e3z6gEYMU2uTb4od4lmwJZcR567r79
MSNhzOYhpqal4h0SdyMkVCqhmvEGt1gGA+DY95Rt8Lwff7TgoL2Klo6BXJo2JrsapfY2Lovt
x1bLZQBDwg9neBtw7HvKNowIh3YwFcUaiPVb/oNkHk6KSx2txrGdh8nvusYRdluqT8Bg7Gmv
oheAokMRc+x7yjZ4iqmgxE0ZvYvBwJ6gwI885oTQgR2Msw+DCKoqiMylkhq5WVgNSuH+3bwJ
2iWO0bFn5hqwlzriROmNsOapgHC4B7F/FAmpZBfPBjn95NtmALvrtsitwISqzbusvecX4XlD
BVyzTg64Zvgh5ZoAqsGHNNomODzymKhgmPAua8geHkouQkVUM3qxhg3KEEsdQbGDgX0L9Vfg
5SbVn45YX1ffXqqjmVGz1DhRI4YeRAOU9L+0kpBD5fuR1C3fzvC0EKPljds2RffM30fhQi3S
5pKNeHhFT3lbtLwkAN0lG1bh0NOK8Kg4wtcIP1SjFHFdYFtAytDDAUIP7jtYg6HIBnpp1amH
gUbnIHmjqHrT+eWHlxtwmeHw0JESo3te1+zAiRV7VpJt25ctomQOzxFx7ORSfu5a8pvx+/GH
1u+k8pCfaADMldRcRMz2ejwOZgmFgacRhlYYeHBnR5kBF2sZPTpd14TN5TtJZWt/ef8K6FqE
OEcNSmu3+hjMQw+6hdKWEJcy1AmqEW2D6C4Mr6KVK0pps0nrKEZXU7y4GeGNdcVFbXCxBs1t
xcsC0DW7yVz3bHFx31N0+Ck0nxJZqjNKxsJHOI1cauNQMPe+5RV8IySr03CARlajuWhwFzTg
IYQy4DF0YbAGaWXF6RYDr+zHoSdDzYFIXfUqUrm3vaW/AvoqMDJHMR47akRW28fBcxxh9nYo
0ByE4QWM5kTbCK43zm++EoiU4YX90YcBCKM0VU82kgurTh8JnqpcsXN4+al1m7qKembvb954
uiFS0li5wIiKOMLgPKMk6/zQEy2VTRy+G95eDX03APRVLtiJ59aXhweW7ykODj/8Rkkbpeux
f37ZcoMNzpLwodKSVVhXUr7h5PKesl19ZcvWG4dK1pd0XqlRBgJHLOhsg7eYe4LbR06T3jbE
DqQD7e37EE91mNCzrz8M/fuHg0APGtgRCgNEQmEaiYTDxAxFwpEQhgwaagcwe0MhOG6o8eCI
E3UN8EMreouM7ad21onoH9KmBshEFbwk0YKGPK9BUBLpjWnJsXjEsOfhmMmlRtJbsfOQEL4V
kQjZE+QRIfyDEIOYIuSvyRoqQoGIkJwEdRzeiIgYAmo/phKKHLvVr6pcGqsfgl4K1TqSjrqh
ouEqC5xIBMripCGmEHREhrwm+KGlH2pLi6KH6rvWHpTd0A6UaScD/byVzZjJpZ7i6vs4DSkx
/yTXx8pOA37O7NKoAcd3nQvVvxMsiq5tRC21jYVc6u/MLtuaD46pCDrWpZyujrg5DhObo+no
iBpxTfBDPUpVDCAdiVUHcZKtkIGhNI7tY0VT4PBakEvFux6lMvQFrzxTfOVikyP4rd7KzJKF
2qVhque0YZGjmIUb6jjf4pqw0xSqQUcY+4uIIAI8ogBjfxiiMpAA+wJhgwhVHslrxTUi0PeJ
ZUFhxlAHO9q4iol9eXXXLZTUpnjgswU1kRcfgbdmR54t2H++6B44PnXRldpzwWb4zfTNkaWP
DEyY8RRDZt/Knk5hhuqtCyjJJjFrpT1dK/qhxCGZUHnzFxOfaZ21dU3Btps/vOOFtoL62z/f
8l5g60DBnpu/uHfJvm3f2IXUPLirlUZajrIBfY5Jq72NHQg9R42Y2eakpVmdhzxvL/qhGkgT
zUm/DXwxp+PzRfeak95/7vPH95mzP3/u/bYDA/tx4oGmy09Ef8pS9peVLAh3lXBt42AQsa6s
xOgvLtsUy0bGbt3Cc9xEPpmmLP3+b8NDdw4/1JQ/d/KZ4OCDXTNv+GzL+4Gtxsmpf/G7W+c+
0P8jNkWjJ1aFYKD15C4Kx5mSUdpRbzRvOrXcsVRjxYKGMVnH935mF5mybOLWcN8DuHbN1HWT
3m67OGfqipmfb3m/7de9UzdO3L18/f7hO3kzzgcAI5Vlm1gLDTC3bdiLb2xsKQvGDsaxW7dI
7Yvh5IdI76WzjwW+uH/X4OT76LQPaz9f+Vc47bPNHwZ2D33fnHgsMMRayJOf2w9waHndGqQM
h6SnakF4W3nZ+pjJEBML+qrKpTKNkrxJQdXdn92zdt+tv5kzrWrif97xzN4bmv/ss0dfXvFQ
/U2VX/34Jy9s6f8+px5dNYjbwt2bgBzvhIFdpC5Qt4/06qM7OKDD5n1N6IdzhfcBkhcnbIo+
e6/xmwmhpdM2v730UXjtnqqu/KlTpqxZ+kh1dOnDxFzNUvcvm78c6kqXze/Y81L5zqGH15cE
z5dWlceMUuv8w7HQD7340ziEUs71efBOOLOfBwziES7J0INSAhCaLu2v3rMReqq2N4T3NNTv
M+srd0KkvnwHxM9DwWOvulwqPwqlpC1NGPJUMsRjTSJYEveY7a8BddKLENxQMXnZL0TEKCLy
qBmV79iuH/qIyS6CrREpdYvzHLXTqUFQxolCpWqINTaijl2xdGNHqeAYpdkFj+fMWCo7ShUJ
Ld8ESHAziQk6q9eK42bCWK5beLO16UrYExIdy9dEI8lum60XWgljWzKW9lIP/ND1pqXq6wNi
Y247NGLHBf1d09Ixmofp9cPEALpxzbFCpNneFpQq+1zMJQ3XpH6obReol+KVGU21PiYItf5P
ki+lY2in8eKLMSP9OPJZS7DXgK++f6nwEfYTO9EbFPJix2Ieeoox5AGH/oCx02evHT9v1sVz
RYjXzAF3U1kiNOAxmIdp9syId8NPzE6v8NIY2mmMpLdUDFr4RX19fXX19ur67fJNf4r/av5f
Xa2uO6A+4bVdvVhuDTOEJ/vVl0v5G6G//OH148ePv37816+Xb/pT/I/n/+PHq+sO+HrC63r1
4umuGys7jQfdAqG3o6OjN+QOcdc72AX5SgXsfi9qmebqruPb0TgzDrJdV10ulR+gjypwAyve
NqqwvfosjLQwFvZST2vAyhE26UpgjPIUG5g2BajF42tDLhVfkwUhj79vv5I+Yu0toeK8p6uv
H6YW2ZzBl/2AbGP21w/TyaVZFhmvgdiXdlUyD2OlH2Ys1pd/QDoW/jRe9nJns/ir7ued5bKv
FX+aLBY+NvPQSH4v2zi8Buw0WS57LPxpwMP6YZZgDGNBp9PxswnXjlyaJRgT/9LMxfryDfC/
+WFmyriKOKTXiJ0mewDZj8nOIb1vYpZAebJfQ+dbZKX0McAhXkWZZkx8MTJ7voX/4rNNS6Vv
YvL7Y6Ef/tempWNxNsJV1Q+pfZZsFuEq2mkoHQt+6GX9MIuFXyP7LbIHY7PfYgQx2VPYuGMP
klNFyBvxe4jGzp/GSHoLZBQlR4VGCu4Py1GaSRQm5gWp9z1lf5QKHGZGBYaEL8obKwXHhzJH
SmotJ9nfxdgDpHELUdZD+khmq2i0fBmVl5jND0ffTEz4IjNOjkNg89C58c49jYcSrZSJXZBZ
jm9tr7LxialXZsp1cnT6iNpLonFOmXGLhtY1WVC8rykoD1q5XkyTrTF7BWpvV0V72yDPNoV+
CGWqbMt91qq6HmnqM7ZRjg4E2zHR9rV1DNPMnQcMzipZW3f5hVS0tFSVraMDol60t4+hVp/W
ndiFev2cjhkZkw93DWC0NMsm79T8sDK7hVN+huVbjY0NDUecr0b9Z785/tSVuKvyT781NFov
9rcueQvhJVmmTKgycOSVpIiEa3bRjQ3OF8t6ybgT82aNAGbO8wpFs4pTtPBgkeeMRggl47Ku
vqQAn4emjgzG0TA/wTrGUyPRl9EK/Zow0x1gT3g7J7WZN3kTAcC19LgyrCqIbRfxSYQjEcbl
g3KLChmHihUlsBkvEI8D6aTjcIXhW3qM1Bm4us+4ViKBncfdc/XFgXGIiYK8FJZ039hdDYKH
gi1OqVQ64C+lcR2UzheGuHjSgPaQUi5faouMFN1Q+VApvmTHkXAP+MlvjEtStiNARVydqZg/
KYZehgAc35z7fdBtX3OK2iRroSNHt2uoqURsx2WEcsQMBTH6JH7idsiAinGSzgqTtoXxTUSJ
QofnmC4vc5CQF9rvkp7FDsmUZbu30N59BETvs3LmiDSkU9kSbwYb6VCgeNHhGBEcMQpa/qUu
m7riIBkOUdPYDdAqJ75oihgtiKehUoQxkmKzTD8S77okoPfNgFQNB54SORNJyqDfOBdEWUMt
ACMmb2iSFsoC+GDYbj6Kjg6TVPklnKe3yNnB4iFjHFzVXEb9QDp0i60/sEq9E/igzdKW1DjC
5NamJC3kgZkINZCEw9GfAIRE7AkaIeIsCsRlxkukk/0IM24XkryHR6DMTPt4hY2wEeEZ9wKh
oeEfiZbyOFC8Frvb3gl2mAghhIgZkiyL30vSRvcWIj3eNng/KT/z0uSNx/NqLhY8wptIL6wx
Z/O7g3mrl740LUB+XVATefLFn/CWwdsBPnIzAzCwYOrAqwVtcHDGo+GhmbPv5xcHF8HZJtaW
yDP3nVk2czM5W/AY3fbabZ18fPb9Az5rJMks2Tw8VvvxzeQnH3z70dmXbmtd+3BugJPsizde
uYW3MFqw75lb/3HN4IS1N0Vz774rwEfUv9ead2eqgXQ4p6DlurUToz+rzgu+PW36/XyeDN0C
b+5nJZElFcdufWayOX32d4y50365mT8wfFv/7clyc20hG9S/e+JX3/j4B//PptDtg7dcvon8
6xY+BszxeQE+5qN3RCeE3vvB8zV9f3blL8I/C3Kk/39Pf3R/phYIyOA3wltXm3f17CTP78sP
HfsWzzf652aBwSf7Pwf/tWLoL774Fjy/5a79H00Wc+T5ux5MRgSS4fDD70/4m/s5daoAAAND
SURBVP947udgfvPK9z/9b7P+/nERBubl/0u0YeAvo39GP/3B38+c+ZUv/or+KsBp3if//f+t
NTLTQDYi/wj/adrdXws3T//rfb9PL9/Mu878cc8f8PlGf2X8SwC/+5//bebfLs6hV74nKP4n
X0lqKklGSy9/96bp/xR4gUS/eeV7H143taCGX4VffYNPNTT/MnoD+fS//9/5+Q9fvgV+FeSk
bPj/fD6YIRQCDP4h/Pzh0oX91xf8bN+f0sG/FBn/82vfEyaKfzL+1SDf/fDbU2fWFuDgZDFw
Pvo/gj5bCMNf/6t/yzNegMiNg9/7/E56Jci1oGjOD4N8UET/cvgG/OzvfmbQHV/cQp8P8rET
ycvPmLqHg39I/zlID3/0Lfov+6/Dy6KF8N4PnxDs+FfBfwmSGz/7H/S8wVr4PcEqfvnjO33y
Q4p/+/j//Cr8k2F+c/Cbl74S+vkW3ntv/9F/TOb3on/T8fv46f/410lnv/r5t9goFSH9fv4H
GWofq/GVP6S/u+nd3/v4j/r++omfr/7VLYL7fzGuiccdxF8t4ji88nsdf1/7bbzyfR7Rdegr
F38/mVScVLf45y1nv0m3GpGbon+8+fmvfxV5vIaXn7v8F/ye+bf3fxc++7srX/vjRZdvwdcD
Qnf69+9lSmpDOjjJHPrjv35g+Prxuc+987WvTeIjkQx9hQhB4Ld/8LqBt5s//9o3YCYdmszV
to9vMh8ykuSWbB5in2G20R7ANqwLREtY7wGJ9AK2ikAGJ2tb6XDYOLkQzE7aQ8SOxv94AjMl
0lCzDbFrgQEnVw4Hcc++MA8eQRl1E4c5DW9kJbZCT1kbdgBLyS8FoScZqUmhWygtV8pFUkAi
YElqOha6Fgj7fxHI1DRU6xRCB5WBMEWr3/qWnUQvVyixWARBSwJJ5VIRO1Pq+bwDPymYOrMg
CNg/o6Bg5hap+6tAHfRkwYyZ017//QyK3iJWMh+T4g3NwpkzZz7yx4vJr2fOmHmviAEKyjaD
0cIZM2asSaFhJMMh0UZjtUdsiFs02WgJc+tmpxD6lf2CQn8Du/c/N2dQt9A6qCF0QWqyMo8c
/QMk3Q0N2/cBKlOKCGbC7zV0somSLLP/H+wJ8u/w8RHAAAAAAElFTkSuQmCC</binary>
  <binary id="img_14_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAkQAAAEMBAMAAADXLbT1AAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_15_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAkQAAAGtBAMAAAAFbXa+AAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_16_novyjjrazmer_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAdAAAACmBAMAAACYf8NbAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_17_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAZQAAAMMBAMAAACGQUyUAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_20_novyjjrazmer.png" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAkQAAACpBAMAAAA4iz8cAAAAMFBMVEUAAAAREREiIiIzMzNE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</binary>
  <binary id="img_21.png_0" content-type="image/png">iVBORw0KGgoAAAANSUhEUgAAAGsAAAA8BAMAAACTGllwAAAAMFBMVEUAAAAREREiIiIzMzNE
RERVVVVmZmZ3d3eIiIiZmZmqqqq7u7vMzMzd3d3u7u7///97EBgKAAAAB3RJTUUH4gYXBTQ1
PoR/kAAAAdpJREFUeJzNlzFLw0AUx1OKOtrFzUi3QtGv0A8gKHVysx9CC07xE1iROhY6uRa6
OkjBtbbEyS1QKLEqvVIMoca+85IQc03vmrvDoW+4JI/88n/v8t4L0bCKTbT1woYlpIBBvqSk
NlPD3lXVVHJTV1PC/j03T8tlLB5m89XMlsN6ZmB5rc/BoI1GelqwDLUL5LJCScGgiG+bnkZs
TwYjhFyMIWYfxw5NwLZDbGqQ5cd36BIYmIwtFgiyyntnKzFTk9t9LD1LIG+IYYuzZNAtCaot
9NslEg2S7rePqCrk+u0k6i85NbsioRYVENmRljBGq71YEmpxbvXoNB2jZgmckgWBEEbNkvku
UXM2kOT37btClhE3yMEWsyXuTN/ttTgY7D+xMOj4kwaMaw7m1sLjF1MzKG0GBm0rPBnyu5eB
OTl9lRoPgypWUYNicHuH1GHGmjAHFwubH1Bq4thfO8vlNrwigWIkm5vZI0v5bFHNr9+giLnY
vX9XM+EcZBGUd/jY7Cj4WD0kA2w/Yjee+UvYZ8YH7Dcr4a9XsBM/itM402xSraGj11Rsyea1
Am7El6LYrH+ODHnMHZvPN/LYCDuHPWkMutjbpHZJVI3kVaAuxTDokLdJbeTa/QewsV8x4b2Y
Fs/0xAAAAABJRU5ErkJggg==</binary>
  <binary id="cover.jpg" content-type="image/jpeg">/9j/4QCwRXhpZgAASUkqAAgAAAAFABIBAwABAAAAAQAAADEBAgAcAAAASgAAADIBAgAUAAAA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</binary>
</FictionBook>